{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f85d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffdb8c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预定义的变量\n",
    "save_path = 'D:\\\\sorf_models\\\\model\\\\tests\\\\model_saves' # 储存模型结果的文件夹，以\\\\结尾\n",
    "\n",
    "# 模型超参数\n",
    "window_size = 51  # 每次输入的序列长度，为奇数,且至少为5\n",
    "lr_00 = lr = 0.8\n",
    "momentum = 0.8\n",
    "dropout = 0\n",
    "batch_size = 32\n",
    "num_layers = 2  # LSTM层数\n",
    "hidden_dim = 128  # LSTM隐藏层大小\n",
    "proj_size = 64  # LSTM映射层大小\n",
    "lr_epoch_decay = 0.997  # 每个epoch的lr衰减\n",
    "inspect_loss_decay = 0.5  # 每当loss下降为原来的inspect_loss_decay，便更新一次lr\n",
    "lr_adapt_decay = 0.8  # 更新lr为原来的lr_adapt_decay\n",
    "inspect_num = 3  # 以inspect_num个batch为单位判定模型收敛程度，要么1要么2\n",
    "weight_scale=0.02\n",
    "loss_ratio=0.5\n",
    "TIS_max_num=40\n",
    "\n",
    "j = 'all_10'\n",
    "\n",
    "# writer\n",
    "run_header=\"train_2_15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6f4e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取fasta\n",
    "def read_fasta(input): #用def定义函数read_fasta()，并向函数传递参数用变量input接收\n",
    "    with open(input,'r') as f: # 打开文件\n",
    "        fasta = {} # 定义一个空的字典\n",
    "        for line in f:\n",
    "            line = line.strip() # 去除末尾换行符\n",
    "            if line[0] == '>':\n",
    "                header = line[1:]\n",
    "            else:\n",
    "                sequence = line\n",
    "                fasta[header] = fasta.get(header,'') + sequence\n",
    "    return fasta\n",
    "fa=read_fasta('gencode.v38.annotation.gff3_gffreadto_simple_plane_new.fa')\n",
    "def find_TIS(transcript,prints=False):\n",
    "    seq=fa[transcript]\n",
    "    pattern=re.compile(r'(?=(ATG|TTG|CTG|GTG|AAG|ACG|AGG|ATA|ATT|ATC))')\n",
    "    it=re.finditer(pattern,seq)\n",
    "    TIS=[(i.group(1),i.span()[0]) for i in it]\n",
    "    if prints==True:\n",
    "        index=transcripts.index(transcript)\n",
    "        vector=vectors[index]\n",
    "        print('transcript:',transcript)\n",
    "        print('length:',len(vector))\n",
    "        print('TPM:',TPMs[index])\n",
    "        print('normalized sum read count:',sum(vector))\n",
    "        print('raw peak read count:',np.max(raw_vectors[index]))\n",
    "        print('max peak at position',np.argmax(vector))\n",
    "    return TIS[0:TIS_max_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaef863a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1578\n",
      "mRNA_start_NF count: 9\n",
      "[503, 747, 1305, 1391, 1450, 1472, 1473, 1491, 1496]\n",
      "['ENST00000293860.6', 'ENST00000329099.4', 'ENST00000399815.2', 'ENST00000486442.6', 'ENST00000548861.2', 'ENST00000569622.5', 'ENST00000570054.3', 'ENST00000594769.5', 'ENST00000597961.1']\n",
      "1569\n"
     ]
    }
   ],
   "source": [
    "# 读取和处理数据：\n",
    "with open('final_transcripts_all5.pkl','rb') as file:\n",
    "    transcripts=pickle.load(file)\n",
    "with open('final_vectors_all5.pkl','rb') as file:\n",
    "    vectors=pickle.load(file)\n",
    "with open('final_raw_vectors_all5.pkl','rb') as file:\n",
    "    raw_vectors=pickle.load(file)\n",
    "with open('final_TPMs_all5.pkl','rb') as file:\n",
    "    TPMs=pickle.load(file)\n",
    "print(len(TPMs))\n",
    "meta=pd.read_csv('gencode_transcript_meta_new.txt',sep='\\t',header=None)\n",
    "meta.columns=['ID','Parent','transcript_id','gene_id','gene_type','gene_name','transcript_type','transcript_name','ccdsid','mRNA_start_NF','mRNA_end_NF','cds_start_NF','cds_end_NF']\n",
    "used_meta=pd.DataFrame(data=transcripts,columns=['ID']).merge(meta,on='ID',how='left')\n",
    "print('mRNA_start_NF count:',np.sum(~(used_meta['mRNA_start_NF'].values.astype('<U32')=='nan')))\n",
    "remove=[i for i in range(len(transcripts)) if used_meta['mRNA_start_NF'].values[i]=='mRNA_start_NF']\n",
    "print(remove)\n",
    "print([transcripts[i] for i in remove])\n",
    "transcripts=[transcripts[i] for i in range(len(transcripts)) if i not in remove]\n",
    "vectors=[vectors[i] for i in range(len(vectors)) if i not in remove]\n",
    "raw_vectors=[raw_vectors[i] for i in range(len(raw_vectors)) if i not in remove]\n",
    "TPMs=[TPMs[i] for i in range(len(TPMs)) if i not in remove]\n",
    "print(len(TPMs))\n",
    "\n",
    "padding_size = int(window_size / 2)\n",
    "padded_seq_list=[\"P\"*padding_size+fa[i]+\"P\"*padding_size for i in transcripts]\n",
    "dict = {'P': np.array([1, 0, 0, 0, 0]),\n",
    "        'A': np.array([0, 1, 0, 0, 0]),\n",
    "        'G': np.array([0, 0, 1, 0, 0]),\n",
    "        'C': np.array([0, 0, 0, 1, 0]),\n",
    "        'T': np.array([0, 0, 0, 0, 1])\n",
    "        }\n",
    "\n",
    "def is_validate(k,sig_ratio_cutoff=2):\n",
    "    if vectors[iii][k-padding_size]==0:\n",
    "        return 0\n",
    "    else:\n",
    "        background_pos=[i for i in set(range(k-3,k+4))-set(pos3) if i>=padding_size and i<=len(vectors[iii])+padding_size-1]\n",
    "        if len(background_pos)==0:\n",
    "            print('Error: background_pos len=0 for iii='+str(iii)+' and position='+str(k-padding_size))\n",
    "        background_signal=np.mean(vectors[iii][[i-padding_size for i in background_pos]])\n",
    "        if background_signal==0:\n",
    "            return 1\n",
    "        else:\n",
    "            signal_ratio=vectors[iii][k-padding_size]/background_signal\n",
    "            if signal_ratio>=sig_ratio_cutoff:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "    \n",
    "def form_target(k,left_diff,right_diff):\n",
    "    if left_diff>=3:\n",
    "        left_value=vectors[iii][k-padding_size-1]\n",
    "    elif left_diff==1:\n",
    "        left_value=0\n",
    "    elif left_diff==0 and k==padding_size:\n",
    "        left_value=0\n",
    "    elif left_diff==0 and k>padding_size:\n",
    "        left_value=vectors[iii][k-padding_size-1]\n",
    "    else:\n",
    "        left_value=0.5*vectors[iii][k-padding_size-1]\n",
    "    if right_diff>=3 or right_diff==0:\n",
    "        right_value=vectors[iii][k-padding_size+1]\n",
    "    elif right_diff==1:\n",
    "        right_value=0\n",
    "    else:\n",
    "        right_value=0.5*vectors[iii][k-padding_size+1]\n",
    "    return left_value+vectors[iii][k-padding_size]+right_value\n",
    "\n",
    "def ifleftequalzero(j):\n",
    "    if j==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return pos[j]-pos[j-1]\n",
    "\n",
    "def ifrightequalmax(j):\n",
    "    if j==(len(pos)-1):\n",
    "        return 0\n",
    "    else:\n",
    "        return pos[j+1]-pos[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "195c7a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_index(inspect_index):\n",
    "    print('test:',inspect_index)\n",
    "    print(transcripts[inspect_index])\n",
    "    print('TPM:',TPMs[inspect_index])\n",
    "    print('sum normalized counts:',sum(vectors[inspect_index]))\n",
    "    np.savetxt('final_true_vs_predicts\\\\inspect.txt',vectors[inspect_index],header=transcripts[inspect_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93744c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #测试：\n",
    "# iii=1326\n",
    "# ii=padded_seq_list[iii]\n",
    "# print(fa[transcripts[1326]])\n",
    "# pattern=re.compile(r'(?=(ATG|TTG|CTG|GTG|AAG|ACG|AGG|ATA|ATT|ATC))')\n",
    "# it=re.finditer(pattern,ii)\n",
    "# pos3=[i.span()[0] for i in it][0:53]\n",
    "# pos2=pos3[0:51]\n",
    "# pos=pos2[0:50]\n",
    "# if len(pos2)==len(pos):\n",
    "#     pos2=pos2+[pos2[len(pos2)-1]+20]\n",
    "# inspect_index(iii)\n",
    "# print(list(zip(find_TIS(transcripts[iii]),[is_validate(pos[j]) for j in range(len(pos))])))\n",
    "# print(torch.tensor([form_target(pos[j],ifleftequalzero(j),ifrightequalmax(j))*is_validate(pos[j]) for j in range(len(pos))]))\n",
    "# validate_pos=[i for i in pos if is_validate(i)==1]\n",
    "# all_pos_count_middle=set([i-padding_size for i in validate_pos])\n",
    "# all_pos_count_left=set([max(i-padding_size-1,0) for i in validate_pos])\n",
    "# all_pos_count_right=set([i-padding_size+1 for i in validate_pos])\n",
    "# all_pos_count=all_pos_count_middle.union(all_pos_count_left,all_pos_count_right)\n",
    "# print(all_pos_count)\n",
    "# print(sum([raw_vectors[iii][i] for i in all_pos_count]))\n",
    "# print(torch.tensor([1-math.e**(-weight_scale*sum([raw_vectors[iii][i] for i in all_pos_count]))]*len(pos)))\n",
    "# pos1=[padding_size]+pos\n",
    "# print(torch.stack([torch.tensor([pos1[i+1]-pos1[i] for i in range(len(pos1)-1)]),torch.tensor([pos2[i+1]-pos2[i] for i in range(len(pos2)-1)])],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "510b8700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of seq data is:  1563\n",
      "tensor([[[1, 0, 0, 0, 0],\n",
      "         [1, 0, 0, 0, 0],\n",
      "         [1, 0, 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 1, 0, 0],\n",
      "         [0, 0, 1, 0, 0],\n",
      "         [0, 0, 1, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0, 0, 0],\n",
      "         [1, 0, 0, 0, 0],\n",
      "         [1, 0, 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0, 0, 1],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 0, 1]],\n",
      "\n",
      "        [[1, 0, 0, 0, 0],\n",
      "         [1, 0, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 0, 1],\n",
      "         [0, 1, 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0, 0, 0, 0, 1],\n",
      "         [0, 0, 1, 0, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         ...,\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 0, 1],\n",
      "         [0, 1, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 1, 0, 0],\n",
      "         [0, 0, 1, 0, 0],\n",
      "         [0, 1, 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 0, 1],\n",
      "         [0, 0, 1, 0, 0]],\n",
      "\n",
      "        [[0, 1, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 1, 0, 0, 0],\n",
      "         [0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0]]])\n",
      "torch.Size([40, 51, 5])\n",
      "[('GTG', 3, tensor(0., dtype=torch.float64), tensor(3), tensor(13)), ('AGG', 16, tensor(0., dtype=torch.float64), tensor(13), tensor(7)), ('AGG', 23, tensor(0., dtype=torch.float64), tensor(7), tensor(7)), ('ACG', 30, tensor(0.0441, dtype=torch.float64), tensor(7), tensor(3)), ('CTG', 33, tensor(0.9001, dtype=torch.float64), tensor(3), tensor(7)), ('CTG', 40, tensor(0., dtype=torch.float64), tensor(7), tensor(12)), ('CTG', 52, tensor(0.0078, dtype=torch.float64), tensor(12), tensor(13)), ('CTG', 65, tensor(0., dtype=torch.float64), tensor(13), tensor(17)), ('CTG', 82, tensor(0.0045, dtype=torch.float64), tensor(17), tensor(15)), ('ATC', 97, tensor(0., dtype=torch.float64), tensor(15), tensor(8)), ('AAG', 105, tensor(0., dtype=torch.float64), tensor(8), tensor(1)), ('AGG', 106, tensor(0., dtype=torch.float64), tensor(1), tensor(5)), ('ATT', 111, tensor(0.0045, dtype=torch.float64), tensor(5), tensor(5)), ('CTG', 116, tensor(0.0661, dtype=torch.float64), tensor(5), tensor(6)), ('ATT', 122, tensor(0., dtype=torch.float64), tensor(6), tensor(3)), ('CTG', 125, tensor(0., dtype=torch.float64), tensor(3), tensor(7)), ('TTG', 132, tensor(0.0428, dtype=torch.float64), tensor(7), tensor(19)), ('ACG', 151, tensor(0., dtype=torch.float64), tensor(19), tensor(5)), ('ACG', 156, tensor(0., dtype=torch.float64), tensor(5), tensor(3)), ('ATG', 159, tensor(0.2183, dtype=torch.float64), tensor(3), tensor(17)), ('CTG', 176, tensor(0., dtype=torch.float64), tensor(17), tensor(3)), ('CTG', 179, tensor(0., dtype=torch.float64), tensor(3), tensor(4)), ('AGG', 183, tensor(0., dtype=torch.float64), tensor(4), tensor(4)), ('CTG', 187, tensor(0., dtype=torch.float64), tensor(4), tensor(5)), ('CTG', 192, tensor(0., dtype=torch.float64), tensor(5), tensor(15)), ('CTG', 207, tensor(0., dtype=torch.float64), tensor(15), tensor(4)), ('CTG', 211, tensor(0., dtype=torch.float64), tensor(4), tensor(2)), ('GTG', 213, tensor(0.0152, dtype=torch.float64), tensor(2), tensor(6)), ('GTG', 219, tensor(0., dtype=torch.float64), tensor(6), tensor(8)), ('ATC', 227, tensor(0., dtype=torch.float64), tensor(8), tensor(3)), ('CTG', 230, tensor(0., dtype=torch.float64), tensor(3), tensor(11)), ('AAG', 241, tensor(0., dtype=torch.float64), tensor(11), tensor(10)), ('TTG', 251, tensor(0., dtype=torch.float64), tensor(10), tensor(7)), ('TTG', 258, tensor(0., dtype=torch.float64), tensor(7), tensor(5)), ('AGG', 263, tensor(0., dtype=torch.float64), tensor(5), tensor(7)), ('AAG', 270, tensor(0., dtype=torch.float64), tensor(7), tensor(1)), ('AGG', 271, tensor(0., dtype=torch.float64), tensor(1), tensor(6)), ('AAG', 277, tensor(0., dtype=torch.float64), tensor(6), tensor(12)), ('AAG', 289, tensor(0., dtype=torch.float64), tensor(12), tensor(5)), ('TTG', 294, tensor(0.0155, dtype=torch.float64), tensor(5), tensor(9))]\n",
      "torch.Size([40])\n",
      "weight: tensor([0.9976, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976,\n",
      "        0.9976], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq = []\n",
    "target=[]\n",
    "weight=[]\n",
    "dis=[]\n",
    "for iii in range(len(padded_seq_list)):\n",
    "    ii=padded_seq_list[iii]\n",
    "    pattern=re.compile(r'(?=(ATG|TTG|CTG|GTG|AAG|ACG|AGG|ATA|ATT|ATC))')\n",
    "    it=re.finditer(pattern,ii)\n",
    "    pos3=[i.span()[0] for i in it][0:(TIS_max_num+3)]\n",
    "    pos2=pos3[0:(TIS_max_num+1)]\n",
    "    pos=pos2[0:TIS_max_num]\n",
    "    if len(pos2)==len(pos):\n",
    "        pos2=pos2+[pos2[len(pos2)-1]+20]\n",
    "    seq.append(torch.stack([torch.tensor([dict[j] for j in list(ii[(p-padding_size):(p+padding_size+1)])], dtype=torch.long) for p in pos]))    \n",
    "    target.append(torch.tensor([form_target(pos[j],ifleftequalzero(j),ifrightequalmax(j))*is_validate(pos[j]) for j in range(len(pos))]))\n",
    "    validate_pos=[i for i in pos if is_validate(i)==1]\n",
    "    all_pos_count_middle=set([i-padding_size for i in validate_pos])\n",
    "    all_pos_count_left=set([max(i-padding_size-1,0) for i in validate_pos])\n",
    "    all_pos_count_right=set([i-padding_size+1 for i in validate_pos])\n",
    "    all_pos_count=all_pos_count_middle.union(all_pos_count_left,all_pos_count_right)\n",
    "    weight.append(torch.tensor([1-math.e**(-weight_scale*sum([raw_vectors[iii][i] for i in all_pos_count]))]*len(pos)))\n",
    "    pos1=[padding_size]+pos\n",
    "    dis.append(torch.stack([torch.tensor([pos1[i+1]-pos1[i] for i in range(len(pos1)-1)]),torch.tensor([pos2[i+1]-pos2[i] for i in range(len(pos2)-1)])],1))\n",
    "\n",
    "remove=[i for i in range(len(weight)) if weight[i][0]==0]\n",
    "seq = [seq[i] for i in range(len(seq)) if i not in remove]\n",
    "target=[target[i] for i in range(len(target)) if i not in remove]\n",
    "weight=[weight[i] for i in range(len(weight)) if i not in remove]\n",
    "dis=[dis[i] for i in range(len(dis)) if i not in remove]\n",
    "transcript=[transcripts[i] for i in range(len(transcripts)) if i not in remove]\n",
    "\n",
    "print(\"The length of seq data is: \", len(seq))\n",
    "print(seq[0])\n",
    "print(seq[0].shape)\n",
    "show=find_TIS(transcript[0])\n",
    "print([(show[i][0],show[i][1],target[0][i],dis[0][i,0],dis[0][i,1]) for i in range(len(target[0]))])\n",
    "print(target[0].shape)\n",
    "print('weight:',weight[0][0:10])\n",
    "sns.histplot(np.array([i.shape[0] for i in seq]),binwidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2375a653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Sum raw read count', ylabel='Weight'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=np.arange(0,300,0.01)\n",
    "y=1-math.e**(-weight_scale*x)\n",
    "sns.lineplot(data=pd.DataFrame({'Weight': y,'Sum raw read count': x}),x='Sum raw read count',y='Weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a090f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #数据预处理——归一化、权重\n",
    "# target0=copy.deepcopy(target)\n",
    "# outliers_index=[i for i in range(len(target)) if torch.sum(target[i])>15]\n",
    "# for i in outliers_index:\n",
    "#     target[i]=target[i]*15/sum(target[i])\n",
    "\n",
    "# target=[i*math.log(torch.sum(i)+1)/torch.sum(i) for i in target]\n",
    "# plotdata={'Sum label signal': np.array([torch.sum(i) for i in target0]+[torch.sum(i) for i in target]),\n",
    "#          'col': ['before']*len(target0)+['after']*len(target)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56aebca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.displot(data=plotdata,x='Sum label signal',col='col',facet_kws={'sharex': False},common_bins=False).savefig('new_standardize_target_before_after.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b410f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target0=copy.deepcopy(target)\n",
    "# target=[i/torch.sum(i) for i in target]\n",
    "# sns.displot(data=np.array([sum(i) for i in target0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "253700ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardization ratio: tensor(7.4752, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "dis0=dis\n",
    "sqrt_scale=torch.sqrt(torch.var(torch.cat(dis).flatten(0).type(torch.DoubleTensor),unbiased=False))\n",
    "print(\"standardization ratio:\",sqrt_scale)\n",
    "dis=[i/sqrt_scale for i in dis]\n",
    "plotdata={'TIS distance': np.concatenate((np.array(torch.cat([i[:,0] for i in dis0],0)),np.array(torch.cat([i[:,0] for i in dis],0)))),\n",
    "         'col': ['before']*len(np.array(torch.cat([i[:,0] for i in dis0],0)))+['after']*len(np.array(torch.cat([i[:,0] for i in dis],0)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "198f7bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotdata=pd.DataFrame(plotdata)\n",
    "# fig, ax = plt.subplots(1,2,figsize=(15, 5))\n",
    "# sns.histplot(plotdata[plotdata.col=='before'],x='TIS distance',binwidth=1,ax=ax[0])\n",
    "# sns.histplot(plotdata[plotdata.col=='after'],x='TIS distance',binwidth=1/sqrt_scale-0.00001,ax=ax[1])\n",
    "# ax[0].set_title('Before')\n",
    "# ax[1].set_title('After')\n",
    "# fig.savefig('new_standardize_distance_before_after.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04f2afdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "ENST00000418945.2\n",
      "tensor([0.0000, 0.0000, 0.0749, 0.0000, 0.0000, 0.0000, 0.0000, 1.0173, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0749, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0926, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0749, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.1617, 0.2601], dtype=torch.float64)\n",
      "[1329]\n",
      "4887\n"
     ]
    }
   ],
   "source": [
    "#检查是否有nan值：\n",
    "print([i for i in range(len(target)) if torch.sum(torch.isnan(target[i]))!=0])\n",
    "print(transcript[1326])\n",
    "print(target[1326])\n",
    "print([i for i in range(len(transcripts)) if transcripts[i]==transcript[1326]])\n",
    "print(len(vectors[1326]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5646f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall dataset size:  1563\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, dropout, num_layers, hidden_dim, proj_size, input_dim=62):\n",
    "        # 即表示每一个window（31个碱基）对应一个cell，再加上一个frame indicator\n",
    "        super(MyLSTM, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, (5,3), padding=(2,1))\n",
    "        self.conv2 = nn.Conv2d(16, 16, (5,3), padding=(2,1))\n",
    "        #self.conv3 = nn.Conv2d(16, 16, (5,3), padding=(2,1))\n",
    "        #self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc0 = nn.Linear(16 * 5 * window_size, input_dim)\n",
    "        #self.fc00 = nn.Linear(64, 32)\n",
    "        #self.fc000 = nn.Linear(4 * window_size * 4, window_size * 4)\n",
    "        self.rnn = nn.LSTM(input_size=input_dim+2, hidden_size=hidden_dim, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_dim, int(hidden_dim/2))\n",
    "        #self.fc2 = nn.Linear(proj_size, int(proj_size/2))\n",
    "        self.fc2 = nn.Linear(int(hidden_dim/2), 1)\n",
    "        #self.fc4 = nn.Linear(int(proj_size/4), 1)\n",
    "        self.lrelu1 = nn.LeakyReLU(0.05)\n",
    "        self.lrelu2 = nn.LeakyReLU(0.05)\n",
    "        #self.thresh = nn.Threshold(0.01, 0)\n",
    "        #self.shrink = nn.Hardshrink(0.01)\n",
    "\n",
    "    def forward(self, x, sizes, diss):\n",
    "        output = F.relu(self.conv1(x))  # (sum_seq_len, 1, window_size, 5)\n",
    "        output = F.relu(self.conv2(output))  # (sum_seq_len, 16, window_size, 5)\n",
    "        #output = self.sigmoid(self.conv2(output))  # in_output: (sum_seq_len, 4, window_size, 4)\n",
    "        output = F.relu(self.fc0(torch.flatten(output, 1))) # (sum_seq_len, 16*window_size*5)\n",
    "        #output = F.relu(self.fc00(output))  # (sum_seq_len, 62)\n",
    "        #output = self.lrelu(self.fc000(output))\n",
    "        output = torch.cat((output, diss), 1)  # (sum_seq_len, 62)\n",
    "        output = nn.utils.rnn.PackedSequence(data=output, batch_sizes=sizes)  # (sum_seq_len, 64)\n",
    "        output, _ = self.rnn(output)  # (packed_len, 64)\n",
    "        output = self.lrelu1(output.data)  # (sum_seq_len, 64)\n",
    "        #output = F.relu(self.fc0(output))\n",
    "        output = self.lrelu2(self.fc1(output))  # (sum_seq_len, 64)\n",
    "        #output = F.relu(self.fc1(output))  # in_output: (sum_seq_len, proj_size)\n",
    "        output = self.fc2(output).squeeze()  # (sum_seq_len, 32)\n",
    "        #output = self.fc4(output).squeeze()  # in_output: (sum_seq_len, proj_size/4)\n",
    "        output = nn.utils.rnn.PackedSequence(data=output, batch_sizes=sizes)  # (packed_len)\n",
    "        output = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)  # (batch_size, max_seq_length)\n",
    "        return output[0]\n",
    "\n",
    "# 设定随机数种子\n",
    "torch.manual_seed(201)\n",
    "torch.cuda.manual_seed(88)\n",
    "\n",
    "# 十折交叉验证+训练\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, inputset, targetset, weightset, disset, transcriptset, k, overall_size, state='train'):\n",
    "        if state == 'train':\n",
    "            index2 = list(range(int((k % 10) * overall_size / 10))) + \\\n",
    "                     list(range(int((k % 10 + 1) * overall_size / 10), overall_size))\n",
    "            self.inputset = [inputset[k] for k in index2]\n",
    "            self.targetset = [targetset[k] for k in index2]\n",
    "            self.weightset = [weightset[k] for k in index2]\n",
    "            self.disset = [disset[k] for k in index2]\n",
    "            self.transcriptset = [transcriptset[k] for k in index2]\n",
    "        if state == 'test':\n",
    "            index2 = list(range(int((k % 10) * overall_size / 10), int((k % 10 + 1) * overall_size / 10)))\n",
    "            self.inputset = [inputset[k] for k in index2]\n",
    "            self.targetset = [targetset[k] for k in index2]\n",
    "            self.weightset = [weightset[k] for k in index2]\n",
    "            self.disset = [disset[k] for k in index2]\n",
    "            self.transcriptset = [transcriptset[k] for k in index2]\n",
    "        if state == 'all':\n",
    "            self.inputset = inputset\n",
    "            self.targetset = targetset\n",
    "            self.weightset = weightset\n",
    "            self.disset = disset\n",
    "            self.transcriptset = transcriptset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input = self.inputset[idx]\n",
    "        label = self.targetset[idx]\n",
    "        weights = self.weightset[idx]\n",
    "        diss = self.disset[idx]\n",
    "        transcriptt = self.transcriptset[idx]\n",
    "        return input, label, weights, diss, transcriptt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targetset)\n",
    "\n",
    "# 随机打乱原始数据集\n",
    "np.random.seed(3)\n",
    "index = np.arange(len(target))\n",
    "np.random.shuffle(index)\n",
    "index1 = index.tolist()\n",
    "target_all = [target[i] for i in index1]\n",
    "seq_all = [seq[i] for i in index1]\n",
    "weight_all = [weight[i] for i in index1]\n",
    "dis_all = [dis[i] for i in index1]\n",
    "transcript_all = [transcript[i] for i in index1]\n",
    "\n",
    "overall_size = len(target)\n",
    "print(\"overall dataset size: \", overall_size)\n",
    "cuda_avail = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(cuda_avail)\n",
    "epoch_num = 20\n",
    "write_every = 1\n",
    "\n",
    "# 由于每个sample长度不一，需要自定义Dataloader的collate_fn:\n",
    "def collate_fn_padd(batch):\n",
    "    batch_target = [i[1] for i in batch]\n",
    "    target_lengths = torch.tensor([t.shape[0] for t in batch_target])\n",
    "    batch_seq = [i[0] for i in batch]\n",
    "    batch_weight = [i[2] for i in batch]\n",
    "    batch_dis = [i[3] for i in batch]\n",
    "    batch_trans = [i[4] for i in batch]\n",
    "    ## padd\n",
    "    target_lengths, idx = target_lengths.sort(0, descending=True)\n",
    "    batch_seq = [batch_seq[i] for i in idx]\n",
    "    batch_target = [batch_target[i] for i in idx]\n",
    "    batch_weight = [batch_weight[i] for i in idx]\n",
    "    batch_dis = [batch_dis[i] for i in idx]\n",
    "    batch_trans = [batch_trans[i] for i in idx]\n",
    "    batch_seq = [t.type(torch.float).to(device) for t in batch_seq]\n",
    "    batch_target = [t.type(torch.float).to(device) for t in batch_target]\n",
    "    batch_weight = [t.type(torch.float).to(device) for t in batch_weight]\n",
    "    batch_dis = [t.type(torch.float).to(device) for t in batch_dis]\n",
    "\n",
    "    batch_seq = pad_sequence(batch_seq, batch_first=True)  # (batch_size, max_seq_length, window_size, 4)\n",
    "    batch_seq = pack_padded_sequence(input=batch_seq, lengths=target_lengths, batch_first=True)\n",
    "    # (sum_seq_length, window_size, 4)\n",
    "    batch_weight = pad_sequence(batch_weight, batch_first=True)\n",
    "    #batch_weight = pack_padded_sequence(input=batch_weight, lengths=target_lengths, batch_first=True).data\n",
    "    # (sum_seq_length, 3)\n",
    "    batch_target = pad_sequence(batch_target, batch_first=True)  # (batch_size, max_seq_length)\n",
    "    #batch_target = pack_padded_sequence(input=batch_target, lengths=target_lengths, batch_first=True).data\n",
    "    # (sum_seq_len)\n",
    "    batch_dis = pad_sequence(batch_dis, batch_first=True)  # (batch_size, max_seq_length)\n",
    "    batch_dis = pack_padded_sequence(input=batch_dis, lengths=target_lengths, batch_first=True).data\n",
    "    return torch.unsqueeze(batch_seq.data, 1), batch_seq.batch_sizes, batch_target, batch_weight, batch_dis, batch_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf7a97a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[193, 471, 1053, 70, 804]\n",
      "['ENST00000246792.4', 'ENST00000286548.9', 'ENST00000371443.6', 'ENST00000220244.7', 'ENST00000338492.9']\n"
     ]
    }
   ],
   "source": [
    "print(index1[0:5])\n",
    "print(transcript_all[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e0135ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [2, 3, 4],\n",
      "        [5, 7, 6]])\n",
      "tensor([[3],\n",
      "        [4],\n",
      "        [7]])\n",
      "tensor([[0.3333, 0.6667, 1.0000],\n",
      "        [0.5000, 0.7500, 1.0000],\n",
      "        [0.7143, 1.0000, 0.8571]])\n",
      "tensor([[ 6],\n",
      "        [ 9],\n",
      "        [18]])\n",
      "tensor([[0.1667, 0.3333, 0.5000],\n",
      "        [0.2222, 0.3333, 0.4444],\n",
      "        [0.2778, 0.3889, 0.3333]])\n"
     ]
    }
   ],
   "source": [
    "test0=torch.tensor([[1,2,3],[2,3,4],[5,7,6]])\n",
    "print(test0)\n",
    "test,_=torch.max(test0,1,keepdim=True)\n",
    "test1=torch.sum(torch.abs(test0),1,keepdim=True)\n",
    "print(test)\n",
    "print(test0/test)\n",
    "print(test1)\n",
    "print(test0/test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfe02bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 0],\n",
      "        [1, 2, 3, 4, 0],\n",
      "        [1, 2, 0, 0, 0]])\n",
      "tensor([1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5])\n",
      "tensor([[1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 0],\n",
      "        [1, 2, 3, 4, 0],\n",
      "        [1, 2, 0, 0, 0]])\n",
      "tensor([1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "test1=pad_sequence([torch.tensor([1,2,3,4,5]),torch.tensor([1,2,3,4]),torch.tensor([1,2,3,4]),torch.tensor([1,2])], batch_first=True)\n",
    "print(test1)\n",
    "test2=pack_padded_sequence(input=test1, lengths=torch.tensor([5,4,4,2]), batch_first=True)\n",
    "print(test2.data)\n",
    "print(nn.utils.rnn.pad_packed_sequence(test2, batch_first=True)[0])\n",
    "print(nn.utils.rnn.PackedSequence(data=test2.data, batch_sizes=torch.tensor([5,4,4,2])).data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe51332e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is cuda available:  True\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(run_header)\n",
    "writer_title='run_'+str(j)\n",
    "MyData = MyDataset(inputset=seq_all, targetset=target_all, weightset=weight_all, disset=dis_all, transcriptset=transcript_all, k=j, overall_size=overall_size, state='all')\n",
    "Myloader = torch.utils.data.DataLoader(MyData, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=collate_fn_padd, drop_last=True)\n",
    "\n",
    "Mymodel = MyLSTM(dropout=dropout, hidden_dim=hidden_dim, num_layers=num_layers, proj_size=proj_size)\n",
    "Mymodel.to(device)\n",
    "print(\"Is cuda available: \", cuda_avail)\n",
    "\n",
    "def my_loss(outputs,labels,weights,sum_seq_len,loss_ratio):\n",
    "    outputs_sum=torch.sum(torch.abs(outputs),1,keepdim=True)\n",
    "    outputs1=outputs/outputs_sum\n",
    "    labels_sum=torch.sum(labels,1,keepdim=True)\n",
    "    labels=labels/labels_sum\n",
    "    return torch.sum(weights*((1-loss_ratio)*(labels - outputs)**2+loss_ratio*(labels - outputs1)**2))/sum_seq_len\n",
    "\n",
    "#criterion = nn.MSELoss(reduction='sum')\n",
    "criterion = my_loss\n",
    "optimizer = optim.SGD(Mymodel.parameters(), lr=lr, momentum=momentum)\n",
    "jj = 0\n",
    "running_loss = []\n",
    "val_loss=[]\n",
    "MyvalData = MyDataset(inputset=seq_all, targetset=target_all, weightset=weight_all, disset=dis_all, transcriptset=transcript_all, k=j, overall_size=overall_size, state='all')\n",
    "Myvalloader = torch.utils.data.DataLoader(MyvalData, batch_size=len(MyvalData), shuffle=True, num_workers=0, collate_fn=collate_fn_padd, drop_last=True)\n",
    "iter0=iter(enumerate(Myvalloader, 0))\n",
    "iii, val_batch=next(iter0)\n",
    "val_inputs, val_sizes, val_labels, val_weights, val_diss, val_transcripts = val_batch\n",
    "val_label_mTIS_indices=torch.argmax(val_labels,dim=1)\n",
    "\n",
    "epoch = 0\n",
    "inspect = False\n",
    "initialize = True\n",
    "converge_level = 0\n",
    "sigma_index = 0\n",
    "val_min_loss = math.inf\n",
    "inspect_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7ed1aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter0=iter(enumerate(Myloader))\n",
    "# i,test=next(iter0)\n",
    "# test_input,test_batch_size,test_label,test_weight,test_dis,_=test\n",
    "# #print(sum(test_label))\n",
    "# print('test_batch_size:',test_batch_size)\n",
    "# print('torch.sum(test_batch_size):',torch.sum(test_batch_size))\n",
    "# print('test_input.shape:',test_input.shape)\n",
    "# print('torch.squeeze(test_input).shape:',torch.squeeze(test_input).shape)\n",
    "# print('test_label.shape:',test_label.shape)\n",
    "# print('test_weight:',test_weight)\n",
    "# print('test_dis:',test_dis)\n",
    "# print('test_dis.shape:',test_dis.shape)\n",
    "#print(test_input[50:500])\n",
    "#print(test_label[50:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef80b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mymodel():\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'jj': jj,\n",
    "        'converge_level': converge_level,\n",
    "        'running_loss': running_loss,\n",
    "        'inspect_loss': inspect_loss,\n",
    "        'state_dict': Mymodel.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'j': j,\n",
    "        'loss_ratio': loss_ratio,\n",
    "        'sigma_index': sigma_index\n",
    "    }\n",
    "    os.makedirs(save_path + \"\\\\\"+run_header, exist_ok=True)\n",
    "    torch.save(state, save_path + \"\\\\\"+run_header+\"\\\\\"+writer_title+\".pkl\")\n",
    "def save_mTIS_prediction_data():\n",
    "    np.savetxt('mTIS_identity\\\\val_transcripts_'+str(j)+'.txt',np.array(val_transcripts),fmt=\"%s\",header='')\n",
    "    np.savetxt('mTIS_identity\\\\val_weights_'+str(j)+'.txt',np.array(val_weights[:,0].cpu()),header='')\n",
    "    val_label_mTIS_indices=torch.argmax(val_labels,dim=1)\n",
    "    np.savetxt('mTIS_identity\\\\val_label_mTIS_indices_'+str(j)+'.txt',np.array(val_label_mTIS_indices.cpu()),fmt=\"%d\",header='')\n",
    "    val_output_mTIS_indices=torch.argmax(val_outputs,dim=1)\n",
    "    np.savetxt('mTIS_identity\\\\val_output_mTIS_indices_'+str(j)+'.txt',np.array(val_output_mTIS_indices.cpu()),fmt=\"%d\",header='')\n",
    "    val_label_mTIS_codons=[find_TIS(val_transcripts[i])[val_label_mTIS_indices[i]][0] for i in range(len(val_transcripts))]\n",
    "    np.savetxt('mTIS_identity\\\\val_label_mTIS_codons_'+str(j)+'.txt',np.array(val_label_mTIS_codons),fmt=\"%s\",header='')\n",
    "    val_output_mTIS_codons=[find_TIS(val_transcripts[i])[val_output_mTIS_indices[i]][0] for i in range(len(val_transcripts))]\n",
    "    np.savetxt('mTIS_identity\\\\val_output_mTIS_codons_'+str(j)+'.txt',np.array(val_output_mTIS_codons),fmt=\"%s\",header='')\n",
    "    val_label_mTIS_positions=[find_TIS(val_transcripts[i])[val_label_mTIS_indices[i]][1] for i in range(len(val_transcripts))]\n",
    "    np.savetxt('mTIS_identity\\\\val_label_mTIS_positions_'+str(j)+'.txt',np.array(val_label_mTIS_positions),fmt=\"%d\",header='')\n",
    "    val_output_mTIS_positions=[find_TIS(val_transcripts[i])[val_output_mTIS_indices[i]][1] for i in range(len(val_transcripts))]\n",
    "    np.savetxt('mTIS_identity\\\\val_output_mTIS_positions_'+str(j)+'.txt',np.array(val_output_mTIS_positions),fmt=\"%d\",header='')\n",
    "    np.savetxt('mTIS_identity\\\\final_mTIS_accuracy_'+str(j)+'.txt',np.array([mTIS_accuracy.cpu()]),fmt=\"%.6f\")\n",
    "    np.savetxt('mTIS_identity\\\\final_val_loss_'+str(j)+'.txt',np.array([val_min_loss]),fmt=\"%.6f\")\n",
    "def high_mTIS_prediction(weights_cutoff=0.75):\n",
    "    with torch.no_grad():\n",
    "        mindex=[i for i in range(len(val_transcripts)) if val_weights[i,0]>weights_cutoff]\n",
    "        val_high_outputs=val_outputs[mindex]\n",
    "        val_high_labels=val_labels[mindex]\n",
    "        val_high_label_argmax=torch.argmax(val_high_labels,dim=1)\n",
    "        val_high_output_argmax=torch.argmax(val_high_outputs,dim=1)\n",
    "    return sum(val_high_label_argmax==val_high_output_argmax)/len(val_high_label_argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15583adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[1]-[1] lr=[0.8] loss=[0.009]\n",
      "[all_10]-[1]-[2] lr=[0.8] loss=[0.007]\n",
      "[all_10]-[1]-[3] lr=[0.8] loss=[0.008]\n",
      "[all_10]-[1]-[4] lr=[0.8] loss=[0.008]\n",
      "[all_10]-[1]-[5] lr=[0.8] loss=[0.006]\n",
      "[all_10]-[1]-[6] lr=[0.8] loss=[0.007]\n",
      "[all_10]-[1]-[7] lr=[0.8] loss=[0.007]\n",
      "[all_10]-[1]-[8] lr=[0.8] loss=[0.007]\n",
      "[all_10]-[1]-[9] lr=[0.8] loss=[0.007]\n",
      "[all_10]-[1]-[10] lr=[0.8] loss=[0.007]\n",
      "[all_10]-[1]-[11] lr=[0.8] loss=[0.008]\n",
      "[all_10]-[1]-[12] lr=[0.8] loss=[0.007]\n",
      "[all_10]-[1]-[13] lr=[0.8] loss=[0.006]\n",
      "[all_10]-[1]-[14] lr=[0.8] loss=[0.007]\n",
      "[all_10]-[1]-[15] lr=[0.8] loss=[0.007]\n",
      "[all_10]-[1]-[16] lr=[0.8] loss=[0.007]\n",
      "[all_10]-[1]-[17] lr=[0.8] loss=[0.008]\n",
      "[all_10]-[1]-[18] lr=[0.8] loss=[0.007]\n",
      "[all_10]-[1]-[19] lr=[0.8] loss=[0.005]\n",
      "[all_10]-[1]-[20] lr=[0.8] loss=[0.007]\n",
      "[all_10]-[1]-[21] lr=[0.8] loss=[0.008]\n",
      "[all_10]-[1]-[22] lr=[0.8] loss=[0.007]\n",
      "[all_10]-[1]-[23] lr=[0.8] loss=[0.006]\n",
      "[all_10]-[1]-[24] lr=[0.8] loss=[0.008]\n",
      "[all_10]-[1]-[25] lr=[0.8] loss=[0.006]\n",
      "[all_10]-[1]-[26] lr=[0.8] loss=[0.006]\n",
      "[all_10]-[1]-[27] lr=[0.8] loss=[0.005]\n",
      "[all_10]-[1]-[28] lr=[0.8] loss=[0.006]\n",
      "[all_10]-[1]-[29] lr=[0.8] loss=[0.007]\n",
      "inspect loss cutoff initialized as: 0.006307133007794619\n",
      "first inspect loss cutoff: 0.0031535665038973093\n",
      "[all_10]-[1]-[30] lr=[0.8] loss=[0.006]\n",
      "[all_10]-[1]-[31] lr=[0.8] loss=[0.007]\n",
      "[all_10]-[1]-[32] lr=[0.8] loss=[0.008]\n",
      "[all_10]-[1]-[33] lr=[0.8] loss=[0.006]\n",
      "[all_10]-[1]-[34] lr=[0.8] loss=[0.007]\n",
      "[all_10]-[1]-[35] lr=[0.8] loss=[0.006]\n",
      "[all_10]-[1]-[36] lr=[0.8] loss=[0.007]\n",
      "[all_10]-[1]-[37] lr=[0.8] loss=[0.007]\n",
      "[all_10]-[1]-[38] lr=[0.8] loss=[0.007]\n",
      "[all_10]-[1]-[39] lr=[0.8] loss=[0.006]\n",
      "[all_10]-[1]-[40] lr=[0.8] loss=[0.006]\n",
      "[all_10]-[1]-[41] lr=[0.8] loss=[0.007]\n",
      "[all_10]-[1]-[42] lr=[0.8] loss=[0.006]\n",
      "[all_10]-[1]-[43] lr=[0.8] loss=[0.006]\n",
      "[all_10]-[1]-[44] lr=[0.8] loss=[0.005]\n",
      "[all_10]-[1]-[45] lr=[0.8] loss=[0.006]\n",
      "[all_10]-[1]-[46] lr=[0.8] loss=[0.006]\n",
      "[all_10]-[1]-[47] lr=[0.8] loss=[0.006]\n",
      "[all_10]-[1]-[48] lr=[0.8] loss=[0.007]\n",
      "tensor([[0.0282, 0.0257, 0.0248,  ..., 0.0238, 0.0236, 0.0235],\n",
      "        [0.0281, 0.0256, 0.0252,  ..., 0.0251, 0.0248, 0.0245],\n",
      "        [0.0280, 0.0260, 0.0260,  ..., 0.0266, 0.0264, 0.0266],\n",
      "        ...,\n",
      "        [0.0282, 0.0260, 0.0257,  ..., 0.0256, 0.0251, 0.0252],\n",
      "        [0.0280, 0.0256, 0.0250,  ..., 0.0253, 0.0254, 0.0252],\n",
      "        [0.0281, 0.0256, 0.0246,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0106, 0.0149],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0131, 0.0000, 0.0000,  ..., 0.0131, 0.0687, 0.0000],\n",
      "        [0.0000, 0.0573, 0.0000,  ..., 0.0000, 0.0000, 0.1992],\n",
      "        [2.5909, 0.4467, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[2]-[1] lr=[0.7976000000000001] loss=[0.007]\n",
      "[all_10]-[2]-[2] lr=[0.7976000000000001] loss=[0.007]\n",
      "[all_10]-[2]-[3] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[4] lr=[0.7976000000000001] loss=[0.005]\n",
      "[all_10]-[2]-[5] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[6] lr=[0.7976000000000001] loss=[0.007]\n",
      "[all_10]-[2]-[7] lr=[0.7976000000000001] loss=[0.007]\n",
      "[all_10]-[2]-[8] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[9] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[10] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[11] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[12] lr=[0.7976000000000001] loss=[0.007]\n",
      "[all_10]-[2]-[13] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[14] lr=[0.7976000000000001] loss=[0.007]\n",
      "[all_10]-[2]-[15] lr=[0.7976000000000001] loss=[0.008]\n",
      "[all_10]-[2]-[16] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[17] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[18] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[19] lr=[0.7976000000000001] loss=[0.008]\n",
      "[all_10]-[2]-[20] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[21] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[22] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[23] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[24] lr=[0.7976000000000001] loss=[0.008]\n",
      "[all_10]-[2]-[25] lr=[0.7976000000000001] loss=[0.005]\n",
      "[all_10]-[2]-[26] lr=[0.7976000000000001] loss=[0.007]\n",
      "[all_10]-[2]-[27] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[28] lr=[0.7976000000000001] loss=[0.007]\n",
      "[all_10]-[2]-[29] lr=[0.7976000000000001] loss=[0.008]\n",
      "[all_10]-[2]-[30] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[31] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[32] lr=[0.7976000000000001] loss=[0.008]\n",
      "[all_10]-[2]-[33] lr=[0.7976000000000001] loss=[0.007]\n",
      "[all_10]-[2]-[34] lr=[0.7976000000000001] loss=[0.005]\n",
      "[all_10]-[2]-[35] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[36] lr=[0.7976000000000001] loss=[0.007]\n",
      "[all_10]-[2]-[37] lr=[0.7976000000000001] loss=[0.007]\n",
      "[all_10]-[2]-[38] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[39] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[40] lr=[0.7976000000000001] loss=[0.007]\n",
      "[all_10]-[2]-[41] lr=[0.7976000000000001] loss=[0.005]\n",
      "[all_10]-[2]-[42] lr=[0.7976000000000001] loss=[0.005]\n",
      "[all_10]-[2]-[43] lr=[0.7976000000000001] loss=[0.006]\n",
      "[all_10]-[2]-[44] lr=[0.7976000000000001] loss=[0.005]\n",
      "[all_10]-[2]-[45] lr=[0.7976000000000001] loss=[0.007]\n",
      "[all_10]-[2]-[46] lr=[0.7976000000000001] loss=[0.007]\n",
      "[all_10]-[2]-[47] lr=[0.7976000000000001] loss=[0.005]\n",
      "[all_10]-[2]-[48] lr=[0.7976000000000001] loss=[0.007]\n",
      "tensor([[0.0277, 0.0262, 0.0251,  ..., 0.0188, 0.0199, 0.0208],\n",
      "        [0.0261, 0.0232, 0.0225,  ..., 0.0222, 0.0211, 0.0203],\n",
      "        [0.0271, 0.0236, 0.0233,  ..., 0.0218, 0.0238, 0.0265],\n",
      "        ...,\n",
      "        [0.0265, 0.0231, 0.0216,  ..., 0.0207, 0.0196, 0.0197],\n",
      "        [0.0270, 0.0241, 0.0225,  ..., 0.0199, 0.0204, 0.0206],\n",
      "        [0.0267, 0.0236, 0.0225,  ..., 0.0215, 0.0212, 0.0215]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.2346, 0.1751,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.7147,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0198, 0.3970,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0704,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0811, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[3]-[1] lr=[0.7952072000000001] loss=[0.007]\n",
      "[all_10]-[3]-[2] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[3] lr=[0.7952072000000001] loss=[0.007]\n",
      "[all_10]-[3]-[4] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[5] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[6] lr=[0.7952072000000001] loss=[0.005]\n",
      "[all_10]-[3]-[7] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[8] lr=[0.7952072000000001] loss=[0.007]\n",
      "[all_10]-[3]-[9] lr=[0.7952072000000001] loss=[0.007]\n",
      "[all_10]-[3]-[10] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[11] lr=[0.7952072000000001] loss=[0.007]\n",
      "[all_10]-[3]-[12] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[13] lr=[0.7952072000000001] loss=[0.007]\n",
      "[all_10]-[3]-[14] lr=[0.7952072000000001] loss=[0.005]\n",
      "[all_10]-[3]-[15] lr=[0.7952072000000001] loss=[0.007]\n",
      "[all_10]-[3]-[16] lr=[0.7952072000000001] loss=[0.007]\n",
      "[all_10]-[3]-[17] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[18] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[19] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[20] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[21] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[22] lr=[0.7952072000000001] loss=[0.007]\n",
      "[all_10]-[3]-[23] lr=[0.7952072000000001] loss=[0.008]\n",
      "[all_10]-[3]-[24] lr=[0.7952072000000001] loss=[0.007]\n",
      "[all_10]-[3]-[25] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[26] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[27] lr=[0.7952072000000001] loss=[0.007]\n",
      "[all_10]-[3]-[28] lr=[0.7952072000000001] loss=[0.005]\n",
      "[all_10]-[3]-[29] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[30] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[31] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[32] lr=[0.7952072000000001] loss=[0.007]\n",
      "[all_10]-[3]-[33] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[34] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[35] lr=[0.7952072000000001] loss=[0.007]\n",
      "[all_10]-[3]-[36] lr=[0.7952072000000001] loss=[0.007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[3]-[37] lr=[0.7952072000000001] loss=[0.007]\n",
      "[all_10]-[3]-[38] lr=[0.7952072000000001] loss=[0.008]\n",
      "[all_10]-[3]-[39] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[40] lr=[0.7952072000000001] loss=[0.007]\n",
      "[all_10]-[3]-[41] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[42] lr=[0.7952072000000001] loss=[0.007]\n",
      "[all_10]-[3]-[43] lr=[0.7952072000000001] loss=[0.005]\n",
      "[all_10]-[3]-[44] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[45] lr=[0.7952072000000001] loss=[0.007]\n",
      "[all_10]-[3]-[46] lr=[0.7952072000000001] loss=[0.006]\n",
      "[all_10]-[3]-[47] lr=[0.7952072000000001] loss=[0.007]\n",
      "[all_10]-[3]-[48] lr=[0.7952072000000001] loss=[0.007]\n",
      "tensor([[0.0303, 0.0271, 0.0267,  ..., 0.0200, 0.0228, 0.0241],\n",
      "        [0.0294, 0.0241, 0.0221,  ..., 0.0185, 0.0197, 0.0202],\n",
      "        [0.0291, 0.0260, 0.0252,  ..., 0.0250, 0.0236, 0.0223],\n",
      "        ...,\n",
      "        [0.0297, 0.0251, 0.0251,  ..., 0.0216, 0.0224, 0.0237],\n",
      "        [0.0297, 0.0262, 0.0250,  ..., 0.0234, 0.0209, 0.0194],\n",
      "        [0.0296, 0.0253, 0.0242,  ..., 0.0179, 0.0181, 0.0184]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0376,  ..., 0.0000, 0.0208, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0778, 0.1359, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0105, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0146, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[4]-[1] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[2] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[3] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[4] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[5] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[6] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[7] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[8] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[9] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[10] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[11] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[12] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[13] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[14] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[15] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[16] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[17] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[18] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[19] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[20] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[21] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[22] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[23] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[24] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[25] lr=[0.7928215784000001] loss=[0.005]\n",
      "[all_10]-[4]-[26] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[27] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[28] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[29] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[30] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[31] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[32] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[33] lr=[0.7928215784000001] loss=[0.005]\n",
      "[all_10]-[4]-[34] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[35] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[36] lr=[0.7928215784000001] loss=[0.005]\n",
      "[all_10]-[4]-[37] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[38] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[39] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[40] lr=[0.7928215784000001] loss=[0.005]\n",
      "[all_10]-[4]-[41] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[42] lr=[0.7928215784000001] loss=[0.005]\n",
      "[all_10]-[4]-[43] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[44] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[45] lr=[0.7928215784000001] loss=[0.008]\n",
      "[all_10]-[4]-[46] lr=[0.7928215784000001] loss=[0.006]\n",
      "[all_10]-[4]-[47] lr=[0.7928215784000001] loss=[0.007]\n",
      "[all_10]-[4]-[48] lr=[0.7928215784000001] loss=[0.006]\n",
      "tensor([[0.0375, 0.0355, 0.0344,  ..., 0.0176, 0.0178, 0.0180],\n",
      "        [0.0371, 0.0339, 0.0309,  ..., 0.0257, 0.0226, 0.0212],\n",
      "        [0.0341, 0.0282, 0.0246,  ..., 0.0194, 0.0188, 0.0176],\n",
      "        ...,\n",
      "        [0.0328, 0.0303, 0.0305,  ..., 0.0183, 0.0169, 0.0176],\n",
      "        [0.0328, 0.0264, 0.0228,  ..., 0.0173, 0.0172, 0.0175],\n",
      "        [0.0326, 0.0257, 0.0256,  ..., 0.0409, 0.0458, 0.0458]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0078, 0.0000, 0.0037,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0712, 0.5636, 0.0000,  ..., 0.0000, 0.0192, 0.0926],\n",
      "        [0.0000, 0.0080, 0.0282,  ..., 0.0085, 0.0000, 0.0323],\n",
      "        ...,\n",
      "        [0.1046, 0.0648, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0347, 0.0000,  ..., 0.0023, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0775, 0.0529, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[5]-[1] lr=[0.7904431136648001] loss=[0.006]\n",
      "[all_10]-[5]-[2] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[3] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[4] lr=[0.7904431136648001] loss=[0.006]\n",
      "[all_10]-[5]-[5] lr=[0.7904431136648001] loss=[0.006]\n",
      "[all_10]-[5]-[6] lr=[0.7904431136648001] loss=[0.006]\n",
      "[all_10]-[5]-[7] lr=[0.7904431136648001] loss=[0.005]\n",
      "[all_10]-[5]-[8] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[9] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[10] lr=[0.7904431136648001] loss=[0.005]\n",
      "[all_10]-[5]-[11] lr=[0.7904431136648001] loss=[0.006]\n",
      "[all_10]-[5]-[12] lr=[0.7904431136648001] loss=[0.008]\n",
      "[all_10]-[5]-[13] lr=[0.7904431136648001] loss=[0.006]\n",
      "[all_10]-[5]-[14] lr=[0.7904431136648001] loss=[0.005]\n",
      "[all_10]-[5]-[15] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[16] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[17] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[18] lr=[0.7904431136648001] loss=[0.006]\n",
      "[all_10]-[5]-[19] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[20] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[21] lr=[0.7904431136648001] loss=[0.006]\n",
      "[all_10]-[5]-[22] lr=[0.7904431136648001] loss=[0.006]\n",
      "[all_10]-[5]-[23] lr=[0.7904431136648001] loss=[0.009]\n",
      "[all_10]-[5]-[24] lr=[0.7904431136648001] loss=[0.006]\n",
      "[all_10]-[5]-[25] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[26] lr=[0.7904431136648001] loss=[0.005]\n",
      "[all_10]-[5]-[27] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[28] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[29] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[30] lr=[0.7904431136648001] loss=[0.006]\n",
      "[all_10]-[5]-[31] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[32] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[33] lr=[0.7904431136648001] loss=[0.006]\n",
      "[all_10]-[5]-[34] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[35] lr=[0.7904431136648001] loss=[0.005]\n",
      "[all_10]-[5]-[36] lr=[0.7904431136648001] loss=[0.004]\n",
      "[all_10]-[5]-[37] lr=[0.7904431136648001] loss=[0.006]\n",
      "[all_10]-[5]-[38] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[39] lr=[0.7904431136648001] loss=[0.006]\n",
      "[all_10]-[5]-[40] lr=[0.7904431136648001] loss=[0.006]\n",
      "[all_10]-[5]-[41] lr=[0.7904431136648001] loss=[0.006]\n",
      "[all_10]-[5]-[42] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[43] lr=[0.7904431136648001] loss=[0.006]\n",
      "[all_10]-[5]-[44] lr=[0.7904431136648001] loss=[0.006]\n",
      "[all_10]-[5]-[45] lr=[0.7904431136648001] loss=[0.006]\n",
      "[all_10]-[5]-[46] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[47] lr=[0.7904431136648001] loss=[0.007]\n",
      "[all_10]-[5]-[48] lr=[0.7904431136648001] loss=[0.007]\n",
      "tensor([[0.0386, 0.0329, 0.0298,  ..., 0.0166, 0.0161, 0.0154],\n",
      "        [0.0366, 0.0312, 0.0275,  ..., 0.0168, 0.0161, 0.0169],\n",
      "        [0.0389, 0.0378, 0.0329,  ..., 0.0138, 0.0132, 0.0128],\n",
      "        ...,\n",
      "        [0.0373, 0.0325, 0.0285,  ..., 0.0176, 0.0167, 0.0163],\n",
      "        [0.0348, 0.0283, 0.0254,  ..., 0.0158, 0.0145, 0.0128],\n",
      "        [0.0380, 0.0311, 0.0269,  ..., 0.0268, 0.0248, 0.0219]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0146,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2189, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0355, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[6]-[1] lr=[0.7880717843238058] loss=[0.007]\n",
      "[all_10]-[6]-[2] lr=[0.7880717843238058] loss=[0.005]\n",
      "[all_10]-[6]-[3] lr=[0.7880717843238058] loss=[0.007]\n",
      "[all_10]-[6]-[4] lr=[0.7880717843238058] loss=[0.007]\n",
      "[all_10]-[6]-[5] lr=[0.7880717843238058] loss=[0.005]\n",
      "[all_10]-[6]-[6] lr=[0.7880717843238058] loss=[0.007]\n",
      "[all_10]-[6]-[7] lr=[0.7880717843238058] loss=[0.007]\n",
      "[all_10]-[6]-[8] lr=[0.7880717843238058] loss=[0.006]\n",
      "[all_10]-[6]-[9] lr=[0.7880717843238058] loss=[0.007]\n",
      "[all_10]-[6]-[10] lr=[0.7880717843238058] loss=[0.007]\n",
      "[all_10]-[6]-[11] lr=[0.7880717843238058] loss=[0.008]\n",
      "[all_10]-[6]-[12] lr=[0.7880717843238058] loss=[0.006]\n",
      "[all_10]-[6]-[13] lr=[0.7880717843238058] loss=[0.007]\n",
      "[all_10]-[6]-[14] lr=[0.7880717843238058] loss=[0.006]\n",
      "[all_10]-[6]-[15] lr=[0.7880717843238058] loss=[0.006]\n",
      "[all_10]-[6]-[16] lr=[0.7880717843238058] loss=[0.006]\n",
      "[all_10]-[6]-[17] lr=[0.7880717843238058] loss=[0.006]\n",
      "[all_10]-[6]-[18] lr=[0.7880717843238058] loss=[0.006]\n",
      "[all_10]-[6]-[19] lr=[0.7880717843238058] loss=[0.008]\n",
      "[all_10]-[6]-[20] lr=[0.7880717843238058] loss=[0.007]\n",
      "[all_10]-[6]-[21] lr=[0.7880717843238058] loss=[0.007]\n",
      "[all_10]-[6]-[22] lr=[0.7880717843238058] loss=[0.006]\n",
      "[all_10]-[6]-[23] lr=[0.7880717843238058] loss=[0.005]\n",
      "[all_10]-[6]-[24] lr=[0.7880717843238058] loss=[0.006]\n",
      "[all_10]-[6]-[25] lr=[0.7880717843238058] loss=[0.007]\n",
      "[all_10]-[6]-[26] lr=[0.7880717843238058] loss=[0.005]\n",
      "[all_10]-[6]-[27] lr=[0.7880717843238058] loss=[0.005]\n",
      "[all_10]-[6]-[28] lr=[0.7880717843238058] loss=[0.007]\n",
      "[all_10]-[6]-[29] lr=[0.7880717843238058] loss=[0.006]\n",
      "[all_10]-[6]-[30] lr=[0.7880717843238058] loss=[0.005]\n",
      "[all_10]-[6]-[31] lr=[0.7880717843238058] loss=[0.005]\n",
      "[all_10]-[6]-[32] lr=[0.7880717843238058] loss=[0.006]\n",
      "[all_10]-[6]-[33] lr=[0.7880717843238058] loss=[0.007]\n",
      "[all_10]-[6]-[34] lr=[0.7880717843238058] loss=[0.007]\n",
      "[all_10]-[6]-[35] lr=[0.7880717843238058] loss=[0.006]\n",
      "[all_10]-[6]-[36] lr=[0.7880717843238058] loss=[0.004]\n",
      "[all_10]-[6]-[37] lr=[0.7880717843238058] loss=[0.006]\n",
      "[all_10]-[6]-[38] lr=[0.7880717843238058] loss=[0.008]\n",
      "[all_10]-[6]-[39] lr=[0.7880717843238058] loss=[0.006]\n",
      "[all_10]-[6]-[40] lr=[0.7880717843238058] loss=[0.008]\n",
      "[all_10]-[6]-[41] lr=[0.7880717843238058] loss=[0.007]\n",
      "[all_10]-[6]-[42] lr=[0.7880717843238058] loss=[0.006]\n",
      "[all_10]-[6]-[43] lr=[0.7880717843238058] loss=[0.007]\n",
      "[all_10]-[6]-[44] lr=[0.7880717843238058] loss=[0.005]\n",
      "[all_10]-[6]-[45] lr=[0.7880717843238058] loss=[0.007]\n",
      "[all_10]-[6]-[46] lr=[0.7880717843238058] loss=[0.006]\n",
      "[all_10]-[6]-[47] lr=[0.7880717843238058] loss=[0.006]\n",
      "[all_10]-[6]-[48] lr=[0.7880717843238058] loss=[0.007]\n",
      "tensor([[0.0381, 0.0341, 0.0287,  ..., 0.0122, 0.0138, 0.0145],\n",
      "        [0.0438, 0.0490, 0.0634,  ..., 0.0162, 0.0136, 0.0130],\n",
      "        [0.0342, 0.0254, 0.0267,  ..., 0.0128, 0.0105, 0.0093],\n",
      "        ...,\n",
      "        [0.0347, 0.0277, 0.0282,  ..., 0.0126, 0.0114, 0.0097],\n",
      "        [0.0373, 0.0292, 0.0241,  ..., 0.0324, 0.0326, 0.0298],\n",
      "        [0.0358, 0.0343, 0.0334,  ..., 0.0136, 0.0121, 0.0118]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0820, 0.0000,  ..., 0.3164, 0.0000, 0.0000],\n",
      "        [0.0311, 0.0131, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0882, 0.0000,  ..., 0.0000, 0.0000, 0.0515],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.1367,  ..., 0.5118, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0447, 0.0653,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0852, 0.0420,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[7]-[1] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[2] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[3] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[4] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[5] lr=[0.7857075689708344] loss=[0.005]\n",
      "[all_10]-[7]-[6] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[7] lr=[0.7857075689708344] loss=[0.007]\n",
      "[all_10]-[7]-[8] lr=[0.7857075689708344] loss=[0.008]\n",
      "[all_10]-[7]-[9] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[10] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[11] lr=[0.7857075689708344] loss=[0.005]\n",
      "[all_10]-[7]-[12] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[13] lr=[0.7857075689708344] loss=[0.007]\n",
      "[all_10]-[7]-[14] lr=[0.7857075689708344] loss=[0.007]\n",
      "[all_10]-[7]-[15] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[16] lr=[0.7857075689708344] loss=[0.005]\n",
      "[all_10]-[7]-[17] lr=[0.7857075689708344] loss=[0.005]\n",
      "[all_10]-[7]-[18] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[19] lr=[0.7857075689708344] loss=[0.005]\n",
      "[all_10]-[7]-[20] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[21] lr=[0.7857075689708344] loss=[0.007]\n",
      "[all_10]-[7]-[22] lr=[0.7857075689708344] loss=[0.007]\n",
      "[all_10]-[7]-[23] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[24] lr=[0.7857075689708344] loss=[0.007]\n",
      "[all_10]-[7]-[25] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[26] lr=[0.7857075689708344] loss=[0.005]\n",
      "[all_10]-[7]-[27] lr=[0.7857075689708344] loss=[0.008]\n",
      "[all_10]-[7]-[28] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[29] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[30] lr=[0.7857075689708344] loss=[0.008]\n",
      "[all_10]-[7]-[31] lr=[0.7857075689708344] loss=[0.005]\n",
      "[all_10]-[7]-[32] lr=[0.7857075689708344] loss=[0.007]\n",
      "[all_10]-[7]-[33] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[34] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[35] lr=[0.7857075689708344] loss=[0.005]\n",
      "[all_10]-[7]-[36] lr=[0.7857075689708344] loss=[0.007]\n",
      "[all_10]-[7]-[37] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[38] lr=[0.7857075689708344] loss=[0.008]\n",
      "[all_10]-[7]-[39] lr=[0.7857075689708344] loss=[0.005]\n",
      "[all_10]-[7]-[40] lr=[0.7857075689708344] loss=[0.007]\n",
      "[all_10]-[7]-[41] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[42] lr=[0.7857075689708344] loss=[0.005]\n",
      "[all_10]-[7]-[43] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[44] lr=[0.7857075689708344] loss=[0.007]\n",
      "[all_10]-[7]-[45] lr=[0.7857075689708344] loss=[0.006]\n",
      "[all_10]-[7]-[46] lr=[0.7857075689708344] loss=[0.007]\n",
      "[all_10]-[7]-[47] lr=[0.7857075689708344] loss=[0.007]\n",
      "[all_10]-[7]-[48] lr=[0.7857075689708344] loss=[0.007]\n",
      "tensor([[0.0417, 0.0338, 0.0325,  ..., 0.0271, 0.0201, 0.0162],\n",
      "        [0.0368, 0.0353, 0.0361,  ..., 0.0279, 0.0333, 0.0386],\n",
      "        [0.0463, 0.0410, 0.0340,  ..., 0.0350, 0.0290, 0.0231],\n",
      "        ...,\n",
      "        [0.0368, 0.0287, 0.0247,  ..., 0.0091, 0.0118, 0.0143],\n",
      "        [0.0452, 0.0456, 0.0399,  ..., 0.0082, 0.0100, 0.0117],\n",
      "        [0.0399, 0.0348, 0.0499,  ..., 0.0061, 0.0057, 0.0089]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         3.7769e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.0997e-01, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.9739e-02, 0.0000e+00, 1.3620e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [6.4702e-03, 3.7764e-02, 0.0000e+00,  ..., 0.0000e+00, 1.8353e-02,\n",
      "         2.4823e-02],\n",
      "        [0.0000e+00, 3.5021e-03, 0.0000e+00,  ..., 1.4464e-02, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [4.4339e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='cuda:0')\n",
      "[all_10]-[8]-[1] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[2] lr=[0.7833504462639219] loss=[0.005]\n",
      "[all_10]-[8]-[3] lr=[0.7833504462639219] loss=[0.007]\n",
      "[all_10]-[8]-[4] lr=[0.7833504462639219] loss=[0.007]\n",
      "[all_10]-[8]-[5] lr=[0.7833504462639219] loss=[0.007]\n",
      "[all_10]-[8]-[6] lr=[0.7833504462639219] loss=[0.007]\n",
      "[all_10]-[8]-[7] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[8] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[9] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[10] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[11] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[12] lr=[0.7833504462639219] loss=[0.005]\n",
      "[all_10]-[8]-[13] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[14] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[15] lr=[0.7833504462639219] loss=[0.007]\n",
      "[all_10]-[8]-[16] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[17] lr=[0.7833504462639219] loss=[0.005]\n",
      "[all_10]-[8]-[18] lr=[0.7833504462639219] loss=[0.007]\n",
      "[all_10]-[8]-[19] lr=[0.7833504462639219] loss=[0.007]\n",
      "[all_10]-[8]-[20] lr=[0.7833504462639219] loss=[0.006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[8]-[21] lr=[0.7833504462639219] loss=[0.007]\n",
      "[all_10]-[8]-[22] lr=[0.7833504462639219] loss=[0.005]\n",
      "[all_10]-[8]-[23] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[24] lr=[0.7833504462639219] loss=[0.005]\n",
      "[all_10]-[8]-[25] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[26] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[27] lr=[0.7833504462639219] loss=[0.007]\n",
      "[all_10]-[8]-[28] lr=[0.7833504462639219] loss=[0.005]\n",
      "[all_10]-[8]-[29] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[30] lr=[0.7833504462639219] loss=[0.007]\n",
      "[all_10]-[8]-[31] lr=[0.7833504462639219] loss=[0.007]\n",
      "[all_10]-[8]-[32] lr=[0.7833504462639219] loss=[0.007]\n",
      "[all_10]-[8]-[33] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[34] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[35] lr=[0.7833504462639219] loss=[0.007]\n",
      "[all_10]-[8]-[36] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[37] lr=[0.7833504462639219] loss=[0.007]\n",
      "[all_10]-[8]-[38] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[39] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[40] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[41] lr=[0.7833504462639219] loss=[0.007]\n",
      "[all_10]-[8]-[42] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[43] lr=[0.7833504462639219] loss=[0.007]\n",
      "[all_10]-[8]-[44] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[45] lr=[0.7833504462639219] loss=[0.006]\n",
      "[all_10]-[8]-[46] lr=[0.7833504462639219] loss=[0.007]\n",
      "[all_10]-[8]-[47] lr=[0.7833504462639219] loss=[0.007]\n",
      "[all_10]-[8]-[48] lr=[0.7833504462639219] loss=[0.006]\n",
      "tensor([[0.0392, 0.0383, 0.0372,  ..., 0.0222, 0.0253, 0.0293],\n",
      "        [0.0374, 0.0303, 0.0247,  ..., 0.0084, 0.0093, 0.0122],\n",
      "        [0.0361, 0.0298, 0.0349,  ..., 0.0084, 0.0084, 0.0180],\n",
      "        ...,\n",
      "        [0.0359, 0.0279, 0.0457,  ..., 0.0281, 0.0221, 0.0197],\n",
      "        [0.0358, 0.0274, 0.0209,  ..., 0.0107, 0.0123, 0.0104],\n",
      "        [0.0354, 0.0332, 0.0333,  ..., 0.0148, 0.0132, 0.0124]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 1.2145, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3710, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1021],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0125, 0.0462, 0.0213]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[9]-[1] lr=[0.7810003949251302] loss=[0.006]\n",
      "[all_10]-[9]-[2] lr=[0.7810003949251302] loss=[0.007]\n",
      "[all_10]-[9]-[3] lr=[0.7810003949251302] loss=[0.007]\n",
      "[all_10]-[9]-[4] lr=[0.7810003949251302] loss=[0.006]\n",
      "[all_10]-[9]-[5] lr=[0.7810003949251302] loss=[0.007]\n",
      "[all_10]-[9]-[6] lr=[0.7810003949251302] loss=[0.006]\n",
      "[all_10]-[9]-[7] lr=[0.7810003949251302] loss=[0.005]\n",
      "[all_10]-[9]-[8] lr=[0.7810003949251302] loss=[0.008]\n",
      "[all_10]-[9]-[9] lr=[0.7810003949251302] loss=[0.007]\n",
      "[all_10]-[9]-[10] lr=[0.7810003949251302] loss=[0.005]\n",
      "[all_10]-[9]-[11] lr=[0.7810003949251302] loss=[0.005]\n",
      "[all_10]-[9]-[12] lr=[0.7810003949251302] loss=[0.007]\n",
      "[all_10]-[9]-[13] lr=[0.7810003949251302] loss=[0.005]\n",
      "[all_10]-[9]-[14] lr=[0.7810003949251302] loss=[0.006]\n",
      "[all_10]-[9]-[15] lr=[0.7810003949251302] loss=[0.007]\n",
      "[all_10]-[9]-[16] lr=[0.7810003949251302] loss=[0.005]\n",
      "[all_10]-[9]-[17] lr=[0.7810003949251302] loss=[0.007]\n",
      "[all_10]-[9]-[18] lr=[0.7810003949251302] loss=[0.006]\n",
      "[all_10]-[9]-[19] lr=[0.7810003949251302] loss=[0.007]\n",
      "[all_10]-[9]-[20] lr=[0.7810003949251302] loss=[0.007]\n",
      "[all_10]-[9]-[21] lr=[0.7810003949251302] loss=[0.007]\n",
      "[all_10]-[9]-[22] lr=[0.7810003949251302] loss=[0.006]\n",
      "[all_10]-[9]-[23] lr=[0.7810003949251302] loss=[0.008]\n",
      "[all_10]-[9]-[24] lr=[0.7810003949251302] loss=[0.007]\n",
      "[all_10]-[9]-[25] lr=[0.7810003949251302] loss=[0.007]\n",
      "[all_10]-[9]-[26] lr=[0.7810003949251302] loss=[0.005]\n",
      "[all_10]-[9]-[27] lr=[0.7810003949251302] loss=[0.008]\n",
      "[all_10]-[9]-[28] lr=[0.7810003949251302] loss=[0.006]\n",
      "[all_10]-[9]-[29] lr=[0.7810003949251302] loss=[0.006]\n",
      "[all_10]-[9]-[30] lr=[0.7810003949251302] loss=[0.008]\n",
      "[all_10]-[9]-[31] lr=[0.7810003949251302] loss=[0.008]\n",
      "[all_10]-[9]-[32] lr=[0.7810003949251302] loss=[0.006]\n",
      "[all_10]-[9]-[33] lr=[0.7810003949251302] loss=[0.007]\n",
      "[all_10]-[9]-[34] lr=[0.7810003949251302] loss=[0.006]\n",
      "[all_10]-[9]-[35] lr=[0.7810003949251302] loss=[0.006]\n",
      "[all_10]-[9]-[36] lr=[0.7810003949251302] loss=[0.005]\n",
      "[all_10]-[9]-[37] lr=[0.7810003949251302] loss=[0.005]\n",
      "[all_10]-[9]-[38] lr=[0.7810003949251302] loss=[0.006]\n",
      "[all_10]-[9]-[39] lr=[0.7810003949251302] loss=[0.004]\n",
      "[all_10]-[9]-[40] lr=[0.7810003949251302] loss=[0.006]\n",
      "[all_10]-[9]-[41] lr=[0.7810003949251302] loss=[0.006]\n",
      "[all_10]-[9]-[42] lr=[0.7810003949251302] loss=[0.005]\n",
      "[all_10]-[9]-[43] lr=[0.7810003949251302] loss=[0.007]\n",
      "[all_10]-[9]-[44] lr=[0.7810003949251302] loss=[0.007]\n",
      "[all_10]-[9]-[45] lr=[0.7810003949251302] loss=[0.007]\n",
      "[all_10]-[9]-[46] lr=[0.7810003949251302] loss=[0.006]\n",
      "[all_10]-[9]-[47] lr=[0.7810003949251302] loss=[0.006]\n",
      "[all_10]-[9]-[48] lr=[0.7810003949251302] loss=[0.006]\n",
      "tensor([[0.0407, 0.0354, 0.0375,  ..., 0.0136, 0.0114, 0.0174],\n",
      "        [0.0419, 0.0357, 0.0309,  ..., 0.0491, 0.0577, 0.0619],\n",
      "        [0.0472, 0.0431, 0.0405,  ..., 0.0147, 0.0143, 0.0128],\n",
      "        ...,\n",
      "        [0.0481, 0.0462, 0.0401,  ..., 0.0139, 0.0147, 0.0172],\n",
      "        [0.0407, 0.0376, 0.0465,  ..., 0.0206, 0.0228, 0.0268],\n",
      "        [0.0424, 0.0445, 0.0455,  ..., 0.0322, 0.0271, 0.0231]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.2031, 0.0870,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0729,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3111,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0179, 0.0179, 0.0358]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[10]-[1] lr=[0.7786573937403548] loss=[0.006]\n",
      "[all_10]-[10]-[2] lr=[0.7786573937403548] loss=[0.007]\n",
      "[all_10]-[10]-[3] lr=[0.7786573937403548] loss=[0.005]\n",
      "[all_10]-[10]-[4] lr=[0.7786573937403548] loss=[0.008]\n",
      "[all_10]-[10]-[5] lr=[0.7786573937403548] loss=[0.006]\n",
      "[all_10]-[10]-[6] lr=[0.7786573937403548] loss=[0.006]\n",
      "[all_10]-[10]-[7] lr=[0.7786573937403548] loss=[0.006]\n",
      "[all_10]-[10]-[8] lr=[0.7786573937403548] loss=[0.008]\n",
      "[all_10]-[10]-[9] lr=[0.7786573937403548] loss=[0.008]\n",
      "[all_10]-[10]-[10] lr=[0.7786573937403548] loss=[0.007]\n",
      "[all_10]-[10]-[11] lr=[0.7786573937403548] loss=[0.006]\n",
      "[all_10]-[10]-[12] lr=[0.7786573937403548] loss=[0.007]\n",
      "[all_10]-[10]-[13] lr=[0.7786573937403548] loss=[0.005]\n",
      "[all_10]-[10]-[14] lr=[0.7786573937403548] loss=[0.006]\n",
      "[all_10]-[10]-[15] lr=[0.7786573937403548] loss=[0.007]\n",
      "[all_10]-[10]-[16] lr=[0.7786573937403548] loss=[0.007]\n",
      "[all_10]-[10]-[17] lr=[0.7786573937403548] loss=[0.005]\n",
      "[all_10]-[10]-[18] lr=[0.7786573937403548] loss=[0.007]\n",
      "[all_10]-[10]-[19] lr=[0.7786573937403548] loss=[0.006]\n",
      "[all_10]-[10]-[20] lr=[0.7786573937403548] loss=[0.006]\n",
      "[all_10]-[10]-[21] lr=[0.7786573937403548] loss=[0.006]\n",
      "[all_10]-[10]-[22] lr=[0.7786573937403548] loss=[0.007]\n",
      "[all_10]-[10]-[23] lr=[0.7786573937403548] loss=[0.007]\n",
      "[all_10]-[10]-[24] lr=[0.7786573937403548] loss=[0.006]\n",
      "[all_10]-[10]-[25] lr=[0.7786573937403548] loss=[0.006]\n",
      "[all_10]-[10]-[26] lr=[0.7786573937403548] loss=[0.005]\n",
      "[all_10]-[10]-[27] lr=[0.7786573937403548] loss=[0.008]\n",
      "[all_10]-[10]-[28] lr=[0.7786573937403548] loss=[0.006]\n",
      "[all_10]-[10]-[29] lr=[0.7786573937403548] loss=[0.004]\n",
      "[all_10]-[10]-[30] lr=[0.7786573937403548] loss=[0.006]\n",
      "[all_10]-[10]-[31] lr=[0.7786573937403548] loss=[0.005]\n",
      "[all_10]-[10]-[32] lr=[0.7786573937403548] loss=[0.007]\n",
      "[all_10]-[10]-[33] lr=[0.7786573937403548] loss=[0.005]\n",
      "[all_10]-[10]-[34] lr=[0.7786573937403548] loss=[0.006]\n",
      "[all_10]-[10]-[35] lr=[0.7786573937403548] loss=[0.006]\n",
      "[all_10]-[10]-[36] lr=[0.7786573937403548] loss=[0.007]\n",
      "[all_10]-[10]-[37] lr=[0.7786573937403548] loss=[0.007]\n",
      "[all_10]-[10]-[38] lr=[0.7786573937403548] loss=[0.004]\n",
      "[all_10]-[10]-[39] lr=[0.7786573937403548] loss=[0.007]\n",
      "[all_10]-[10]-[40] lr=[0.7786573937403548] loss=[0.007]\n",
      "[all_10]-[10]-[41] lr=[0.7786573937403548] loss=[0.006]\n",
      "[all_10]-[10]-[42] lr=[0.7786573937403548] loss=[0.006]\n",
      "[all_10]-[10]-[43] lr=[0.7786573937403548] loss=[0.008]\n",
      "[all_10]-[10]-[44] lr=[0.7786573937403548] loss=[0.007]\n",
      "[all_10]-[10]-[45] lr=[0.7786573937403548] loss=[0.006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[10]-[46] lr=[0.7786573937403548] loss=[0.006]\n",
      "[all_10]-[10]-[47] lr=[0.7786573937403548] loss=[0.005]\n",
      "[all_10]-[10]-[48] lr=[0.7786573937403548] loss=[0.006]\n",
      "tensor([[0.0447, 0.0371, 0.0345,  ..., 0.0162, 0.0144, 0.0149],\n",
      "        [0.0412, 0.0357, 0.0328,  ..., 0.0380, 0.0337, 0.0408],\n",
      "        [0.0423, 0.0421, 0.0422,  ..., 0.0446, 0.0455, 0.0412],\n",
      "        ...,\n",
      "        [0.0427, 0.0365, 0.0391,  ..., 0.0363, 0.0317, 0.0259],\n",
      "        [0.0445, 0.0378, 0.0369,  ..., 0.0234, 0.0238, 0.0222],\n",
      "        [0.0450, 0.0439, 0.0428,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1741, 0.2901, 0.6963],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0313],\n",
      "        [0.0000, 0.0573, 0.0000,  ..., 0.0000, 0.0000, 0.1992],\n",
      "        [5.8950, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[11]-[1] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[2] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[3] lr=[0.7763214215591338] loss=[0.007]\n",
      "[all_10]-[11]-[4] lr=[0.7763214215591338] loss=[0.005]\n",
      "[all_10]-[11]-[5] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[6] lr=[0.7763214215591338] loss=[0.007]\n",
      "[all_10]-[11]-[7] lr=[0.7763214215591338] loss=[0.005]\n",
      "[all_10]-[11]-[8] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[9] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[10] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[11] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[12] lr=[0.7763214215591338] loss=[0.007]\n",
      "[all_10]-[11]-[13] lr=[0.7763214215591338] loss=[0.007]\n",
      "[all_10]-[11]-[14] lr=[0.7763214215591338] loss=[0.007]\n",
      "[all_10]-[11]-[15] lr=[0.7763214215591338] loss=[0.005]\n",
      "[all_10]-[11]-[16] lr=[0.7763214215591338] loss=[0.005]\n",
      "[all_10]-[11]-[17] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[18] lr=[0.7763214215591338] loss=[0.007]\n",
      "[all_10]-[11]-[19] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[20] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[21] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[22] lr=[0.7763214215591338] loss=[0.007]\n",
      "[all_10]-[11]-[23] lr=[0.7763214215591338] loss=[0.005]\n",
      "[all_10]-[11]-[24] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[25] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[26] lr=[0.7763214215591338] loss=[0.005]\n",
      "[all_10]-[11]-[27] lr=[0.7763214215591338] loss=[0.008]\n",
      "[all_10]-[11]-[28] lr=[0.7763214215591338] loss=[0.007]\n",
      "[all_10]-[11]-[29] lr=[0.7763214215591338] loss=[0.007]\n",
      "[all_10]-[11]-[30] lr=[0.7763214215591338] loss=[0.007]\n",
      "[all_10]-[11]-[31] lr=[0.7763214215591338] loss=[0.005]\n",
      "[all_10]-[11]-[32] lr=[0.7763214215591338] loss=[0.007]\n",
      "[all_10]-[11]-[33] lr=[0.7763214215591338] loss=[0.007]\n",
      "[all_10]-[11]-[34] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[35] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[36] lr=[0.7763214215591338] loss=[0.008]\n",
      "[all_10]-[11]-[37] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[38] lr=[0.7763214215591338] loss=[0.007]\n",
      "[all_10]-[11]-[39] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[40] lr=[0.7763214215591338] loss=[0.007]\n",
      "[all_10]-[11]-[41] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[42] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[43] lr=[0.7763214215591338] loss=[0.007]\n",
      "[all_10]-[11]-[44] lr=[0.7763214215591338] loss=[0.007]\n",
      "[all_10]-[11]-[45] lr=[0.7763214215591338] loss=[0.008]\n",
      "[all_10]-[11]-[46] lr=[0.7763214215591338] loss=[0.006]\n",
      "[all_10]-[11]-[47] lr=[0.7763214215591338] loss=[0.004]\n",
      "[all_10]-[11]-[48] lr=[0.7763214215591338] loss=[0.006]\n",
      "tensor([[0.0546, 0.0639, 0.0595,  ..., 0.0258, 0.0251, 0.0273],\n",
      "        [0.0413, 0.0385, 0.0371,  ..., 0.0263, 0.0363, 0.0292],\n",
      "        [0.0422, 0.0377, 0.0365,  ..., 0.0210, 0.0219, 0.0207],\n",
      "        ...,\n",
      "        [0.0500, 0.0538, 0.0469,  ..., 0.0457, 0.0365, 0.0257],\n",
      "        [0.0542, 0.0571, 0.0566,  ..., 0.0256, 0.0280, 0.0347],\n",
      "        [0.0428, 0.0391, 0.0501,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.3082, 0.1541,  ..., 0.0000, 1.3867, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6608,  ..., 0.0000, 0.0000, 0.0143],\n",
      "        [0.0000, 0.0000, 0.5530,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.1574,  ..., 0.0000, 0.0000, 0.0218],\n",
      "        [0.0000, 0.0000, 0.3122,  ..., 0.1398, 0.0000, 0.0000],\n",
      "        [0.0540, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[12]-[1] lr=[0.7739924572944563] loss=[0.007]\n",
      "[all_10]-[12]-[2] lr=[0.7739924572944563] loss=[0.007]\n",
      "[all_10]-[12]-[3] lr=[0.7739924572944563] loss=[0.005]\n",
      "[all_10]-[12]-[4] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[5] lr=[0.7739924572944563] loss=[0.007]\n",
      "[all_10]-[12]-[6] lr=[0.7739924572944563] loss=[0.007]\n",
      "[all_10]-[12]-[7] lr=[0.7739924572944563] loss=[0.007]\n",
      "[all_10]-[12]-[8] lr=[0.7739924572944563] loss=[0.005]\n",
      "[all_10]-[12]-[9] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[10] lr=[0.7739924572944563] loss=[0.007]\n",
      "[all_10]-[12]-[11] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[12] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[13] lr=[0.7739924572944563] loss=[0.007]\n",
      "[all_10]-[12]-[14] lr=[0.7739924572944563] loss=[0.007]\n",
      "[all_10]-[12]-[15] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[16] lr=[0.7739924572944563] loss=[0.007]\n",
      "[all_10]-[12]-[17] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[18] lr=[0.7739924572944563] loss=[0.007]\n",
      "[all_10]-[12]-[19] lr=[0.7739924572944563] loss=[0.005]\n",
      "[all_10]-[12]-[20] lr=[0.7739924572944563] loss=[0.005]\n",
      "[all_10]-[12]-[21] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[22] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[23] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[24] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[25] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[26] lr=[0.7739924572944563] loss=[0.007]\n",
      "[all_10]-[12]-[27] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[28] lr=[0.7739924572944563] loss=[0.007]\n",
      "[all_10]-[12]-[29] lr=[0.7739924572944563] loss=[0.005]\n",
      "[all_10]-[12]-[30] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[31] lr=[0.7739924572944563] loss=[0.005]\n",
      "[all_10]-[12]-[32] lr=[0.7739924572944563] loss=[0.007]\n",
      "[all_10]-[12]-[33] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[34] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[35] lr=[0.7739924572944563] loss=[0.007]\n",
      "[all_10]-[12]-[36] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[37] lr=[0.7739924572944563] loss=[0.007]\n",
      "[all_10]-[12]-[38] lr=[0.7739924572944563] loss=[0.008]\n",
      "[all_10]-[12]-[39] lr=[0.7739924572944563] loss=[0.005]\n",
      "[all_10]-[12]-[40] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[41] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[42] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[43] lr=[0.7739924572944563] loss=[0.007]\n",
      "[all_10]-[12]-[44] lr=[0.7739924572944563] loss=[0.008]\n",
      "[all_10]-[12]-[45] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[46] lr=[0.7739924572944563] loss=[0.006]\n",
      "[all_10]-[12]-[47] lr=[0.7739924572944563] loss=[0.007]\n",
      "[all_10]-[12]-[48] lr=[0.7739924572944563] loss=[0.006]\n",
      "tensor([[0.0582, 0.0571, 0.0487,  ..., 0.0442, 0.0601, 0.0614],\n",
      "        [0.0397, 0.0608, 0.0741,  ..., 0.0197, 0.0193, 0.0173],\n",
      "        [0.0470, 0.0455, 0.0420,  ..., 0.0216, 0.0253, 0.0258],\n",
      "        ...,\n",
      "        [0.0426, 0.0476, 0.0482,  ..., 0.0095, 0.0094, 0.0119],\n",
      "        [0.0417, 0.0395, 0.0364,  ..., 0.0180, 0.0154, 0.0141],\n",
      "        [0.0490, 0.0552, 0.0649,  ..., 0.0131, 0.0187, 0.0256]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0532, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2522,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0847, 0.0528, 0.2594,  ..., 0.0583, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0142, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[13]-[1] lr=[0.771670479922573] loss=[0.007]\n",
      "[all_10]-[13]-[2] lr=[0.771670479922573] loss=[0.005]\n",
      "[all_10]-[13]-[3] lr=[0.771670479922573] loss=[0.006]\n",
      "[all_10]-[13]-[4] lr=[0.771670479922573] loss=[0.007]\n",
      "[all_10]-[13]-[5] lr=[0.771670479922573] loss=[0.006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[13]-[6] lr=[0.771670479922573] loss=[0.006]\n",
      "[all_10]-[13]-[7] lr=[0.771670479922573] loss=[0.007]\n",
      "[all_10]-[13]-[8] lr=[0.771670479922573] loss=[0.007]\n",
      "[all_10]-[13]-[9] lr=[0.771670479922573] loss=[0.005]\n",
      "[all_10]-[13]-[10] lr=[0.771670479922573] loss=[0.006]\n",
      "[all_10]-[13]-[11] lr=[0.771670479922573] loss=[0.008]\n",
      "[all_10]-[13]-[12] lr=[0.771670479922573] loss=[0.005]\n",
      "[all_10]-[13]-[13] lr=[0.771670479922573] loss=[0.005]\n",
      "[all_10]-[13]-[14] lr=[0.771670479922573] loss=[0.007]\n",
      "[all_10]-[13]-[15] lr=[0.771670479922573] loss=[0.008]\n",
      "[all_10]-[13]-[16] lr=[0.771670479922573] loss=[0.005]\n",
      "[all_10]-[13]-[17] lr=[0.771670479922573] loss=[0.006]\n",
      "[all_10]-[13]-[18] lr=[0.771670479922573] loss=[0.007]\n",
      "[all_10]-[13]-[19] lr=[0.771670479922573] loss=[0.008]\n",
      "[all_10]-[13]-[20] lr=[0.771670479922573] loss=[0.007]\n",
      "[all_10]-[13]-[21] lr=[0.771670479922573] loss=[0.005]\n",
      "[all_10]-[13]-[22] lr=[0.771670479922573] loss=[0.007]\n",
      "[all_10]-[13]-[23] lr=[0.771670479922573] loss=[0.006]\n",
      "[all_10]-[13]-[24] lr=[0.771670479922573] loss=[0.008]\n",
      "[all_10]-[13]-[25] lr=[0.771670479922573] loss=[0.006]\n",
      "[all_10]-[13]-[26] lr=[0.771670479922573] loss=[0.006]\n",
      "[all_10]-[13]-[27] lr=[0.771670479922573] loss=[0.006]\n",
      "[all_10]-[13]-[28] lr=[0.771670479922573] loss=[0.006]\n",
      "[all_10]-[13]-[29] lr=[0.771670479922573] loss=[0.007]\n",
      "[all_10]-[13]-[30] lr=[0.771670479922573] loss=[0.005]\n",
      "[all_10]-[13]-[31] lr=[0.771670479922573] loss=[0.007]\n",
      "[all_10]-[13]-[32] lr=[0.771670479922573] loss=[0.006]\n",
      "[all_10]-[13]-[33] lr=[0.771670479922573] loss=[0.006]\n",
      "[all_10]-[13]-[34] lr=[0.771670479922573] loss=[0.007]\n",
      "[all_10]-[13]-[35] lr=[0.771670479922573] loss=[0.006]\n",
      "[all_10]-[13]-[36] lr=[0.771670479922573] loss=[0.007]\n",
      "[all_10]-[13]-[37] lr=[0.771670479922573] loss=[0.006]\n",
      "[all_10]-[13]-[38] lr=[0.771670479922573] loss=[0.006]\n",
      "[all_10]-[13]-[39] lr=[0.771670479922573] loss=[0.006]\n",
      "[all_10]-[13]-[40] lr=[0.771670479922573] loss=[0.005]\n",
      "[all_10]-[13]-[41] lr=[0.771670479922573] loss=[0.006]\n",
      "[all_10]-[13]-[42] lr=[0.771670479922573] loss=[0.006]\n",
      "[all_10]-[13]-[43] lr=[0.771670479922573] loss=[0.007]\n",
      "[all_10]-[13]-[44] lr=[0.771670479922573] loss=[0.006]\n",
      "[all_10]-[13]-[45] lr=[0.771670479922573] loss=[0.007]\n",
      "[all_10]-[13]-[46] lr=[0.771670479922573] loss=[0.006]\n",
      "[all_10]-[13]-[47] lr=[0.771670479922573] loss=[0.005]\n",
      "[all_10]-[13]-[48] lr=[0.771670479922573] loss=[0.008]\n",
      "tensor([[0.0405, 0.0430, 0.0499,  ..., 0.0180, 0.0122, 0.0099],\n",
      "        [0.0405, 0.0503, 0.0537,  ..., 0.0154, 0.0132, 0.0131],\n",
      "        [0.0508, 0.0565, 0.0517,  ..., 0.0169, 0.0152, 0.0131],\n",
      "        ...,\n",
      "        [0.0505, 0.0564, 0.0523,  ..., 0.0203, 0.0177, 0.0175],\n",
      "        [0.0455, 0.0562, 0.0584,  ..., 0.0151, 0.0171, 0.0157],\n",
      "        [0.0507, 0.0583, 0.0582,  ..., 0.0230, 0.0313, 0.0346]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0188, 0.0000,  ..., 0.0000, 0.0000, 0.0067],\n",
      "        [0.0000, 0.0852, 0.0420,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3438, 0.1959, 0.2522,  ..., 0.0000, 0.0403, 0.0000],\n",
      "        ...,\n",
      "        [0.0255, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0045, 2.3592,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 3.0004, 0.0000,  ..., 0.0000, 0.0000, 0.0150]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[14]-[1] lr=[0.7693554684828052] loss=[0.005]\n",
      "[all_10]-[14]-[2] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[3] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[4] lr=[0.7693554684828052] loss=[0.007]\n",
      "[all_10]-[14]-[5] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[6] lr=[0.7693554684828052] loss=[0.008]\n",
      "[all_10]-[14]-[7] lr=[0.7693554684828052] loss=[0.005]\n",
      "[all_10]-[14]-[8] lr=[0.7693554684828052] loss=[0.005]\n",
      "[all_10]-[14]-[9] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[10] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[11] lr=[0.7693554684828052] loss=[0.007]\n",
      "[all_10]-[14]-[12] lr=[0.7693554684828052] loss=[0.005]\n",
      "[all_10]-[14]-[13] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[14] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[15] lr=[0.7693554684828052] loss=[0.007]\n",
      "[all_10]-[14]-[16] lr=[0.7693554684828052] loss=[0.005]\n",
      "[all_10]-[14]-[17] lr=[0.7693554684828052] loss=[0.007]\n",
      "[all_10]-[14]-[18] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[19] lr=[0.7693554684828052] loss=[0.007]\n",
      "[all_10]-[14]-[20] lr=[0.7693554684828052] loss=[0.005]\n",
      "[all_10]-[14]-[21] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[22] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[23] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[24] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[25] lr=[0.7693554684828052] loss=[0.005]\n",
      "[all_10]-[14]-[26] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[27] lr=[0.7693554684828052] loss=[0.005]\n",
      "[all_10]-[14]-[28] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[29] lr=[0.7693554684828052] loss=[0.007]\n",
      "[all_10]-[14]-[30] lr=[0.7693554684828052] loss=[0.005]\n",
      "[all_10]-[14]-[31] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[32] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[33] lr=[0.7693554684828052] loss=[0.007]\n",
      "[all_10]-[14]-[34] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[35] lr=[0.7693554684828052] loss=[0.007]\n",
      "[all_10]-[14]-[36] lr=[0.7693554684828052] loss=[0.007]\n",
      "[all_10]-[14]-[37] lr=[0.7693554684828052] loss=[0.007]\n",
      "[all_10]-[14]-[38] lr=[0.7693554684828052] loss=[0.008]\n",
      "[all_10]-[14]-[39] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[40] lr=[0.7693554684828052] loss=[0.007]\n",
      "[all_10]-[14]-[41] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[42] lr=[0.7693554684828052] loss=[0.007]\n",
      "[all_10]-[14]-[43] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[44] lr=[0.7693554684828052] loss=[0.007]\n",
      "[all_10]-[14]-[45] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[46] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[47] lr=[0.7693554684828052] loss=[0.006]\n",
      "[all_10]-[14]-[48] lr=[0.7693554684828052] loss=[0.006]\n",
      "tensor([[0.0406, 0.0441, 0.0439,  ..., 0.0229, 0.0260, 0.0246],\n",
      "        [0.0311, 0.0364, 0.0391,  ..., 0.0168, 0.0111, 0.0066],\n",
      "        [0.0311, 0.0421, 0.0505,  ..., 0.0153, 0.0152, 0.0148],\n",
      "        ...,\n",
      "        [0.0320, 0.0326, 0.0326,  ..., 0.0049, 0.0038, 0.0028],\n",
      "        [0.0317, 0.0345, 0.0351,  ..., 0.0287, 0.0214, 0.0220],\n",
      "        [0.0307, 0.0365, 0.0394,  ..., 0.0257, 0.0174, 0.0150]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0520, 0.0000, 0.4347,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0110, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0600,  ..., 0.0063, 0.0063, 0.0000],\n",
      "        ...,\n",
      "        [0.0094, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2604,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[15]-[1] lr=[0.7670474020773568] loss=[0.007]\n",
      "[all_10]-[15]-[2] lr=[0.7670474020773568] loss=[0.006]\n",
      "[all_10]-[15]-[3] lr=[0.7670474020773568] loss=[0.005]\n",
      "[all_10]-[15]-[4] lr=[0.7670474020773568] loss=[0.006]\n",
      "[all_10]-[15]-[5] lr=[0.7670474020773568] loss=[0.007]\n",
      "[all_10]-[15]-[6] lr=[0.7670474020773568] loss=[0.006]\n",
      "[all_10]-[15]-[7] lr=[0.7670474020773568] loss=[0.006]\n",
      "[all_10]-[15]-[8] lr=[0.7670474020773568] loss=[0.005]\n",
      "[all_10]-[15]-[9] lr=[0.7670474020773568] loss=[0.006]\n",
      "[all_10]-[15]-[10] lr=[0.7670474020773568] loss=[0.006]\n",
      "[all_10]-[15]-[11] lr=[0.7670474020773568] loss=[0.006]\n",
      "[all_10]-[15]-[12] lr=[0.7670474020773568] loss=[0.007]\n",
      "[all_10]-[15]-[13] lr=[0.7670474020773568] loss=[0.006]\n",
      "[all_10]-[15]-[14] lr=[0.7670474020773568] loss=[0.005]\n",
      "[all_10]-[15]-[15] lr=[0.7670474020773568] loss=[0.006]\n",
      "[all_10]-[15]-[16] lr=[0.7670474020773568] loss=[0.007]\n",
      "[all_10]-[15]-[17] lr=[0.7670474020773568] loss=[0.006]\n",
      "[all_10]-[15]-[18] lr=[0.7670474020773568] loss=[0.006]\n",
      "[all_10]-[15]-[19] lr=[0.7670474020773568] loss=[0.006]\n",
      "[all_10]-[15]-[20] lr=[0.7670474020773568] loss=[0.005]\n",
      "[all_10]-[15]-[21] lr=[0.7670474020773568] loss=[0.007]\n",
      "[all_10]-[15]-[22] lr=[0.7670474020773568] loss=[0.005]\n",
      "[all_10]-[15]-[23] lr=[0.7670474020773568] loss=[0.007]\n",
      "[all_10]-[15]-[24] lr=[0.7670474020773568] loss=[0.005]\n",
      "[all_10]-[15]-[25] lr=[0.7670474020773568] loss=[0.007]\n",
      "[all_10]-[15]-[26] lr=[0.7670474020773568] loss=[0.008]\n",
      "[all_10]-[15]-[27] lr=[0.7670474020773568] loss=[0.005]\n",
      "[all_10]-[15]-[28] lr=[0.7670474020773568] loss=[0.007]\n",
      "[all_10]-[15]-[29] lr=[0.7670474020773568] loss=[0.007]\n",
      "[all_10]-[15]-[30] lr=[0.7670474020773568] loss=[0.007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[15]-[31] lr=[0.7670474020773568] loss=[0.005]\n",
      "[all_10]-[15]-[32] lr=[0.7670474020773568] loss=[0.006]\n",
      "[all_10]-[15]-[33] lr=[0.7670474020773568] loss=[0.007]\n",
      "[all_10]-[15]-[34] lr=[0.7670474020773568] loss=[0.006]\n",
      "[all_10]-[15]-[35] lr=[0.7670474020773568] loss=[0.005]\n",
      "[all_10]-[15]-[36] lr=[0.7670474020773568] loss=[0.008]\n",
      "[all_10]-[15]-[37] lr=[0.7670474020773568] loss=[0.006]\n",
      "[all_10]-[15]-[38] lr=[0.7670474020773568] loss=[0.008]\n",
      "[all_10]-[15]-[39] lr=[0.7670474020773568] loss=[0.007]\n",
      "[all_10]-[15]-[40] lr=[0.7670474020773568] loss=[0.007]\n",
      "[all_10]-[15]-[41] lr=[0.7670474020773568] loss=[0.006]\n",
      "[all_10]-[15]-[42] lr=[0.7670474020773568] loss=[0.005]\n",
      "[all_10]-[15]-[43] lr=[0.7670474020773568] loss=[0.006]\n",
      "[all_10]-[15]-[44] lr=[0.7670474020773568] loss=[0.006]\n",
      "[all_10]-[15]-[45] lr=[0.7670474020773568] loss=[0.007]\n",
      "[all_10]-[15]-[46] lr=[0.7670474020773568] loss=[0.007]\n",
      "[all_10]-[15]-[47] lr=[0.7670474020773568] loss=[0.006]\n",
      "[all_10]-[15]-[48] lr=[0.7670474020773568] loss=[0.007]\n",
      "tensor([[0.0439, 0.0599, 0.0646,  ..., 0.0323, 0.0377, 0.0338],\n",
      "        [0.0492, 0.0540, 0.0556,  ..., 0.0240, 0.0237, 0.0185],\n",
      "        [0.0486, 0.0644, 0.0630,  ..., 0.0188, 0.0153, 0.0107],\n",
      "        ...,\n",
      "        [0.0417, 0.0504, 0.0549,  ..., 0.0160, 0.0201, 0.0205],\n",
      "        [0.0403, 0.0477, 0.0508,  ..., 0.0285, 0.0296, 0.0278],\n",
      "        [0.0375, 0.0417, 0.0430,  ..., 0.0178, 0.0262, 0.0273]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0887, 0.0000, 0.0000,  ..., 0.0000, 0.0887, 0.0000],\n",
      "        [0.0000, 0.0000, 0.4947,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0254,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.5949,  ..., 0.0000, 0.0000, 0.0496],\n",
      "        [0.0000, 0.0320, 0.0260,  ..., 0.0606, 0.0000, 0.0392]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[16]-[1] lr=[0.7647462598711247] loss=[0.007]\n",
      "[all_10]-[16]-[2] lr=[0.7647462598711247] loss=[0.007]\n",
      "[all_10]-[16]-[3] lr=[0.7647462598711247] loss=[0.007]\n",
      "[all_10]-[16]-[4] lr=[0.7647462598711247] loss=[0.007]\n",
      "[all_10]-[16]-[5] lr=[0.7647462598711247] loss=[0.006]\n",
      "[all_10]-[16]-[6] lr=[0.7647462598711247] loss=[0.005]\n",
      "[all_10]-[16]-[7] lr=[0.7647462598711247] loss=[0.005]\n",
      "[all_10]-[16]-[8] lr=[0.7647462598711247] loss=[0.006]\n",
      "[all_10]-[16]-[9] lr=[0.7647462598711247] loss=[0.005]\n",
      "[all_10]-[16]-[10] lr=[0.7647462598711247] loss=[0.007]\n",
      "[all_10]-[16]-[11] lr=[0.7647462598711247] loss=[0.006]\n",
      "[all_10]-[16]-[12] lr=[0.7647462598711247] loss=[0.006]\n",
      "[all_10]-[16]-[13] lr=[0.7647462598711247] loss=[0.006]\n",
      "[all_10]-[16]-[14] lr=[0.7647462598711247] loss=[0.006]\n",
      "[all_10]-[16]-[15] lr=[0.7647462598711247] loss=[0.007]\n",
      "[all_10]-[16]-[16] lr=[0.7647462598711247] loss=[0.007]\n",
      "[all_10]-[16]-[17] lr=[0.7647462598711247] loss=[0.006]\n",
      "[all_10]-[16]-[18] lr=[0.7647462598711247] loss=[0.007]\n",
      "[all_10]-[16]-[19] lr=[0.7647462598711247] loss=[0.007]\n",
      "[all_10]-[16]-[20] lr=[0.7647462598711247] loss=[0.008]\n",
      "[all_10]-[16]-[21] lr=[0.7647462598711247] loss=[0.007]\n",
      "[all_10]-[16]-[22] lr=[0.7647462598711247] loss=[0.006]\n",
      "[all_10]-[16]-[23] lr=[0.7647462598711247] loss=[0.007]\n",
      "[all_10]-[16]-[24] lr=[0.7647462598711247] loss=[0.006]\n",
      "[all_10]-[16]-[25] lr=[0.7647462598711247] loss=[0.006]\n",
      "[all_10]-[16]-[26] lr=[0.7647462598711247] loss=[0.006]\n",
      "[all_10]-[16]-[27] lr=[0.7647462598711247] loss=[0.005]\n",
      "[all_10]-[16]-[28] lr=[0.7647462598711247] loss=[0.005]\n",
      "[all_10]-[16]-[29] lr=[0.7647462598711247] loss=[0.008]\n",
      "[all_10]-[16]-[30] lr=[0.7647462598711247] loss=[0.007]\n",
      "[all_10]-[16]-[31] lr=[0.7647462598711247] loss=[0.006]\n",
      "[all_10]-[16]-[32] lr=[0.7647462598711247] loss=[0.006]\n",
      "[all_10]-[16]-[33] lr=[0.7647462598711247] loss=[0.007]\n",
      "[all_10]-[16]-[34] lr=[0.7647462598711247] loss=[0.007]\n",
      "[all_10]-[16]-[35] lr=[0.7647462598711247] loss=[0.005]\n",
      "[all_10]-[16]-[36] lr=[0.7647462598711247] loss=[0.007]\n",
      "[all_10]-[16]-[37] lr=[0.7647462598711247] loss=[0.005]\n",
      "[all_10]-[16]-[38] lr=[0.7647462598711247] loss=[0.006]\n",
      "[all_10]-[16]-[39] lr=[0.7647462598711247] loss=[0.006]\n",
      "[all_10]-[16]-[40] lr=[0.7647462598711247] loss=[0.005]\n",
      "[all_10]-[16]-[41] lr=[0.7647462598711247] loss=[0.007]\n",
      "[all_10]-[16]-[42] lr=[0.7647462598711247] loss=[0.007]\n",
      "[all_10]-[16]-[43] lr=[0.7647462598711247] loss=[0.006]\n",
      "[all_10]-[16]-[44] lr=[0.7647462598711247] loss=[0.007]\n",
      "[all_10]-[16]-[45] lr=[0.7647462598711247] loss=[0.005]\n",
      "[all_10]-[16]-[46] lr=[0.7647462598711247] loss=[0.006]\n",
      "[all_10]-[16]-[47] lr=[0.7647462598711247] loss=[0.007]\n",
      "[all_10]-[16]-[48] lr=[0.7647462598711247] loss=[0.006]\n",
      "tensor([[0.0382, 0.0444, 0.0435,  ..., 0.0095, 0.0173, 0.0198],\n",
      "        [0.0323, 0.0415, 0.0456,  ..., 0.0128, 0.0136, 0.0150],\n",
      "        [0.0361, 0.0459, 0.0476,  ..., 0.0274, 0.0232, 0.0184],\n",
      "        ...,\n",
      "        [0.0368, 0.0463, 0.0497,  ..., 0.0168, 0.0232, 0.0277],\n",
      "        [0.0411, 0.0569, 0.0572,  ..., 0.0155, 0.0138, 0.0150],\n",
      "        [0.0358, 0.0413, 0.0448,  ..., 0.0161, 0.0201, 0.0223]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.1061, 0.0750, 0.2797,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0568, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0065],\n",
      "        [0.0724, 0.6066, 0.0000,  ..., 0.0000, 0.0000, 0.0390],\n",
      "        [0.0000, 0.0000, 0.2898,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[17]-[1] lr=[0.7624520210915113] loss=[0.005]\n",
      "[all_10]-[17]-[2] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[3] lr=[0.7624520210915113] loss=[0.006]\n",
      "[all_10]-[17]-[4] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[5] lr=[0.7624520210915113] loss=[0.006]\n",
      "[all_10]-[17]-[6] lr=[0.7624520210915113] loss=[0.005]\n",
      "[all_10]-[17]-[7] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[8] lr=[0.7624520210915113] loss=[0.006]\n",
      "[all_10]-[17]-[9] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[10] lr=[0.7624520210915113] loss=[0.005]\n",
      "[all_10]-[17]-[11] lr=[0.7624520210915113] loss=[0.006]\n",
      "[all_10]-[17]-[12] lr=[0.7624520210915113] loss=[0.006]\n",
      "[all_10]-[17]-[13] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[14] lr=[0.7624520210915113] loss=[0.005]\n",
      "[all_10]-[17]-[15] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[16] lr=[0.7624520210915113] loss=[0.006]\n",
      "[all_10]-[17]-[17] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[18] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[19] lr=[0.7624520210915113] loss=[0.006]\n",
      "[all_10]-[17]-[20] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[21] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[22] lr=[0.7624520210915113] loss=[0.006]\n",
      "[all_10]-[17]-[23] lr=[0.7624520210915113] loss=[0.006]\n",
      "[all_10]-[17]-[24] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[25] lr=[0.7624520210915113] loss=[0.006]\n",
      "[all_10]-[17]-[26] lr=[0.7624520210915113] loss=[0.005]\n",
      "[all_10]-[17]-[27] lr=[0.7624520210915113] loss=[0.006]\n",
      "[all_10]-[17]-[28] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[29] lr=[0.7624520210915113] loss=[0.006]\n",
      "[all_10]-[17]-[30] lr=[0.7624520210915113] loss=[0.005]\n",
      "[all_10]-[17]-[31] lr=[0.7624520210915113] loss=[0.006]\n",
      "[all_10]-[17]-[32] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[33] lr=[0.7624520210915113] loss=[0.006]\n",
      "[all_10]-[17]-[34] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[35] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[36] lr=[0.7624520210915113] loss=[0.005]\n",
      "[all_10]-[17]-[37] lr=[0.7624520210915113] loss=[0.006]\n",
      "[all_10]-[17]-[38] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[39] lr=[0.7624520210915113] loss=[0.005]\n",
      "[all_10]-[17]-[40] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[41] lr=[0.7624520210915113] loss=[0.006]\n",
      "[all_10]-[17]-[42] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[43] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[44] lr=[0.7624520210915113] loss=[0.007]\n",
      "[all_10]-[17]-[45] lr=[0.7624520210915113] loss=[0.006]\n",
      "[all_10]-[17]-[46] lr=[0.7624520210915113] loss=[0.006]\n",
      "[all_10]-[17]-[47] lr=[0.7624520210915113] loss=[0.006]\n",
      "[all_10]-[17]-[48] lr=[0.7624520210915113] loss=[0.006]\n",
      "tensor([[0.0441, 0.0722, 0.0851,  ..., 0.0059, 0.0043, 0.0036],\n",
      "        [0.0313, 0.0415, 0.0597,  ..., 0.0218, 0.0161, 0.0120],\n",
      "        [0.0404, 0.0655, 0.0761,  ..., 0.0220, 0.0252, 0.0289],\n",
      "        ...,\n",
      "        [0.0255, 0.0326, 0.0393,  ..., 0.0242, 0.0219, 0.0163],\n",
      "        [0.0337, 0.0485, 0.0549,  ..., 0.0110, 0.0041, 0.0106],\n",
      "        [0.0357, 0.0433, 0.0440,  ..., 0.0171, 0.0147, 0.0091]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.1157, 0.0615, 0.1089,  ..., 0.0000, 0.0155, 0.0000],\n",
      "        [0.0000, 0.1027, 0.0000,  ..., 0.0000, 0.0128, 0.0000],\n",
      "        [0.0000, 0.0604, 0.2718,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0772, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0343, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0114],\n",
      "        [4.1614, 0.0699, 0.0172,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[18]-[1] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[2] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[3] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[4] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[5] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[6] lr=[0.7601646650282368] loss=[0.007]\n",
      "[all_10]-[18]-[7] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[8] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[9] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[10] lr=[0.7601646650282368] loss=[0.008]\n",
      "[all_10]-[18]-[11] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[12] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[13] lr=[0.7601646650282368] loss=[0.007]\n",
      "[all_10]-[18]-[14] lr=[0.7601646650282368] loss=[0.005]\n",
      "[all_10]-[18]-[15] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[16] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[17] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[18] lr=[0.7601646650282368] loss=[0.005]\n",
      "[all_10]-[18]-[19] lr=[0.7601646650282368] loss=[0.007]\n",
      "[all_10]-[18]-[20] lr=[0.7601646650282368] loss=[0.007]\n",
      "[all_10]-[18]-[21] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[22] lr=[0.7601646650282368] loss=[0.007]\n",
      "[all_10]-[18]-[23] lr=[0.7601646650282368] loss=[0.005]\n",
      "[all_10]-[18]-[24] lr=[0.7601646650282368] loss=[0.007]\n",
      "[all_10]-[18]-[25] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[26] lr=[0.7601646650282368] loss=[0.007]\n",
      "[all_10]-[18]-[27] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[28] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[29] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[30] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[31] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[32] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[33] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[34] lr=[0.7601646650282368] loss=[0.004]\n",
      "[all_10]-[18]-[35] lr=[0.7601646650282368] loss=[0.007]\n",
      "[all_10]-[18]-[36] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[37] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[38] lr=[0.7601646650282368] loss=[0.005]\n",
      "[all_10]-[18]-[39] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[40] lr=[0.7601646650282368] loss=[0.009]\n",
      "[all_10]-[18]-[41] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[42] lr=[0.7601646650282368] loss=[0.007]\n",
      "[all_10]-[18]-[43] lr=[0.7601646650282368] loss=[0.007]\n",
      "[all_10]-[18]-[44] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[45] lr=[0.7601646650282368] loss=[0.005]\n",
      "[all_10]-[18]-[46] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[47] lr=[0.7601646650282368] loss=[0.006]\n",
      "[all_10]-[18]-[48] lr=[0.7601646650282368] loss=[0.007]\n",
      "tensor([[0.0397, 0.0540, 0.0592,  ..., 0.0187, 0.0168, 0.0158],\n",
      "        [0.0399, 0.0618, 0.0775,  ..., 0.0625, 0.0644, 0.0714],\n",
      "        [0.0305, 0.0431, 0.0541,  ..., 0.0356, 0.0291, 0.0210],\n",
      "        ...,\n",
      "        [0.0301, 0.0414, 0.0476,  ..., 0.0205, 0.0148, 0.0122],\n",
      "        [0.0304, 0.0391, 0.0457,  ..., 0.0142, 0.0203, 0.0237],\n",
      "        [0.0361, 0.0574, 0.0663,  ..., 0.0259, 0.0227, 0.0173]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.1284, 0.0000, 0.7249,  ..., 0.0770, 0.0000, 0.0000],\n",
      "        [0.0000, 0.9079, 0.0712,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.1879, 0.0982,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0622, 0.0000],\n",
      "        [0.0000, 0.0800, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[19]-[1] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[2] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[3] lr=[0.7578841710331521] loss=[0.007]\n",
      "[all_10]-[19]-[4] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[5] lr=[0.7578841710331521] loss=[0.008]\n",
      "[all_10]-[19]-[6] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[7] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[8] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[9] lr=[0.7578841710331521] loss=[0.007]\n",
      "[all_10]-[19]-[10] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[11] lr=[0.7578841710331521] loss=[0.005]\n",
      "[all_10]-[19]-[12] lr=[0.7578841710331521] loss=[0.007]\n",
      "[all_10]-[19]-[13] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[14] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[15] lr=[0.7578841710331521] loss=[0.007]\n",
      "[all_10]-[19]-[16] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[17] lr=[0.7578841710331521] loss=[0.005]\n",
      "[all_10]-[19]-[18] lr=[0.7578841710331521] loss=[0.007]\n",
      "[all_10]-[19]-[19] lr=[0.7578841710331521] loss=[0.005]\n",
      "[all_10]-[19]-[20] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[21] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[22] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[23] lr=[0.7578841710331521] loss=[0.005]\n",
      "[all_10]-[19]-[24] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[25] lr=[0.7578841710331521] loss=[0.007]\n",
      "[all_10]-[19]-[26] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[27] lr=[0.7578841710331521] loss=[0.007]\n",
      "[all_10]-[19]-[28] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[29] lr=[0.7578841710331521] loss=[0.005]\n",
      "[all_10]-[19]-[30] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[31] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[32] lr=[0.7578841710331521] loss=[0.007]\n",
      "[all_10]-[19]-[33] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[34] lr=[0.7578841710331521] loss=[0.007]\n",
      "[all_10]-[19]-[35] lr=[0.7578841710331521] loss=[0.005]\n",
      "[all_10]-[19]-[36] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[37] lr=[0.7578841710331521] loss=[0.005]\n",
      "[all_10]-[19]-[38] lr=[0.7578841710331521] loss=[0.007]\n",
      "[all_10]-[19]-[39] lr=[0.7578841710331521] loss=[0.005]\n",
      "[all_10]-[19]-[40] lr=[0.7578841710331521] loss=[0.007]\n",
      "[all_10]-[19]-[41] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[42] lr=[0.7578841710331521] loss=[0.007]\n",
      "[all_10]-[19]-[43] lr=[0.7578841710331521] loss=[0.007]\n",
      "[all_10]-[19]-[44] lr=[0.7578841710331521] loss=[0.007]\n",
      "[all_10]-[19]-[45] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[46] lr=[0.7578841710331521] loss=[0.007]\n",
      "[all_10]-[19]-[47] lr=[0.7578841710331521] loss=[0.006]\n",
      "[all_10]-[19]-[48] lr=[0.7578841710331521] loss=[0.007]\n",
      "tensor([[ 0.0218,  0.0470,  0.0580,  ...,  0.0056,  0.0061,  0.0023],\n",
      "        [ 0.0291,  0.0470,  0.0496,  ..., -0.0027, -0.0030, -0.0016],\n",
      "        [ 0.0203,  0.0471,  0.0598,  ..., -0.0022, -0.0030, -0.0049],\n",
      "        ...,\n",
      "        [ 0.0253,  0.0368,  0.0379,  ...,  0.0195,  0.0204,  0.0167],\n",
      "        [ 0.0166,  0.0319,  0.0545,  ...,  0.0096,  0.0076,  0.0036],\n",
      "        [ 0.0175,  0.0339,  0.0438,  ...,  0.0058,  0.0036,  0.0041]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.3443, 0.1788,  ..., 0.0000, 0.0000, 0.0467],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0106, 0.0811, 0.0000,  ..., 0.0000, 0.0000, 0.0181],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0373, 0.0000,  ..., 0.0000, 0.0323, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[20]-[1] lr=[0.7556105185200527] loss=[0.007]\n",
      "[all_10]-[20]-[2] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[3] lr=[0.7556105185200527] loss=[0.007]\n",
      "[all_10]-[20]-[4] lr=[0.7556105185200527] loss=[0.005]\n",
      "[all_10]-[20]-[5] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[6] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[7] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[8] lr=[0.7556105185200527] loss=[0.007]\n",
      "[all_10]-[20]-[9] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[10] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[11] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[12] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[13] lr=[0.7556105185200527] loss=[0.005]\n",
      "[all_10]-[20]-[14] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[15] lr=[0.7556105185200527] loss=[0.009]\n",
      "[all_10]-[20]-[16] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[17] lr=[0.7556105185200527] loss=[0.008]\n",
      "[all_10]-[20]-[18] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[19] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[20] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[21] lr=[0.7556105185200527] loss=[0.007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[20]-[22] lr=[0.7556105185200527] loss=[0.005]\n",
      "[all_10]-[20]-[23] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[24] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[25] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[26] lr=[0.7556105185200527] loss=[0.005]\n",
      "[all_10]-[20]-[27] lr=[0.7556105185200527] loss=[0.007]\n",
      "[all_10]-[20]-[28] lr=[0.7556105185200527] loss=[0.007]\n",
      "[all_10]-[20]-[29] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[30] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[31] lr=[0.7556105185200527] loss=[0.007]\n",
      "[all_10]-[20]-[32] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[33] lr=[0.7556105185200527] loss=[0.007]\n",
      "[all_10]-[20]-[34] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[35] lr=[0.7556105185200527] loss=[0.005]\n",
      "[all_10]-[20]-[36] lr=[0.7556105185200527] loss=[0.005]\n",
      "[all_10]-[20]-[37] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[38] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[39] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[40] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[41] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[42] lr=[0.7556105185200527] loss=[0.007]\n",
      "[all_10]-[20]-[43] lr=[0.7556105185200527] loss=[0.007]\n",
      "[all_10]-[20]-[44] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[45] lr=[0.7556105185200527] loss=[0.007]\n",
      "[all_10]-[20]-[46] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[47] lr=[0.7556105185200527] loss=[0.006]\n",
      "[all_10]-[20]-[48] lr=[0.7556105185200527] loss=[0.007]\n",
      "tensor([[0.0362, 0.0584, 0.0697,  ..., 0.0498, 0.0428, 0.0374],\n",
      "        [0.0365, 0.0525, 0.0598,  ..., 0.0328, 0.0424, 0.0480],\n",
      "        [0.0361, 0.0544, 0.0630,  ..., 0.0286, 0.0244, 0.0198],\n",
      "        ...,\n",
      "        [0.0417, 0.0589, 0.0645,  ..., 0.0250, 0.0285, 0.0330],\n",
      "        [0.0337, 0.0470, 0.0536,  ..., 0.0271, 0.0299, 0.0278],\n",
      "        [0.0407, 0.0550, 0.0584,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0293, 0.0000, 1.9097,  ..., 0.0567, 0.0000, 0.0151],\n",
      "        [0.0000, 0.0000, 0.1415,  ..., 0.0000, 0.0037, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.3329, 0.0000,  ..., 0.1206, 0.0134, 0.0000],\n",
      "        [0.0000, 0.0920, 0.0000,  ..., 0.0000, 0.0427, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[21]-[1] lr=[0.7533436869644925] loss=[0.007]\n",
      "[all_10]-[21]-[2] lr=[0.7533436869644925] loss=[0.007]\n",
      "[all_10]-[21]-[3] lr=[0.7533436869644925] loss=[0.007]\n",
      "[all_10]-[21]-[4] lr=[0.7533436869644925] loss=[0.007]\n",
      "[all_10]-[21]-[5] lr=[0.7533436869644925] loss=[0.005]\n",
      "[all_10]-[21]-[6] lr=[0.7533436869644925] loss=[0.007]\n",
      "[all_10]-[21]-[7] lr=[0.7533436869644925] loss=[0.006]\n",
      "[all_10]-[21]-[8] lr=[0.7533436869644925] loss=[0.008]\n",
      "[all_10]-[21]-[9] lr=[0.7533436869644925] loss=[0.007]\n",
      "[all_10]-[21]-[10] lr=[0.7533436869644925] loss=[0.007]\n",
      "[all_10]-[21]-[11] lr=[0.7533436869644925] loss=[0.006]\n",
      "[all_10]-[21]-[12] lr=[0.7533436869644925] loss=[0.005]\n",
      "[all_10]-[21]-[13] lr=[0.7533436869644925] loss=[0.007]\n",
      "[all_10]-[21]-[14] lr=[0.7533436869644925] loss=[0.006]\n",
      "[all_10]-[21]-[15] lr=[0.7533436869644925] loss=[0.005]\n",
      "[all_10]-[21]-[16] lr=[0.7533436869644925] loss=[0.005]\n",
      "[all_10]-[21]-[17] lr=[0.7533436869644925] loss=[0.007]\n",
      "[all_10]-[21]-[18] lr=[0.7533436869644925] loss=[0.006]\n",
      "[all_10]-[21]-[19] lr=[0.7533436869644925] loss=[0.005]\n",
      "[all_10]-[21]-[20] lr=[0.7533436869644925] loss=[0.006]\n",
      "[all_10]-[21]-[21] lr=[0.7533436869644925] loss=[0.007]\n",
      "[all_10]-[21]-[22] lr=[0.7533436869644925] loss=[0.006]\n",
      "[all_10]-[21]-[23] lr=[0.7533436869644925] loss=[0.006]\n",
      "[all_10]-[21]-[24] lr=[0.7533436869644925] loss=[0.008]\n",
      "[all_10]-[21]-[25] lr=[0.7533436869644925] loss=[0.007]\n",
      "[all_10]-[21]-[26] lr=[0.7533436869644925] loss=[0.008]\n",
      "[all_10]-[21]-[27] lr=[0.7533436869644925] loss=[0.005]\n",
      "[all_10]-[21]-[28] lr=[0.7533436869644925] loss=[0.007]\n",
      "[all_10]-[21]-[29] lr=[0.7533436869644925] loss=[0.006]\n",
      "[all_10]-[21]-[30] lr=[0.7533436869644925] loss=[0.006]\n",
      "[all_10]-[21]-[31] lr=[0.7533436869644925] loss=[0.005]\n",
      "[all_10]-[21]-[32] lr=[0.7533436869644925] loss=[0.006]\n",
      "[all_10]-[21]-[33] lr=[0.7533436869644925] loss=[0.006]\n",
      "[all_10]-[21]-[34] lr=[0.7533436869644925] loss=[0.007]\n",
      "[all_10]-[21]-[35] lr=[0.7533436869644925] loss=[0.004]\n",
      "[all_10]-[21]-[36] lr=[0.7533436869644925] loss=[0.007]\n",
      "[all_10]-[21]-[37] lr=[0.7533436869644925] loss=[0.005]\n",
      "[all_10]-[21]-[38] lr=[0.7533436869644925] loss=[0.006]\n",
      "[all_10]-[21]-[39] lr=[0.7533436869644925] loss=[0.005]\n",
      "[all_10]-[21]-[40] lr=[0.7533436869644925] loss=[0.006]\n",
      "[all_10]-[21]-[41] lr=[0.7533436869644925] loss=[0.006]\n",
      "[all_10]-[21]-[42] lr=[0.7533436869644925] loss=[0.006]\n",
      "[all_10]-[21]-[43] lr=[0.7533436869644925] loss=[0.006]\n",
      "[all_10]-[21]-[44] lr=[0.7533436869644925] loss=[0.006]\n",
      "[all_10]-[21]-[45] lr=[0.7533436869644925] loss=[0.005]\n",
      "[all_10]-[21]-[46] lr=[0.7533436869644925] loss=[0.007]\n",
      "[all_10]-[21]-[47] lr=[0.7533436869644925] loss=[0.007]\n",
      "[all_10]-[21]-[48] lr=[0.7533436869644925] loss=[0.007]\n",
      "tensor([[0.0185, 0.0301, 0.0365,  ..., 0.0133, 0.0145, 0.0133],\n",
      "        [0.0305, 0.0530, 0.0649,  ..., 0.0091, 0.0160, 0.0245],\n",
      "        [0.0202, 0.0389, 0.0490,  ..., 0.0182, 0.0164, 0.0169],\n",
      "        ...,\n",
      "        [0.0212, 0.0373, 0.0451,  ..., 0.0135, 0.0126, 0.0109],\n",
      "        [0.0278, 0.0537, 0.0640,  ..., 0.0043, 0.0027, 0.0033],\n",
      "        [0.0276, 0.0451, 0.0564,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0035,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0387, 0.1007,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0566, 0.0244, 0.0000,  ..., 0.0000, 0.0000, 0.0330],\n",
      "        [0.1954, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[22]-[1] lr=[0.751083655903599] loss=[0.007]\n",
      "[all_10]-[22]-[2] lr=[0.751083655903599] loss=[0.007]\n",
      "[all_10]-[22]-[3] lr=[0.751083655903599] loss=[0.007]\n",
      "[all_10]-[22]-[4] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[5] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[6] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[7] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[8] lr=[0.751083655903599] loss=[0.005]\n",
      "[all_10]-[22]-[9] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[10] lr=[0.751083655903599] loss=[0.005]\n",
      "[all_10]-[22]-[11] lr=[0.751083655903599] loss=[0.005]\n",
      "[all_10]-[22]-[12] lr=[0.751083655903599] loss=[0.007]\n",
      "[all_10]-[22]-[13] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[14] lr=[0.751083655903599] loss=[0.007]\n",
      "[all_10]-[22]-[15] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[16] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[17] lr=[0.751083655903599] loss=[0.005]\n",
      "[all_10]-[22]-[18] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[19] lr=[0.751083655903599] loss=[0.005]\n",
      "[all_10]-[22]-[20] lr=[0.751083655903599] loss=[0.007]\n",
      "[all_10]-[22]-[21] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[22] lr=[0.751083655903599] loss=[0.008]\n",
      "[all_10]-[22]-[23] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[24] lr=[0.751083655903599] loss=[0.005]\n",
      "[all_10]-[22]-[25] lr=[0.751083655903599] loss=[0.007]\n",
      "[all_10]-[22]-[26] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[27] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[28] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[29] lr=[0.751083655903599] loss=[0.008]\n",
      "[all_10]-[22]-[30] lr=[0.751083655903599] loss=[0.005]\n",
      "[all_10]-[22]-[31] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[32] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[33] lr=[0.751083655903599] loss=[0.007]\n",
      "[all_10]-[22]-[34] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[35] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[36] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[37] lr=[0.751083655903599] loss=[0.005]\n",
      "[all_10]-[22]-[38] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[39] lr=[0.751083655903599] loss=[0.005]\n",
      "[all_10]-[22]-[40] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[41] lr=[0.751083655903599] loss=[0.007]\n",
      "[all_10]-[22]-[42] lr=[0.751083655903599] loss=[0.005]\n",
      "[all_10]-[22]-[43] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[44] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[45] lr=[0.751083655903599] loss=[0.005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[22]-[46] lr=[0.751083655903599] loss=[0.006]\n",
      "[all_10]-[22]-[47] lr=[0.751083655903599] loss=[0.007]\n",
      "[all_10]-[22]-[48] lr=[0.751083655903599] loss=[0.008]\n",
      "tensor([[0.0336, 0.0513, 0.0606,  ..., 0.0299, 0.0271, 0.0285],\n",
      "        [0.0288, 0.0518, 0.0647,  ..., 0.0295, 0.0330, 0.0381],\n",
      "        [0.0415, 0.0631, 0.0669,  ..., 0.0231, 0.0288, 0.0310],\n",
      "        ...,\n",
      "        [0.0402, 0.0560, 0.0619,  ..., 0.0333, 0.0311, 0.0259],\n",
      "        [0.0380, 0.0562, 0.0598,  ..., 0.0209, 0.0208, 0.0236],\n",
      "        [0.0354, 0.0554, 0.0721,  ..., 0.0244, 0.0261, 0.0235]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0792,  ..., 0.0060, 0.0070, 0.0064],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0506,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [4.1614, 0.0699, 0.0172,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0186, 0.0000],\n",
      "        [0.0000, 0.0221, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[23]-[1] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[2] lr=[0.7488304049358883] loss=[0.005]\n",
      "[all_10]-[23]-[3] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[4] lr=[0.7488304049358883] loss=[0.007]\n",
      "[all_10]-[23]-[5] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[6] lr=[0.7488304049358883] loss=[0.007]\n",
      "[all_10]-[23]-[7] lr=[0.7488304049358883] loss=[0.005]\n",
      "[all_10]-[23]-[8] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[9] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[10] lr=[0.7488304049358883] loss=[0.007]\n",
      "[all_10]-[23]-[11] lr=[0.7488304049358883] loss=[0.005]\n",
      "[all_10]-[23]-[12] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[13] lr=[0.7488304049358883] loss=[0.007]\n",
      "[all_10]-[23]-[14] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[15] lr=[0.7488304049358883] loss=[0.005]\n",
      "[all_10]-[23]-[16] lr=[0.7488304049358883] loss=[0.008]\n",
      "[all_10]-[23]-[17] lr=[0.7488304049358883] loss=[0.007]\n",
      "[all_10]-[23]-[18] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[19] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[20] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[21] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[22] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[23] lr=[0.7488304049358883] loss=[0.007]\n",
      "[all_10]-[23]-[24] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[25] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[26] lr=[0.7488304049358883] loss=[0.005]\n",
      "[all_10]-[23]-[27] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[28] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[29] lr=[0.7488304049358883] loss=[0.005]\n",
      "[all_10]-[23]-[30] lr=[0.7488304049358883] loss=[0.007]\n",
      "[all_10]-[23]-[31] lr=[0.7488304049358883] loss=[0.005]\n",
      "[all_10]-[23]-[32] lr=[0.7488304049358883] loss=[0.008]\n",
      "[all_10]-[23]-[33] lr=[0.7488304049358883] loss=[0.004]\n",
      "[all_10]-[23]-[34] lr=[0.7488304049358883] loss=[0.008]\n",
      "[all_10]-[23]-[35] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[36] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[37] lr=[0.7488304049358883] loss=[0.007]\n",
      "[all_10]-[23]-[38] lr=[0.7488304049358883] loss=[0.007]\n",
      "[all_10]-[23]-[39] lr=[0.7488304049358883] loss=[0.007]\n",
      "[all_10]-[23]-[40] lr=[0.7488304049358883] loss=[0.005]\n",
      "[all_10]-[23]-[41] lr=[0.7488304049358883] loss=[0.004]\n",
      "[all_10]-[23]-[42] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[43] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[44] lr=[0.7488304049358883] loss=[0.008]\n",
      "[all_10]-[23]-[45] lr=[0.7488304049358883] loss=[0.007]\n",
      "[all_10]-[23]-[46] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[47] lr=[0.7488304049358883] loss=[0.006]\n",
      "[all_10]-[23]-[48] lr=[0.7488304049358883] loss=[0.006]\n",
      "tensor([[0.0281, 0.0515, 0.0673,  ..., 0.0119, 0.0111, 0.0100],\n",
      "        [0.0253, 0.0460, 0.0572,  ..., 0.0172, 0.0180, 0.0178],\n",
      "        [0.0255, 0.0427, 0.0527,  ..., 0.0294, 0.0225, 0.0172],\n",
      "        ...,\n",
      "        [0.0321, 0.0571, 0.0738,  ..., 0.0148, 0.0209, 0.0272],\n",
      "        [0.0258, 0.0467, 0.0583,  ..., 0.0134, 0.0106, 0.0088],\n",
      "        [0.0234, 0.0456, 0.0589,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[1.3742e-02, 0.0000e+00, 0.0000e+00,  ..., 1.3742e-02, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 2.1761e-02, 1.3218e-02,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 7.8544e-02, 5.2046e-03,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.0595e-01, 0.0000e+00, 5.1351e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [5.8950e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='cuda:0')\n",
      "[all_10]-[24]-[1] lr=[0.7465839137210806] loss=[0.007]\n",
      "[all_10]-[24]-[2] lr=[0.7465839137210806] loss=[0.007]\n",
      "[all_10]-[24]-[3] lr=[0.7465839137210806] loss=[0.005]\n",
      "[all_10]-[24]-[4] lr=[0.7465839137210806] loss=[0.007]\n",
      "[all_10]-[24]-[5] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[6] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[7] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[8] lr=[0.7465839137210806] loss=[0.007]\n",
      "[all_10]-[24]-[9] lr=[0.7465839137210806] loss=[0.007]\n",
      "[all_10]-[24]-[10] lr=[0.7465839137210806] loss=[0.007]\n",
      "[all_10]-[24]-[11] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[12] lr=[0.7465839137210806] loss=[0.007]\n",
      "[all_10]-[24]-[13] lr=[0.7465839137210806] loss=[0.008]\n",
      "[all_10]-[24]-[14] lr=[0.7465839137210806] loss=[0.007]\n",
      "[all_10]-[24]-[15] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[16] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[17] lr=[0.7465839137210806] loss=[0.005]\n",
      "[all_10]-[24]-[18] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[19] lr=[0.7465839137210806] loss=[0.008]\n",
      "[all_10]-[24]-[20] lr=[0.7465839137210806] loss=[0.005]\n",
      "[all_10]-[24]-[21] lr=[0.7465839137210806] loss=[0.005]\n",
      "[all_10]-[24]-[22] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[23] lr=[0.7465839137210806] loss=[0.007]\n",
      "[all_10]-[24]-[24] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[25] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[26] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[27] lr=[0.7465839137210806] loss=[0.005]\n",
      "[all_10]-[24]-[28] lr=[0.7465839137210806] loss=[0.007]\n",
      "[all_10]-[24]-[29] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[30] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[31] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[32] lr=[0.7465839137210806] loss=[0.005]\n",
      "[all_10]-[24]-[33] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[34] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[35] lr=[0.7465839137210806] loss=[0.007]\n",
      "[all_10]-[24]-[36] lr=[0.7465839137210806] loss=[0.005]\n",
      "[all_10]-[24]-[37] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[38] lr=[0.7465839137210806] loss=[0.007]\n",
      "[all_10]-[24]-[39] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[40] lr=[0.7465839137210806] loss=[0.007]\n",
      "[all_10]-[24]-[41] lr=[0.7465839137210806] loss=[0.005]\n",
      "[all_10]-[24]-[42] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[43] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[44] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[45] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[46] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[47] lr=[0.7465839137210806] loss=[0.006]\n",
      "[all_10]-[24]-[48] lr=[0.7465839137210806] loss=[0.007]\n",
      "tensor([[0.0229, 0.0389, 0.0488,  ..., 0.0149, 0.0125, 0.0106],\n",
      "        [0.0330, 0.0666, 0.0921,  ..., 0.0202, 0.0166, 0.0168],\n",
      "        [0.0192, 0.0377, 0.0485,  ..., 0.0237, 0.0286, 0.0264],\n",
      "        ...,\n",
      "        [0.0224, 0.0504, 0.0664,  ..., 0.0195, 0.0168, 0.0140],\n",
      "        [0.0255, 0.0491, 0.0606,  ..., 0.0280, 0.0295, 0.0264],\n",
      "        [0.0317, 0.0602, 0.0745,  ..., 0.0252, 0.0205, 0.0156]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0891,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0311, 0.0131, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0786],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1740, 0.0000],\n",
      "        [0.0000, 0.6005, 0.0212,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[25]-[1] lr=[0.7443441619799174] loss=[0.007]\n",
      "[all_10]-[25]-[2] lr=[0.7443441619799174] loss=[0.005]\n",
      "[all_10]-[25]-[3] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[4] lr=[0.7443441619799174] loss=[0.005]\n",
      "[all_10]-[25]-[5] lr=[0.7443441619799174] loss=[0.005]\n",
      "[all_10]-[25]-[6] lr=[0.7443441619799174] loss=[0.007]\n",
      "[all_10]-[25]-[7] lr=[0.7443441619799174] loss=[0.005]\n",
      "[all_10]-[25]-[8] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[9] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[10] lr=[0.7443441619799174] loss=[0.007]\n",
      "[all_10]-[25]-[11] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[12] lr=[0.7443441619799174] loss=[0.007]\n",
      "[all_10]-[25]-[13] lr=[0.7443441619799174] loss=[0.005]\n",
      "[all_10]-[25]-[14] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[15] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[16] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[17] lr=[0.7443441619799174] loss=[0.007]\n",
      "[all_10]-[25]-[18] lr=[0.7443441619799174] loss=[0.007]\n",
      "[all_10]-[25]-[19] lr=[0.7443441619799174] loss=[0.007]\n",
      "[all_10]-[25]-[20] lr=[0.7443441619799174] loss=[0.005]\n",
      "[all_10]-[25]-[21] lr=[0.7443441619799174] loss=[0.005]\n",
      "[all_10]-[25]-[22] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[23] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[24] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[25] lr=[0.7443441619799174] loss=[0.007]\n",
      "[all_10]-[25]-[26] lr=[0.7443441619799174] loss=[0.005]\n",
      "[all_10]-[25]-[27] lr=[0.7443441619799174] loss=[0.007]\n",
      "[all_10]-[25]-[28] lr=[0.7443441619799174] loss=[0.007]\n",
      "[all_10]-[25]-[29] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[30] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[31] lr=[0.7443441619799174] loss=[0.007]\n",
      "[all_10]-[25]-[32] lr=[0.7443441619799174] loss=[0.005]\n",
      "[all_10]-[25]-[33] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[34] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[35] lr=[0.7443441619799174] loss=[0.007]\n",
      "[all_10]-[25]-[36] lr=[0.7443441619799174] loss=[0.007]\n",
      "[all_10]-[25]-[37] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[38] lr=[0.7443441619799174] loss=[0.007]\n",
      "[all_10]-[25]-[39] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[40] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[41] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[42] lr=[0.7443441619799174] loss=[0.005]\n",
      "[all_10]-[25]-[43] lr=[0.7443441619799174] loss=[0.008]\n",
      "[all_10]-[25]-[44] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[45] lr=[0.7443441619799174] loss=[0.007]\n",
      "[all_10]-[25]-[46] lr=[0.7443441619799174] loss=[0.006]\n",
      "[all_10]-[25]-[47] lr=[0.7443441619799174] loss=[0.007]\n",
      "[all_10]-[25]-[48] lr=[0.7443441619799174] loss=[0.007]\n",
      "tensor([[0.0309, 0.0503, 0.0624,  ..., 0.0156, 0.0120, 0.0152],\n",
      "        [0.0357, 0.0680, 0.0837,  ..., 0.0272, 0.0233, 0.0234],\n",
      "        [0.0247, 0.0399, 0.0632,  ..., 0.0175, 0.0137, 0.0126],\n",
      "        ...,\n",
      "        [0.0268, 0.0442, 0.0719,  ..., 0.0349, 0.0279, 0.0239],\n",
      "        [0.0341, 0.0538, 0.0647,  ..., 0.0187, 0.0192, 0.0253],\n",
      "        [0.0324, 0.0578, 0.0727,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0168, 0.0153, 0.1543,  ..., 0.0096, 0.0000, 0.0000],\n",
      "        [0.0553, 0.8854, 0.4427,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1027,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0542,  ..., 0.0000, 0.0000, 0.0305],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[26]-[1] lr=[0.7421111294939776] loss=[0.005]\n",
      "[all_10]-[26]-[2] lr=[0.7421111294939776] loss=[0.005]\n",
      "[all_10]-[26]-[3] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[4] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[5] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[6] lr=[0.7421111294939776] loss=[0.004]\n",
      "[all_10]-[26]-[7] lr=[0.7421111294939776] loss=[0.007]\n",
      "[all_10]-[26]-[8] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[9] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[10] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[11] lr=[0.7421111294939776] loss=[0.005]\n",
      "[all_10]-[26]-[12] lr=[0.7421111294939776] loss=[0.007]\n",
      "[all_10]-[26]-[13] lr=[0.7421111294939776] loss=[0.005]\n",
      "[all_10]-[26]-[14] lr=[0.7421111294939776] loss=[0.005]\n",
      "[all_10]-[26]-[15] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[16] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[17] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[18] lr=[0.7421111294939776] loss=[0.008]\n",
      "[all_10]-[26]-[19] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[20] lr=[0.7421111294939776] loss=[0.005]\n",
      "[all_10]-[26]-[21] lr=[0.7421111294939776] loss=[0.007]\n",
      "[all_10]-[26]-[22] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[23] lr=[0.7421111294939776] loss=[0.008]\n",
      "[all_10]-[26]-[24] lr=[0.7421111294939776] loss=[0.007]\n",
      "[all_10]-[26]-[25] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[26] lr=[0.7421111294939776] loss=[0.007]\n",
      "[all_10]-[26]-[27] lr=[0.7421111294939776] loss=[0.007]\n",
      "[all_10]-[26]-[28] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[29] lr=[0.7421111294939776] loss=[0.009]\n",
      "[all_10]-[26]-[30] lr=[0.7421111294939776] loss=[0.005]\n",
      "[all_10]-[26]-[31] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[32] lr=[0.7421111294939776] loss=[0.007]\n",
      "[all_10]-[26]-[33] lr=[0.7421111294939776] loss=[0.004]\n",
      "[all_10]-[26]-[34] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[35] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[36] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[37] lr=[0.7421111294939776] loss=[0.007]\n",
      "[all_10]-[26]-[38] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[39] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[40] lr=[0.7421111294939776] loss=[0.007]\n",
      "[all_10]-[26]-[41] lr=[0.7421111294939776] loss=[0.008]\n",
      "[all_10]-[26]-[42] lr=[0.7421111294939776] loss=[0.008]\n",
      "[all_10]-[26]-[43] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[44] lr=[0.7421111294939776] loss=[0.005]\n",
      "[all_10]-[26]-[45] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[46] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[47] lr=[0.7421111294939776] loss=[0.006]\n",
      "[all_10]-[26]-[48] lr=[0.7421111294939776] loss=[0.006]\n",
      "tensor([[ 0.0175,  0.0332,  0.0552,  ...,  0.0176,  0.0138,  0.0161],\n",
      "        [ 0.0151,  0.0322,  0.0485,  ...,  0.0070,  0.0049,  0.0069],\n",
      "        [ 0.0156,  0.0326,  0.0411,  ...,  0.0050,  0.0060,  0.0086],\n",
      "        ...,\n",
      "        [ 0.0310,  0.0565,  0.0695,  ...,  0.0137,  0.0156,  0.0203],\n",
      "        [ 0.0182,  0.0421,  0.0581,  ...,  0.0006, -0.0002,  0.0024],\n",
      "        [ 0.0252,  0.0643,  0.0851,  ...,  0.0333,  0.0302,  0.0242]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.3122,  ..., 0.1398, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[27]-[1] lr=[0.7398847961054957] loss=[0.006]\n",
      "[all_10]-[27]-[2] lr=[0.7398847961054957] loss=[0.006]\n",
      "[all_10]-[27]-[3] lr=[0.7398847961054957] loss=[0.005]\n",
      "[all_10]-[27]-[4] lr=[0.7398847961054957] loss=[0.007]\n",
      "[all_10]-[27]-[5] lr=[0.7398847961054957] loss=[0.006]\n",
      "[all_10]-[27]-[6] lr=[0.7398847961054957] loss=[0.006]\n",
      "[all_10]-[27]-[7] lr=[0.7398847961054957] loss=[0.007]\n",
      "[all_10]-[27]-[8] lr=[0.7398847961054957] loss=[0.006]\n",
      "[all_10]-[27]-[9] lr=[0.7398847961054957] loss=[0.007]\n",
      "[all_10]-[27]-[10] lr=[0.7398847961054957] loss=[0.006]\n",
      "[all_10]-[27]-[11] lr=[0.7398847961054957] loss=[0.006]\n",
      "[all_10]-[27]-[12] lr=[0.7398847961054957] loss=[0.005]\n",
      "[all_10]-[27]-[13] lr=[0.7398847961054957] loss=[0.007]\n",
      "[all_10]-[27]-[14] lr=[0.7398847961054957] loss=[0.005]\n",
      "[all_10]-[27]-[15] lr=[0.7398847961054957] loss=[0.007]\n",
      "[all_10]-[27]-[16] lr=[0.7398847961054957] loss=[0.007]\n",
      "[all_10]-[27]-[17] lr=[0.7398847961054957] loss=[0.007]\n",
      "[all_10]-[27]-[18] lr=[0.7398847961054957] loss=[0.006]\n",
      "[all_10]-[27]-[19] lr=[0.7398847961054957] loss=[0.004]\n",
      "[all_10]-[27]-[20] lr=[0.7398847961054957] loss=[0.005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[27]-[21] lr=[0.7398847961054957] loss=[0.004]\n",
      "[all_10]-[27]-[22] lr=[0.7398847961054957] loss=[0.005]\n",
      "[all_10]-[27]-[23] lr=[0.7398847961054957] loss=[0.007]\n",
      "[all_10]-[27]-[24] lr=[0.7398847961054957] loss=[0.005]\n",
      "[all_10]-[27]-[25] lr=[0.7398847961054957] loss=[0.007]\n",
      "[all_10]-[27]-[26] lr=[0.7398847961054957] loss=[0.007]\n",
      "[all_10]-[27]-[27] lr=[0.7398847961054957] loss=[0.007]\n",
      "[all_10]-[27]-[28] lr=[0.7398847961054957] loss=[0.005]\n",
      "[all_10]-[27]-[29] lr=[0.7398847961054957] loss=[0.007]\n",
      "[all_10]-[27]-[30] lr=[0.7398847961054957] loss=[0.006]\n",
      "[all_10]-[27]-[31] lr=[0.7398847961054957] loss=[0.007]\n",
      "[all_10]-[27]-[32] lr=[0.7398847961054957] loss=[0.007]\n",
      "[all_10]-[27]-[33] lr=[0.7398847961054957] loss=[0.006]\n",
      "[all_10]-[27]-[34] lr=[0.7398847961054957] loss=[0.006]\n",
      "[all_10]-[27]-[35] lr=[0.7398847961054957] loss=[0.008]\n",
      "[all_10]-[27]-[36] lr=[0.7398847961054957] loss=[0.009]\n",
      "[all_10]-[27]-[37] lr=[0.7398847961054957] loss=[0.006]\n",
      "[all_10]-[27]-[38] lr=[0.7398847961054957] loss=[0.007]\n",
      "[all_10]-[27]-[39] lr=[0.7398847961054957] loss=[0.006]\n",
      "[all_10]-[27]-[40] lr=[0.7398847961054957] loss=[0.007]\n",
      "[all_10]-[27]-[41] lr=[0.7398847961054957] loss=[0.006]\n",
      "[all_10]-[27]-[42] lr=[0.7398847961054957] loss=[0.006]\n",
      "[all_10]-[27]-[43] lr=[0.7398847961054957] loss=[0.007]\n",
      "[all_10]-[27]-[44] lr=[0.7398847961054957] loss=[0.006]\n",
      "[all_10]-[27]-[45] lr=[0.7398847961054957] loss=[0.005]\n",
      "[all_10]-[27]-[46] lr=[0.7398847961054957] loss=[0.006]\n",
      "[all_10]-[27]-[47] lr=[0.7398847961054957] loss=[0.005]\n",
      "[all_10]-[27]-[48] lr=[0.7398847961054957] loss=[0.007]\n",
      "tensor([[ 0.0126,  0.0282,  0.0429,  ...,  0.0091,  0.0059,  0.0013],\n",
      "        [ 0.0258,  0.0475,  0.0591,  ...,  0.0100,  0.0140,  0.0152],\n",
      "        [ 0.0174,  0.0372,  0.0486,  ..., -0.0024, -0.0001,  0.0025],\n",
      "        ...,\n",
      "        [ 0.0176,  0.0368,  0.0507,  ...,  0.0119,  0.0141,  0.0137],\n",
      "        [ 0.0266,  0.0499,  0.0580,  ...,  0.0038,  0.0056,  0.0054],\n",
      "        [ 0.0111,  0.0285,  0.0406,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.6096, 0.0000, 0.0544,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0092, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[28]-[1] lr=[0.7376651417171792] loss=[0.007]\n",
      "[all_10]-[28]-[2] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[3] lr=[0.7376651417171792] loss=[0.007]\n",
      "[all_10]-[28]-[4] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[5] lr=[0.7376651417171792] loss=[0.007]\n",
      "[all_10]-[28]-[6] lr=[0.7376651417171792] loss=[0.007]\n",
      "[all_10]-[28]-[7] lr=[0.7376651417171792] loss=[0.007]\n",
      "[all_10]-[28]-[8] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[9] lr=[0.7376651417171792] loss=[0.005]\n",
      "[all_10]-[28]-[10] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[11] lr=[0.7376651417171792] loss=[0.005]\n",
      "[all_10]-[28]-[12] lr=[0.7376651417171792] loss=[0.005]\n",
      "[all_10]-[28]-[13] lr=[0.7376651417171792] loss=[0.005]\n",
      "[all_10]-[28]-[14] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[15] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[16] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[17] lr=[0.7376651417171792] loss=[0.007]\n",
      "[all_10]-[28]-[18] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[19] lr=[0.7376651417171792] loss=[0.007]\n",
      "[all_10]-[28]-[20] lr=[0.7376651417171792] loss=[0.007]\n",
      "[all_10]-[28]-[21] lr=[0.7376651417171792] loss=[0.005]\n",
      "[all_10]-[28]-[22] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[23] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[24] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[25] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[26] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[27] lr=[0.7376651417171792] loss=[0.005]\n",
      "[all_10]-[28]-[28] lr=[0.7376651417171792] loss=[0.005]\n",
      "[all_10]-[28]-[29] lr=[0.7376651417171792] loss=[0.005]\n",
      "[all_10]-[28]-[30] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[31] lr=[0.7376651417171792] loss=[0.005]\n",
      "[all_10]-[28]-[32] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[33] lr=[0.7376651417171792] loss=[0.007]\n",
      "[all_10]-[28]-[34] lr=[0.7376651417171792] loss=[0.007]\n",
      "[all_10]-[28]-[35] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[36] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[37] lr=[0.7376651417171792] loss=[0.005]\n",
      "[all_10]-[28]-[38] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[39] lr=[0.7376651417171792] loss=[0.008]\n",
      "[all_10]-[28]-[40] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[41] lr=[0.7376651417171792] loss=[0.007]\n",
      "[all_10]-[28]-[42] lr=[0.7376651417171792] loss=[0.007]\n",
      "[all_10]-[28]-[43] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[44] lr=[0.7376651417171792] loss=[0.006]\n",
      "[all_10]-[28]-[45] lr=[0.7376651417171792] loss=[0.007]\n",
      "[all_10]-[28]-[46] lr=[0.7376651417171792] loss=[0.008]\n",
      "[all_10]-[28]-[47] lr=[0.7376651417171792] loss=[0.005]\n",
      "[all_10]-[28]-[48] lr=[0.7376651417171792] loss=[0.007]\n",
      "tensor([[0.0294, 0.0566, 0.0683,  ..., 0.0116, 0.0238, 0.0255],\n",
      "        [0.0142, 0.0346, 0.0479,  ..., 0.0231, 0.0211, 0.0167],\n",
      "        [0.0191, 0.0377, 0.0511,  ..., 0.0198, 0.0205, 0.0171],\n",
      "        ...,\n",
      "        [0.0168, 0.0348, 0.0478,  ..., 0.0241, 0.0292, 0.0279],\n",
      "        [0.0145, 0.0324, 0.0468,  ..., 0.0156, 0.0266, 0.0316],\n",
      "        [0.0147, 0.0303, 0.0410,  ..., 0.0050, 0.0061, 0.0052]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0592, 0.0347],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0291, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[29]-[1] lr=[0.7354521462920277] loss=[0.007]\n",
      "[all_10]-[29]-[2] lr=[0.7354521462920277] loss=[0.005]\n",
      "[all_10]-[29]-[3] lr=[0.7354521462920277] loss=[0.005]\n",
      "[all_10]-[29]-[4] lr=[0.7354521462920277] loss=[0.007]\n",
      "[all_10]-[29]-[5] lr=[0.7354521462920277] loss=[0.007]\n",
      "[all_10]-[29]-[6] lr=[0.7354521462920277] loss=[0.007]\n",
      "[all_10]-[29]-[7] lr=[0.7354521462920277] loss=[0.006]\n",
      "[all_10]-[29]-[8] lr=[0.7354521462920277] loss=[0.005]\n",
      "[all_10]-[29]-[9] lr=[0.7354521462920277] loss=[0.009]\n",
      "[all_10]-[29]-[10] lr=[0.7354521462920277] loss=[0.007]\n",
      "[all_10]-[29]-[11] lr=[0.7354521462920277] loss=[0.006]\n",
      "[all_10]-[29]-[12] lr=[0.7354521462920277] loss=[0.006]\n",
      "[all_10]-[29]-[13] lr=[0.7354521462920277] loss=[0.006]\n",
      "[all_10]-[29]-[14] lr=[0.7354521462920277] loss=[0.007]\n",
      "[all_10]-[29]-[15] lr=[0.7354521462920277] loss=[0.006]\n",
      "[all_10]-[29]-[16] lr=[0.7354521462920277] loss=[0.005]\n",
      "[all_10]-[29]-[17] lr=[0.7354521462920277] loss=[0.007]\n",
      "[all_10]-[29]-[18] lr=[0.7354521462920277] loss=[0.005]\n",
      "[all_10]-[29]-[19] lr=[0.7354521462920277] loss=[0.005]\n",
      "[all_10]-[29]-[20] lr=[0.7354521462920277] loss=[0.005]\n",
      "[all_10]-[29]-[21] lr=[0.7354521462920277] loss=[0.006]\n",
      "[all_10]-[29]-[22] lr=[0.7354521462920277] loss=[0.006]\n",
      "[all_10]-[29]-[23] lr=[0.7354521462920277] loss=[0.005]\n",
      "[all_10]-[29]-[24] lr=[0.7354521462920277] loss=[0.005]\n",
      "[all_10]-[29]-[25] lr=[0.7354521462920277] loss=[0.006]\n",
      "[all_10]-[29]-[26] lr=[0.7354521462920277] loss=[0.006]\n",
      "[all_10]-[29]-[27] lr=[0.7354521462920277] loss=[0.009]\n",
      "[all_10]-[29]-[28] lr=[0.7354521462920277] loss=[0.005]\n",
      "[all_10]-[29]-[29] lr=[0.7354521462920277] loss=[0.006]\n",
      "[all_10]-[29]-[30] lr=[0.7354521462920277] loss=[0.007]\n",
      "[all_10]-[29]-[31] lr=[0.7354521462920277] loss=[0.006]\n",
      "[all_10]-[29]-[32] lr=[0.7354521462920277] loss=[0.005]\n",
      "[all_10]-[29]-[33] lr=[0.7354521462920277] loss=[0.006]\n",
      "[all_10]-[29]-[34] lr=[0.7354521462920277] loss=[0.006]\n",
      "[all_10]-[29]-[35] lr=[0.7354521462920277] loss=[0.007]\n",
      "[all_10]-[29]-[36] lr=[0.7354521462920277] loss=[0.005]\n",
      "[all_10]-[29]-[37] lr=[0.7354521462920277] loss=[0.007]\n",
      "[all_10]-[29]-[38] lr=[0.7354521462920277] loss=[0.007]\n",
      "[all_10]-[29]-[39] lr=[0.7354521462920277] loss=[0.006]\n",
      "[all_10]-[29]-[40] lr=[0.7354521462920277] loss=[0.007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[29]-[41] lr=[0.7354521462920277] loss=[0.006]\n",
      "[all_10]-[29]-[42] lr=[0.7354521462920277] loss=[0.006]\n",
      "[all_10]-[29]-[43] lr=[0.7354521462920277] loss=[0.007]\n",
      "[all_10]-[29]-[44] lr=[0.7354521462920277] loss=[0.007]\n",
      "[all_10]-[29]-[45] lr=[0.7354521462920277] loss=[0.005]\n",
      "[all_10]-[29]-[46] lr=[0.7354521462920277] loss=[0.006]\n",
      "[all_10]-[29]-[47] lr=[0.7354521462920277] loss=[0.007]\n",
      "[all_10]-[29]-[48] lr=[0.7354521462920277] loss=[0.006]\n",
      "tensor([[0.0371, 0.0653, 0.0734,  ..., 0.0103, 0.0144, 0.0159],\n",
      "        [0.0269, 0.0643, 0.0845,  ..., 0.0125, 0.0206, 0.0242],\n",
      "        [0.0240, 0.0453, 0.0631,  ..., 0.0153, 0.0145, 0.0215],\n",
      "        ...,\n",
      "        [0.0141, 0.0350, 0.0490,  ..., 0.0276, 0.0257, 0.0213],\n",
      "        [0.0245, 0.0451, 0.0644,  ..., 0.0083, 0.0122, 0.0241],\n",
      "        [0.0168, 0.0358, 0.0499,  ..., 0.0027, 0.0036, 0.0046]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 5.5639,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0348, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0592, 0.0347],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0791,  ..., 0.0000, 0.0000, 0.0130]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[30]-[1] lr=[0.7332457898531516] loss=[0.007]\n",
      "[all_10]-[30]-[2] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[3] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[4] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[5] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[6] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[7] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[8] lr=[0.7332457898531516] loss=[0.007]\n",
      "[all_10]-[30]-[9] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[10] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[11] lr=[0.7332457898531516] loss=[0.005]\n",
      "[all_10]-[30]-[12] lr=[0.7332457898531516] loss=[0.005]\n",
      "[all_10]-[30]-[13] lr=[0.7332457898531516] loss=[0.007]\n",
      "[all_10]-[30]-[14] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[15] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[16] lr=[0.7332457898531516] loss=[0.005]\n",
      "[all_10]-[30]-[17] lr=[0.7332457898531516] loss=[0.007]\n",
      "[all_10]-[30]-[18] lr=[0.7332457898531516] loss=[0.005]\n",
      "[all_10]-[30]-[19] lr=[0.7332457898531516] loss=[0.005]\n",
      "[all_10]-[30]-[20] lr=[0.7332457898531516] loss=[0.007]\n",
      "[all_10]-[30]-[21] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[22] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[23] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[24] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[25] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[26] lr=[0.7332457898531516] loss=[0.007]\n",
      "[all_10]-[30]-[27] lr=[0.7332457898531516] loss=[0.005]\n",
      "[all_10]-[30]-[28] lr=[0.7332457898531516] loss=[0.007]\n",
      "[all_10]-[30]-[29] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[30] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[31] lr=[0.7332457898531516] loss=[0.007]\n",
      "[all_10]-[30]-[32] lr=[0.7332457898531516] loss=[0.007]\n",
      "[all_10]-[30]-[33] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[34] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[35] lr=[0.7332457898531516] loss=[0.007]\n",
      "[all_10]-[30]-[36] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[37] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[38] lr=[0.7332457898531516] loss=[0.007]\n",
      "[all_10]-[30]-[39] lr=[0.7332457898531516] loss=[0.007]\n",
      "[all_10]-[30]-[40] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[41] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[42] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[43] lr=[0.7332457898531516] loss=[0.005]\n",
      "[all_10]-[30]-[44] lr=[0.7332457898531516] loss=[0.007]\n",
      "[all_10]-[30]-[45] lr=[0.7332457898531516] loss=[0.006]\n",
      "[all_10]-[30]-[46] lr=[0.7332457898531516] loss=[0.007]\n",
      "[all_10]-[30]-[47] lr=[0.7332457898531516] loss=[0.005]\n",
      "[all_10]-[30]-[48] lr=[0.7332457898531516] loss=[0.006]\n",
      "tensor([[0.0175, 0.0397, 0.0504,  ..., 0.0219, 0.0225, 0.0237],\n",
      "        [0.0127, 0.0323, 0.0450,  ..., 0.0202, 0.0243, 0.0207],\n",
      "        [0.0236, 0.0539, 0.0668,  ..., 0.0166, 0.0146, 0.0115],\n",
      "        ...,\n",
      "        [0.0138, 0.0297, 0.0420,  ..., 0.0253, 0.0227, 0.0173],\n",
      "        [0.0270, 0.0515, 0.0586,  ..., 0.0127, 0.0112, 0.0090],\n",
      "        [0.0137, 0.0315, 0.0410,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0020, 0.0000, 0.0237,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0064, 0.0372,  ..., 0.0059, 0.0117, 0.0411],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0425, 0.4970, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2211, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1031,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[31]-[1] lr=[0.7310460524835921] loss=[0.007]\n",
      "[all_10]-[31]-[2] lr=[0.7310460524835921] loss=[0.006]\n",
      "[all_10]-[31]-[3] lr=[0.7310460524835921] loss=[0.006]\n",
      "[all_10]-[31]-[4] lr=[0.7310460524835921] loss=[0.007]\n",
      "[all_10]-[31]-[5] lr=[0.7310460524835921] loss=[0.007]\n",
      "[all_10]-[31]-[6] lr=[0.7310460524835921] loss=[0.006]\n",
      "[all_10]-[31]-[7] lr=[0.7310460524835921] loss=[0.007]\n",
      "[all_10]-[31]-[8] lr=[0.7310460524835921] loss=[0.006]\n",
      "[all_10]-[31]-[9] lr=[0.7310460524835921] loss=[0.005]\n",
      "[all_10]-[31]-[10] lr=[0.7310460524835921] loss=[0.006]\n",
      "[all_10]-[31]-[11] lr=[0.7310460524835921] loss=[0.004]\n",
      "[all_10]-[31]-[12] lr=[0.7310460524835921] loss=[0.005]\n",
      "[all_10]-[31]-[13] lr=[0.7310460524835921] loss=[0.007]\n",
      "[all_10]-[31]-[14] lr=[0.7310460524835921] loss=[0.007]\n",
      "[all_10]-[31]-[15] lr=[0.7310460524835921] loss=[0.006]\n",
      "[all_10]-[31]-[16] lr=[0.7310460524835921] loss=[0.008]\n",
      "[all_10]-[31]-[17] lr=[0.7310460524835921] loss=[0.005]\n",
      "[all_10]-[31]-[18] lr=[0.7310460524835921] loss=[0.006]\n",
      "[all_10]-[31]-[19] lr=[0.7310460524835921] loss=[0.005]\n",
      "[all_10]-[31]-[20] lr=[0.7310460524835921] loss=[0.007]\n",
      "[all_10]-[31]-[21] lr=[0.7310460524835921] loss=[0.007]\n",
      "[all_10]-[31]-[22] lr=[0.7310460524835921] loss=[0.007]\n",
      "[all_10]-[31]-[23] lr=[0.7310460524835921] loss=[0.006]\n",
      "[all_10]-[31]-[24] lr=[0.7310460524835921] loss=[0.006]\n",
      "[all_10]-[31]-[25] lr=[0.7310460524835921] loss=[0.006]\n",
      "[all_10]-[31]-[26] lr=[0.7310460524835921] loss=[0.007]\n",
      "[all_10]-[31]-[27] lr=[0.7310460524835921] loss=[0.005]\n",
      "[all_10]-[31]-[28] lr=[0.7310460524835921] loss=[0.006]\n",
      "[all_10]-[31]-[29] lr=[0.7310460524835921] loss=[0.006]\n",
      "[all_10]-[31]-[30] lr=[0.7310460524835921] loss=[0.005]\n",
      "[all_10]-[31]-[31] lr=[0.7310460524835921] loss=[0.005]\n",
      "[all_10]-[31]-[32] lr=[0.7310460524835921] loss=[0.006]\n",
      "[all_10]-[31]-[33] lr=[0.7310460524835921] loss=[0.007]\n",
      "[all_10]-[31]-[34] lr=[0.7310460524835921] loss=[0.007]\n",
      "[all_10]-[31]-[35] lr=[0.7310460524835921] loss=[0.007]\n",
      "[all_10]-[31]-[36] lr=[0.7310460524835921] loss=[0.006]\n",
      "[all_10]-[31]-[37] lr=[0.7310460524835921] loss=[0.007]\n",
      "[all_10]-[31]-[38] lr=[0.7310460524835921] loss=[0.007]\n",
      "[all_10]-[31]-[39] lr=[0.7310460524835921] loss=[0.005]\n",
      "[all_10]-[31]-[40] lr=[0.7310460524835921] loss=[0.006]\n",
      "[all_10]-[31]-[41] lr=[0.7310460524835921] loss=[0.005]\n",
      "[all_10]-[31]-[42] lr=[0.7310460524835921] loss=[0.008]\n",
      "[all_10]-[31]-[43] lr=[0.7310460524835921] loss=[0.007]\n",
      "[all_10]-[31]-[44] lr=[0.7310460524835921] loss=[0.006]\n",
      "[all_10]-[31]-[45] lr=[0.7310460524835921] loss=[0.006]\n",
      "[all_10]-[31]-[46] lr=[0.7310460524835921] loss=[0.006]\n",
      "[all_10]-[31]-[47] lr=[0.7310460524835921] loss=[0.006]\n",
      "[all_10]-[31]-[48] lr=[0.7310460524835921] loss=[0.005]\n",
      "tensor([[0.0160, 0.0332, 0.0452,  ..., 0.0147, 0.0151, 0.0127],\n",
      "        [0.0204, 0.0386, 0.0571,  ..., 0.0291, 0.0198, 0.0137],\n",
      "        [0.0322, 0.0652, 0.0839,  ..., 0.0090, 0.0094, 0.0129],\n",
      "        ...,\n",
      "        [0.0174, 0.0335, 0.0428,  ..., 0.0172, 0.0107, 0.0049],\n",
      "        [0.0258, 0.0478, 0.0751,  ..., 0.0027, 0.0014, 0.0011],\n",
      "        [0.0241, 0.0451, 0.0615,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0864, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1728],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0556, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1954, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[32]-[1] lr=[0.7288529143261413] loss=[0.007]\n",
      "[all_10]-[32]-[2] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[3] lr=[0.7288529143261413] loss=[0.005]\n",
      "[all_10]-[32]-[4] lr=[0.7288529143261413] loss=[0.007]\n",
      "[all_10]-[32]-[5] lr=[0.7288529143261413] loss=[0.007]\n",
      "[all_10]-[32]-[6] lr=[0.7288529143261413] loss=[0.005]\n",
      "[all_10]-[32]-[7] lr=[0.7288529143261413] loss=[0.007]\n",
      "[all_10]-[32]-[8] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[9] lr=[0.7288529143261413] loss=[0.005]\n",
      "[all_10]-[32]-[10] lr=[0.7288529143261413] loss=[0.005]\n",
      "[all_10]-[32]-[11] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[12] lr=[0.7288529143261413] loss=[0.007]\n",
      "[all_10]-[32]-[13] lr=[0.7288529143261413] loss=[0.007]\n",
      "[all_10]-[32]-[14] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[15] lr=[0.7288529143261413] loss=[0.008]\n",
      "[all_10]-[32]-[16] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[17] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[18] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[19] lr=[0.7288529143261413] loss=[0.008]\n",
      "[all_10]-[32]-[20] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[21] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[22] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[23] lr=[0.7288529143261413] loss=[0.007]\n",
      "[all_10]-[32]-[24] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[25] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[26] lr=[0.7288529143261413] loss=[0.007]\n",
      "[all_10]-[32]-[27] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[28] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[29] lr=[0.7288529143261413] loss=[0.007]\n",
      "[all_10]-[32]-[30] lr=[0.7288529143261413] loss=[0.004]\n",
      "[all_10]-[32]-[31] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[32] lr=[0.7288529143261413] loss=[0.004]\n",
      "[all_10]-[32]-[33] lr=[0.7288529143261413] loss=[0.008]\n",
      "[all_10]-[32]-[34] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[35] lr=[0.7288529143261413] loss=[0.005]\n",
      "[all_10]-[32]-[36] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[37] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[38] lr=[0.7288529143261413] loss=[0.007]\n",
      "[all_10]-[32]-[39] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[40] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[41] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[42] lr=[0.7288529143261413] loss=[0.005]\n",
      "[all_10]-[32]-[43] lr=[0.7288529143261413] loss=[0.007]\n",
      "[all_10]-[32]-[44] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[45] lr=[0.7288529143261413] loss=[0.006]\n",
      "[all_10]-[32]-[46] lr=[0.7288529143261413] loss=[0.008]\n",
      "[all_10]-[32]-[47] lr=[0.7288529143261413] loss=[0.005]\n",
      "[all_10]-[32]-[48] lr=[0.7288529143261413] loss=[0.006]\n",
      "tensor([[ 0.0286,  0.0483,  0.0557,  ...,  0.0187,  0.0169,  0.0107],\n",
      "        [ 0.0207,  0.0445,  0.0524,  ..., -0.0052, -0.0025, -0.0004],\n",
      "        [ 0.0186,  0.0387,  0.0539,  ...,  0.0080,  0.0079,  0.0061],\n",
      "        ...,\n",
      "        [ 0.0124,  0.0428,  0.0602,  ...,  0.0082,  0.0083,  0.0110],\n",
      "        [ 0.0081,  0.0215,  0.0413,  ...,  0.0119,  0.0122,  0.0099],\n",
      "        [ 0.0123,  0.0287,  0.0376,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.8413, 0.0411, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3455,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0234, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1031,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[33]-[1] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[2] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[3] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[4] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[5] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[6] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[7] lr=[0.7266663555831628] loss=[0.005]\n",
      "[all_10]-[33]-[8] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[9] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[10] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[11] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[12] lr=[0.7266663555831628] loss=[0.007]\n",
      "[all_10]-[33]-[13] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[14] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[15] lr=[0.7266663555831628] loss=[0.005]\n",
      "[all_10]-[33]-[16] lr=[0.7266663555831628] loss=[0.007]\n",
      "[all_10]-[33]-[17] lr=[0.7266663555831628] loss=[0.005]\n",
      "[all_10]-[33]-[18] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[19] lr=[0.7266663555831628] loss=[0.008]\n",
      "[all_10]-[33]-[20] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[21] lr=[0.7266663555831628] loss=[0.008]\n",
      "[all_10]-[33]-[22] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[23] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[24] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[25] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[26] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[27] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[28] lr=[0.7266663555831628] loss=[0.005]\n",
      "[all_10]-[33]-[29] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[30] lr=[0.7266663555831628] loss=[0.007]\n",
      "[all_10]-[33]-[31] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[32] lr=[0.7266663555831628] loss=[0.008]\n",
      "[all_10]-[33]-[33] lr=[0.7266663555831628] loss=[0.005]\n",
      "[all_10]-[33]-[34] lr=[0.7266663555831628] loss=[0.007]\n",
      "[all_10]-[33]-[35] lr=[0.7266663555831628] loss=[0.005]\n",
      "[all_10]-[33]-[36] lr=[0.7266663555831628] loss=[0.005]\n",
      "[all_10]-[33]-[37] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[38] lr=[0.7266663555831628] loss=[0.005]\n",
      "[all_10]-[33]-[39] lr=[0.7266663555831628] loss=[0.007]\n",
      "[all_10]-[33]-[40] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[41] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[42] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[43] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[44] lr=[0.7266663555831628] loss=[0.008]\n",
      "[all_10]-[33]-[45] lr=[0.7266663555831628] loss=[0.006]\n",
      "[all_10]-[33]-[46] lr=[0.7266663555831628] loss=[0.005]\n",
      "[all_10]-[33]-[47] lr=[0.7266663555831628] loss=[0.008]\n",
      "[all_10]-[33]-[48] lr=[0.7266663555831628] loss=[0.007]\n",
      "tensor([[0.0128, 0.0437, 0.0616,  ..., 0.0046, 0.0046, 0.0070],\n",
      "        [0.0124, 0.0278, 0.0389,  ..., 0.0008, 0.0004, 0.0018],\n",
      "        [0.0344, 0.0695, 0.0898,  ..., 0.0213, 0.0220, 0.0273],\n",
      "        ...,\n",
      "        [0.0132, 0.0298, 0.0473,  ..., 0.0091, 0.0053, 0.0024],\n",
      "        [0.0111, 0.0299, 0.0412,  ..., 0.0015, 0.0035, 0.0084],\n",
      "        [0.0120, 0.0344, 0.0543,  ..., 0.0153, 0.0170, 0.0136]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3254, 0.0000, 0.6807,  ..., 0.0000, 0.2476, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0449, 0.0000, 0.0000,  ..., 0.0000, 0.0703, 0.0224],\n",
      "        [0.0000, 0.1267, 0.0000,  ..., 0.0255, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[34]-[1] lr=[0.7244863565164134] loss=[0.005]\n",
      "[all_10]-[34]-[2] lr=[0.7244863565164134] loss=[0.007]\n",
      "[all_10]-[34]-[3] lr=[0.7244863565164134] loss=[0.006]\n",
      "[all_10]-[34]-[4] lr=[0.7244863565164134] loss=[0.006]\n",
      "[all_10]-[34]-[5] lr=[0.7244863565164134] loss=[0.006]\n",
      "[all_10]-[34]-[6] lr=[0.7244863565164134] loss=[0.006]\n",
      "[all_10]-[34]-[7] lr=[0.7244863565164134] loss=[0.006]\n",
      "[all_10]-[34]-[8] lr=[0.7244863565164134] loss=[0.004]\n",
      "[all_10]-[34]-[9] lr=[0.7244863565164134] loss=[0.008]\n",
      "[all_10]-[34]-[10] lr=[0.7244863565164134] loss=[0.006]\n",
      "[all_10]-[34]-[11] lr=[0.7244863565164134] loss=[0.007]\n",
      "[all_10]-[34]-[12] lr=[0.7244863565164134] loss=[0.006]\n",
      "[all_10]-[34]-[13] lr=[0.7244863565164134] loss=[0.007]\n",
      "[all_10]-[34]-[14] lr=[0.7244863565164134] loss=[0.005]\n",
      "[all_10]-[34]-[15] lr=[0.7244863565164134] loss=[0.005]\n",
      "[all_10]-[34]-[16] lr=[0.7244863565164134] loss=[0.006]\n",
      "[all_10]-[34]-[17] lr=[0.7244863565164134] loss=[0.006]\n",
      "[all_10]-[34]-[18] lr=[0.7244863565164134] loss=[0.006]\n",
      "[all_10]-[34]-[19] lr=[0.7244863565164134] loss=[0.005]\n",
      "[all_10]-[34]-[20] lr=[0.7244863565164134] loss=[0.006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[34]-[21] lr=[0.7244863565164134] loss=[0.008]\n",
      "[all_10]-[34]-[22] lr=[0.7244863565164134] loss=[0.007]\n",
      "[all_10]-[34]-[23] lr=[0.7244863565164134] loss=[0.007]\n",
      "[all_10]-[34]-[24] lr=[0.7244863565164134] loss=[0.005]\n",
      "[all_10]-[34]-[25] lr=[0.7244863565164134] loss=[0.005]\n",
      "[all_10]-[34]-[26] lr=[0.7244863565164134] loss=[0.005]\n",
      "[all_10]-[34]-[27] lr=[0.7244863565164134] loss=[0.006]\n",
      "[all_10]-[34]-[28] lr=[0.7244863565164134] loss=[0.006]\n",
      "[all_10]-[34]-[29] lr=[0.7244863565164134] loss=[0.005]\n",
      "[all_10]-[34]-[30] lr=[0.7244863565164134] loss=[0.008]\n",
      "[all_10]-[34]-[31] lr=[0.7244863565164134] loss=[0.006]\n",
      "[all_10]-[34]-[32] lr=[0.7244863565164134] loss=[0.005]\n",
      "[all_10]-[34]-[33] lr=[0.7244863565164134] loss=[0.007]\n",
      "[all_10]-[34]-[34] lr=[0.7244863565164134] loss=[0.005]\n",
      "[all_10]-[34]-[35] lr=[0.7244863565164134] loss=[0.006]\n",
      "[all_10]-[34]-[36] lr=[0.7244863565164134] loss=[0.006]\n",
      "[all_10]-[34]-[37] lr=[0.7244863565164134] loss=[0.007]\n",
      "[all_10]-[34]-[38] lr=[0.7244863565164134] loss=[0.007]\n",
      "[all_10]-[34]-[39] lr=[0.7244863565164134] loss=[0.005]\n",
      "[all_10]-[34]-[40] lr=[0.7244863565164134] loss=[0.007]\n",
      "[all_10]-[34]-[41] lr=[0.7244863565164134] loss=[0.007]\n",
      "[all_10]-[34]-[42] lr=[0.7244863565164134] loss=[0.006]\n",
      "[all_10]-[34]-[43] lr=[0.7244863565164134] loss=[0.007]\n",
      "[all_10]-[34]-[44] lr=[0.7244863565164134] loss=[0.007]\n",
      "[all_10]-[34]-[45] lr=[0.7244863565164134] loss=[0.005]\n",
      "[all_10]-[34]-[46] lr=[0.7244863565164134] loss=[0.005]\n",
      "[all_10]-[34]-[47] lr=[0.7244863565164134] loss=[0.007]\n",
      "[all_10]-[34]-[48] lr=[0.7244863565164134] loss=[0.007]\n",
      "tensor([[ 1.7885e-02,  4.8218e-02,  6.6794e-02,  ..., -2.6786e-03,\n",
      "          6.6742e-05, -1.3309e-03],\n",
      "        [ 1.8054e-02,  3.8103e-02,  4.6795e-02,  ...,  1.6375e-02,\n",
      "          1.8599e-02,  1.7499e-02],\n",
      "        [ 2.0075e-02,  3.8371e-02,  4.7445e-02,  ...,  1.2455e-02,\n",
      "          1.3379e-02,  1.4416e-02],\n",
      "        ...,\n",
      "        [ 7.3950e-03,  2.4636e-02,  3.8661e-02,  ..., -1.4378e-03,\n",
      "         -3.6174e-04,  2.8785e-03],\n",
      "        [ 2.3149e-02,  4.1547e-02,  5.4419e-02,  ...,  9.1569e-03,\n",
      "          7.0207e-03,  3.8615e-03],\n",
      "        [ 8.2664e-03,  2.4878e-02,  3.7183e-02,  ...,  8.5208e-03,\n",
      "          5.2130e-03,  8.4929e-03]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0045, 2.3592,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0000, 0.0067,  ..., 0.0000, 0.0470, 0.0000],\n",
      "        [0.0160, 0.0000, 0.0122,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0709, 0.0000,  ..., 0.0000, 0.0093, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0095, 0.0041, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[35]-[1] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[2] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[3] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[4] lr=[0.7223128974468641] loss=[0.005]\n",
      "[all_10]-[35]-[5] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[6] lr=[0.7223128974468641] loss=[0.005]\n",
      "[all_10]-[35]-[7] lr=[0.7223128974468641] loss=[0.005]\n",
      "[all_10]-[35]-[8] lr=[0.7223128974468641] loss=[0.008]\n",
      "[all_10]-[35]-[9] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[10] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[11] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[12] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[13] lr=[0.7223128974468641] loss=[0.005]\n",
      "[all_10]-[35]-[14] lr=[0.7223128974468641] loss=[0.005]\n",
      "[all_10]-[35]-[15] lr=[0.7223128974468641] loss=[0.008]\n",
      "[all_10]-[35]-[16] lr=[0.7223128974468641] loss=[0.005]\n",
      "[all_10]-[35]-[17] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[18] lr=[0.7223128974468641] loss=[0.007]\n",
      "[all_10]-[35]-[19] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[20] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[21] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[22] lr=[0.7223128974468641] loss=[0.008]\n",
      "[all_10]-[35]-[23] lr=[0.7223128974468641] loss=[0.007]\n",
      "[all_10]-[35]-[24] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[25] lr=[0.7223128974468641] loss=[0.005]\n",
      "[all_10]-[35]-[26] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[27] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[28] lr=[0.7223128974468641] loss=[0.007]\n",
      "[all_10]-[35]-[29] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[30] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[31] lr=[0.7223128974468641] loss=[0.007]\n",
      "[all_10]-[35]-[32] lr=[0.7223128974468641] loss=[0.005]\n",
      "[all_10]-[35]-[33] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[34] lr=[0.7223128974468641] loss=[0.005]\n",
      "[all_10]-[35]-[35] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[36] lr=[0.7223128974468641] loss=[0.007]\n",
      "[all_10]-[35]-[37] lr=[0.7223128974468641] loss=[0.007]\n",
      "[all_10]-[35]-[38] lr=[0.7223128974468641] loss=[0.007]\n",
      "[all_10]-[35]-[39] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[40] lr=[0.7223128974468641] loss=[0.007]\n",
      "[all_10]-[35]-[41] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[42] lr=[0.7223128974468641] loss=[0.008]\n",
      "[all_10]-[35]-[43] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[44] lr=[0.7223128974468641] loss=[0.007]\n",
      "[all_10]-[35]-[45] lr=[0.7223128974468641] loss=[0.005]\n",
      "[all_10]-[35]-[46] lr=[0.7223128974468641] loss=[0.007]\n",
      "[all_10]-[35]-[47] lr=[0.7223128974468641] loss=[0.006]\n",
      "[all_10]-[35]-[48] lr=[0.7223128974468641] loss=[0.005]\n",
      "tensor([[ 0.0104,  0.0319,  0.0518,  ...,  0.0089,  0.0105,  0.0071],\n",
      "        [ 0.0072,  0.0374,  0.0572,  ...,  0.0018,  0.0009, -0.0012],\n",
      "        [ 0.0076,  0.0220,  0.0408,  ...,  0.0036, -0.0012, -0.0045],\n",
      "        ...,\n",
      "        [ 0.0173,  0.0378,  0.0456,  ..., -0.0013, -0.0047, -0.0073],\n",
      "        [ 0.0109,  0.0246,  0.0360,  ..., -0.0069, -0.0075, -0.0031],\n",
      "        [ 0.0181,  0.0426,  0.0557,  ..., -0.0014, -0.0027, -0.0019]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0962, 0.0000, 0.0612,  ..., 0.0000, 0.0000, 0.1372],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0313],\n",
      "        ...,\n",
      "        [0.0000, 0.0942, 0.0000,  ..., 0.0813, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5928, 0.0000,  ..., 0.0000, 0.0000, 0.0053],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[36]-[1] lr=[0.7201459587545235] loss=[0.007]\n",
      "[all_10]-[36]-[2] lr=[0.7201459587545235] loss=[0.005]\n",
      "[all_10]-[36]-[3] lr=[0.7201459587545235] loss=[0.007]\n",
      "[all_10]-[36]-[4] lr=[0.7201459587545235] loss=[0.007]\n",
      "[all_10]-[36]-[5] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[6] lr=[0.7201459587545235] loss=[0.007]\n",
      "[all_10]-[36]-[7] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[8] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[9] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[10] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[11] lr=[0.7201459587545235] loss=[0.007]\n",
      "[all_10]-[36]-[12] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[13] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[14] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[15] lr=[0.7201459587545235] loss=[0.004]\n",
      "[all_10]-[36]-[16] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[17] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[18] lr=[0.7201459587545235] loss=[0.005]\n",
      "[all_10]-[36]-[19] lr=[0.7201459587545235] loss=[0.005]\n",
      "[all_10]-[36]-[20] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[21] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[22] lr=[0.7201459587545235] loss=[0.004]\n",
      "[all_10]-[36]-[23] lr=[0.7201459587545235] loss=[0.007]\n",
      "[all_10]-[36]-[24] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[25] lr=[0.7201459587545235] loss=[0.007]\n",
      "[all_10]-[36]-[26] lr=[0.7201459587545235] loss=[0.005]\n",
      "[all_10]-[36]-[27] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[28] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[29] lr=[0.7201459587545235] loss=[0.004]\n",
      "[all_10]-[36]-[30] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[31] lr=[0.7201459587545235] loss=[0.007]\n",
      "[all_10]-[36]-[32] lr=[0.7201459587545235] loss=[0.007]\n",
      "[all_10]-[36]-[33] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[34] lr=[0.7201459587545235] loss=[0.007]\n",
      "[all_10]-[36]-[35] lr=[0.7201459587545235] loss=[0.007]\n",
      "[all_10]-[36]-[36] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[37] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[38] lr=[0.7201459587545235] loss=[0.008]\n",
      "[all_10]-[36]-[39] lr=[0.7201459587545235] loss=[0.007]\n",
      "[all_10]-[36]-[40] lr=[0.7201459587545235] loss=[0.007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[36]-[41] lr=[0.7201459587545235] loss=[0.007]\n",
      "[all_10]-[36]-[42] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[43] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[44] lr=[0.7201459587545235] loss=[0.005]\n",
      "[all_10]-[36]-[45] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[46] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[47] lr=[0.7201459587545235] loss=[0.006]\n",
      "[all_10]-[36]-[48] lr=[0.7201459587545235] loss=[0.006]\n",
      "tensor([[ 0.0097,  0.0215,  0.0359,  ...,  0.0015, -0.0021, -0.0041],\n",
      "        [ 0.0118,  0.0365,  0.0521,  ...,  0.0102,  0.0091,  0.0103],\n",
      "        [ 0.0131,  0.0466,  0.0691,  ...,  0.0063,  0.0083,  0.0103],\n",
      "        ...,\n",
      "        [ 0.0245,  0.0399,  0.0529,  ...,  0.0167,  0.0100,  0.0081],\n",
      "        [ 0.0172,  0.0367,  0.0502,  ...,  0.0055,  0.0062,  0.0072],\n",
      "        [ 0.0156,  0.0378,  0.0534,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[3.3318e-03, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.2468e-02, 4.6195e-02,\n",
      "         2.1259e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.3379e-02, 1.6934e-01, 0.0000e+00,  ..., 1.0119e-01, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [5.8950e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='cuda:0')\n",
      "[all_10]-[37]-[1] lr=[0.71798552087826] loss=[0.008]\n",
      "[all_10]-[37]-[2] lr=[0.71798552087826] loss=[0.008]\n",
      "[all_10]-[37]-[3] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[4] lr=[0.71798552087826] loss=[0.005]\n",
      "[all_10]-[37]-[5] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[6] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[7] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[8] lr=[0.71798552087826] loss=[0.005]\n",
      "[all_10]-[37]-[9] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[10] lr=[0.71798552087826] loss=[0.005]\n",
      "[all_10]-[37]-[11] lr=[0.71798552087826] loss=[0.005]\n",
      "[all_10]-[37]-[12] lr=[0.71798552087826] loss=[0.007]\n",
      "[all_10]-[37]-[13] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[14] lr=[0.71798552087826] loss=[0.005]\n",
      "[all_10]-[37]-[15] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[16] lr=[0.71798552087826] loss=[0.007]\n",
      "[all_10]-[37]-[17] lr=[0.71798552087826] loss=[0.007]\n",
      "[all_10]-[37]-[18] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[19] lr=[0.71798552087826] loss=[0.007]\n",
      "[all_10]-[37]-[20] lr=[0.71798552087826] loss=[0.005]\n",
      "[all_10]-[37]-[21] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[22] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[23] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[24] lr=[0.71798552087826] loss=[0.005]\n",
      "[all_10]-[37]-[25] lr=[0.71798552087826] loss=[0.008]\n",
      "[all_10]-[37]-[26] lr=[0.71798552087826] loss=[0.005]\n",
      "[all_10]-[37]-[27] lr=[0.71798552087826] loss=[0.008]\n",
      "[all_10]-[37]-[28] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[29] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[30] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[31] lr=[0.71798552087826] loss=[0.007]\n",
      "[all_10]-[37]-[32] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[33] lr=[0.71798552087826] loss=[0.007]\n",
      "[all_10]-[37]-[34] lr=[0.71798552087826] loss=[0.007]\n",
      "[all_10]-[37]-[35] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[36] lr=[0.71798552087826] loss=[0.005]\n",
      "[all_10]-[37]-[37] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[38] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[39] lr=[0.71798552087826] loss=[0.005]\n",
      "[all_10]-[37]-[40] lr=[0.71798552087826] loss=[0.005]\n",
      "[all_10]-[37]-[41] lr=[0.71798552087826] loss=[0.007]\n",
      "[all_10]-[37]-[42] lr=[0.71798552087826] loss=[0.007]\n",
      "[all_10]-[37]-[43] lr=[0.71798552087826] loss=[0.005]\n",
      "[all_10]-[37]-[44] lr=[0.71798552087826] loss=[0.007]\n",
      "[all_10]-[37]-[45] lr=[0.71798552087826] loss=[0.007]\n",
      "[all_10]-[37]-[46] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[47] lr=[0.71798552087826] loss=[0.006]\n",
      "[all_10]-[37]-[48] lr=[0.71798552087826] loss=[0.007]\n",
      "tensor([[0.0238, 0.0417, 0.0585,  ..., 0.0112, 0.0110, 0.0110],\n",
      "        [0.0098, 0.0209, 0.0288,  ..., 0.0149, 0.0104, 0.0075],\n",
      "        [0.0114, 0.0323, 0.0484,  ..., 0.0159, 0.0113, 0.0112],\n",
      "        ...,\n",
      "        [0.0114, 0.0363, 0.0557,  ..., 0.0099, 0.0074, 0.0086],\n",
      "        [0.0202, 0.0399, 0.0546,  ..., 0.0042, 0.0256, 0.0285],\n",
      "        [0.0326, 0.0577, 0.0659,  ..., 0.0114, 0.0102, 0.0061]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0014, 0.0000, 0.9256,  ..., 0.0000, 0.0000, 0.0089],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0267, 0.0000,  ..., 0.0000, 0.0000, 0.0267],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[38]-[1] lr=[0.7158315643156252] loss=[0.006]\n",
      "[all_10]-[38]-[2] lr=[0.7158315643156252] loss=[0.006]\n",
      "[all_10]-[38]-[3] lr=[0.7158315643156252] loss=[0.006]\n",
      "[all_10]-[38]-[4] lr=[0.7158315643156252] loss=[0.007]\n",
      "[all_10]-[38]-[5] lr=[0.7158315643156252] loss=[0.007]\n",
      "[all_10]-[38]-[6] lr=[0.7158315643156252] loss=[0.007]\n",
      "[all_10]-[38]-[7] lr=[0.7158315643156252] loss=[0.008]\n",
      "[all_10]-[38]-[8] lr=[0.7158315643156252] loss=[0.005]\n",
      "[all_10]-[38]-[9] lr=[0.7158315643156252] loss=[0.006]\n",
      "[all_10]-[38]-[10] lr=[0.7158315643156252] loss=[0.006]\n",
      "[all_10]-[38]-[11] lr=[0.7158315643156252] loss=[0.006]\n",
      "[all_10]-[38]-[12] lr=[0.7158315643156252] loss=[0.007]\n",
      "[all_10]-[38]-[13] lr=[0.7158315643156252] loss=[0.005]\n",
      "[all_10]-[38]-[14] lr=[0.7158315643156252] loss=[0.006]\n",
      "[all_10]-[38]-[15] lr=[0.7158315643156252] loss=[0.004]\n",
      "[all_10]-[38]-[16] lr=[0.7158315643156252] loss=[0.005]\n",
      "[all_10]-[38]-[17] lr=[0.7158315643156252] loss=[0.007]\n",
      "[all_10]-[38]-[18] lr=[0.7158315643156252] loss=[0.006]\n",
      "[all_10]-[38]-[19] lr=[0.7158315643156252] loss=[0.006]\n",
      "[all_10]-[38]-[20] lr=[0.7158315643156252] loss=[0.006]\n",
      "[all_10]-[38]-[21] lr=[0.7158315643156252] loss=[0.006]\n",
      "[all_10]-[38]-[22] lr=[0.7158315643156252] loss=[0.007]\n",
      "[all_10]-[38]-[23] lr=[0.7158315643156252] loss=[0.005]\n",
      "[all_10]-[38]-[24] lr=[0.7158315643156252] loss=[0.007]\n",
      "[all_10]-[38]-[25] lr=[0.7158315643156252] loss=[0.005]\n",
      "[all_10]-[38]-[26] lr=[0.7158315643156252] loss=[0.005]\n",
      "[all_10]-[38]-[27] lr=[0.7158315643156252] loss=[0.008]\n",
      "[all_10]-[38]-[28] lr=[0.7158315643156252] loss=[0.005]\n",
      "[all_10]-[38]-[29] lr=[0.7158315643156252] loss=[0.006]\n",
      "[all_10]-[38]-[30] lr=[0.7158315643156252] loss=[0.006]\n",
      "[all_10]-[38]-[31] lr=[0.7158315643156252] loss=[0.005]\n",
      "[all_10]-[38]-[32] lr=[0.7158315643156252] loss=[0.006]\n",
      "[all_10]-[38]-[33] lr=[0.7158315643156252] loss=[0.005]\n",
      "[all_10]-[38]-[34] lr=[0.7158315643156252] loss=[0.007]\n",
      "[all_10]-[38]-[35] lr=[0.7158315643156252] loss=[0.006]\n",
      "[all_10]-[38]-[36] lr=[0.7158315643156252] loss=[0.006]\n",
      "[all_10]-[38]-[37] lr=[0.7158315643156252] loss=[0.006]\n",
      "[all_10]-[38]-[38] lr=[0.7158315643156252] loss=[0.006]\n",
      "[all_10]-[38]-[39] lr=[0.7158315643156252] loss=[0.005]\n",
      "[all_10]-[38]-[40] lr=[0.7158315643156252] loss=[0.006]\n",
      "[all_10]-[38]-[41] lr=[0.7158315643156252] loss=[0.005]\n",
      "[all_10]-[38]-[42] lr=[0.7158315643156252] loss=[0.007]\n",
      "[all_10]-[38]-[43] lr=[0.7158315643156252] loss=[0.005]\n",
      "[all_10]-[38]-[44] lr=[0.7158315643156252] loss=[0.007]\n",
      "[all_10]-[38]-[45] lr=[0.7158315643156252] loss=[0.007]\n",
      "[all_10]-[38]-[46] lr=[0.7158315643156252] loss=[0.007]\n",
      "[all_10]-[38]-[47] lr=[0.7158315643156252] loss=[0.007]\n",
      "[all_10]-[38]-[48] lr=[0.7158315643156252] loss=[0.006]\n",
      "tensor([[ 0.0042,  0.0216,  0.0409,  ...,  0.0060,  0.0098,  0.0102],\n",
      "        [ 0.0092,  0.0339,  0.0542,  ...,  0.0112,  0.0132,  0.0084],\n",
      "        [ 0.0314,  0.0630,  0.0732,  ...,  0.0124,  0.0133,  0.0107],\n",
      "        ...,\n",
      "        [ 0.0177,  0.0369,  0.0526,  ..., -0.0126, -0.0118, -0.0102],\n",
      "        [ 0.0073,  0.0210,  0.0369,  ...,  0.0028, -0.0007, -0.0012],\n",
      "        [ 0.0075,  0.0359,  0.0587,  ...,  0.0048,  0.0087,  0.0070]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2314, 0.0000],\n",
      "        [0.0000, 1.1976, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.6311, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0434, 0.0000,  ..., 0.0165, 0.0323, 0.0227]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[39]-[1] lr=[0.7136840696226784] loss=[0.005]\n",
      "[all_10]-[39]-[2] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[3] lr=[0.7136840696226784] loss=[0.008]\n",
      "[all_10]-[39]-[4] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[5] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[6] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[7] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[8] lr=[0.7136840696226784] loss=[0.007]\n",
      "[all_10]-[39]-[9] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[10] lr=[0.7136840696226784] loss=[0.007]\n",
      "[all_10]-[39]-[11] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[12] lr=[0.7136840696226784] loss=[0.007]\n",
      "[all_10]-[39]-[13] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[14] lr=[0.7136840696226784] loss=[0.009]\n",
      "[all_10]-[39]-[15] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[16] lr=[0.7136840696226784] loss=[0.007]\n",
      "[all_10]-[39]-[17] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[18] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[19] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[20] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[21] lr=[0.7136840696226784] loss=[0.007]\n",
      "[all_10]-[39]-[22] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[23] lr=[0.7136840696226784] loss=[0.005]\n",
      "[all_10]-[39]-[24] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[25] lr=[0.7136840696226784] loss=[0.005]\n",
      "[all_10]-[39]-[26] lr=[0.7136840696226784] loss=[0.005]\n",
      "[all_10]-[39]-[27] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[28] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[29] lr=[0.7136840696226784] loss=[0.005]\n",
      "[all_10]-[39]-[30] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[31] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[32] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[33] lr=[0.7136840696226784] loss=[0.004]\n",
      "[all_10]-[39]-[34] lr=[0.7136840696226784] loss=[0.007]\n",
      "[all_10]-[39]-[35] lr=[0.7136840696226784] loss=[0.005]\n",
      "[all_10]-[39]-[36] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[37] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[38] lr=[0.7136840696226784] loss=[0.007]\n",
      "[all_10]-[39]-[39] lr=[0.7136840696226784] loss=[0.008]\n",
      "[all_10]-[39]-[40] lr=[0.7136840696226784] loss=[0.007]\n",
      "[all_10]-[39]-[41] lr=[0.7136840696226784] loss=[0.005]\n",
      "[all_10]-[39]-[42] lr=[0.7136840696226784] loss=[0.007]\n",
      "[all_10]-[39]-[43] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[44] lr=[0.7136840696226784] loss=[0.005]\n",
      "[all_10]-[39]-[45] lr=[0.7136840696226784] loss=[0.007]\n",
      "[all_10]-[39]-[46] lr=[0.7136840696226784] loss=[0.006]\n",
      "[all_10]-[39]-[47] lr=[0.7136840696226784] loss=[0.007]\n",
      "[all_10]-[39]-[48] lr=[0.7136840696226784] loss=[0.007]\n",
      "tensor([[ 0.0105,  0.0253,  0.0375,  ..., -0.0119, -0.0094, -0.0045],\n",
      "        [ 0.0105,  0.0443,  0.0651,  ..., -0.0043, -0.0067, -0.0103],\n",
      "        [ 0.0131,  0.0369,  0.0552,  ..., -0.0082, -0.0082, -0.0078],\n",
      "        ...,\n",
      "        [ 0.0335,  0.0538,  0.0715,  ...,  0.0008, -0.0012, -0.0055],\n",
      "        [ 0.0231,  0.0392,  0.0515,  ...,  0.0033,  0.0021, -0.0006],\n",
      "        [ 0.0140,  0.0293,  0.0371,  ..., -0.0008, -0.0008,  0.0014]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0055, 0.0742,  ..., 0.0000, 0.0070, 0.0000],\n",
      "        ...,\n",
      "        [0.0072, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0709, 0.0000,  ..., 0.0000, 0.0093, 0.0000],\n",
      "        [0.0666, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[40]-[1] lr=[0.7115430174138103] loss=[0.006]\n",
      "[all_10]-[40]-[2] lr=[0.7115430174138103] loss=[0.005]\n",
      "[all_10]-[40]-[3] lr=[0.7115430174138103] loss=[0.005]\n",
      "[all_10]-[40]-[4] lr=[0.7115430174138103] loss=[0.006]\n",
      "[all_10]-[40]-[5] lr=[0.7115430174138103] loss=[0.007]\n",
      "[all_10]-[40]-[6] lr=[0.7115430174138103] loss=[0.006]\n",
      "[all_10]-[40]-[7] lr=[0.7115430174138103] loss=[0.007]\n",
      "[all_10]-[40]-[8] lr=[0.7115430174138103] loss=[0.007]\n",
      "[all_10]-[40]-[9] lr=[0.7115430174138103] loss=[0.005]\n",
      "[all_10]-[40]-[10] lr=[0.7115430174138103] loss=[0.005]\n",
      "[all_10]-[40]-[11] lr=[0.7115430174138103] loss=[0.006]\n",
      "[all_10]-[40]-[12] lr=[0.7115430174138103] loss=[0.006]\n",
      "[all_10]-[40]-[13] lr=[0.7115430174138103] loss=[0.006]\n",
      "[all_10]-[40]-[14] lr=[0.7115430174138103] loss=[0.006]\n",
      "[all_10]-[40]-[15] lr=[0.7115430174138103] loss=[0.006]\n",
      "[all_10]-[40]-[16] lr=[0.7115430174138103] loss=[0.007]\n",
      "[all_10]-[40]-[17] lr=[0.7115430174138103] loss=[0.005]\n",
      "[all_10]-[40]-[18] lr=[0.7115430174138103] loss=[0.007]\n",
      "[all_10]-[40]-[19] lr=[0.7115430174138103] loss=[0.005]\n",
      "[all_10]-[40]-[20] lr=[0.7115430174138103] loss=[0.008]\n",
      "[all_10]-[40]-[21] lr=[0.7115430174138103] loss=[0.005]\n",
      "[all_10]-[40]-[22] lr=[0.7115430174138103] loss=[0.005]\n",
      "[all_10]-[40]-[23] lr=[0.7115430174138103] loss=[0.007]\n",
      "[all_10]-[40]-[24] lr=[0.7115430174138103] loss=[0.006]\n",
      "[all_10]-[40]-[25] lr=[0.7115430174138103] loss=[0.006]\n",
      "[all_10]-[40]-[26] lr=[0.7115430174138103] loss=[0.006]\n",
      "[all_10]-[40]-[27] lr=[0.7115430174138103] loss=[0.006]\n",
      "[all_10]-[40]-[28] lr=[0.7115430174138103] loss=[0.006]\n",
      "[all_10]-[40]-[29] lr=[0.7115430174138103] loss=[0.005]\n",
      "[all_10]-[40]-[30] lr=[0.7115430174138103] loss=[0.006]\n",
      "[all_10]-[40]-[31] lr=[0.7115430174138103] loss=[0.005]\n",
      "[all_10]-[40]-[32] lr=[0.7115430174138103] loss=[0.006]\n",
      "[all_10]-[40]-[33] lr=[0.7115430174138103] loss=[0.004]\n",
      "[all_10]-[40]-[34] lr=[0.7115430174138103] loss=[0.006]\n",
      "[all_10]-[40]-[35] lr=[0.7115430174138103] loss=[0.007]\n",
      "[all_10]-[40]-[36] lr=[0.7115430174138103] loss=[0.007]\n",
      "[all_10]-[40]-[37] lr=[0.7115430174138103] loss=[0.007]\n",
      "[all_10]-[40]-[38] lr=[0.7115430174138103] loss=[0.006]\n",
      "[all_10]-[40]-[39] lr=[0.7115430174138103] loss=[0.005]\n",
      "[all_10]-[40]-[40] lr=[0.7115430174138103] loss=[0.005]\n",
      "[all_10]-[40]-[41] lr=[0.7115430174138103] loss=[0.005]\n",
      "[all_10]-[40]-[42] lr=[0.7115430174138103] loss=[0.007]\n",
      "[all_10]-[40]-[43] lr=[0.7115430174138103] loss=[0.007]\n",
      "[all_10]-[40]-[44] lr=[0.7115430174138103] loss=[0.006]\n",
      "[all_10]-[40]-[45] lr=[0.7115430174138103] loss=[0.006]\n",
      "[all_10]-[40]-[46] lr=[0.7115430174138103] loss=[0.007]\n",
      "[all_10]-[40]-[47] lr=[0.7115430174138103] loss=[0.007]\n",
      "[all_10]-[40]-[48] lr=[0.7115430174138103] loss=[0.006]\n",
      "tensor([[ 4.5144e-02,  7.3217e-02,  8.2329e-02,  ...,  3.2710e-03,\n",
      "          1.3875e-02,  1.5068e-02],\n",
      "        [ 6.5572e-03,  2.6831e-02,  5.9741e-02,  ...,  1.2735e-03,\n",
      "          6.1079e-03,  9.3329e-03],\n",
      "        [ 1.6762e-02,  3.1782e-02,  5.1268e-02,  ...,  1.0850e-03,\n",
      "          1.4518e-04, -1.3041e-03],\n",
      "        ...,\n",
      "        [ 1.4533e-02,  3.1988e-02,  4.5702e-02,  ..., -7.5888e-03,\n",
      "         -9.8900e-03, -5.0162e-03],\n",
      "        [ 2.0092e-02,  4.3852e-02,  5.8171e-02,  ...,  1.9450e-04,\n",
      "         -5.9025e-03, -8.4779e-03],\n",
      "        [ 1.1089e-02,  3.8420e-02,  5.1828e-02,  ..., -2.0004e-03,\n",
      "         -1.7178e-03, -9.7305e-05]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0792, 0.0000, 0.2143,  ..., 0.0874, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2214,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0000, 0.0070,  ..., 0.0000, 0.0342, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.6240, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[41]-[1] lr=[0.7094083883615688] loss=[0.007]\n",
      "[all_10]-[41]-[2] lr=[0.7094083883615688] loss=[0.007]\n",
      "[all_10]-[41]-[3] lr=[0.7094083883615688] loss=[0.007]\n",
      "[all_10]-[41]-[4] lr=[0.7094083883615688] loss=[0.005]\n",
      "[all_10]-[41]-[5] lr=[0.7094083883615688] loss=[0.005]\n",
      "[all_10]-[41]-[6] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[7] lr=[0.7094083883615688] loss=[0.005]\n",
      "[all_10]-[41]-[8] lr=[0.7094083883615688] loss=[0.007]\n",
      "[all_10]-[41]-[9] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[10] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[11] lr=[0.7094083883615688] loss=[0.005]\n",
      "[all_10]-[41]-[12] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[13] lr=[0.7094083883615688] loss=[0.008]\n",
      "[all_10]-[41]-[14] lr=[0.7094083883615688] loss=[0.005]\n",
      "[all_10]-[41]-[15] lr=[0.7094083883615688] loss=[0.007]\n",
      "[all_10]-[41]-[16] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[17] lr=[0.7094083883615688] loss=[0.005]\n",
      "[all_10]-[41]-[18] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[19] lr=[0.7094083883615688] loss=[0.005]\n",
      "[all_10]-[41]-[20] lr=[0.7094083883615688] loss=[0.007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[41]-[21] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[22] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[23] lr=[0.7094083883615688] loss=[0.004]\n",
      "[all_10]-[41]-[24] lr=[0.7094083883615688] loss=[0.005]\n",
      "[all_10]-[41]-[25] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[26] lr=[0.7094083883615688] loss=[0.007]\n",
      "[all_10]-[41]-[27] lr=[0.7094083883615688] loss=[0.007]\n",
      "[all_10]-[41]-[28] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[29] lr=[0.7094083883615688] loss=[0.007]\n",
      "[all_10]-[41]-[30] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[31] lr=[0.7094083883615688] loss=[0.007]\n",
      "[all_10]-[41]-[32] lr=[0.7094083883615688] loss=[0.005]\n",
      "[all_10]-[41]-[33] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[34] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[35] lr=[0.7094083883615688] loss=[0.005]\n",
      "[all_10]-[41]-[36] lr=[0.7094083883615688] loss=[0.008]\n",
      "[all_10]-[41]-[37] lr=[0.7094083883615688] loss=[0.005]\n",
      "[all_10]-[41]-[38] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[39] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[40] lr=[0.7094083883615688] loss=[0.005]\n",
      "[all_10]-[41]-[41] lr=[0.7094083883615688] loss=[0.005]\n",
      "[all_10]-[41]-[42] lr=[0.7094083883615688] loss=[0.009]\n",
      "[all_10]-[41]-[43] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[44] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[45] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[46] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[47] lr=[0.7094083883615688] loss=[0.006]\n",
      "[all_10]-[41]-[48] lr=[0.7094083883615688] loss=[0.006]\n",
      "tensor([[0.0305, 0.0474, 0.0577,  ..., 0.0034, 0.0082, 0.0129],\n",
      "        [0.0261, 0.0372, 0.0505,  ..., 0.0343, 0.0284, 0.0234],\n",
      "        [0.0420, 0.0628, 0.0816,  ..., 0.0318, 0.0262, 0.0208],\n",
      "        ...,\n",
      "        [0.0350, 0.0564, 0.0722,  ..., 0.0257, 0.0303, 0.0354],\n",
      "        [0.0447, 0.0662, 0.0741,  ..., 0.0221, 0.0174, 0.0152],\n",
      "        [0.0247, 0.0398, 0.0564,  ..., 0.0293, 0.0294, 0.0240]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0484, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1397],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.4947,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0242,  ..., 0.0000, 0.0140, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0134, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[42]-[1] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[2] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[3] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[4] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[5] lr=[0.7072801631964841] loss=[0.007]\n",
      "[all_10]-[42]-[6] lr=[0.7072801631964841] loss=[0.007]\n",
      "[all_10]-[42]-[7] lr=[0.7072801631964841] loss=[0.005]\n",
      "[all_10]-[42]-[8] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[9] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[10] lr=[0.7072801631964841] loss=[0.005]\n",
      "[all_10]-[42]-[11] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[12] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[13] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[14] lr=[0.7072801631964841] loss=[0.005]\n",
      "[all_10]-[42]-[15] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[16] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[17] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[18] lr=[0.7072801631964841] loss=[0.007]\n",
      "[all_10]-[42]-[19] lr=[0.7072801631964841] loss=[0.005]\n",
      "[all_10]-[42]-[20] lr=[0.7072801631964841] loss=[0.007]\n",
      "[all_10]-[42]-[21] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[22] lr=[0.7072801631964841] loss=[0.007]\n",
      "[all_10]-[42]-[23] lr=[0.7072801631964841] loss=[0.007]\n",
      "[all_10]-[42]-[24] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[25] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[26] lr=[0.7072801631964841] loss=[0.008]\n",
      "[all_10]-[42]-[27] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[28] lr=[0.7072801631964841] loss=[0.007]\n",
      "[all_10]-[42]-[29] lr=[0.7072801631964841] loss=[0.004]\n",
      "[all_10]-[42]-[30] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[31] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[32] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[33] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[34] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[35] lr=[0.7072801631964841] loss=[0.005]\n",
      "[all_10]-[42]-[36] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[37] lr=[0.7072801631964841] loss=[0.005]\n",
      "[all_10]-[42]-[38] lr=[0.7072801631964841] loss=[0.007]\n",
      "[all_10]-[42]-[39] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[40] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[41] lr=[0.7072801631964841] loss=[0.007]\n",
      "[all_10]-[42]-[42] lr=[0.7072801631964841] loss=[0.006]\n",
      "[all_10]-[42]-[43] lr=[0.7072801631964841] loss=[0.004]\n",
      "[all_10]-[42]-[44] lr=[0.7072801631964841] loss=[0.007]\n",
      "[all_10]-[42]-[45] lr=[0.7072801631964841] loss=[0.005]\n",
      "[all_10]-[42]-[46] lr=[0.7072801631964841] loss=[0.005]\n",
      "[all_10]-[42]-[47] lr=[0.7072801631964841] loss=[0.007]\n",
      "[all_10]-[42]-[48] lr=[0.7072801631964841] loss=[0.006]\n",
      "tensor([[ 0.0091,  0.0164,  0.0225,  ...,  0.0189,  0.0140,  0.0079],\n",
      "        [ 0.0189,  0.0426,  0.0638,  ...,  0.0148,  0.0163,  0.0159],\n",
      "        [ 0.0152,  0.0395,  0.0641,  ...,  0.0103,  0.0105,  0.0110],\n",
      "        ...,\n",
      "        [ 0.0166,  0.0417,  0.0717,  ...,  0.0154,  0.0196,  0.0188],\n",
      "        [ 0.0242,  0.0426,  0.0509,  ...,  0.0187,  0.0104,  0.0064],\n",
      "        [ 0.0105,  0.0358,  0.0645,  ..., -0.0067, -0.0065, -0.0039]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.5949,  ..., 0.0000, 0.0000, 0.0496],\n",
      "        [0.0000, 0.0000, 0.0151,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.2485, 0.0000, 1.6343,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0605, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0657, 0.0361, 0.2232,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[43]-[1] lr=[0.7051583227068947] loss=[0.005]\n",
      "[all_10]-[43]-[2] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[3] lr=[0.7051583227068947] loss=[0.007]\n",
      "[all_10]-[43]-[4] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[5] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[6] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[7] lr=[0.7051583227068947] loss=[0.005]\n",
      "[all_10]-[43]-[8] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[9] lr=[0.7051583227068947] loss=[0.007]\n",
      "[all_10]-[43]-[10] lr=[0.7051583227068947] loss=[0.005]\n",
      "[all_10]-[43]-[11] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[12] lr=[0.7051583227068947] loss=[0.008]\n",
      "[all_10]-[43]-[13] lr=[0.7051583227068947] loss=[0.007]\n",
      "[all_10]-[43]-[14] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[15] lr=[0.7051583227068947] loss=[0.007]\n",
      "[all_10]-[43]-[16] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[17] lr=[0.7051583227068947] loss=[0.008]\n",
      "[all_10]-[43]-[18] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[19] lr=[0.7051583227068947] loss=[0.007]\n",
      "[all_10]-[43]-[20] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[21] lr=[0.7051583227068947] loss=[0.007]\n",
      "[all_10]-[43]-[22] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[23] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[24] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[25] lr=[0.7051583227068947] loss=[0.007]\n",
      "[all_10]-[43]-[26] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[27] lr=[0.7051583227068947] loss=[0.005]\n",
      "[all_10]-[43]-[28] lr=[0.7051583227068947] loss=[0.008]\n",
      "[all_10]-[43]-[29] lr=[0.7051583227068947] loss=[0.005]\n",
      "[all_10]-[43]-[30] lr=[0.7051583227068947] loss=[0.008]\n",
      "[all_10]-[43]-[31] lr=[0.7051583227068947] loss=[0.004]\n",
      "[all_10]-[43]-[32] lr=[0.7051583227068947] loss=[0.005]\n",
      "[all_10]-[43]-[33] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[34] lr=[0.7051583227068947] loss=[0.005]\n",
      "[all_10]-[43]-[35] lr=[0.7051583227068947] loss=[0.007]\n",
      "[all_10]-[43]-[36] lr=[0.7051583227068947] loss=[0.007]\n",
      "[all_10]-[43]-[37] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[38] lr=[0.7051583227068947] loss=[0.007]\n",
      "[all_10]-[43]-[39] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[40] lr=[0.7051583227068947] loss=[0.007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[43]-[41] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[42] lr=[0.7051583227068947] loss=[0.005]\n",
      "[all_10]-[43]-[43] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[44] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[45] lr=[0.7051583227068947] loss=[0.005]\n",
      "[all_10]-[43]-[46] lr=[0.7051583227068947] loss=[0.006]\n",
      "[all_10]-[43]-[47] lr=[0.7051583227068947] loss=[0.007]\n",
      "[all_10]-[43]-[48] lr=[0.7051583227068947] loss=[0.007]\n",
      "tensor([[ 0.0168,  0.0390,  0.0529,  ...,  0.0129,  0.0153,  0.0162],\n",
      "        [ 0.0084,  0.0366,  0.0554,  ..., -0.0001, -0.0050, -0.0067],\n",
      "        [ 0.0158,  0.0363,  0.0501,  ...,  0.0376,  0.0306,  0.0248],\n",
      "        ...,\n",
      "        [ 0.0279,  0.0613,  0.0698,  ...,  0.0032, -0.0009, -0.0034],\n",
      "        [ 0.0061,  0.0148,  0.0268,  ...,  0.0171,  0.0129,  0.0054],\n",
      "        [ 0.0158,  0.0300,  0.0433,  ..., -0.0011, -0.0028, -0.0042]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0700,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0605,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 2.9628, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1035]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[44]-[1] lr=[0.703042847738774] loss=[0.005]\n",
      "[all_10]-[44]-[2] lr=[0.703042847738774] loss=[0.006]\n",
      "[all_10]-[44]-[3] lr=[0.703042847738774] loss=[0.006]\n",
      "[all_10]-[44]-[4] lr=[0.703042847738774] loss=[0.005]\n",
      "[all_10]-[44]-[5] lr=[0.703042847738774] loss=[0.007]\n",
      "[all_10]-[44]-[6] lr=[0.703042847738774] loss=[0.007]\n",
      "[all_10]-[44]-[7] lr=[0.703042847738774] loss=[0.006]\n",
      "[all_10]-[44]-[8] lr=[0.703042847738774] loss=[0.006]\n",
      "[all_10]-[44]-[9] lr=[0.703042847738774] loss=[0.007]\n",
      "[all_10]-[44]-[10] lr=[0.703042847738774] loss=[0.005]\n",
      "[all_10]-[44]-[11] lr=[0.703042847738774] loss=[0.006]\n",
      "[all_10]-[44]-[12] lr=[0.703042847738774] loss=[0.006]\n",
      "[all_10]-[44]-[13] lr=[0.703042847738774] loss=[0.006]\n",
      "[all_10]-[44]-[14] lr=[0.703042847738774] loss=[0.006]\n",
      "[all_10]-[44]-[15] lr=[0.703042847738774] loss=[0.007]\n",
      "[all_10]-[44]-[16] lr=[0.703042847738774] loss=[0.006]\n",
      "[all_10]-[44]-[17] lr=[0.703042847738774] loss=[0.007]\n",
      "[all_10]-[44]-[18] lr=[0.703042847738774] loss=[0.005]\n",
      "[all_10]-[44]-[19] lr=[0.703042847738774] loss=[0.006]\n",
      "[all_10]-[44]-[20] lr=[0.703042847738774] loss=[0.005]\n",
      "[all_10]-[44]-[21] lr=[0.703042847738774] loss=[0.006]\n",
      "[all_10]-[44]-[22] lr=[0.703042847738774] loss=[0.006]\n",
      "[all_10]-[44]-[23] lr=[0.703042847738774] loss=[0.006]\n",
      "[all_10]-[44]-[24] lr=[0.703042847738774] loss=[0.006]\n",
      "[all_10]-[44]-[25] lr=[0.703042847738774] loss=[0.007]\n",
      "[all_10]-[44]-[26] lr=[0.703042847738774] loss=[0.007]\n",
      "[all_10]-[44]-[27] lr=[0.703042847738774] loss=[0.006]\n",
      "[all_10]-[44]-[28] lr=[0.703042847738774] loss=[0.006]\n",
      "[all_10]-[44]-[29] lr=[0.703042847738774] loss=[0.007]\n",
      "[all_10]-[44]-[30] lr=[0.703042847738774] loss=[0.005]\n",
      "[all_10]-[44]-[31] lr=[0.703042847738774] loss=[0.005]\n",
      "[all_10]-[44]-[32] lr=[0.703042847738774] loss=[0.005]\n",
      "[all_10]-[44]-[33] lr=[0.703042847738774] loss=[0.007]\n",
      "[all_10]-[44]-[34] lr=[0.703042847738774] loss=[0.005]\n",
      "[all_10]-[44]-[35] lr=[0.703042847738774] loss=[0.007]\n",
      "[all_10]-[44]-[36] lr=[0.703042847738774] loss=[0.007]\n",
      "[all_10]-[44]-[37] lr=[0.703042847738774] loss=[0.005]\n",
      "[all_10]-[44]-[38] lr=[0.703042847738774] loss=[0.007]\n",
      "[all_10]-[44]-[39] lr=[0.703042847738774] loss=[0.005]\n",
      "[all_10]-[44]-[40] lr=[0.703042847738774] loss=[0.005]\n",
      "[all_10]-[44]-[41] lr=[0.703042847738774] loss=[0.007]\n",
      "[all_10]-[44]-[42] lr=[0.703042847738774] loss=[0.005]\n",
      "[all_10]-[44]-[43] lr=[0.703042847738774] loss=[0.007]\n",
      "[all_10]-[44]-[44] lr=[0.703042847738774] loss=[0.007]\n",
      "[all_10]-[44]-[45] lr=[0.703042847738774] loss=[0.006]\n",
      "[all_10]-[44]-[46] lr=[0.703042847738774] loss=[0.007]\n",
      "[all_10]-[44]-[47] lr=[0.703042847738774] loss=[0.007]\n",
      "[all_10]-[44]-[48] lr=[0.703042847738774] loss=[0.006]\n",
      "tensor([[0.0088, 0.0190, 0.0421,  ..., 0.0288, 0.0262, 0.0353],\n",
      "        [0.0191, 0.0318, 0.0579,  ..., 0.0202, 0.0169, 0.0115],\n",
      "        [0.0209, 0.0434, 0.0530,  ..., 0.0148, 0.0171, 0.0192],\n",
      "        ...,\n",
      "        [0.0065, 0.0204, 0.0365,  ..., 0.0069, 0.0170, 0.0192],\n",
      "        [0.0267, 0.0619, 0.0757,  ..., 0.0031, 0.0070, 0.0051],\n",
      "        [0.0186, 0.0342, 0.0454,  ..., 0.0092, 0.0040, 0.0022]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0811, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0148, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0147, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2346, 0.1751,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0605, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[45]-[1] lr=[0.7009337191955577] loss=[0.008]\n",
      "[all_10]-[45]-[2] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[3] lr=[0.7009337191955577] loss=[0.007]\n",
      "[all_10]-[45]-[4] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[5] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[6] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[7] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[8] lr=[0.7009337191955577] loss=[0.005]\n",
      "[all_10]-[45]-[9] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[10] lr=[0.7009337191955577] loss=[0.005]\n",
      "[all_10]-[45]-[11] lr=[0.7009337191955577] loss=[0.005]\n",
      "[all_10]-[45]-[12] lr=[0.7009337191955577] loss=[0.007]\n",
      "[all_10]-[45]-[13] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[14] lr=[0.7009337191955577] loss=[0.007]\n",
      "[all_10]-[45]-[15] lr=[0.7009337191955577] loss=[0.005]\n",
      "[all_10]-[45]-[16] lr=[0.7009337191955577] loss=[0.005]\n",
      "[all_10]-[45]-[17] lr=[0.7009337191955577] loss=[0.007]\n",
      "[all_10]-[45]-[18] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[19] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[20] lr=[0.7009337191955577] loss=[0.005]\n",
      "[all_10]-[45]-[21] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[22] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[23] lr=[0.7009337191955577] loss=[0.005]\n",
      "[all_10]-[45]-[24] lr=[0.7009337191955577] loss=[0.005]\n",
      "[all_10]-[45]-[25] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[26] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[27] lr=[0.7009337191955577] loss=[0.007]\n",
      "[all_10]-[45]-[28] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[29] lr=[0.7009337191955577] loss=[0.005]\n",
      "[all_10]-[45]-[30] lr=[0.7009337191955577] loss=[0.005]\n",
      "[all_10]-[45]-[31] lr=[0.7009337191955577] loss=[0.005]\n",
      "[all_10]-[45]-[32] lr=[0.7009337191955577] loss=[0.007]\n",
      "[all_10]-[45]-[33] lr=[0.7009337191955577] loss=[0.005]\n",
      "[all_10]-[45]-[34] lr=[0.7009337191955577] loss=[0.005]\n",
      "[all_10]-[45]-[35] lr=[0.7009337191955577] loss=[0.007]\n",
      "[all_10]-[45]-[36] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[37] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[38] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[39] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[40] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[41] lr=[0.7009337191955577] loss=[0.007]\n",
      "[all_10]-[45]-[42] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[43] lr=[0.7009337191955577] loss=[0.006]\n",
      "[all_10]-[45]-[44] lr=[0.7009337191955577] loss=[0.005]\n",
      "[all_10]-[45]-[45] lr=[0.7009337191955577] loss=[0.005]\n",
      "[all_10]-[45]-[46] lr=[0.7009337191955577] loss=[0.007]\n",
      "[all_10]-[45]-[47] lr=[0.7009337191955577] loss=[0.007]\n",
      "[all_10]-[45]-[48] lr=[0.7009337191955577] loss=[0.004]\n",
      "tensor([[ 0.0249,  0.0387,  0.0493,  ...,  0.0064,  0.0069,  0.0115],\n",
      "        [ 0.0161,  0.0206,  0.0338,  ...,  0.0092,  0.0070,  0.0038],\n",
      "        [ 0.0365,  0.0574,  0.0790,  ..., -0.0103, -0.0148, -0.0162],\n",
      "        ...,\n",
      "        [ 0.0320,  0.0430,  0.0605,  ..., -0.0006, -0.0022, -0.0009],\n",
      "        [ 0.0359,  0.0464,  0.0509,  ..., -0.0024, -0.0042,  0.0008],\n",
      "        [ 0.0300,  0.0490,  0.0567,  ...,  0.0189,  0.0161,  0.0157]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0229],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3906, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1236],\n",
      "        [0.0000, 0.0239, 0.1013,  ..., 0.0000, 0.1934, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[46]-[1] lr=[0.698830918037971] loss=[0.007]\n",
      "[all_10]-[46]-[2] lr=[0.698830918037971] loss=[0.007]\n",
      "[all_10]-[46]-[3] lr=[0.698830918037971] loss=[0.007]\n",
      "[all_10]-[46]-[4] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[5] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[6] lr=[0.698830918037971] loss=[0.007]\n",
      "[all_10]-[46]-[7] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[8] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[9] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[10] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[11] lr=[0.698830918037971] loss=[0.005]\n",
      "[all_10]-[46]-[12] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[13] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[14] lr=[0.698830918037971] loss=[0.005]\n",
      "[all_10]-[46]-[15] lr=[0.698830918037971] loss=[0.005]\n",
      "[all_10]-[46]-[16] lr=[0.698830918037971] loss=[0.005]\n",
      "[all_10]-[46]-[17] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[18] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[19] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[20] lr=[0.698830918037971] loss=[0.007]\n",
      "[all_10]-[46]-[21] lr=[0.698830918037971] loss=[0.007]\n",
      "[all_10]-[46]-[22] lr=[0.698830918037971] loss=[0.007]\n",
      "[all_10]-[46]-[23] lr=[0.698830918037971] loss=[0.007]\n",
      "[all_10]-[46]-[24] lr=[0.698830918037971] loss=[0.005]\n",
      "[all_10]-[46]-[25] lr=[0.698830918037971] loss=[0.007]\n",
      "[all_10]-[46]-[26] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[27] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[28] lr=[0.698830918037971] loss=[0.007]\n",
      "[all_10]-[46]-[29] lr=[0.698830918037971] loss=[0.004]\n",
      "[all_10]-[46]-[30] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[31] lr=[0.698830918037971] loss=[0.007]\n",
      "[all_10]-[46]-[32] lr=[0.698830918037971] loss=[0.007]\n",
      "[all_10]-[46]-[33] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[34] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[35] lr=[0.698830918037971] loss=[0.005]\n",
      "[all_10]-[46]-[36] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[37] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[38] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[39] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[40] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[41] lr=[0.698830918037971] loss=[0.005]\n",
      "[all_10]-[46]-[42] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[43] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[44] lr=[0.698830918037971] loss=[0.005]\n",
      "[all_10]-[46]-[45] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[46] lr=[0.698830918037971] loss=[0.005]\n",
      "[all_10]-[46]-[47] lr=[0.698830918037971] loss=[0.006]\n",
      "[all_10]-[46]-[48] lr=[0.698830918037971] loss=[0.006]\n",
      "tensor([[ 0.0121,  0.0161,  0.0216,  ...,  0.0004,  0.0067,  0.0069],\n",
      "        [ 0.0052,  0.0101,  0.0200,  ..., -0.0275, -0.0232, -0.0102],\n",
      "        [ 0.0203,  0.0332,  0.0533,  ...,  0.0048,  0.0033,  0.0122],\n",
      "        ...,\n",
      "        [ 0.0143,  0.0248,  0.0348,  ...,  0.0064,  0.0016,  0.0002],\n",
      "        [ 0.0178,  0.0308,  0.0401,  ...,  0.0067,  0.0026, -0.0031],\n",
      "        [ 0.0153,  0.0379,  0.0569,  ..., -0.0014,  0.0020,  0.0020]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.3668, 0.0000, 0.1205,  ..., 0.0000, 0.0301, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3280, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2290,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[47]-[1] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[2] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[3] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[4] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[5] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[6] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[7] lr=[0.6967344252838571] loss=[0.007]\n",
      "[all_10]-[47]-[8] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[9] lr=[0.6967344252838571] loss=[0.005]\n",
      "[all_10]-[47]-[10] lr=[0.6967344252838571] loss=[0.005]\n",
      "[all_10]-[47]-[11] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[12] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[13] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[14] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[15] lr=[0.6967344252838571] loss=[0.005]\n",
      "[all_10]-[47]-[16] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[17] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[18] lr=[0.6967344252838571] loss=[0.005]\n",
      "[all_10]-[47]-[19] lr=[0.6967344252838571] loss=[0.007]\n",
      "[all_10]-[47]-[20] lr=[0.6967344252838571] loss=[0.007]\n",
      "[all_10]-[47]-[21] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[22] lr=[0.6967344252838571] loss=[0.005]\n",
      "[all_10]-[47]-[23] lr=[0.6967344252838571] loss=[0.007]\n",
      "[all_10]-[47]-[24] lr=[0.6967344252838571] loss=[0.005]\n",
      "[all_10]-[47]-[25] lr=[0.6967344252838571] loss=[0.005]\n",
      "[all_10]-[47]-[26] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[27] lr=[0.6967344252838571] loss=[0.005]\n",
      "[all_10]-[47]-[28] lr=[0.6967344252838571] loss=[0.007]\n",
      "[all_10]-[47]-[29] lr=[0.6967344252838571] loss=[0.007]\n",
      "[all_10]-[47]-[30] lr=[0.6967344252838571] loss=[0.005]\n",
      "[all_10]-[47]-[31] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[32] lr=[0.6967344252838571] loss=[0.005]\n",
      "[all_10]-[47]-[33] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[34] lr=[0.6967344252838571] loss=[0.008]\n",
      "[all_10]-[47]-[35] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[36] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[37] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[38] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[39] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[40] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[41] lr=[0.6967344252838571] loss=[0.007]\n",
      "[all_10]-[47]-[42] lr=[0.6967344252838571] loss=[0.007]\n",
      "[all_10]-[47]-[43] lr=[0.6967344252838571] loss=[0.007]\n",
      "[all_10]-[47]-[44] lr=[0.6967344252838571] loss=[0.007]\n",
      "[all_10]-[47]-[45] lr=[0.6967344252838571] loss=[0.005]\n",
      "[all_10]-[47]-[46] lr=[0.6967344252838571] loss=[0.006]\n",
      "[all_10]-[47]-[47] lr=[0.6967344252838571] loss=[0.008]\n",
      "[all_10]-[47]-[48] lr=[0.6967344252838571] loss=[0.007]\n",
      "tensor([[0.0242, 0.0288, 0.0396,  ..., 0.0111, 0.0182, 0.0213],\n",
      "        [0.0311, 0.0438, 0.0551,  ..., 0.0166, 0.0175, 0.0254],\n",
      "        [0.0611, 0.0961, 0.1143,  ..., 0.0120, 0.0147, 0.0177],\n",
      "        ...,\n",
      "        [0.0264, 0.0491, 0.0616,  ..., 0.0159, 0.0103, 0.0109],\n",
      "        [0.0230, 0.0266, 0.0400,  ..., 0.0239, 0.0216, 0.0179],\n",
      "        [0.0306, 0.0466, 0.0590,  ..., 0.0192, 0.0107, 0.0135]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1107, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1193,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.4548,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.1046, 0.0648, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0248, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[48]-[1] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[2] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[3] lr=[0.6946442220080056] loss=[0.005]\n",
      "[all_10]-[48]-[4] lr=[0.6946442220080056] loss=[0.005]\n",
      "[all_10]-[48]-[5] lr=[0.6946442220080056] loss=[0.005]\n",
      "[all_10]-[48]-[6] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[7] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[8] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[9] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[10] lr=[0.6946442220080056] loss=[0.007]\n",
      "[all_10]-[48]-[11] lr=[0.6946442220080056] loss=[0.007]\n",
      "[all_10]-[48]-[12] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[13] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[14] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[15] lr=[0.6946442220080056] loss=[0.005]\n",
      "[all_10]-[48]-[16] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[17] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[18] lr=[0.6946442220080056] loss=[0.007]\n",
      "[all_10]-[48]-[19] lr=[0.6946442220080056] loss=[0.007]\n",
      "[all_10]-[48]-[20] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[21] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[22] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[23] lr=[0.6946442220080056] loss=[0.007]\n",
      "[all_10]-[48]-[24] lr=[0.6946442220080056] loss=[0.006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[48]-[25] lr=[0.6946442220080056] loss=[0.005]\n",
      "[all_10]-[48]-[26] lr=[0.6946442220080056] loss=[0.005]\n",
      "[all_10]-[48]-[27] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[28] lr=[0.6946442220080056] loss=[0.007]\n",
      "[all_10]-[48]-[29] lr=[0.6946442220080056] loss=[0.007]\n",
      "[all_10]-[48]-[30] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[31] lr=[0.6946442220080056] loss=[0.005]\n",
      "[all_10]-[48]-[32] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[33] lr=[0.6946442220080056] loss=[0.005]\n",
      "[all_10]-[48]-[34] lr=[0.6946442220080056] loss=[0.005]\n",
      "[all_10]-[48]-[35] lr=[0.6946442220080056] loss=[0.005]\n",
      "[all_10]-[48]-[36] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[37] lr=[0.6946442220080056] loss=[0.005]\n",
      "[all_10]-[48]-[38] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[39] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[40] lr=[0.6946442220080056] loss=[0.007]\n",
      "[all_10]-[48]-[41] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[42] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[43] lr=[0.6946442220080056] loss=[0.007]\n",
      "[all_10]-[48]-[44] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[45] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[46] lr=[0.6946442220080056] loss=[0.005]\n",
      "[all_10]-[48]-[47] lr=[0.6946442220080056] loss=[0.006]\n",
      "[all_10]-[48]-[48] lr=[0.6946442220080056] loss=[0.005]\n",
      "tensor([[ 0.0203,  0.0407,  0.0632,  ...,  0.0007,  0.0009, -0.0002],\n",
      "        [ 0.0335,  0.0437,  0.0571,  ...,  0.0035,  0.0040, -0.0004],\n",
      "        [ 0.0182,  0.0193,  0.0246,  ...,  0.0133,  0.0077,  0.0013],\n",
      "        ...,\n",
      "        [ 0.0265,  0.0407,  0.0557,  ...,  0.0032,  0.0075,  0.0069],\n",
      "        [ 0.0291,  0.0496,  0.0663,  ...,  0.0334,  0.0258,  0.0170],\n",
      "        [ 0.0281,  0.0455,  0.0561,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.1135, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0709, 0.0000,  ..., 0.0000, 0.0093, 0.0000],\n",
      "        [0.0312, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0332, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[49]-[1] lr=[0.6925602893419815] loss=[0.005]\n",
      "[all_10]-[49]-[2] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[3] lr=[0.6925602893419815] loss=[0.005]\n",
      "[all_10]-[49]-[4] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[5] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[6] lr=[0.6925602893419815] loss=[0.007]\n",
      "[all_10]-[49]-[7] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[8] lr=[0.6925602893419815] loss=[0.007]\n",
      "[all_10]-[49]-[9] lr=[0.6925602893419815] loss=[0.007]\n",
      "[all_10]-[49]-[10] lr=[0.6925602893419815] loss=[0.008]\n",
      "[all_10]-[49]-[11] lr=[0.6925602893419815] loss=[0.007]\n",
      "[all_10]-[49]-[12] lr=[0.6925602893419815] loss=[0.005]\n",
      "[all_10]-[49]-[13] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[14] lr=[0.6925602893419815] loss=[0.005]\n",
      "[all_10]-[49]-[15] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[16] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[17] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[18] lr=[0.6925602893419815] loss=[0.008]\n",
      "[all_10]-[49]-[19] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[20] lr=[0.6925602893419815] loss=[0.005]\n",
      "[all_10]-[49]-[21] lr=[0.6925602893419815] loss=[0.007]\n",
      "[all_10]-[49]-[22] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[23] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[24] lr=[0.6925602893419815] loss=[0.005]\n",
      "[all_10]-[49]-[25] lr=[0.6925602893419815] loss=[0.005]\n",
      "[all_10]-[49]-[26] lr=[0.6925602893419815] loss=[0.005]\n",
      "[all_10]-[49]-[27] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[28] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[29] lr=[0.6925602893419815] loss=[0.007]\n",
      "[all_10]-[49]-[30] lr=[0.6925602893419815] loss=[0.007]\n",
      "[all_10]-[49]-[31] lr=[0.6925602893419815] loss=[0.005]\n",
      "[all_10]-[49]-[32] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[33] lr=[0.6925602893419815] loss=[0.005]\n",
      "[all_10]-[49]-[34] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[35] lr=[0.6925602893419815] loss=[0.005]\n",
      "[all_10]-[49]-[36] lr=[0.6925602893419815] loss=[0.005]\n",
      "[all_10]-[49]-[37] lr=[0.6925602893419815] loss=[0.005]\n",
      "[all_10]-[49]-[38] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[39] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[40] lr=[0.6925602893419815] loss=[0.005]\n",
      "[all_10]-[49]-[41] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[42] lr=[0.6925602893419815] loss=[0.007]\n",
      "[all_10]-[49]-[43] lr=[0.6925602893419815] loss=[0.005]\n",
      "[all_10]-[49]-[44] lr=[0.6925602893419815] loss=[0.005]\n",
      "[all_10]-[49]-[45] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[46] lr=[0.6925602893419815] loss=[0.006]\n",
      "[all_10]-[49]-[47] lr=[0.6925602893419815] loss=[0.005]\n",
      "[all_10]-[49]-[48] lr=[0.6925602893419815] loss=[0.007]\n",
      "tensor([[ 0.0188,  0.0217,  0.0276,  ...,  0.0049,  0.0030,  0.0056],\n",
      "        [ 0.0282,  0.0428,  0.0435,  ...,  0.0183,  0.0045, -0.0011],\n",
      "        [ 0.0120,  0.0141,  0.0156,  ...,  0.0031,  0.0064,  0.0064],\n",
      "        ...,\n",
      "        [ 0.0162,  0.0525,  0.0767,  ...,  0.0227,  0.0253,  0.0231],\n",
      "        [ 0.0085,  0.0076,  0.0055,  ...,  0.0062,  0.0162,  0.0196],\n",
      "        [ 0.0140,  0.0301,  0.0566,  ...,  0.0111,  0.0142,  0.0129]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.5928, 0.0000,  ..., 0.0000, 0.0000, 0.0053],\n",
      "        [0.0000, 0.0605, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0094, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0085, 0.5904, 0.0212,  ..., 0.0463, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0524, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0413,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[50]-[1] lr=[0.6904826084739556] loss=[0.005]\n",
      "[all_10]-[50]-[2] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[3] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[4] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[5] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[6] lr=[0.6904826084739556] loss=[0.008]\n",
      "[all_10]-[50]-[7] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[8] lr=[0.6904826084739556] loss=[0.005]\n",
      "[all_10]-[50]-[9] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[10] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[11] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[12] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[13] lr=[0.6904826084739556] loss=[0.005]\n",
      "[all_10]-[50]-[14] lr=[0.6904826084739556] loss=[0.005]\n",
      "[all_10]-[50]-[15] lr=[0.6904826084739556] loss=[0.007]\n",
      "[all_10]-[50]-[16] lr=[0.6904826084739556] loss=[0.005]\n",
      "[all_10]-[50]-[17] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[18] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[19] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[20] lr=[0.6904826084739556] loss=[0.007]\n",
      "[all_10]-[50]-[21] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[22] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[23] lr=[0.6904826084739556] loss=[0.007]\n",
      "[all_10]-[50]-[24] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[25] lr=[0.6904826084739556] loss=[0.005]\n",
      "[all_10]-[50]-[26] lr=[0.6904826084739556] loss=[0.005]\n",
      "[all_10]-[50]-[27] lr=[0.6904826084739556] loss=[0.007]\n",
      "[all_10]-[50]-[28] lr=[0.6904826084739556] loss=[0.005]\n",
      "[all_10]-[50]-[29] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[30] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[31] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[32] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[33] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[34] lr=[0.6904826084739556] loss=[0.005]\n",
      "[all_10]-[50]-[35] lr=[0.6904826084739556] loss=[0.007]\n",
      "[all_10]-[50]-[36] lr=[0.6904826084739556] loss=[0.007]\n",
      "[all_10]-[50]-[37] lr=[0.6904826084739556] loss=[0.005]\n",
      "[all_10]-[50]-[38] lr=[0.6904826084739556] loss=[0.007]\n",
      "[all_10]-[50]-[39] lr=[0.6904826084739556] loss=[0.007]\n",
      "[all_10]-[50]-[40] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[41] lr=[0.6904826084739556] loss=[0.005]\n",
      "[all_10]-[50]-[42] lr=[0.6904826084739556] loss=[0.005]\n",
      "[all_10]-[50]-[43] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[44] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[45] lr=[0.6904826084739556] loss=[0.005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[50]-[46] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[47] lr=[0.6904826084739556] loss=[0.006]\n",
      "[all_10]-[50]-[48] lr=[0.6904826084739556] loss=[0.006]\n",
      "tensor([[ 4.4550e-02,  5.7874e-02,  6.3497e-02,  ...,  2.3022e-03,\n",
      "          1.5506e-02,  2.4465e-02],\n",
      "        [ 1.9501e-02,  3.8255e-02,  6.0891e-02,  ...,  2.8313e-03,\n",
      "          5.3601e-03,  4.7523e-03],\n",
      "        [ 1.0132e-02,  2.3769e-02,  3.5351e-02,  ...,  1.8801e-02,\n",
      "          1.0570e-02,  8.8642e-03],\n",
      "        ...,\n",
      "        [ 1.3790e-02,  2.0497e-02,  3.2808e-02,  ...,  2.7198e-03,\n",
      "          9.5704e-03,  1.2123e-02],\n",
      "        [ 9.8603e-03,  3.0504e-02,  5.3562e-02,  ...,  1.6732e-02,\n",
      "          1.3519e-02,  1.8185e-02],\n",
      "        [ 8.2901e-03,  7.0923e-03,  2.3691e-02,  ...,  1.3061e-05,\n",
      "         -2.0130e-03, -3.6169e-03]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0506,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2290,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0320, 0.0260,  ..., 0.0606, 0.0000, 0.0392],\n",
      "        [0.0962, 0.0000, 0.0612,  ..., 0.0000, 0.0000, 0.1372],\n",
      "        [0.0000, 0.0882, 0.0000,  ..., 0.0000, 0.0000, 0.0515]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[51]-[1] lr=[0.6884111606485337] loss=[0.007]\n",
      "[all_10]-[51]-[2] lr=[0.6884111606485337] loss=[0.007]\n",
      "[all_10]-[51]-[3] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[4] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[5] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[6] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[7] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[8] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[9] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[10] lr=[0.6884111606485337] loss=[0.005]\n",
      "[all_10]-[51]-[11] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[12] lr=[0.6884111606485337] loss=[0.005]\n",
      "[all_10]-[51]-[13] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[14] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[15] lr=[0.6884111606485337] loss=[0.007]\n",
      "[all_10]-[51]-[16] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[17] lr=[0.6884111606485337] loss=[0.007]\n",
      "[all_10]-[51]-[18] lr=[0.6884111606485337] loss=[0.007]\n",
      "[all_10]-[51]-[19] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[20] lr=[0.6884111606485337] loss=[0.005]\n",
      "[all_10]-[51]-[21] lr=[0.6884111606485337] loss=[0.007]\n",
      "[all_10]-[51]-[22] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[23] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[24] lr=[0.6884111606485337] loss=[0.005]\n",
      "[all_10]-[51]-[25] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[26] lr=[0.6884111606485337] loss=[0.007]\n",
      "[all_10]-[51]-[27] lr=[0.6884111606485337] loss=[0.005]\n",
      "[all_10]-[51]-[28] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[29] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[30] lr=[0.6884111606485337] loss=[0.007]\n",
      "[all_10]-[51]-[31] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[32] lr=[0.6884111606485337] loss=[0.005]\n",
      "[all_10]-[51]-[33] lr=[0.6884111606485337] loss=[0.005]\n",
      "[all_10]-[51]-[34] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[35] lr=[0.6884111606485337] loss=[0.005]\n",
      "[all_10]-[51]-[36] lr=[0.6884111606485337] loss=[0.005]\n",
      "[all_10]-[51]-[37] lr=[0.6884111606485337] loss=[0.005]\n",
      "[all_10]-[51]-[38] lr=[0.6884111606485337] loss=[0.005]\n",
      "[all_10]-[51]-[39] lr=[0.6884111606485337] loss=[0.007]\n",
      "[all_10]-[51]-[40] lr=[0.6884111606485337] loss=[0.005]\n",
      "[all_10]-[51]-[41] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[42] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[43] lr=[0.6884111606485337] loss=[0.004]\n",
      "[all_10]-[51]-[44] lr=[0.6884111606485337] loss=[0.006]\n",
      "[all_10]-[51]-[45] lr=[0.6884111606485337] loss=[0.005]\n",
      "[all_10]-[51]-[46] lr=[0.6884111606485337] loss=[0.005]\n",
      "[all_10]-[51]-[47] lr=[0.6884111606485337] loss=[0.005]\n",
      "[all_10]-[51]-[48] lr=[0.6884111606485337] loss=[0.006]\n",
      "tensor([[ 0.0585,  0.0623,  0.0604,  ...,  0.0027,  0.0171,  0.0367],\n",
      "        [ 0.0248,  0.0600,  0.0924,  ...,  0.0154,  0.0164,  0.0121],\n",
      "        [ 0.0272,  0.0492,  0.0583,  ...,  0.0011, -0.0024,  0.0022],\n",
      "        ...,\n",
      "        [ 0.0615,  0.0797,  0.1011,  ...,  0.0057,  0.0095,  0.0152],\n",
      "        [ 0.0118,  0.0046,  0.0111,  ...,  0.0113,  0.0018, -0.0022],\n",
      "        [ 0.0216,  0.0367,  0.0454,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[2.9495, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.4538],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0189, 0.0119, 0.0000,  ..., 0.0000, 0.0000, 0.0081],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1031,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[52]-[1] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[2] lr=[0.686345927166588] loss=[0.007]\n",
      "[all_10]-[52]-[3] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[4] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[5] lr=[0.686345927166588] loss=[0.005]\n",
      "[all_10]-[52]-[6] lr=[0.686345927166588] loss=[0.005]\n",
      "[all_10]-[52]-[7] lr=[0.686345927166588] loss=[0.007]\n",
      "[all_10]-[52]-[8] lr=[0.686345927166588] loss=[0.005]\n",
      "[all_10]-[52]-[9] lr=[0.686345927166588] loss=[0.005]\n",
      "[all_10]-[52]-[10] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[11] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[12] lr=[0.686345927166588] loss=[0.005]\n",
      "[all_10]-[52]-[13] lr=[0.686345927166588] loss=[0.005]\n",
      "[all_10]-[52]-[14] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[15] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[16] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[17] lr=[0.686345927166588] loss=[0.007]\n",
      "[all_10]-[52]-[18] lr=[0.686345927166588] loss=[0.005]\n",
      "[all_10]-[52]-[19] lr=[0.686345927166588] loss=[0.005]\n",
      "[all_10]-[52]-[20] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[21] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[22] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[23] lr=[0.686345927166588] loss=[0.007]\n",
      "[all_10]-[52]-[24] lr=[0.686345927166588] loss=[0.007]\n",
      "[all_10]-[52]-[25] lr=[0.686345927166588] loss=[0.005]\n",
      "[all_10]-[52]-[26] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[27] lr=[0.686345927166588] loss=[0.005]\n",
      "[all_10]-[52]-[28] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[29] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[30] lr=[0.686345927166588] loss=[0.007]\n",
      "[all_10]-[52]-[31] lr=[0.686345927166588] loss=[0.005]\n",
      "[all_10]-[52]-[32] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[33] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[34] lr=[0.686345927166588] loss=[0.007]\n",
      "[all_10]-[52]-[35] lr=[0.686345927166588] loss=[0.005]\n",
      "[all_10]-[52]-[36] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[37] lr=[0.686345927166588] loss=[0.005]\n",
      "[all_10]-[52]-[38] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[39] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[40] lr=[0.686345927166588] loss=[0.007]\n",
      "[all_10]-[52]-[41] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[42] lr=[0.686345927166588] loss=[0.005]\n",
      "[all_10]-[52]-[43] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[44] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[45] lr=[0.686345927166588] loss=[0.006]\n",
      "[all_10]-[52]-[46] lr=[0.686345927166588] loss=[0.005]\n",
      "[all_10]-[52]-[47] lr=[0.686345927166588] loss=[0.005]\n",
      "[all_10]-[52]-[48] lr=[0.686345927166588] loss=[0.006]\n",
      "tensor([[ 0.0027, -0.0012,  0.0019,  ...,  0.0143,  0.0293,  0.0015],\n",
      "        [ 0.0293,  0.0404,  0.0757,  ...,  0.0040,  0.0028,  0.0045],\n",
      "        [ 0.0186,  0.0220,  0.0182,  ..., -0.0123, -0.0064, -0.0035],\n",
      "        ...,\n",
      "        [ 0.0143,  0.0174,  0.0176,  ...,  0.0052,  0.0041,  0.0101],\n",
      "        [ 0.0163,  0.0176,  0.0360,  ..., -0.0009, -0.0069, -0.0025],\n",
      "        [ 0.0223,  0.0315,  0.0621,  ..., -0.0033, -0.0032,  0.0045]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1716, 0.0000],\n",
      "        [0.0000, 0.0601, 0.0000,  ..., 0.0058, 0.0000, 0.0000],\n",
      "        [0.0484, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1397],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0636, 0.0000,  ..., 0.0000, 0.0000, 0.0064],\n",
      "        [0.0000, 0.0000, 0.3455,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[53]-[1] lr=[0.6842868893850883] loss=[0.005]\n",
      "[all_10]-[53]-[2] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[3] lr=[0.6842868893850883] loss=[0.005]\n",
      "[all_10]-[53]-[4] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[5] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[6] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[7] lr=[0.6842868893850883] loss=[0.007]\n",
      "[all_10]-[53]-[8] lr=[0.6842868893850883] loss=[0.005]\n",
      "[all_10]-[53]-[9] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[10] lr=[0.6842868893850883] loss=[0.005]\n",
      "[all_10]-[53]-[11] lr=[0.6842868893850883] loss=[0.005]\n",
      "[all_10]-[53]-[12] lr=[0.6842868893850883] loss=[0.007]\n",
      "[all_10]-[53]-[13] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[14] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[15] lr=[0.6842868893850883] loss=[0.005]\n",
      "[all_10]-[53]-[16] lr=[0.6842868893850883] loss=[0.005]\n",
      "[all_10]-[53]-[17] lr=[0.6842868893850883] loss=[0.007]\n",
      "[all_10]-[53]-[18] lr=[0.6842868893850883] loss=[0.005]\n",
      "[all_10]-[53]-[19] lr=[0.6842868893850883] loss=[0.005]\n",
      "[all_10]-[53]-[20] lr=[0.6842868893850883] loss=[0.005]\n",
      "[all_10]-[53]-[21] lr=[0.6842868893850883] loss=[0.005]\n",
      "[all_10]-[53]-[22] lr=[0.6842868893850883] loss=[0.005]\n",
      "[all_10]-[53]-[23] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[24] lr=[0.6842868893850883] loss=[0.007]\n",
      "[all_10]-[53]-[25] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[26] lr=[0.6842868893850883] loss=[0.005]\n",
      "[all_10]-[53]-[27] lr=[0.6842868893850883] loss=[0.007]\n",
      "[all_10]-[53]-[28] lr=[0.6842868893850883] loss=[0.005]\n",
      "[all_10]-[53]-[29] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[30] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[31] lr=[0.6842868893850883] loss=[0.007]\n",
      "[all_10]-[53]-[32] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[33] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[34] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[35] lr=[0.6842868893850883] loss=[0.007]\n",
      "[all_10]-[53]-[36] lr=[0.6842868893850883] loss=[0.007]\n",
      "[all_10]-[53]-[37] lr=[0.6842868893850883] loss=[0.005]\n",
      "[all_10]-[53]-[38] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[39] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[40] lr=[0.6842868893850883] loss=[0.005]\n",
      "[all_10]-[53]-[41] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[42] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[43] lr=[0.6842868893850883] loss=[0.007]\n",
      "[all_10]-[53]-[44] lr=[0.6842868893850883] loss=[0.005]\n",
      "[all_10]-[53]-[45] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[46] lr=[0.6842868893850883] loss=[0.005]\n",
      "[all_10]-[53]-[47] lr=[0.6842868893850883] loss=[0.006]\n",
      "[all_10]-[53]-[48] lr=[0.6842868893850883] loss=[0.005]\n",
      "tensor([[ 0.0220,  0.0629,  0.1109,  ...,  0.0173, -0.0118, -0.0255],\n",
      "        [ 0.0211,  0.0696,  0.0802,  ...,  0.0280,  0.0251,  0.0173],\n",
      "        [ 0.0310,  0.0408,  0.0554,  ...,  0.0215,  0.0206,  0.0187],\n",
      "        ...,\n",
      "        [ 0.0301,  0.0739,  0.0925,  ..., -0.0140, -0.0157, -0.0126],\n",
      "        [ 0.0463,  0.0962,  0.0991,  ...,  0.0071,  0.0134,  0.0284],\n",
      "        [ 0.0091,  0.0012,  0.0250,  ...,  0.0190,  0.0128,  0.0130]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0172, 0.4641, 0.0382,  ..., 0.0000, 0.0000, 0.0269],\n",
      "        [0.0000, 0.0439, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0837,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.4759, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0241, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0161, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[54]-[1] lr=[0.6822340287169331] loss=[0.005]\n",
      "[all_10]-[54]-[2] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[3] lr=[0.6822340287169331] loss=[0.007]\n",
      "[all_10]-[54]-[4] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[5] lr=[0.6822340287169331] loss=[0.007]\n",
      "[all_10]-[54]-[6] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[7] lr=[0.6822340287169331] loss=[0.005]\n",
      "[all_10]-[54]-[8] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[9] lr=[0.6822340287169331] loss=[0.005]\n",
      "[all_10]-[54]-[10] lr=[0.6822340287169331] loss=[0.007]\n",
      "[all_10]-[54]-[11] lr=[0.6822340287169331] loss=[0.005]\n",
      "[all_10]-[54]-[12] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[13] lr=[0.6822340287169331] loss=[0.005]\n",
      "[all_10]-[54]-[14] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[15] lr=[0.6822340287169331] loss=[0.005]\n",
      "[all_10]-[54]-[16] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[17] lr=[0.6822340287169331] loss=[0.005]\n",
      "[all_10]-[54]-[18] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[19] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[20] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[21] lr=[0.6822340287169331] loss=[0.007]\n",
      "[all_10]-[54]-[22] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[23] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[24] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[25] lr=[0.6822340287169331] loss=[0.005]\n",
      "[all_10]-[54]-[26] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[27] lr=[0.6822340287169331] loss=[0.005]\n",
      "[all_10]-[54]-[28] lr=[0.6822340287169331] loss=[0.005]\n",
      "[all_10]-[54]-[29] lr=[0.6822340287169331] loss=[0.005]\n",
      "[all_10]-[54]-[30] lr=[0.6822340287169331] loss=[0.007]\n",
      "[all_10]-[54]-[31] lr=[0.6822340287169331] loss=[0.004]\n",
      "[all_10]-[54]-[32] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[33] lr=[0.6822340287169331] loss=[0.007]\n",
      "[all_10]-[54]-[34] lr=[0.6822340287169331] loss=[0.005]\n",
      "[all_10]-[54]-[35] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[36] lr=[0.6822340287169331] loss=[0.004]\n",
      "[all_10]-[54]-[37] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[38] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[39] lr=[0.6822340287169331] loss=[0.007]\n",
      "[all_10]-[54]-[40] lr=[0.6822340287169331] loss=[0.007]\n",
      "[all_10]-[54]-[41] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[42] lr=[0.6822340287169331] loss=[0.005]\n",
      "[all_10]-[54]-[43] lr=[0.6822340287169331] loss=[0.005]\n",
      "[all_10]-[54]-[44] lr=[0.6822340287169331] loss=[0.007]\n",
      "[all_10]-[54]-[45] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[46] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[47] lr=[0.6822340287169331] loss=[0.006]\n",
      "[all_10]-[54]-[48] lr=[0.6822340287169331] loss=[0.005]\n",
      "tensor([[ 0.0269,  0.0199,  0.0271,  ..., -0.0155, -0.0031,  0.0010],\n",
      "        [-0.0029,  0.0085,  0.0147,  ..., -0.0139, -0.0142, -0.0121],\n",
      "        [ 0.0053, -0.0024,  0.0284,  ..., -0.0249, -0.0152, -0.0113],\n",
      "        ...,\n",
      "        [ 0.0138,  0.0235,  0.0325,  ...,  0.0001, -0.0142, -0.0175],\n",
      "        [ 0.0187,  0.0331,  0.0532,  ..., -0.0290, -0.0149, -0.0106],\n",
      "        [ 0.0111,  0.0273,  0.0329,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0719,  ..., 0.0168, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0000, 0.0000,  ..., 0.0629, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0255, 0.2876, 0.0000,  ..., 0.0000, 0.0000, 0.0187],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1031,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[55]-[1] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[2] lr=[0.6801873266307823] loss=[0.005]\n",
      "[all_10]-[55]-[3] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[4] lr=[0.6801873266307823] loss=[0.005]\n",
      "[all_10]-[55]-[5] lr=[0.6801873266307823] loss=[0.007]\n",
      "[all_10]-[55]-[6] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[7] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[8] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[9] lr=[0.6801873266307823] loss=[0.004]\n",
      "[all_10]-[55]-[10] lr=[0.6801873266307823] loss=[0.007]\n",
      "[all_10]-[55]-[11] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[12] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[13] lr=[0.6801873266307823] loss=[0.005]\n",
      "[all_10]-[55]-[14] lr=[0.6801873266307823] loss=[0.005]\n",
      "[all_10]-[55]-[15] lr=[0.6801873266307823] loss=[0.005]\n",
      "[all_10]-[55]-[16] lr=[0.6801873266307823] loss=[0.005]\n",
      "[all_10]-[55]-[17] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[18] lr=[0.6801873266307823] loss=[0.007]\n",
      "[all_10]-[55]-[19] lr=[0.6801873266307823] loss=[0.005]\n",
      "[all_10]-[55]-[20] lr=[0.6801873266307823] loss=[0.006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[55]-[21] lr=[0.6801873266307823] loss=[0.005]\n",
      "[all_10]-[55]-[22] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[23] lr=[0.6801873266307823] loss=[0.007]\n",
      "[all_10]-[55]-[24] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[25] lr=[0.6801873266307823] loss=[0.007]\n",
      "[all_10]-[55]-[26] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[27] lr=[0.6801873266307823] loss=[0.008]\n",
      "[all_10]-[55]-[28] lr=[0.6801873266307823] loss=[0.005]\n",
      "[all_10]-[55]-[29] lr=[0.6801873266307823] loss=[0.007]\n",
      "[all_10]-[55]-[30] lr=[0.6801873266307823] loss=[0.007]\n",
      "[all_10]-[55]-[31] lr=[0.6801873266307823] loss=[0.005]\n",
      "[all_10]-[55]-[32] lr=[0.6801873266307823] loss=[0.005]\n",
      "[all_10]-[55]-[33] lr=[0.6801873266307823] loss=[0.005]\n",
      "[all_10]-[55]-[34] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[35] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[36] lr=[0.6801873266307823] loss=[0.004]\n",
      "[all_10]-[55]-[37] lr=[0.6801873266307823] loss=[0.005]\n",
      "[all_10]-[55]-[38] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[39] lr=[0.6801873266307823] loss=[0.005]\n",
      "[all_10]-[55]-[40] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[41] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[42] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[43] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[44] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[45] lr=[0.6801873266307823] loss=[0.005]\n",
      "[all_10]-[55]-[46] lr=[0.6801873266307823] loss=[0.005]\n",
      "[all_10]-[55]-[47] lr=[0.6801873266307823] loss=[0.006]\n",
      "[all_10]-[55]-[48] lr=[0.6801873266307823] loss=[0.005]\n",
      "tensor([[ 0.0255,  0.0663,  0.0767,  ..., -0.0096,  0.0043,  0.0098],\n",
      "        [ 0.0149,  0.0005,  0.0178,  ...,  0.0042, -0.0023,  0.0073],\n",
      "        [ 0.0506,  0.0806,  0.0629,  ..., -0.0014,  0.0128,  0.0195],\n",
      "        ...,\n",
      "        [ 0.0266,  0.0446,  0.0852,  ..., -0.0013, -0.0003, -0.0060],\n",
      "        [ 0.0141,  0.0001,  0.0206,  ...,  0.0206,  0.0163,  0.0114],\n",
      "        [ 0.0120,  0.0053,  0.0247,  ...,  0.0119,  0.0108,  0.0060]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0221, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0119,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0351, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0110, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[56]-[1] lr=[0.67814676465089] loss=[0.006]\n",
      "[all_10]-[56]-[2] lr=[0.67814676465089] loss=[0.005]\n",
      "[all_10]-[56]-[3] lr=[0.67814676465089] loss=[0.007]\n",
      "[all_10]-[56]-[4] lr=[0.67814676465089] loss=[0.004]\n",
      "[all_10]-[56]-[5] lr=[0.67814676465089] loss=[0.006]\n",
      "[all_10]-[56]-[6] lr=[0.67814676465089] loss=[0.005]\n",
      "[all_10]-[56]-[7] lr=[0.67814676465089] loss=[0.004]\n",
      "[all_10]-[56]-[8] lr=[0.67814676465089] loss=[0.005]\n",
      "[all_10]-[56]-[9] lr=[0.67814676465089] loss=[0.005]\n",
      "[all_10]-[56]-[10] lr=[0.67814676465089] loss=[0.005]\n",
      "[all_10]-[56]-[11] lr=[0.67814676465089] loss=[0.005]\n",
      "[all_10]-[56]-[12] lr=[0.67814676465089] loss=[0.004]\n",
      "[all_10]-[56]-[13] lr=[0.67814676465089] loss=[0.005]\n",
      "[all_10]-[56]-[14] lr=[0.67814676465089] loss=[0.006]\n",
      "[all_10]-[56]-[15] lr=[0.67814676465089] loss=[0.005]\n",
      "[all_10]-[56]-[16] lr=[0.67814676465089] loss=[0.006]\n",
      "[all_10]-[56]-[17] lr=[0.67814676465089] loss=[0.006]\n",
      "[all_10]-[56]-[18] lr=[0.67814676465089] loss=[0.005]\n",
      "[all_10]-[56]-[19] lr=[0.67814676465089] loss=[0.005]\n",
      "[all_10]-[56]-[20] lr=[0.67814676465089] loss=[0.005]\n",
      "[all_10]-[56]-[21] lr=[0.67814676465089] loss=[0.005]\n",
      "[all_10]-[56]-[22] lr=[0.67814676465089] loss=[0.007]\n",
      "[all_10]-[56]-[23] lr=[0.67814676465089] loss=[0.006]\n",
      "[all_10]-[56]-[24] lr=[0.67814676465089] loss=[0.005]\n",
      "[all_10]-[56]-[25] lr=[0.67814676465089] loss=[0.005]\n",
      "[all_10]-[56]-[26] lr=[0.67814676465089] loss=[0.006]\n",
      "[all_10]-[56]-[27] lr=[0.67814676465089] loss=[0.006]\n",
      "[all_10]-[56]-[28] lr=[0.67814676465089] loss=[0.007]\n",
      "[all_10]-[56]-[29] lr=[0.67814676465089] loss=[0.006]\n",
      "[all_10]-[56]-[30] lr=[0.67814676465089] loss=[0.006]\n",
      "[all_10]-[56]-[31] lr=[0.67814676465089] loss=[0.006]\n",
      "[all_10]-[56]-[32] lr=[0.67814676465089] loss=[0.006]\n",
      "[all_10]-[56]-[33] lr=[0.67814676465089] loss=[0.005]\n",
      "[all_10]-[56]-[34] lr=[0.67814676465089] loss=[0.006]\n",
      "[all_10]-[56]-[35] lr=[0.67814676465089] loss=[0.006]\n",
      "[all_10]-[56]-[36] lr=[0.67814676465089] loss=[0.005]\n",
      "[all_10]-[56]-[37] lr=[0.67814676465089] loss=[0.006]\n",
      "[all_10]-[56]-[38] lr=[0.67814676465089] loss=[0.007]\n",
      "[all_10]-[56]-[39] lr=[0.67814676465089] loss=[0.005]\n",
      "[all_10]-[56]-[40] lr=[0.67814676465089] loss=[0.006]\n",
      "[all_10]-[56]-[41] lr=[0.67814676465089] loss=[0.007]\n",
      "[all_10]-[56]-[42] lr=[0.67814676465089] loss=[0.006]\n",
      "[all_10]-[56]-[43] lr=[0.67814676465089] loss=[0.007]\n",
      "[all_10]-[56]-[44] lr=[0.67814676465089] loss=[0.006]\n",
      "[all_10]-[56]-[45] lr=[0.67814676465089] loss=[0.004]\n",
      "[all_10]-[56]-[46] lr=[0.67814676465089] loss=[0.007]\n",
      "[all_10]-[56]-[47] lr=[0.67814676465089] loss=[0.006]\n",
      "[all_10]-[56]-[48] lr=[0.67814676465089] loss=[0.005]\n",
      "tensor([[ 0.0354,  0.1132,  0.1249,  ..., -0.0173, -0.0203, -0.0075],\n",
      "        [ 0.0224,  0.0185,  0.0142,  ..., -0.0205, -0.0070, -0.0003],\n",
      "        [ 0.0070, -0.0087,  0.0226,  ..., -0.0022,  0.0081,  0.0093],\n",
      "        ...,\n",
      "        [ 0.0916,  0.1252,  0.0916,  ..., -0.0279, -0.0089, -0.0221],\n",
      "        [ 0.0013, -0.0027,  0.0034,  ...,  0.0197,  0.0379,  0.0151],\n",
      "        [ 0.0300,  0.0070, -0.0013,  ..., -0.0178, -0.0205, -0.0200]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0266, 0.0000, 0.0487,  ..., 0.0000, 0.0000, 0.0078],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [2.0254, 0.1091, 0.0431,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0401, 0.0000, 0.0000,  ..., 0.0829, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5928, 0.0000,  ..., 0.0000, 0.0000, 0.0053]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[57]-[1] lr=[0.6761123243569372] loss=[0.006]\n",
      "[all_10]-[57]-[2] lr=[0.6761123243569372] loss=[0.005]\n",
      "[all_10]-[57]-[3] lr=[0.6761123243569372] loss=[0.005]\n",
      "[all_10]-[57]-[4] lr=[0.6761123243569372] loss=[0.006]\n",
      "[all_10]-[57]-[5] lr=[0.6761123243569372] loss=[0.006]\n",
      "[all_10]-[57]-[6] lr=[0.6761123243569372] loss=[0.005]\n",
      "[all_10]-[57]-[7] lr=[0.6761123243569372] loss=[0.007]\n",
      "[all_10]-[57]-[8] lr=[0.6761123243569372] loss=[0.006]\n",
      "[all_10]-[57]-[9] lr=[0.6761123243569372] loss=[0.006]\n",
      "[all_10]-[57]-[10] lr=[0.6761123243569372] loss=[0.006]\n",
      "[all_10]-[57]-[11] lr=[0.6761123243569372] loss=[0.005]\n",
      "[all_10]-[57]-[12] lr=[0.6761123243569372] loss=[0.006]\n",
      "[all_10]-[57]-[13] lr=[0.6761123243569372] loss=[0.005]\n",
      "[all_10]-[57]-[14] lr=[0.6761123243569372] loss=[0.005]\n",
      "[all_10]-[57]-[15] lr=[0.6761123243569372] loss=[0.006]\n",
      "[all_10]-[57]-[16] lr=[0.6761123243569372] loss=[0.006]\n",
      "[all_10]-[57]-[17] lr=[0.6761123243569372] loss=[0.006]\n",
      "[all_10]-[57]-[18] lr=[0.6761123243569372] loss=[0.005]\n",
      "[all_10]-[57]-[19] lr=[0.6761123243569372] loss=[0.005]\n",
      "[all_10]-[57]-[20] lr=[0.6761123243569372] loss=[0.005]\n",
      "[all_10]-[57]-[21] lr=[0.6761123243569372] loss=[0.004]\n",
      "[all_10]-[57]-[22] lr=[0.6761123243569372] loss=[0.005]\n",
      "[all_10]-[57]-[23] lr=[0.6761123243569372] loss=[0.005]\n",
      "[all_10]-[57]-[24] lr=[0.6761123243569372] loss=[0.006]\n",
      "[all_10]-[57]-[25] lr=[0.6761123243569372] loss=[0.004]\n",
      "[all_10]-[57]-[26] lr=[0.6761123243569372] loss=[0.006]\n",
      "[all_10]-[57]-[27] lr=[0.6761123243569372] loss=[0.006]\n",
      "[all_10]-[57]-[28] lr=[0.6761123243569372] loss=[0.004]\n",
      "[all_10]-[57]-[29] lr=[0.6761123243569372] loss=[0.005]\n",
      "[all_10]-[57]-[30] lr=[0.6761123243569372] loss=[0.005]\n",
      "[all_10]-[57]-[31] lr=[0.6761123243569372] loss=[0.006]\n",
      "[all_10]-[57]-[32] lr=[0.6761123243569372] loss=[0.008]\n",
      "[all_10]-[57]-[33] lr=[0.6761123243569372] loss=[0.004]\n",
      "[all_10]-[57]-[34] lr=[0.6761123243569372] loss=[0.006]\n",
      "[all_10]-[57]-[35] lr=[0.6761123243569372] loss=[0.005]\n",
      "[all_10]-[57]-[36] lr=[0.6761123243569372] loss=[0.006]\n",
      "[all_10]-[57]-[37] lr=[0.6761123243569372] loss=[0.005]\n",
      "[all_10]-[57]-[38] lr=[0.6761123243569372] loss=[0.005]\n",
      "[all_10]-[57]-[39] lr=[0.6761123243569372] loss=[0.005]\n",
      "[all_10]-[57]-[40] lr=[0.6761123243569372] loss=[0.006]\n",
      "[all_10]-[57]-[41] lr=[0.6761123243569372] loss=[0.007]\n",
      "[all_10]-[57]-[42] lr=[0.6761123243569372] loss=[0.007]\n",
      "[all_10]-[57]-[43] lr=[0.6761123243569372] loss=[0.006]\n",
      "[all_10]-[57]-[44] lr=[0.6761123243569372] loss=[0.004]\n",
      "[all_10]-[57]-[45] lr=[0.6761123243569372] loss=[0.005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[57]-[46] lr=[0.6761123243569372] loss=[0.005]\n",
      "[all_10]-[57]-[47] lr=[0.6761123243569372] loss=[0.005]\n",
      "[all_10]-[57]-[48] lr=[0.6761123243569372] loss=[0.005]\n",
      "tensor([[ 0.0250,  0.0426,  0.0909,  ...,  0.0129,  0.0064, -0.0025],\n",
      "        [ 0.0763,  0.0769,  0.0895,  ..., -0.0116,  0.0034,  0.0195],\n",
      "        [ 0.0454,  0.0742,  0.0483,  ...,  0.0020, -0.0109, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0260,  0.0269,  0.0324,  ...,  0.0078,  0.0372,  0.0277],\n",
      "        [ 0.0215,  0.0133,  0.0345,  ..., -0.0095,  0.0089,  0.0240],\n",
      "        [ 0.0243,  0.0431,  0.0348,  ...,  0.0062, -0.0019, -0.0095]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.1574,  ..., 0.0000, 0.0000, 0.0218],\n",
      "        [0.0000, 0.0292, 0.0425,  ..., 0.0000, 0.0000, 0.0292],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0095, 0.0041, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0403, 0.0000,  ..., 0.0311, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0100,  ..., 0.0000, 0.0077, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[58]-[1] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[2] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[3] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[4] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[5] lr=[0.6740839873838664] loss=[0.007]\n",
      "[all_10]-[58]-[6] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[7] lr=[0.6740839873838664] loss=[0.006]\n",
      "[all_10]-[58]-[8] lr=[0.6740839873838664] loss=[0.004]\n",
      "[all_10]-[58]-[9] lr=[0.6740839873838664] loss=[0.006]\n",
      "[all_10]-[58]-[10] lr=[0.6740839873838664] loss=[0.007]\n",
      "[all_10]-[58]-[11] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[12] lr=[0.6740839873838664] loss=[0.006]\n",
      "[all_10]-[58]-[13] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[14] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[15] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[16] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[17] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[18] lr=[0.6740839873838664] loss=[0.007]\n",
      "[all_10]-[58]-[19] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[20] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[21] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[22] lr=[0.6740839873838664] loss=[0.004]\n",
      "[all_10]-[58]-[23] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[24] lr=[0.6740839873838664] loss=[0.004]\n",
      "[all_10]-[58]-[25] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[26] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[27] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[28] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[29] lr=[0.6740839873838664] loss=[0.006]\n",
      "[all_10]-[58]-[30] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[31] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[32] lr=[0.6740839873838664] loss=[0.004]\n",
      "[all_10]-[58]-[33] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[34] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[35] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[36] lr=[0.6740839873838664] loss=[0.006]\n",
      "[all_10]-[58]-[37] lr=[0.6740839873838664] loss=[0.007]\n",
      "[all_10]-[58]-[38] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[39] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[40] lr=[0.6740839873838664] loss=[0.006]\n",
      "[all_10]-[58]-[41] lr=[0.6740839873838664] loss=[0.006]\n",
      "[all_10]-[58]-[42] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[43] lr=[0.6740839873838664] loss=[0.005]\n",
      "[all_10]-[58]-[44] lr=[0.6740839873838664] loss=[0.006]\n",
      "[all_10]-[58]-[45] lr=[0.6740839873838664] loss=[0.006]\n",
      "[all_10]-[58]-[46] lr=[0.6740839873838664] loss=[0.006]\n",
      "[all_10]-[58]-[47] lr=[0.6740839873838664] loss=[0.007]\n",
      "[all_10]-[58]-[48] lr=[0.6740839873838664] loss=[0.005]\n",
      "tensor([[0.0720, 0.1625, 0.1376,  ..., 0.0362, 0.0503, 0.0593],\n",
      "        [0.0402, 0.0445, 0.0444,  ..., 0.0538, 0.0447, 0.0234],\n",
      "        [0.0734, 0.0671, 0.0568,  ..., 0.0879, 0.0748, 0.0489],\n",
      "        ...,\n",
      "        [0.0226, 0.0070, 0.0878,  ..., 0.0218, 0.0359, 0.0271],\n",
      "        [0.0350, 0.0304, 0.0597,  ..., 0.0236, 0.0271, 0.0331],\n",
      "        [0.0402, 0.0465, 0.0396,  ..., 0.0492, 0.0741, 0.0672]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.3443, 0.1788,  ..., 0.0000, 0.0000, 0.0467],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0280, 0.0000, 0.0000,  ..., 0.3149, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.1627,  ..., 0.8091, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0532, 0.0692, 0.0000,  ..., 0.0000, 0.0000, 0.0175]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[59]-[1] lr=[0.6720617354217149] loss=[0.006]\n",
      "[all_10]-[59]-[2] lr=[0.6720617354217149] loss=[0.006]\n",
      "[all_10]-[59]-[3] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[4] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[5] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[6] lr=[0.6720617354217149] loss=[0.006]\n",
      "[all_10]-[59]-[7] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[8] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[9] lr=[0.6720617354217149] loss=[0.006]\n",
      "[all_10]-[59]-[10] lr=[0.6720617354217149] loss=[0.006]\n",
      "[all_10]-[59]-[11] lr=[0.6720617354217149] loss=[0.006]\n",
      "[all_10]-[59]-[12] lr=[0.6720617354217149] loss=[0.006]\n",
      "[all_10]-[59]-[13] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[14] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[15] lr=[0.6720617354217149] loss=[0.004]\n",
      "[all_10]-[59]-[16] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[17] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[18] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[19] lr=[0.6720617354217149] loss=[0.004]\n",
      "[all_10]-[59]-[20] lr=[0.6720617354217149] loss=[0.004]\n",
      "[all_10]-[59]-[21] lr=[0.6720617354217149] loss=[0.006]\n",
      "[all_10]-[59]-[22] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[23] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[24] lr=[0.6720617354217149] loss=[0.004]\n",
      "[all_10]-[59]-[25] lr=[0.6720617354217149] loss=[0.004]\n",
      "[all_10]-[59]-[26] lr=[0.6720617354217149] loss=[0.006]\n",
      "[all_10]-[59]-[27] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[28] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[29] lr=[0.6720617354217149] loss=[0.007]\n",
      "[all_10]-[59]-[30] lr=[0.6720617354217149] loss=[0.004]\n",
      "[all_10]-[59]-[31] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[32] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[33] lr=[0.6720617354217149] loss=[0.006]\n",
      "[all_10]-[59]-[34] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[35] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[36] lr=[0.6720617354217149] loss=[0.004]\n",
      "[all_10]-[59]-[37] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[38] lr=[0.6720617354217149] loss=[0.006]\n",
      "[all_10]-[59]-[39] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[40] lr=[0.6720617354217149] loss=[0.006]\n",
      "[all_10]-[59]-[41] lr=[0.6720617354217149] loss=[0.004]\n",
      "[all_10]-[59]-[42] lr=[0.6720617354217149] loss=[0.006]\n",
      "[all_10]-[59]-[43] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[44] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[45] lr=[0.6720617354217149] loss=[0.005]\n",
      "[all_10]-[59]-[46] lr=[0.6720617354217149] loss=[0.006]\n",
      "[all_10]-[59]-[47] lr=[0.6720617354217149] loss=[0.006]\n",
      "[all_10]-[59]-[48] lr=[0.6720617354217149] loss=[0.005]\n",
      "tensor([[0.0540, 0.0750, 0.0628,  ..., 0.0326, 0.0235, 0.0244],\n",
      "        [0.0432, 0.0329, 0.0519,  ..., 0.0285, 0.0253, 0.0247],\n",
      "        [0.0442, 0.0908, 0.1618,  ..., 0.0009, 0.0058, 0.0117],\n",
      "        ...,\n",
      "        [0.0391, 0.0407, 0.0733,  ..., 0.0470, 0.0215, 0.0200],\n",
      "        [0.0419, 0.1169, 0.0774,  ..., 0.0366, 0.0422, 0.0427],\n",
      "        [0.0363, 0.0295, 0.1062,  ..., 0.0455, 0.0523, 0.0947]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.4594, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0229, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0435],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0152,  ..., 0.1030, 0.0000, 0.1540]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[60]-[1] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[2] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[3] lr=[0.6700455502154498] loss=[0.004]\n",
      "[all_10]-[60]-[4] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[5] lr=[0.6700455502154498] loss=[0.005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[60]-[6] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[7] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[8] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[9] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[10] lr=[0.6700455502154498] loss=[0.006]\n",
      "[all_10]-[60]-[11] lr=[0.6700455502154498] loss=[0.006]\n",
      "[all_10]-[60]-[12] lr=[0.6700455502154498] loss=[0.004]\n",
      "[all_10]-[60]-[13] lr=[0.6700455502154498] loss=[0.007]\n",
      "[all_10]-[60]-[14] lr=[0.6700455502154498] loss=[0.007]\n",
      "[all_10]-[60]-[15] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[16] lr=[0.6700455502154498] loss=[0.006]\n",
      "[all_10]-[60]-[17] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[18] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[19] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[20] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[21] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[22] lr=[0.6700455502154498] loss=[0.004]\n",
      "[all_10]-[60]-[23] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[24] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[25] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[26] lr=[0.6700455502154498] loss=[0.006]\n",
      "[all_10]-[60]-[27] lr=[0.6700455502154498] loss=[0.004]\n",
      "[all_10]-[60]-[28] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[29] lr=[0.6700455502154498] loss=[0.004]\n",
      "[all_10]-[60]-[30] lr=[0.6700455502154498] loss=[0.003]\n",
      "[all_10]-[60]-[31] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[32] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[33] lr=[0.6700455502154498] loss=[0.004]\n",
      "[all_10]-[60]-[34] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[35] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[36] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[37] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[38] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[39] lr=[0.6700455502154498] loss=[0.006]\n",
      "[all_10]-[60]-[40] lr=[0.6700455502154498] loss=[0.006]\n",
      "[all_10]-[60]-[41] lr=[0.6700455502154498] loss=[0.006]\n",
      "[all_10]-[60]-[42] lr=[0.6700455502154498] loss=[0.007]\n",
      "[all_10]-[60]-[43] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[44] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[45] lr=[0.6700455502154498] loss=[0.004]\n",
      "[all_10]-[60]-[46] lr=[0.6700455502154498] loss=[0.006]\n",
      "[all_10]-[60]-[47] lr=[0.6700455502154498] loss=[0.005]\n",
      "[all_10]-[60]-[48] lr=[0.6700455502154498] loss=[0.005]\n",
      "tensor([[ 0.0004, -0.0171, -0.0296,  ..., -0.0114, -0.0077,  0.0132],\n",
      "        [ 0.0135, -0.0278,  0.0410,  ..., -0.0054, -0.0051, -0.0060],\n",
      "        [ 0.0072,  0.0304,  0.0093,  ..., -0.0073, -0.0130, -0.0265],\n",
      "        ...,\n",
      "        [ 0.0188,  0.0004, -0.0070,  ...,  0.0105,  0.0004, -0.0106],\n",
      "        [ 0.0624,  0.0732,  0.0687,  ..., -0.0072,  0.0105, -0.0101],\n",
      "        [ 0.0137, -0.0107,  0.0038,  ..., -0.0076, -0.0114, -0.0185]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0138,  ..., 0.0000, 0.0000, 0.0748],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1367, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0481, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0184, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[61]-[1] lr=[0.6680354135648034] loss=[0.004]\n",
      "[all_10]-[61]-[2] lr=[0.6680354135648034] loss=[0.004]\n",
      "[all_10]-[61]-[3] lr=[0.6680354135648034] loss=[0.006]\n",
      "[all_10]-[61]-[4] lr=[0.6680354135648034] loss=[0.004]\n",
      "[all_10]-[61]-[5] lr=[0.6680354135648034] loss=[0.004]\n",
      "[all_10]-[61]-[6] lr=[0.6680354135648034] loss=[0.004]\n",
      "[all_10]-[61]-[7] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[8] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[9] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[10] lr=[0.6680354135648034] loss=[0.007]\n",
      "[all_10]-[61]-[11] lr=[0.6680354135648034] loss=[0.004]\n",
      "[all_10]-[61]-[12] lr=[0.6680354135648034] loss=[0.006]\n",
      "[all_10]-[61]-[13] lr=[0.6680354135648034] loss=[0.004]\n",
      "[all_10]-[61]-[14] lr=[0.6680354135648034] loss=[0.004]\n",
      "[all_10]-[61]-[15] lr=[0.6680354135648034] loss=[0.006]\n",
      "[all_10]-[61]-[16] lr=[0.6680354135648034] loss=[0.004]\n",
      "[all_10]-[61]-[17] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[18] lr=[0.6680354135648034] loss=[0.004]\n",
      "[all_10]-[61]-[19] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[20] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[21] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[22] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[23] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[24] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[25] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[26] lr=[0.6680354135648034] loss=[0.006]\n",
      "[all_10]-[61]-[27] lr=[0.6680354135648034] loss=[0.006]\n",
      "[all_10]-[61]-[28] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[29] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[30] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[31] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[32] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[33] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[34] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[35] lr=[0.6680354135648034] loss=[0.004]\n",
      "[all_10]-[61]-[36] lr=[0.6680354135648034] loss=[0.004]\n",
      "[all_10]-[61]-[37] lr=[0.6680354135648034] loss=[0.004]\n",
      "[all_10]-[61]-[38] lr=[0.6680354135648034] loss=[0.006]\n",
      "[all_10]-[61]-[39] lr=[0.6680354135648034] loss=[0.006]\n",
      "[all_10]-[61]-[40] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[41] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[42] lr=[0.6680354135648034] loss=[0.004]\n",
      "[all_10]-[61]-[43] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[44] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[45] lr=[0.6680354135648034] loss=[0.004]\n",
      "[all_10]-[61]-[46] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[47] lr=[0.6680354135648034] loss=[0.005]\n",
      "[all_10]-[61]-[48] lr=[0.6680354135648034] loss=[0.004]\n",
      "tensor([[ 2.2454e-02,  2.8231e-02,  2.4051e-02,  ...,  1.3718e-02,\n",
      "          7.5762e-03,  3.2878e-03],\n",
      "        [ 2.8111e-02,  2.0030e-02,  3.3055e-01,  ...,  1.5131e-02,\n",
      "          1.8048e-02,  2.9201e-02],\n",
      "        [ 1.5582e-01,  6.4431e-02,  1.0298e-01,  ...,  4.9277e-03,\n",
      "          8.6318e-03,  1.8895e-02],\n",
      "        ...,\n",
      "        [ 2.7059e-02,  1.9556e-02,  1.0433e-02,  ...,  1.2077e-02,\n",
      "          1.2538e-02,  1.5142e-02],\n",
      "        [ 2.2232e-02, -1.7056e-04,  9.6699e-02,  ...,  8.6962e-03,\n",
      "          2.5425e-02, -1.0799e-03],\n",
      "        [ 2.9080e-02, -4.8997e-04,  8.2351e-03,  ...,  2.4619e-03,\n",
      "          2.0026e-02,  7.5348e-03]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.1741, 0.2901, 0.6963],\n",
      "        [0.0000, 0.0578, 0.5892,  ..., 0.0000, 0.0439, 0.0237],\n",
      "        [1.8801, 0.0000, 0.0000,  ..., 0.1642, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.2522,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[62]-[1] lr=[0.6660313073241091] loss=[0.004]\n",
      "[all_10]-[62]-[2] lr=[0.6660313073241091] loss=[0.006]\n",
      "[all_10]-[62]-[3] lr=[0.6660313073241091] loss=[0.005]\n",
      "[all_10]-[62]-[4] lr=[0.6660313073241091] loss=[0.006]\n",
      "[all_10]-[62]-[5] lr=[0.6660313073241091] loss=[0.004]\n",
      "[all_10]-[62]-[6] lr=[0.6660313073241091] loss=[0.005]\n",
      "[all_10]-[62]-[7] lr=[0.6660313073241091] loss=[0.005]\n",
      "[all_10]-[62]-[8] lr=[0.6660313073241091] loss=[0.005]\n",
      "[all_10]-[62]-[9] lr=[0.6660313073241091] loss=[0.006]\n",
      "[all_10]-[62]-[10] lr=[0.6660313073241091] loss=[0.003]\n",
      "[all_10]-[62]-[11] lr=[0.6660313073241091] loss=[0.005]\n",
      "[all_10]-[62]-[12] lr=[0.6660313073241091] loss=[0.006]\n",
      "[all_10]-[62]-[13] lr=[0.6660313073241091] loss=[0.008]\n",
      "[all_10]-[62]-[14] lr=[0.6660313073241091] loss=[0.005]\n",
      "[all_10]-[62]-[15] lr=[0.6660313073241091] loss=[0.006]\n",
      "[all_10]-[62]-[16] lr=[0.6660313073241091] loss=[0.004]\n",
      "[all_10]-[62]-[17] lr=[0.6660313073241091] loss=[0.004]\n",
      "[all_10]-[62]-[18] lr=[0.6660313073241091] loss=[0.005]\n",
      "[all_10]-[62]-[19] lr=[0.6660313073241091] loss=[0.005]\n",
      "[all_10]-[62]-[20] lr=[0.6660313073241091] loss=[0.006]\n",
      "[all_10]-[62]-[21] lr=[0.6660313073241091] loss=[0.004]\n",
      "[all_10]-[62]-[22] lr=[0.6660313073241091] loss=[0.005]\n",
      "[all_10]-[62]-[23] lr=[0.6660313073241091] loss=[0.004]\n",
      "[all_10]-[62]-[24] lr=[0.6660313073241091] loss=[0.005]\n",
      "[all_10]-[62]-[25] lr=[0.6660313073241091] loss=[0.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[62]-[26] lr=[0.6660313073241091] loss=[0.004]\n",
      "[all_10]-[62]-[27] lr=[0.6660313073241091] loss=[0.003]\n",
      "[all_10]-[62]-[28] lr=[0.6660313073241091] loss=[0.005]\n",
      "[all_10]-[62]-[29] lr=[0.6660313073241091] loss=[0.006]\n",
      "[all_10]-[62]-[30] lr=[0.6660313073241091] loss=[0.004]\n",
      "[all_10]-[62]-[31] lr=[0.6660313073241091] loss=[0.005]\n",
      "[all_10]-[62]-[32] lr=[0.6660313073241091] loss=[0.005]\n",
      "[all_10]-[62]-[33] lr=[0.6660313073241091] loss=[0.004]\n",
      "[all_10]-[62]-[34] lr=[0.6660313073241091] loss=[0.005]\n",
      "[all_10]-[62]-[35] lr=[0.6660313073241091] loss=[0.004]\n",
      "[all_10]-[62]-[36] lr=[0.6660313073241091] loss=[0.004]\n",
      "[all_10]-[62]-[37] lr=[0.6660313073241091] loss=[0.005]\n",
      "[all_10]-[62]-[38] lr=[0.6660313073241091] loss=[0.005]\n",
      "[all_10]-[62]-[39] lr=[0.6660313073241091] loss=[0.003]\n",
      "[all_10]-[62]-[40] lr=[0.6660313073241091] loss=[0.004]\n",
      "[all_10]-[62]-[41] lr=[0.6660313073241091] loss=[0.005]\n",
      "[all_10]-[62]-[42] lr=[0.6660313073241091] loss=[0.004]\n",
      "[all_10]-[62]-[43] lr=[0.6660313073241091] loss=[0.004]\n",
      "[all_10]-[62]-[44] lr=[0.6660313073241091] loss=[0.004]\n",
      "[all_10]-[62]-[45] lr=[0.6660313073241091] loss=[0.005]\n",
      "[all_10]-[62]-[46] lr=[0.6660313073241091] loss=[0.004]\n",
      "[all_10]-[62]-[47] lr=[0.6660313073241091] loss=[0.005]\n",
      "[all_10]-[62]-[48] lr=[0.6660313073241091] loss=[0.004]\n",
      "tensor([[ 0.0237, -0.0121, -0.0079,  ..., -0.0129, -0.0174, -0.0160],\n",
      "        [-0.0004, -0.0081, -0.0272,  ..., -0.0175, -0.0083, -0.0178],\n",
      "        [ 0.1626,  0.0222, -0.0015,  ..., -0.0279, -0.0029, -0.0013],\n",
      "        ...,\n",
      "        [ 0.0755,  0.0456,  0.0619,  ..., -0.0436, -0.0211, -0.0196],\n",
      "        [ 0.0376,  0.0681,  0.0732,  ..., -0.0088, -0.0012, -0.0012],\n",
      "        [ 0.0134, -0.0077,  0.0618,  ..., -0.0269, -0.0286, -0.0354]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0245, 0.0000, 0.0492,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.7057, 0.1314],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [2.6337, 0.0000, 0.4727,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2187,  ..., 0.0000, 0.0000, 0.0187],\n",
      "        [0.0000, 0.0000, 0.0908,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[63]-[1] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[2] lr=[0.6640332134021367] loss=[0.003]\n",
      "[all_10]-[63]-[3] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[4] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[5] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[6] lr=[0.6640332134021367] loss=[0.005]\n",
      "[all_10]-[63]-[7] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[8] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[9] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[10] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[11] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[12] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[13] lr=[0.6640332134021367] loss=[0.003]\n",
      "[all_10]-[63]-[14] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[15] lr=[0.6640332134021367] loss=[0.003]\n",
      "[all_10]-[63]-[16] lr=[0.6640332134021367] loss=[0.003]\n",
      "[all_10]-[63]-[17] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[18] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[19] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[20] lr=[0.6640332134021367] loss=[0.003]\n",
      "[all_10]-[63]-[21] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[22] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[23] lr=[0.6640332134021367] loss=[0.005]\n",
      "[all_10]-[63]-[24] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[25] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[26] lr=[0.6640332134021367] loss=[0.005]\n",
      "[all_10]-[63]-[27] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[28] lr=[0.6640332134021367] loss=[0.003]\n",
      "[all_10]-[63]-[29] lr=[0.6640332134021367] loss=[0.005]\n",
      "[all_10]-[63]-[30] lr=[0.6640332134021367] loss=[0.005]\n",
      "[all_10]-[63]-[31] lr=[0.6640332134021367] loss=[0.005]\n",
      "[all_10]-[63]-[32] lr=[0.6640332134021367] loss=[0.005]\n",
      "[all_10]-[63]-[33] lr=[0.6640332134021367] loss=[0.003]\n",
      "[all_10]-[63]-[34] lr=[0.6640332134021367] loss=[0.003]\n",
      "[all_10]-[63]-[35] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[36] lr=[0.6640332134021367] loss=[0.005]\n",
      "[all_10]-[63]-[37] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[38] lr=[0.6640332134021367] loss=[0.006]\n",
      "[all_10]-[63]-[39] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[40] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[41] lr=[0.6640332134021367] loss=[0.005]\n",
      "[all_10]-[63]-[42] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[43] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[44] lr=[0.6640332134021367] loss=[0.003]\n",
      "[all_10]-[63]-[45] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[46] lr=[0.6640332134021367] loss=[0.003]\n",
      "[all_10]-[63]-[47] lr=[0.6640332134021367] loss=[0.004]\n",
      "[all_10]-[63]-[48] lr=[0.6640332134021367] loss=[0.003]\n",
      "tensor([[ 0.0247,  0.0378,  0.5210,  ...,  0.0395,  0.0289,  0.0448],\n",
      "        [ 0.0206,  0.0631,  0.0560,  ...,  0.0270,  0.0428,  0.0408],\n",
      "        [ 0.0212, -0.0082, -0.0106,  ...,  0.0075,  0.0299,  0.0398],\n",
      "        ...,\n",
      "        [ 0.2100,  0.0307,  0.0119,  ...,  0.2052,  0.0232,  0.0078],\n",
      "        [ 0.0510,  0.0174,  0.0380,  ...,  0.0305,  0.0386,  0.0513],\n",
      "        [ 0.0679,  0.0294,  0.0160,  ...,  0.0558,  0.0323,  0.0291]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 1.3733,  ..., 0.0463, 0.0000, 0.0623],\n",
      "        [0.0000, 0.6910, 0.0000,  ..., 0.0000, 0.0171, 0.0000],\n",
      "        [0.1653, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.3570, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0183],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0795, 0.0397, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[64]-[1] lr=[0.6620411137619303] loss=[0.004]\n",
      "[all_10]-[64]-[2] lr=[0.6620411137619303] loss=[0.004]\n",
      "[all_10]-[64]-[3] lr=[0.6620411137619303] loss=[0.004]\n",
      "[all_10]-[64]-[4] lr=[0.6620411137619303] loss=[0.003]\n",
      "[all_10]-[64]-[5] lr=[0.6620411137619303] loss=[0.003]\n",
      "[all_10]-[64]-[6] lr=[0.6620411137619303] loss=[0.005]\n",
      "[all_10]-[64]-[7] lr=[0.6620411137619303] loss=[0.003]\n",
      "[all_10]-[64]-[8] lr=[0.6620411137619303] loss=[0.003]\n",
      "[all_10]-[64]-[9] lr=[0.6620411137619303] loss=[0.003]\n",
      "lr adapted to 0.8*0.6620411137619303=0.5296328910095442\n",
      "new inspect loss cutoff: 0.0015767832519486547\n",
      "[all_10]-[64]-[10] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[11] lr=[0.5296328910095442] loss=[0.003]\n",
      "[all_10]-[64]-[12] lr=[0.5296328910095442] loss=[0.003]\n",
      "[all_10]-[64]-[13] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[14] lr=[0.5296328910095442] loss=[0.003]\n",
      "[all_10]-[64]-[15] lr=[0.5296328910095442] loss=[0.005]\n",
      "[all_10]-[64]-[16] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[17] lr=[0.5296328910095442] loss=[0.003]\n",
      "[all_10]-[64]-[18] lr=[0.5296328910095442] loss=[0.003]\n",
      "[all_10]-[64]-[19] lr=[0.5296328910095442] loss=[0.003]\n",
      "[all_10]-[64]-[20] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[21] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[22] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[23] lr=[0.5296328910095442] loss=[0.003]\n",
      "[all_10]-[64]-[24] lr=[0.5296328910095442] loss=[0.003]\n",
      "[all_10]-[64]-[25] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[26] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[27] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[28] lr=[0.5296328910095442] loss=[0.003]\n",
      "[all_10]-[64]-[29] lr=[0.5296328910095442] loss=[0.003]\n",
      "[all_10]-[64]-[30] lr=[0.5296328910095442] loss=[0.005]\n",
      "[all_10]-[64]-[31] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[32] lr=[0.5296328910095442] loss=[0.005]\n",
      "[all_10]-[64]-[33] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[34] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[35] lr=[0.5296328910095442] loss=[0.003]\n",
      "[all_10]-[64]-[36] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[37] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[38] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[39] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[40] lr=[0.5296328910095442] loss=[0.003]\n",
      "[all_10]-[64]-[41] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[42] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[43] lr=[0.5296328910095442] loss=[0.003]\n",
      "[all_10]-[64]-[44] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[45] lr=[0.5296328910095442] loss=[0.005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[64]-[46] lr=[0.5296328910095442] loss=[0.005]\n",
      "[all_10]-[64]-[47] lr=[0.5296328910095442] loss=[0.004]\n",
      "[all_10]-[64]-[48] lr=[0.5296328910095442] loss=[0.003]\n",
      "tensor([[ 0.0054, -0.0151, -0.0185,  ..., -0.0251, -0.0195, -0.0028],\n",
      "        [-0.0054, -0.0293, -0.0086,  ..., -0.0193, -0.0231, -0.0061],\n",
      "        [-0.0072, -0.0263, -0.0234,  ..., -0.0169, -0.0122, -0.0179],\n",
      "        ...,\n",
      "        [ 0.0204, -0.0051,  0.4843,  ..., -0.0126, -0.0070, -0.0238],\n",
      "        [ 0.0025,  0.0289, -0.0052,  ..., -0.0263, -0.0230, -0.0166],\n",
      "        [-0.0058, -0.0075, -0.0038,  ..., -0.0045, -0.0151, -0.0239]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0035, 0.0000,  ..., 0.0145, 0.0000, 0.0000],\n",
      "        [0.0058, 0.0000, 0.2360,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0146, 0.0419,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.4565,  ..., 0.0000, 0.0071, 0.0000],\n",
      "        [0.0000, 0.4953, 0.6439,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0800, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[65]-[1] lr=[0.5280439923365157] loss=[0.003]\n",
      "[all_10]-[65]-[2] lr=[0.5280439923365157] loss=[0.003]\n",
      "[all_10]-[65]-[3] lr=[0.5280439923365157] loss=[0.003]\n",
      "[all_10]-[65]-[4] lr=[0.5280439923365157] loss=[0.003]\n",
      "[all_10]-[65]-[5] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[6] lr=[0.5280439923365157] loss=[0.006]\n",
      "[all_10]-[65]-[7] lr=[0.5280439923365157] loss=[0.007]\n",
      "[all_10]-[65]-[8] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[9] lr=[0.5280439923365157] loss=[0.007]\n",
      "[all_10]-[65]-[10] lr=[0.5280439923365157] loss=[0.008]\n",
      "[all_10]-[65]-[11] lr=[0.5280439923365157] loss=[0.005]\n",
      "[all_10]-[65]-[12] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[13] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[14] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[15] lr=[0.5280439923365157] loss=[0.003]\n",
      "[all_10]-[65]-[16] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[17] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[18] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[19] lr=[0.5280439923365157] loss=[0.003]\n",
      "[all_10]-[65]-[20] lr=[0.5280439923365157] loss=[0.003]\n",
      "[all_10]-[65]-[21] lr=[0.5280439923365157] loss=[0.003]\n",
      "[all_10]-[65]-[22] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[23] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[24] lr=[0.5280439923365157] loss=[0.003]\n",
      "[all_10]-[65]-[25] lr=[0.5280439923365157] loss=[0.003]\n",
      "[all_10]-[65]-[26] lr=[0.5280439923365157] loss=[0.003]\n",
      "[all_10]-[65]-[27] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[28] lr=[0.5280439923365157] loss=[0.003]\n",
      "[all_10]-[65]-[29] lr=[0.5280439923365157] loss=[0.006]\n",
      "[all_10]-[65]-[30] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[31] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[32] lr=[0.5280439923365157] loss=[0.003]\n",
      "[all_10]-[65]-[33] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[34] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[35] lr=[0.5280439923365157] loss=[0.003]\n",
      "[all_10]-[65]-[36] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[37] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[38] lr=[0.5280439923365157] loss=[0.005]\n",
      "[all_10]-[65]-[39] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[40] lr=[0.5280439923365157] loss=[0.003]\n",
      "[all_10]-[65]-[41] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[42] lr=[0.5280439923365157] loss=[0.002]\n",
      "[all_10]-[65]-[43] lr=[0.5280439923365157] loss=[0.003]\n",
      "[all_10]-[65]-[44] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[45] lr=[0.5280439923365157] loss=[0.005]\n",
      "[all_10]-[65]-[46] lr=[0.5280439923365157] loss=[0.004]\n",
      "[all_10]-[65]-[47] lr=[0.5280439923365157] loss=[0.002]\n",
      "[all_10]-[65]-[48] lr=[0.5280439923365157] loss=[0.005]\n",
      "tensor([[-0.0221, -0.0325, -0.0409,  ..., -0.0316, -0.0357, -0.0465],\n",
      "        [-0.0331, -0.0552, -0.0348,  ..., -0.0352, -0.0384, -0.0404],\n",
      "        [-0.0402, -0.0483, -0.0624,  ..., -0.0305, -0.0133, -0.0259],\n",
      "        ...,\n",
      "        [-0.0312, -0.0354, -0.0439,  ..., -0.0298, -0.0407, -0.0318],\n",
      "        [-0.0329, -0.0596, -0.0515,  ..., -0.0293, -0.0294, -0.0292],\n",
      "        [-0.0336, -0.0574, -0.0376,  ..., -0.0331, -0.0175, -0.0324]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0270, 0.0000, 0.0679,  ..., 0.0134, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0605, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[66]-[1] lr=[0.5264598603595061] loss=[0.003]\n",
      "[all_10]-[66]-[2] lr=[0.5264598603595061] loss=[0.004]\n",
      "[all_10]-[66]-[3] lr=[0.5264598603595061] loss=[0.004]\n",
      "[all_10]-[66]-[4] lr=[0.5264598603595061] loss=[0.003]\n",
      "[all_10]-[66]-[5] lr=[0.5264598603595061] loss=[0.002]\n",
      "[all_10]-[66]-[6] lr=[0.5264598603595061] loss=[0.002]\n",
      "[all_10]-[66]-[7] lr=[0.5264598603595061] loss=[0.004]\n",
      "[all_10]-[66]-[8] lr=[0.5264598603595061] loss=[0.003]\n",
      "[all_10]-[66]-[9] lr=[0.5264598603595061] loss=[0.004]\n",
      "[all_10]-[66]-[10] lr=[0.5264598603595061] loss=[0.003]\n",
      "[all_10]-[66]-[11] lr=[0.5264598603595061] loss=[0.004]\n",
      "[all_10]-[66]-[12] lr=[0.5264598603595061] loss=[0.003]\n",
      "[all_10]-[66]-[13] lr=[0.5264598603595061] loss=[0.005]\n",
      "[all_10]-[66]-[14] lr=[0.5264598603595061] loss=[0.004]\n",
      "[all_10]-[66]-[15] lr=[0.5264598603595061] loss=[0.004]\n",
      "[all_10]-[66]-[16] lr=[0.5264598603595061] loss=[0.003]\n",
      "[all_10]-[66]-[17] lr=[0.5264598603595061] loss=[0.002]\n",
      "[all_10]-[66]-[18] lr=[0.5264598603595061] loss=[0.004]\n",
      "[all_10]-[66]-[19] lr=[0.5264598603595061] loss=[0.003]\n",
      "[all_10]-[66]-[20] lr=[0.5264598603595061] loss=[0.005]\n",
      "[all_10]-[66]-[21] lr=[0.5264598603595061] loss=[0.004]\n",
      "[all_10]-[66]-[22] lr=[0.5264598603595061] loss=[0.006]\n",
      "[all_10]-[66]-[23] lr=[0.5264598603595061] loss=[0.006]\n",
      "[all_10]-[66]-[24] lr=[0.5264598603595061] loss=[0.004]\n",
      "[all_10]-[66]-[25] lr=[0.5264598603595061] loss=[0.003]\n",
      "[all_10]-[66]-[26] lr=[0.5264598603595061] loss=[0.005]\n",
      "[all_10]-[66]-[27] lr=[0.5264598603595061] loss=[0.004]\n",
      "[all_10]-[66]-[28] lr=[0.5264598603595061] loss=[0.005]\n",
      "[all_10]-[66]-[29] lr=[0.5264598603595061] loss=[0.005]\n",
      "[all_10]-[66]-[30] lr=[0.5264598603595061] loss=[0.004]\n",
      "[all_10]-[66]-[31] lr=[0.5264598603595061] loss=[0.003]\n",
      "[all_10]-[66]-[32] lr=[0.5264598603595061] loss=[0.004]\n",
      "[all_10]-[66]-[33] lr=[0.5264598603595061] loss=[0.003]\n",
      "[all_10]-[66]-[34] lr=[0.5264598603595061] loss=[0.003]\n",
      "[all_10]-[66]-[35] lr=[0.5264598603595061] loss=[0.002]\n",
      "[all_10]-[66]-[36] lr=[0.5264598603595061] loss=[0.003]\n",
      "[all_10]-[66]-[37] lr=[0.5264598603595061] loss=[0.002]\n",
      "[all_10]-[66]-[38] lr=[0.5264598603595061] loss=[0.004]\n",
      "[all_10]-[66]-[39] lr=[0.5264598603595061] loss=[0.003]\n",
      "[all_10]-[66]-[40] lr=[0.5264598603595061] loss=[0.004]\n",
      "[all_10]-[66]-[41] lr=[0.5264598603595061] loss=[0.004]\n",
      "[all_10]-[66]-[42] lr=[0.5264598603595061] loss=[0.002]\n",
      "[all_10]-[66]-[43] lr=[0.5264598603595061] loss=[0.003]\n",
      "[all_10]-[66]-[44] lr=[0.5264598603595061] loss=[0.003]\n",
      "[all_10]-[66]-[45] lr=[0.5264598603595061] loss=[0.004]\n",
      "[all_10]-[66]-[46] lr=[0.5264598603595061] loss=[0.003]\n",
      "[all_10]-[66]-[47] lr=[0.5264598603595061] loss=[0.003]\n",
      "[all_10]-[66]-[48] lr=[0.5264598603595061] loss=[0.003]\n",
      "tensor([[0.0312, 0.0069, 0.5544,  ..., 0.0263, 0.0320, 0.0252],\n",
      "        [0.0301, 0.0216, 0.0484,  ..., 0.0399, 0.0143, 0.0183],\n",
      "        [0.0151, 0.0103, 0.0257,  ..., 0.0408, 0.0195, 0.0157],\n",
      "        ...,\n",
      "        [0.0222, 0.0027, 0.0051,  ..., 0.0242, 0.0269, 0.0254],\n",
      "        [0.0344, 0.0208, 0.5189,  ..., 0.0221, 0.0267, 0.0300],\n",
      "        [0.0289, 0.0393, 0.0164,  ..., 0.0259, 0.0247, 0.0278]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0198, 0.3970,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0437,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0366, 0.0000, 0.4340,  ..., 0.0000, 0.0148, 0.0000],\n",
      "        [0.0065, 0.1841, 0.0000,  ..., 0.0054, 0.0065, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[67]-[1] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[2] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[3] lr=[0.5248804807784275] loss=[0.004]\n",
      "[all_10]-[67]-[4] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[5] lr=[0.5248804807784275] loss=[0.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[67]-[6] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[7] lr=[0.5248804807784275] loss=[0.002]\n",
      "[all_10]-[67]-[8] lr=[0.5248804807784275] loss=[0.005]\n",
      "[all_10]-[67]-[9] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[10] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[11] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[12] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[13] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[14] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[15] lr=[0.5248804807784275] loss=[0.002]\n",
      "[all_10]-[67]-[16] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[17] lr=[0.5248804807784275] loss=[0.004]\n",
      "[all_10]-[67]-[18] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[19] lr=[0.5248804807784275] loss=[0.004]\n",
      "[all_10]-[67]-[20] lr=[0.5248804807784275] loss=[0.002]\n",
      "[all_10]-[67]-[21] lr=[0.5248804807784275] loss=[0.004]\n",
      "[all_10]-[67]-[22] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[23] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[24] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[25] lr=[0.5248804807784275] loss=[0.002]\n",
      "[all_10]-[67]-[26] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[27] lr=[0.5248804807784275] loss=[0.004]\n",
      "[all_10]-[67]-[28] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[29] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[30] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[31] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[32] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[33] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[34] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[35] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[36] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[37] lr=[0.5248804807784275] loss=[0.002]\n",
      "[all_10]-[67]-[38] lr=[0.5248804807784275] loss=[0.002]\n",
      "[all_10]-[67]-[39] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[40] lr=[0.5248804807784275] loss=[0.002]\n",
      "[all_10]-[67]-[41] lr=[0.5248804807784275] loss=[0.003]\n",
      "[all_10]-[67]-[42] lr=[0.5248804807784275] loss=[0.005]\n",
      "[all_10]-[67]-[43] lr=[0.5248804807784275] loss=[0.004]\n",
      "[all_10]-[67]-[44] lr=[0.5248804807784275] loss=[0.002]\n",
      "[all_10]-[67]-[45] lr=[0.5248804807784275] loss=[0.004]\n",
      "[all_10]-[67]-[46] lr=[0.5248804807784275] loss=[0.004]\n",
      "[all_10]-[67]-[47] lr=[0.5248804807784275] loss=[0.005]\n",
      "[all_10]-[67]-[48] lr=[0.5248804807784275] loss=[0.003]\n",
      "tensor([[ 1.5075e-03, -1.0294e-02,  4.5048e-03,  ..., -3.0734e-02,\n",
      "         -2.5869e-02, -2.6681e-02],\n",
      "        [ 1.1257e-02,  1.2176e-02,  2.1772e-01,  ..., -8.9559e-03,\n",
      "         -1.1612e-02, -6.1617e-03],\n",
      "        [ 1.5258e-02,  1.6730e-02,  3.4234e-03,  ..., -2.6168e-02,\n",
      "         -2.1695e-02, -5.9165e-03],\n",
      "        ...,\n",
      "        [ 1.6175e-02,  3.5946e-01,  6.8683e-02,  ..., -3.9537e-02,\n",
      "         -4.2649e-02, -2.3310e-04],\n",
      "        [ 1.1043e-02, -8.6013e-03,  1.3717e-01,  ...,  4.9675e-02,\n",
      "         -2.2128e-02, -2.2154e-02],\n",
      "        [ 1.0919e-02,  3.6250e-03,  2.0447e-02,  ...,  1.8727e-01,\n",
      "         -1.9238e-02, -2.7688e-02]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0828, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0255, 0.2876, 0.0000,  ..., 0.0000, 0.0000, 0.0187],\n",
      "        [0.0198, 0.0000, 0.2069,  ..., 0.0173, 0.0000, 0.0000],\n",
      "        [0.0280, 0.0000, 0.0000,  ..., 0.3149, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[68]-[1] lr=[0.5233058393360922] loss=[0.004]\n",
      "[all_10]-[68]-[2] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[3] lr=[0.5233058393360922] loss=[0.004]\n",
      "[all_10]-[68]-[4] lr=[0.5233058393360922] loss=[0.004]\n",
      "[all_10]-[68]-[5] lr=[0.5233058393360922] loss=[0.005]\n",
      "[all_10]-[68]-[6] lr=[0.5233058393360922] loss=[0.005]\n",
      "[all_10]-[68]-[7] lr=[0.5233058393360922] loss=[0.005]\n",
      "[all_10]-[68]-[8] lr=[0.5233058393360922] loss=[0.007]\n",
      "[all_10]-[68]-[9] lr=[0.5233058393360922] loss=[0.005]\n",
      "[all_10]-[68]-[10] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[11] lr=[0.5233058393360922] loss=[0.004]\n",
      "[all_10]-[68]-[12] lr=[0.5233058393360922] loss=[0.004]\n",
      "[all_10]-[68]-[13] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[14] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[15] lr=[0.5233058393360922] loss=[0.004]\n",
      "[all_10]-[68]-[16] lr=[0.5233058393360922] loss=[0.004]\n",
      "[all_10]-[68]-[17] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[18] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[19] lr=[0.5233058393360922] loss=[0.002]\n",
      "[all_10]-[68]-[20] lr=[0.5233058393360922] loss=[0.002]\n",
      "[all_10]-[68]-[21] lr=[0.5233058393360922] loss=[0.002]\n",
      "[all_10]-[68]-[22] lr=[0.5233058393360922] loss=[0.004]\n",
      "[all_10]-[68]-[23] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[24] lr=[0.5233058393360922] loss=[0.004]\n",
      "[all_10]-[68]-[25] lr=[0.5233058393360922] loss=[0.002]\n",
      "[all_10]-[68]-[26] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[27] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[28] lr=[0.5233058393360922] loss=[0.002]\n",
      "[all_10]-[68]-[29] lr=[0.5233058393360922] loss=[0.002]\n",
      "[all_10]-[68]-[30] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[31] lr=[0.5233058393360922] loss=[0.002]\n",
      "[all_10]-[68]-[32] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[33] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[34] lr=[0.5233058393360922] loss=[0.002]\n",
      "[all_10]-[68]-[35] lr=[0.5233058393360922] loss=[0.002]\n",
      "[all_10]-[68]-[36] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[37] lr=[0.5233058393360922] loss=[0.004]\n",
      "[all_10]-[68]-[38] lr=[0.5233058393360922] loss=[0.004]\n",
      "[all_10]-[68]-[39] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[40] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[41] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[42] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[43] lr=[0.5233058393360922] loss=[0.004]\n",
      "[all_10]-[68]-[44] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[45] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[46] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[47] lr=[0.5233058393360922] loss=[0.003]\n",
      "[all_10]-[68]-[48] lr=[0.5233058393360922] loss=[0.003]\n",
      "tensor([[ 0.0243,  0.0025,  0.0114,  ...,  0.0131,  0.0131,  0.0151],\n",
      "        [ 0.0169,  0.0151, -0.0002,  ...,  0.0203,  0.1250,  0.0133],\n",
      "        [ 0.0173,  0.0043,  0.0160,  ...,  0.0206,  0.0130,  0.0187],\n",
      "        ...,\n",
      "        [ 0.0181,  0.0326,  0.0058,  ...,  0.0146,  0.0110,  0.0130],\n",
      "        [ 0.0143,  0.0057,  0.0303,  ...,  0.0070,  0.0084,  0.0098],\n",
      "        [ 0.0039, -0.0058, -0.0143,  ...,  0.0118,  0.0126,  0.0162]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.6020, 0.0000,  ..., 0.0000, 0.4912, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1193,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.1454, 0.0000,  ..., 0.0000, 0.0000, 0.0302],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0486,  ..., 0.0000, 0.0000, 0.0315]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[69]-[1] lr=[0.5217359218180839] loss=[0.004]\n",
      "[all_10]-[69]-[2] lr=[0.5217359218180839] loss=[0.003]\n",
      "[all_10]-[69]-[3] lr=[0.5217359218180839] loss=[0.003]\n",
      "[all_10]-[69]-[4] lr=[0.5217359218180839] loss=[0.004]\n",
      "[all_10]-[69]-[5] lr=[0.5217359218180839] loss=[0.003]\n",
      "[all_10]-[69]-[6] lr=[0.5217359218180839] loss=[0.004]\n",
      "[all_10]-[69]-[7] lr=[0.5217359218180839] loss=[0.004]\n",
      "[all_10]-[69]-[8] lr=[0.5217359218180839] loss=[0.003]\n",
      "[all_10]-[69]-[9] lr=[0.5217359218180839] loss=[0.004]\n",
      "[all_10]-[69]-[10] lr=[0.5217359218180839] loss=[0.002]\n",
      "[all_10]-[69]-[11] lr=[0.5217359218180839] loss=[0.002]\n",
      "[all_10]-[69]-[12] lr=[0.5217359218180839] loss=[0.002]\n",
      "[all_10]-[69]-[13] lr=[0.5217359218180839] loss=[0.002]\n",
      "[all_10]-[69]-[14] lr=[0.5217359218180839] loss=[0.004]\n",
      "[all_10]-[69]-[15] lr=[0.5217359218180839] loss=[0.002]\n",
      "[all_10]-[69]-[16] lr=[0.5217359218180839] loss=[0.002]\n",
      "[all_10]-[69]-[17] lr=[0.5217359218180839] loss=[0.003]\n",
      "[all_10]-[69]-[18] lr=[0.5217359218180839] loss=[0.003]\n",
      "[all_10]-[69]-[19] lr=[0.5217359218180839] loss=[0.002]\n",
      "[all_10]-[69]-[20] lr=[0.5217359218180839] loss=[0.003]\n",
      "[all_10]-[69]-[21] lr=[0.5217359218180839] loss=[0.002]\n",
      "[all_10]-[69]-[22] lr=[0.5217359218180839] loss=[0.003]\n",
      "[all_10]-[69]-[23] lr=[0.5217359218180839] loss=[0.002]\n",
      "[all_10]-[69]-[24] lr=[0.5217359218180839] loss=[0.003]\n",
      "[all_10]-[69]-[25] lr=[0.5217359218180839] loss=[0.002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[69]-[26] lr=[0.5217359218180839] loss=[0.002]\n",
      "[all_10]-[69]-[27] lr=[0.5217359218180839] loss=[0.002]\n",
      "[all_10]-[69]-[28] lr=[0.5217359218180839] loss=[0.004]\n",
      "[all_10]-[69]-[29] lr=[0.5217359218180839] loss=[0.003]\n",
      "[all_10]-[69]-[30] lr=[0.5217359218180839] loss=[0.002]\n",
      "[all_10]-[69]-[31] lr=[0.5217359218180839] loss=[0.002]\n",
      "[all_10]-[69]-[32] lr=[0.5217359218180839] loss=[0.002]\n",
      "[all_10]-[69]-[33] lr=[0.5217359218180839] loss=[0.003]\n",
      "[all_10]-[69]-[34] lr=[0.5217359218180839] loss=[0.003]\n",
      "[all_10]-[69]-[35] lr=[0.5217359218180839] loss=[0.003]\n",
      "[all_10]-[69]-[36] lr=[0.5217359218180839] loss=[0.003]\n",
      "[all_10]-[69]-[37] lr=[0.5217359218180839] loss=[0.004]\n",
      "[all_10]-[69]-[38] lr=[0.5217359218180839] loss=[0.003]\n",
      "[all_10]-[69]-[39] lr=[0.5217359218180839] loss=[0.003]\n",
      "[all_10]-[69]-[40] lr=[0.5217359218180839] loss=[0.005]\n",
      "[all_10]-[69]-[41] lr=[0.5217359218180839] loss=[0.003]\n",
      "[all_10]-[69]-[42] lr=[0.5217359218180839] loss=[0.004]\n",
      "[all_10]-[69]-[43] lr=[0.5217359218180839] loss=[0.003]\n",
      "[all_10]-[69]-[44] lr=[0.5217359218180839] loss=[0.003]\n",
      "[all_10]-[69]-[45] lr=[0.5217359218180839] loss=[0.004]\n",
      "[all_10]-[69]-[46] lr=[0.5217359218180839] loss=[0.004]\n",
      "[all_10]-[69]-[47] lr=[0.5217359218180839] loss=[0.004]\n",
      "[all_10]-[69]-[48] lr=[0.5217359218180839] loss=[0.003]\n",
      "tensor([[0.0164, 0.0026, 0.0184,  ..., 0.0045, 0.0067, 0.0047],\n",
      "        [0.0082, 0.0101, 0.0248,  ..., 0.0084, 0.0034, 0.0071],\n",
      "        [0.0063, 0.0073, 0.0193,  ..., 0.0031, 0.0024, 0.0082],\n",
      "        ...,\n",
      "        [0.0458, 0.0024, 0.0478,  ..., 0.0208, 0.0076, 0.0037],\n",
      "        [0.0197, 0.0120, 0.0079,  ..., 0.0134, 0.0122, 0.0146],\n",
      "        [0.0110, 0.6636, 0.0649,  ..., 0.0046, 0.0118, 0.0087]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0609, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0050,  ..., 0.0224, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.1126],\n",
      "        [0.0000, 0.4759, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[70]-[1] lr=[0.5201707140526297] loss=[0.005]\n",
      "[all_10]-[70]-[2] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[3] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[4] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[5] lr=[0.5201707140526297] loss=[0.002]\n",
      "[all_10]-[70]-[6] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[7] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[8] lr=[0.5201707140526297] loss=[0.004]\n",
      "[all_10]-[70]-[9] lr=[0.5201707140526297] loss=[0.002]\n",
      "[all_10]-[70]-[10] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[11] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[12] lr=[0.5201707140526297] loss=[0.004]\n",
      "[all_10]-[70]-[13] lr=[0.5201707140526297] loss=[0.002]\n",
      "[all_10]-[70]-[14] lr=[0.5201707140526297] loss=[0.004]\n",
      "[all_10]-[70]-[15] lr=[0.5201707140526297] loss=[0.004]\n",
      "[all_10]-[70]-[16] lr=[0.5201707140526297] loss=[0.004]\n",
      "[all_10]-[70]-[17] lr=[0.5201707140526297] loss=[0.004]\n",
      "[all_10]-[70]-[18] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[19] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[20] lr=[0.5201707140526297] loss=[0.002]\n",
      "[all_10]-[70]-[21] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[22] lr=[0.5201707140526297] loss=[0.005]\n",
      "[all_10]-[70]-[23] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[24] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[25] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[26] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[27] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[28] lr=[0.5201707140526297] loss=[0.002]\n",
      "[all_10]-[70]-[29] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[30] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[31] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[32] lr=[0.5201707140526297] loss=[0.002]\n",
      "[all_10]-[70]-[33] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[34] lr=[0.5201707140526297] loss=[0.004]\n",
      "[all_10]-[70]-[35] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[36] lr=[0.5201707140526297] loss=[0.004]\n",
      "[all_10]-[70]-[37] lr=[0.5201707140526297] loss=[0.004]\n",
      "[all_10]-[70]-[38] lr=[0.5201707140526297] loss=[0.004]\n",
      "[all_10]-[70]-[39] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[40] lr=[0.5201707140526297] loss=[0.004]\n",
      "[all_10]-[70]-[41] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[42] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[43] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[44] lr=[0.5201707140526297] loss=[0.002]\n",
      "[all_10]-[70]-[45] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[46] lr=[0.5201707140526297] loss=[0.002]\n",
      "[all_10]-[70]-[47] lr=[0.5201707140526297] loss=[0.003]\n",
      "[all_10]-[70]-[48] lr=[0.5201707140526297] loss=[0.002]\n",
      "tensor([[0.0806, 0.0208, 0.0235,  ..., 0.0288, 0.0294, 0.0296],\n",
      "        [0.0402, 0.0237, 0.0319,  ..., 0.0263, 0.0413, 0.0332],\n",
      "        [0.0259, 0.0272, 0.0156,  ..., 0.0208, 0.0358, 0.0218],\n",
      "        ...,\n",
      "        [0.0290, 0.5295, 0.0245,  ..., 0.0194, 0.0164, 0.0164],\n",
      "        [0.0277, 0.0131, 0.0180,  ..., 0.0239, 0.0193, 0.0200],\n",
      "        [0.0332, 0.0110, 0.1999,  ..., 0.0249, 0.0185, 0.0217]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.4172, 0.0000, 0.0000,  ..., 0.0000, 0.0641, 0.0000],\n",
      "        [0.2028, 0.0000, 0.0074,  ..., 0.0086, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1355, 0.0417,  ..., 0.1237, 0.0216, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0605, 0.0000,  ..., 0.0000, 0.0000, 0.0101],\n",
      "        [0.0000, 0.0000, 0.0315,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.4138,  ..., 0.0216, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[71]-[1] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[2] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[3] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[4] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[5] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[6] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[7] lr=[0.5186102019104718] loss=[0.004]\n",
      "[all_10]-[71]-[8] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[9] lr=[0.5186102019104718] loss=[0.004]\n",
      "[all_10]-[71]-[10] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[11] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[12] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[13] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[14] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[15] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[16] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[17] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[18] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[19] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[20] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[21] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[22] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[23] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[24] lr=[0.5186102019104718] loss=[0.004]\n",
      "[all_10]-[71]-[25] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[26] lr=[0.5186102019104718] loss=[0.004]\n",
      "[all_10]-[71]-[27] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[28] lr=[0.5186102019104718] loss=[0.004]\n",
      "[all_10]-[71]-[29] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[30] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[31] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[32] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[33] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[34] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[35] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[36] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[37] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[38] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[39] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[40] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[41] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[42] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[43] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[44] lr=[0.5186102019104718] loss=[0.003]\n",
      "[all_10]-[71]-[45] lr=[0.5186102019104718] loss=[0.002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[71]-[46] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[47] lr=[0.5186102019104718] loss=[0.002]\n",
      "[all_10]-[71]-[48] lr=[0.5186102019104718] loss=[0.002]\n",
      "tensor([[ 0.0340,  0.0463,  0.0639,  ...,  0.0044,  0.0099,  0.0105],\n",
      "        [ 0.0189,  0.0247,  0.0103,  ...,  0.0095,  0.0177,  0.0155],\n",
      "        [ 0.2108,  0.0222,  0.0040,  ..., -0.0013,  0.0033,  0.0058],\n",
      "        ...,\n",
      "        [ 0.0167,  0.0026, -0.0014,  ...,  0.0106,  0.0090,  0.0174],\n",
      "        [ 0.0135,  0.0175,  0.0004,  ...,  0.0108, -0.0019,  0.0028],\n",
      "        [ 0.0102,  0.0043,  0.0344,  ...,  0.0087,  0.0074,  0.0078]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.2551,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0361],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2314, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[72]-[1] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[2] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[3] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[4] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[5] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[6] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[7] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[8] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[9] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[10] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[11] lr=[0.5170543713047404] loss=[0.004]\n",
      "[all_10]-[72]-[12] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[13] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[14] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[15] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[16] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[17] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[18] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[19] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[20] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[21] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[22] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[23] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[24] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[25] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[26] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[27] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[28] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[29] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[30] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[31] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[32] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[33] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[34] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[35] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[36] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[37] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[38] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[39] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[40] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[41] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[42] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[43] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[44] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[45] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[46] lr=[0.5170543713047404] loss=[0.002]\n",
      "[all_10]-[72]-[47] lr=[0.5170543713047404] loss=[0.003]\n",
      "[all_10]-[72]-[48] lr=[0.5170543713047404] loss=[0.003]\n",
      "tensor([[ 0.0149,  0.0050,  0.5120,  ...,  0.0156,  0.0299,  0.0152],\n",
      "        [ 0.1107,  0.0192,  0.0142,  ...,  0.0241,  0.0166,  0.0160],\n",
      "        [ 0.0083, -0.0069,  0.0015,  ...,  0.0109,  0.0100,  0.0129],\n",
      "        ...,\n",
      "        [ 0.3279,  0.0184,  0.0017,  ...,  0.0143,  0.0123,  0.0237],\n",
      "        [ 0.0181,  0.0040,  0.0165,  ...,  0.0200,  0.0153,  0.0131],\n",
      "        [ 0.0176,  0.0535,  0.0235,  ...,  0.0071,  0.0074,  0.0098]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0913,  ..., 0.0000, 0.0000, 0.0389],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.6096, 0.0000, 0.0544,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0929, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4594, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[73]-[1] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[2] lr=[0.5155032081908262] loss=[0.002]\n",
      "[all_10]-[73]-[3] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[4] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[5] lr=[0.5155032081908262] loss=[0.002]\n",
      "[all_10]-[73]-[6] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[7] lr=[0.5155032081908262] loss=[0.002]\n",
      "[all_10]-[73]-[8] lr=[0.5155032081908262] loss=[0.002]\n",
      "[all_10]-[73]-[9] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[10] lr=[0.5155032081908262] loss=[0.004]\n",
      "[all_10]-[73]-[11] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[12] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[13] lr=[0.5155032081908262] loss=[0.004]\n",
      "[all_10]-[73]-[14] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[15] lr=[0.5155032081908262] loss=[0.004]\n",
      "[all_10]-[73]-[16] lr=[0.5155032081908262] loss=[0.002]\n",
      "[all_10]-[73]-[17] lr=[0.5155032081908262] loss=[0.004]\n",
      "[all_10]-[73]-[18] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[19] lr=[0.5155032081908262] loss=[0.004]\n",
      "[all_10]-[73]-[20] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[21] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[22] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[23] lr=[0.5155032081908262] loss=[0.002]\n",
      "[all_10]-[73]-[24] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[25] lr=[0.5155032081908262] loss=[0.004]\n",
      "[all_10]-[73]-[26] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[27] lr=[0.5155032081908262] loss=[0.002]\n",
      "[all_10]-[73]-[28] lr=[0.5155032081908262] loss=[0.004]\n",
      "[all_10]-[73]-[29] lr=[0.5155032081908262] loss=[0.002]\n",
      "[all_10]-[73]-[30] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[31] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[32] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[33] lr=[0.5155032081908262] loss=[0.002]\n",
      "[all_10]-[73]-[34] lr=[0.5155032081908262] loss=[0.002]\n",
      "[all_10]-[73]-[35] lr=[0.5155032081908262] loss=[0.002]\n",
      "[all_10]-[73]-[36] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[37] lr=[0.5155032081908262] loss=[0.004]\n",
      "[all_10]-[73]-[38] lr=[0.5155032081908262] loss=[0.002]\n",
      "[all_10]-[73]-[39] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[40] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[41] lr=[0.5155032081908262] loss=[0.002]\n",
      "[all_10]-[73]-[42] lr=[0.5155032081908262] loss=[0.002]\n",
      "[all_10]-[73]-[43] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[44] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[45] lr=[0.5155032081908262] loss=[0.003]\n",
      "[all_10]-[73]-[46] lr=[0.5155032081908262] loss=[0.002]\n",
      "[all_10]-[73]-[47] lr=[0.5155032081908262] loss=[0.002]\n",
      "[all_10]-[73]-[48] lr=[0.5155032081908262] loss=[0.004]\n",
      "tensor([[-1.9178e-02,  2.2455e-01, -1.1540e-02,  ..., -2.5305e-02,\n",
      "         -2.0276e-02, -1.8118e-02],\n",
      "        [-2.3458e-02, -3.2495e-02, -2.7552e-02,  ..., -7.8388e-03,\n",
      "         -2.5547e-02,  1.5551e-03],\n",
      "        [-2.1268e-02, -3.4033e-02, -2.2755e-02,  ..., -1.6063e-02,\n",
      "         -1.9518e-02, -3.0334e-02],\n",
      "        ...,\n",
      "        [-1.3375e-02, -2.8864e-02, -6.1754e-03,  ..., -2.9402e-02,\n",
      "         -7.5474e-03, -1.0427e-02],\n",
      "        [ 1.6664e-04, -3.1948e-02,  1.5834e-01,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2555e-01, -1.8744e-02, -1.9589e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0', requires_grad=True)\n",
      "tensor([[ 0.0000,  0.1418,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0211,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0325,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [20.8226,  0.0000,  4.1969,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 2.5909,  0.4467,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[74]-[1] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[2] lr=[0.5139566985662537] loss=[0.002]\n",
      "[all_10]-[74]-[3] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[4] lr=[0.5139566985662537] loss=[0.002]\n",
      "[all_10]-[74]-[5] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[6] lr=[0.5139566985662537] loss=[0.002]\n",
      "[all_10]-[74]-[7] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[8] lr=[0.5139566985662537] loss=[0.002]\n",
      "[all_10]-[74]-[9] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[10] lr=[0.5139566985662537] loss=[0.002]\n",
      "[all_10]-[74]-[11] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[12] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[13] lr=[0.5139566985662537] loss=[0.002]\n",
      "[all_10]-[74]-[14] lr=[0.5139566985662537] loss=[0.002]\n",
      "[all_10]-[74]-[15] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[16] lr=[0.5139566985662537] loss=[0.002]\n",
      "[all_10]-[74]-[17] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[18] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[19] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[20] lr=[0.5139566985662537] loss=[0.002]\n",
      "[all_10]-[74]-[21] lr=[0.5139566985662537] loss=[0.004]\n",
      "[all_10]-[74]-[22] lr=[0.5139566985662537] loss=[0.002]\n",
      "[all_10]-[74]-[23] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[24] lr=[0.5139566985662537] loss=[0.002]\n",
      "[all_10]-[74]-[25] lr=[0.5139566985662537] loss=[0.002]\n",
      "[all_10]-[74]-[26] lr=[0.5139566985662537] loss=[0.002]\n",
      "[all_10]-[74]-[27] lr=[0.5139566985662537] loss=[0.002]\n",
      "[all_10]-[74]-[28] lr=[0.5139566985662537] loss=[0.002]\n",
      "[all_10]-[74]-[29] lr=[0.5139566985662537] loss=[0.002]\n",
      "[all_10]-[74]-[30] lr=[0.5139566985662537] loss=[0.002]\n",
      "[all_10]-[74]-[31] lr=[0.5139566985662537] loss=[0.002]\n",
      "[all_10]-[74]-[32] lr=[0.5139566985662537] loss=[0.004]\n",
      "[all_10]-[74]-[33] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[34] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[35] lr=[0.5139566985662537] loss=[0.004]\n",
      "[all_10]-[74]-[36] lr=[0.5139566985662537] loss=[0.004]\n",
      "[all_10]-[74]-[37] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[38] lr=[0.5139566985662537] loss=[0.004]\n",
      "[all_10]-[74]-[39] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[40] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[41] lr=[0.5139566985662537] loss=[0.004]\n",
      "[all_10]-[74]-[42] lr=[0.5139566985662537] loss=[0.004]\n",
      "[all_10]-[74]-[43] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[44] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[45] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[46] lr=[0.5139566985662537] loss=[0.002]\n",
      "[all_10]-[74]-[47] lr=[0.5139566985662537] loss=[0.003]\n",
      "[all_10]-[74]-[48] lr=[0.5139566985662537] loss=[0.003]\n",
      "tensor([[ 8.4402e-03,  1.6265e-02, -1.8893e-03,  ...,  4.8815e-03,\n",
      "          8.8063e-03,  2.7038e-03],\n",
      "        [ 1.4558e-05,  8.3030e-03,  7.3480e-01,  ...,  2.5590e-03,\n",
      "          2.7236e-03,  1.5501e-02],\n",
      "        [ 7.0961e-02,  3.0187e-03,  1.0485e-02,  ...,  1.0630e-02,\n",
      "          6.2152e-03,  1.4153e-02],\n",
      "        ...,\n",
      "        [ 1.3571e-02, -1.7908e-03,  6.5629e-01,  ...,  2.0918e-03,\n",
      "          9.9301e-03,  1.0308e-02],\n",
      "        [ 7.5755e-03, -9.1177e-03,  8.2309e-03,  ...,  9.5690e-03,\n",
      "          1.3216e-02,  9.7431e-03],\n",
      "        [ 1.6222e-03, -1.5363e-02,  4.7231e-02,  ...,  1.4771e-02,\n",
      "          4.6829e-03,  5.5705e-03]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0914, 0.0000,  ..., 0.0000, 0.0138, 0.0000],\n",
      "        [0.0000, 0.0000, 0.5801,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.8708, 0.0000, 0.5069,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 2.4225,  ..., 0.0000, 0.0000, 0.0184],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[75]-[1] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[2] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[3] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[4] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[5] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[6] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[7] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[8] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[9] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[10] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[11] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[12] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[13] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[14] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[15] lr=[0.512414828470555] loss=[0.004]\n",
      "[all_10]-[75]-[16] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[17] lr=[0.512414828470555] loss=[0.004]\n",
      "[all_10]-[75]-[18] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[19] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[20] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[21] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[22] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[23] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[24] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[25] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[26] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[27] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[28] lr=[0.512414828470555] loss=[0.004]\n",
      "[all_10]-[75]-[29] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[30] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[31] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[32] lr=[0.512414828470555] loss=[0.004]\n",
      "[all_10]-[75]-[33] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[34] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[35] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[36] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[37] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[38] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[39] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[40] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[41] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[42] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[43] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[44] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[45] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[46] lr=[0.512414828470555] loss=[0.003]\n",
      "[all_10]-[75]-[47] lr=[0.512414828470555] loss=[0.002]\n",
      "[all_10]-[75]-[48] lr=[0.512414828470555] loss=[0.002]\n",
      "tensor([[ 3.2446e-03, -2.2649e-02, -9.8557e-03,  ..., -6.8935e-03,\n",
      "         -4.7240e-03,  1.0174e-02],\n",
      "        [ 1.7574e-02, -9.6818e-03,  3.2590e-02,  ..., -1.2631e-02,\n",
      "         -9.7974e-03, -7.4672e-03],\n",
      "        [-3.8912e-03, -2.3346e-02, -1.0947e-02,  ...,  2.0090e-02,\n",
      "         -1.4629e-02, -1.5734e-02],\n",
      "        ...,\n",
      "        [ 6.3496e-02,  5.0496e-03,  3.0719e-03,  ...,  3.0231e-04,\n",
      "         -1.3700e-02, -1.2757e-02],\n",
      "        [-8.5334e-04, -1.9024e-02,  9.2688e-03,  ...,  5.5833e-03,\n",
      "         -8.5285e-03, -9.9705e-03],\n",
      "        [ 7.3795e-02, -8.4384e-04,  4.7853e-01,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0148, 0.0000, 0.0000,  ..., 0.0000, 0.0618, 0.0000],\n",
      "        [0.0566, 0.0000, 0.1698,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.2498, 0.0000, 0.0278,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0025, 0.0092, 0.0551,  ..., 0.0000, 0.0000, 0.0184],\n",
      "        [0.0000, 0.0000, 0.0169,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[76]-[1] lr=[0.5108775839851433] loss=[0.002]\n",
      "[all_10]-[76]-[2] lr=[0.5108775839851433] loss=[0.002]\n",
      "[all_10]-[76]-[3] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[4] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[5] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[6] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[7] lr=[0.5108775839851433] loss=[0.004]\n",
      "[all_10]-[76]-[8] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[9] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[10] lr=[0.5108775839851433] loss=[0.002]\n",
      "[all_10]-[76]-[11] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[12] lr=[0.5108775839851433] loss=[0.002]\n",
      "[all_10]-[76]-[13] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[14] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[15] lr=[0.5108775839851433] loss=[0.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[76]-[16] lr=[0.5108775839851433] loss=[0.004]\n",
      "[all_10]-[76]-[17] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[18] lr=[0.5108775839851433] loss=[0.005]\n",
      "[all_10]-[76]-[19] lr=[0.5108775839851433] loss=[0.002]\n",
      "[all_10]-[76]-[20] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[21] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[22] lr=[0.5108775839851433] loss=[0.004]\n",
      "[all_10]-[76]-[23] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[24] lr=[0.5108775839851433] loss=[0.002]\n",
      "[all_10]-[76]-[25] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[26] lr=[0.5108775839851433] loss=[0.002]\n",
      "[all_10]-[76]-[27] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[28] lr=[0.5108775839851433] loss=[0.002]\n",
      "[all_10]-[76]-[29] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[30] lr=[0.5108775839851433] loss=[0.002]\n",
      "[all_10]-[76]-[31] lr=[0.5108775839851433] loss=[0.002]\n",
      "[all_10]-[76]-[32] lr=[0.5108775839851433] loss=[0.002]\n",
      "[all_10]-[76]-[33] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[34] lr=[0.5108775839851433] loss=[0.002]\n",
      "[all_10]-[76]-[35] lr=[0.5108775839851433] loss=[0.002]\n",
      "[all_10]-[76]-[36] lr=[0.5108775839851433] loss=[0.002]\n",
      "[all_10]-[76]-[37] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[38] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[39] lr=[0.5108775839851433] loss=[0.002]\n",
      "[all_10]-[76]-[40] lr=[0.5108775839851433] loss=[0.002]\n",
      "[all_10]-[76]-[41] lr=[0.5108775839851433] loss=[0.002]\n",
      "[all_10]-[76]-[42] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[43] lr=[0.5108775839851433] loss=[0.002]\n",
      "[all_10]-[76]-[44] lr=[0.5108775839851433] loss=[0.002]\n",
      "[all_10]-[76]-[45] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[46] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[47] lr=[0.5108775839851433] loss=[0.003]\n",
      "[all_10]-[76]-[48] lr=[0.5108775839851433] loss=[0.002]\n",
      "tensor([[0.0260, 0.0207, 0.0146,  ..., 0.0286, 0.0290, 0.0235],\n",
      "        [0.0146, 0.0107, 0.0264,  ..., 0.0273, 0.0856, 0.0229],\n",
      "        [0.0289, 0.0183, 0.0281,  ..., 0.0222, 0.0234, 0.0234],\n",
      "        ...,\n",
      "        [0.0318, 0.0289, 0.1563,  ..., 0.0230, 0.0190, 0.0217],\n",
      "        [0.0323, 0.0647, 0.0485,  ..., 0.0240, 0.0353, 0.0203],\n",
      "        [0.0301, 0.6367, 0.0213,  ..., 0.0243, 0.0224, 0.0226]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.1866, 0.4417],\n",
      "        [0.0000, 0.0384, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.6864,  ..., 0.0000, 0.0000, 0.0652],\n",
      "        [0.1896, 0.0000, 0.0000,  ..., 0.0948, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0605, 0.0000,  ..., 0.0000, 0.0000, 0.0101]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[77]-[1] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[2] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[3] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[4] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[5] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[6] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[7] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[8] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[9] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[10] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[11] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[12] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[13] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[14] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[15] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[16] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[17] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[18] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[19] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[20] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[21] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[22] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[23] lr=[0.5093449512331878] loss=[0.004]\n",
      "[all_10]-[77]-[24] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[25] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[26] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[27] lr=[0.5093449512331878] loss=[0.004]\n",
      "[all_10]-[77]-[28] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[29] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[30] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[31] lr=[0.5093449512331878] loss=[0.004]\n",
      "[all_10]-[77]-[32] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[33] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[34] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[35] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[36] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[37] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[38] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[39] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[40] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[41] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[42] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[43] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[44] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[45] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[46] lr=[0.5093449512331878] loss=[0.003]\n",
      "[all_10]-[77]-[47] lr=[0.5093449512331878] loss=[0.002]\n",
      "[all_10]-[77]-[48] lr=[0.5093449512331878] loss=[0.002]\n",
      "tensor([[0.0031, 0.0033, 0.0068,  ..., 0.0064, 0.0046, 0.0069],\n",
      "        [0.0160, 0.4413, 0.0127,  ..., 0.0073, 0.0077, 0.0102],\n",
      "        [0.0185, 0.0126, 0.0062,  ..., 0.0061, 0.0096, 0.0249],\n",
      "        ...,\n",
      "        [0.0211, 0.0078, 0.0135,  ..., 0.0085, 0.0135, 0.0087],\n",
      "        [0.0078, 0.0053, 0.0069,  ..., 0.0116, 0.0386, 0.0096],\n",
      "        [0.1014, 0.0102, 0.0144,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0684, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0284],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0447, 0.0653,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1954, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[78]-[1] lr=[0.5078169163794882] loss=[0.003]\n",
      "[all_10]-[78]-[2] lr=[0.5078169163794882] loss=[0.003]\n",
      "[all_10]-[78]-[3] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[4] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[5] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[6] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[7] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[8] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[9] lr=[0.5078169163794882] loss=[0.003]\n",
      "[all_10]-[78]-[10] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[11] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[12] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[13] lr=[0.5078169163794882] loss=[0.003]\n",
      "[all_10]-[78]-[14] lr=[0.5078169163794882] loss=[0.003]\n",
      "[all_10]-[78]-[15] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[16] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[17] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[18] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[19] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[20] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[21] lr=[0.5078169163794882] loss=[0.003]\n",
      "[all_10]-[78]-[22] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[23] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[24] lr=[0.5078169163794882] loss=[0.003]\n",
      "[all_10]-[78]-[25] lr=[0.5078169163794882] loss=[0.004]\n",
      "[all_10]-[78]-[26] lr=[0.5078169163794882] loss=[0.003]\n",
      "[all_10]-[78]-[27] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[28] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[29] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[30] lr=[0.5078169163794882] loss=[0.003]\n",
      "[all_10]-[78]-[31] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[32] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[33] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[34] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[35] lr=[0.5078169163794882] loss=[0.002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[78]-[36] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[37] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[38] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[39] lr=[0.5078169163794882] loss=[0.003]\n",
      "[all_10]-[78]-[40] lr=[0.5078169163794882] loss=[0.003]\n",
      "[all_10]-[78]-[41] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[42] lr=[0.5078169163794882] loss=[0.003]\n",
      "[all_10]-[78]-[43] lr=[0.5078169163794882] loss=[0.003]\n",
      "[all_10]-[78]-[44] lr=[0.5078169163794882] loss=[0.002]\n",
      "[all_10]-[78]-[45] lr=[0.5078169163794882] loss=[0.003]\n",
      "[all_10]-[78]-[46] lr=[0.5078169163794882] loss=[0.003]\n",
      "[all_10]-[78]-[47] lr=[0.5078169163794882] loss=[0.003]\n",
      "[all_10]-[78]-[48] lr=[0.5078169163794882] loss=[0.003]\n",
      "tensor([[ 1.9108e-03, -7.1695e-03, -7.5714e-03,  ...,  2.4419e-04,\n",
      "         -1.1135e-04,  2.9119e-04],\n",
      "        [-5.0191e-03, -9.2143e-03,  1.2386e-03,  ..., -6.1968e-03,\n",
      "         -7.7357e-03, -4.0553e-03],\n",
      "        [ 1.6607e-02,  1.8627e-03,  1.0972e-02,  ..., -1.2255e-03,\n",
      "          1.0298e-02,  1.5420e-03],\n",
      "        ...,\n",
      "        [-5.4266e-03, -1.7715e-02, -9.2596e-03,  ..., -6.1428e-03,\n",
      "         -1.0070e-02, -1.0839e-02],\n",
      "        [-3.3016e-03,  7.1883e-03,  1.5416e-01,  ..., -6.9868e-03,\n",
      "          4.3112e-04, -1.2009e-02],\n",
      "        [ 2.1604e-02, -8.0637e-03, -2.0823e-02,  ..., -7.1454e-03,\n",
      "         -1.6627e-02, -6.7533e-03]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0532, 0.0692, 0.0000,  ..., 0.0000, 0.0000, 0.0175],\n",
      "        [0.0000, 0.0000, 0.0123,  ..., 0.0000, 0.0000, 0.0508],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.3569,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0307, 0.0000, 0.0000,  ..., 0.0000, 0.0153, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[79]-[1] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[2] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[3] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[4] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[5] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[6] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[7] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[8] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[9] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[10] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[11] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[12] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[13] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[14] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[15] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[16] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[17] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[18] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[19] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[20] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[21] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[22] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[23] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[24] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[25] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[26] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[27] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[28] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[29] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[30] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[31] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[32] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[33] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[34] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[35] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[36] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[37] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[38] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[39] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[40] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[41] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[42] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[43] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[44] lr=[0.5062934656303497] loss=[0.003]\n",
      "[all_10]-[79]-[45] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[46] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[47] lr=[0.5062934656303497] loss=[0.002]\n",
      "[all_10]-[79]-[48] lr=[0.5062934656303497] loss=[0.002]\n",
      "tensor([[ 3.7597e-03,  7.3291e-03, -5.7272e-03,  ...,  7.3818e-04,\n",
      "          1.8554e-03,  5.7275e-03],\n",
      "        [ 1.8915e-02,  3.1613e-03, -8.7013e-03,  ..., -5.5669e-03,\n",
      "         -4.5419e-03, -2.9941e-03],\n",
      "        [ 7.5377e-03,  3.1436e-03,  2.1183e-02,  ...,  5.1233e-03,\n",
      "         -4.4391e-05, -5.0577e-03],\n",
      "        ...,\n",
      "        [ 2.2718e-03,  9.6409e-03, -3.3150e-03,  ..., -4.0930e-03,\n",
      "         -9.9361e-04, -1.4918e-03],\n",
      "        [ 1.4984e-02,  1.1493e-02,  4.3162e-04,  ...,  7.5074e-03,\n",
      "          4.2642e-03,  1.2883e-02],\n",
      "        [-2.6259e-03, -8.8336e-03,  8.7188e-03,  ...,  5.9593e-03,\n",
      "          1.0913e-02,  2.7711e-03]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.2341, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0215,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0340, 0.0133,  ..., 0.0000, 0.0000, 0.0215],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0565]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[80]-[1] lr=[0.5047745852334586] loss=[0.003]\n",
      "[all_10]-[80]-[2] lr=[0.5047745852334586] loss=[0.003]\n",
      "[all_10]-[80]-[3] lr=[0.5047745852334586] loss=[0.003]\n",
      "[all_10]-[80]-[4] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[5] lr=[0.5047745852334586] loss=[0.003]\n",
      "[all_10]-[80]-[6] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[7] lr=[0.5047745852334586] loss=[0.003]\n",
      "[all_10]-[80]-[8] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[9] lr=[0.5047745852334586] loss=[0.003]\n",
      "[all_10]-[80]-[10] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[11] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[12] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[13] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[14] lr=[0.5047745852334586] loss=[0.003]\n",
      "[all_10]-[80]-[15] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[16] lr=[0.5047745852334586] loss=[0.003]\n",
      "[all_10]-[80]-[17] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[18] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[19] lr=[0.5047745852334586] loss=[0.003]\n",
      "[all_10]-[80]-[20] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[21] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[22] lr=[0.5047745852334586] loss=[0.003]\n",
      "[all_10]-[80]-[23] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[24] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[25] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[26] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[27] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[28] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[29] lr=[0.5047745852334586] loss=[0.003]\n",
      "[all_10]-[80]-[30] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[31] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[32] lr=[0.5047745852334586] loss=[0.003]\n",
      "[all_10]-[80]-[33] lr=[0.5047745852334586] loss=[0.003]\n",
      "[all_10]-[80]-[34] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[35] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[36] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[37] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[38] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[39] lr=[0.5047745852334586] loss=[0.003]\n",
      "[all_10]-[80]-[40] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[41] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[42] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[43] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[44] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[45] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[46] lr=[0.5047745852334586] loss=[0.003]\n",
      "[all_10]-[80]-[47] lr=[0.5047745852334586] loss=[0.002]\n",
      "[all_10]-[80]-[48] lr=[0.5047745852334586] loss=[0.002]\n",
      "tensor([[ 1.1904e-02,  5.1662e-03,  1.0501e-02,  ...,  2.3295e-02,\n",
      "          2.3100e-03,  7.7143e-05],\n",
      "        [ 1.5004e-02,  6.8974e-03,  3.5820e-03,  ...,  8.8000e-03,\n",
      "          1.6207e-02,  7.9822e-03],\n",
      "        [ 1.1302e-02, -2.6477e-03,  1.0661e-02,  ...,  1.3613e-02,\n",
      "          3.7152e-02,  4.0368e-03],\n",
      "        ...,\n",
      "        [ 4.0870e-02,  3.5512e-02,  2.9935e-02,  ...,  9.4379e-03,\n",
      "          2.2853e-02,  1.1845e-02],\n",
      "        [ 9.5117e-03,  2.1072e-01,  6.9608e-02,  ...,  8.1213e-02,\n",
      "          2.9688e-03,  4.1624e-03],\n",
      "        [ 1.9779e-02, -3.5432e-03, -5.3785e-03,  ...,  7.0944e-03,\n",
      "          1.6561e-02,  1.4065e-02]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0263,  ..., 0.0000, 0.0087, 0.0073],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0962, 0.0290,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.3837,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0089, 0.0031, 0.0000]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[81]-[1] lr=[0.5032602614777583] loss=[0.003]\n",
      "[all_10]-[81]-[2] lr=[0.5032602614777583] loss=[0.003]\n",
      "[all_10]-[81]-[3] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[4] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[5] lr=[0.5032602614777583] loss=[0.003]\n",
      "[all_10]-[81]-[6] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[7] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[8] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[9] lr=[0.5032602614777583] loss=[0.003]\n",
      "[all_10]-[81]-[10] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[11] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[12] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[13] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[14] lr=[0.5032602614777583] loss=[0.004]\n",
      "[all_10]-[81]-[15] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[16] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[17] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[18] lr=[0.5032602614777583] loss=[0.003]\n",
      "[all_10]-[81]-[19] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[20] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[21] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[22] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[23] lr=[0.5032602614777583] loss=[0.003]\n",
      "[all_10]-[81]-[24] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[25] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[26] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[27] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[28] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[29] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[30] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[31] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[32] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[33] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[34] lr=[0.5032602614777583] loss=[0.003]\n",
      "[all_10]-[81]-[35] lr=[0.5032602614777583] loss=[0.003]\n",
      "[all_10]-[81]-[36] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[37] lr=[0.5032602614777583] loss=[0.003]\n",
      "[all_10]-[81]-[38] lr=[0.5032602614777583] loss=[0.003]\n",
      "[all_10]-[81]-[39] lr=[0.5032602614777583] loss=[0.003]\n",
      "[all_10]-[81]-[40] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[41] lr=[0.5032602614777583] loss=[0.003]\n",
      "[all_10]-[81]-[42] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[43] lr=[0.5032602614777583] loss=[0.003]\n",
      "[all_10]-[81]-[44] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[45] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[46] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[47] lr=[0.5032602614777583] loss=[0.002]\n",
      "[all_10]-[81]-[48] lr=[0.5032602614777583] loss=[0.003]\n",
      "tensor([[-0.0092, -0.0214, -0.0142,  ..., -0.0168, -0.0157, -0.0136],\n",
      "        [ 0.0041,  0.0085, -0.0294,  ..., -0.0088, -0.0190, -0.0170],\n",
      "        [-0.0013, -0.0123,  0.0174,  ..., -0.0189, -0.0116, -0.0173],\n",
      "        ...,\n",
      "        [-0.0041, -0.0022, -0.0192,  ..., -0.0162, -0.0104, -0.0116],\n",
      "        [-0.0100, -0.0149, -0.0148,  ..., -0.0172,  0.0067, -0.0260],\n",
      "        [ 0.1164, -0.0122,  0.4782,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0477, 0.0000],\n",
      "        [0.0047, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0094, 0.0996,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.2615, 0.0000,  ..., 0.0000, 0.0000, 0.0896],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0791, 0.0791, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[82]-[1] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[2] lr=[0.501750480693325] loss=[0.003]\n",
      "[all_10]-[82]-[3] lr=[0.501750480693325] loss=[0.003]\n",
      "[all_10]-[82]-[4] lr=[0.501750480693325] loss=[0.003]\n",
      "[all_10]-[82]-[5] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[6] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[7] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[8] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[9] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[10] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[11] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[12] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[13] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[14] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[15] lr=[0.501750480693325] loss=[0.003]\n",
      "[all_10]-[82]-[16] lr=[0.501750480693325] loss=[0.003]\n",
      "[all_10]-[82]-[17] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[18] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[19] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[20] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[21] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[22] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[23] lr=[0.501750480693325] loss=[0.003]\n",
      "[all_10]-[82]-[24] lr=[0.501750480693325] loss=[0.003]\n",
      "[all_10]-[82]-[25] lr=[0.501750480693325] loss=[0.003]\n",
      "[all_10]-[82]-[26] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[27] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[28] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[29] lr=[0.501750480693325] loss=[0.003]\n",
      "[all_10]-[82]-[30] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[31] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[32] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[33] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[34] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[35] lr=[0.501750480693325] loss=[0.003]\n",
      "[all_10]-[82]-[36] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[37] lr=[0.501750480693325] loss=[0.003]\n",
      "[all_10]-[82]-[38] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[39] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[40] lr=[0.501750480693325] loss=[0.003]\n",
      "[all_10]-[82]-[41] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[42] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[43] lr=[0.501750480693325] loss=[0.003]\n",
      "[all_10]-[82]-[44] lr=[0.501750480693325] loss=[0.003]\n",
      "[all_10]-[82]-[45] lr=[0.501750480693325] loss=[0.003]\n",
      "[all_10]-[82]-[46] lr=[0.501750480693325] loss=[0.003]\n",
      "[all_10]-[82]-[47] lr=[0.501750480693325] loss=[0.002]\n",
      "[all_10]-[82]-[48] lr=[0.501750480693325] loss=[0.002]\n",
      "tensor([[-0.0112, -0.0149, -0.0053,  ..., -0.0161, -0.0159, -0.0180],\n",
      "        [-0.0055, -0.0213, -0.0011,  ...,  0.0165, -0.0178, -0.0138],\n",
      "        [-0.0057, -0.0073, -0.0101,  ..., -0.0032, -0.0139, -0.0112],\n",
      "        ...,\n",
      "        [-0.0187, -0.0166, -0.0189,  ..., -0.0152,  0.0445, -0.0140],\n",
      "        [-0.0098, -0.0172, -0.0120,  ..., -0.0137, -0.0065,  0.0141],\n",
      "        [-0.0133, -0.0188, -0.0164,  ..., -0.0081, -0.0083, -0.0118]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0245,  ..., 0.0209, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 1.0075, 0.0000,  ..., 0.4401, 1.3152, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0079, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[83]-[1] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[2] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[3] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[4] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[5] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[6] lr=[0.5002452292512449] loss=[0.003]\n",
      "[all_10]-[83]-[7] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[8] lr=[0.5002452292512449] loss=[0.003]\n",
      "[all_10]-[83]-[9] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[10] lr=[0.5002452292512449] loss=[0.003]\n",
      "[all_10]-[83]-[11] lr=[0.5002452292512449] loss=[0.004]\n",
      "[all_10]-[83]-[12] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[13] lr=[0.5002452292512449] loss=[0.003]\n",
      "[all_10]-[83]-[14] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[15] lr=[0.5002452292512449] loss=[0.003]\n",
      "[all_10]-[83]-[16] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[17] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[18] lr=[0.5002452292512449] loss=[0.003]\n",
      "[all_10]-[83]-[19] lr=[0.5002452292512449] loss=[0.003]\n",
      "[all_10]-[83]-[20] lr=[0.5002452292512449] loss=[0.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[83]-[21] lr=[0.5002452292512449] loss=[0.003]\n",
      "[all_10]-[83]-[22] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[23] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[24] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[25] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[26] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[27] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[28] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[29] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[30] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[31] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[32] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[33] lr=[0.5002452292512449] loss=[0.003]\n",
      "[all_10]-[83]-[34] lr=[0.5002452292512449] loss=[0.003]\n",
      "[all_10]-[83]-[35] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[36] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[37] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[38] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[39] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[40] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[41] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[42] lr=[0.5002452292512449] loss=[0.003]\n",
      "[all_10]-[83]-[43] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[44] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[45] lr=[0.5002452292512449] loss=[0.003]\n",
      "[all_10]-[83]-[46] lr=[0.5002452292512449] loss=[0.002]\n",
      "[all_10]-[83]-[47] lr=[0.5002452292512449] loss=[0.003]\n",
      "[all_10]-[83]-[48] lr=[0.5002452292512449] loss=[0.002]\n",
      "tensor([[ 1.1997e-03,  4.0207e-03, -1.0623e-02,  ...,  1.1106e-02,\n",
      "         -6.1828e-03, -9.7509e-03],\n",
      "        [ 6.8948e-04,  6.4713e-03, -5.1688e-03,  ...,  6.4584e-03,\n",
      "          1.5311e-02,  1.4805e-02],\n",
      "        [ 1.8005e-03, -3.7220e-03,  7.6778e-04,  ..., -8.7741e-03,\n",
      "         -4.3265e-03,  7.0238e-04],\n",
      "        ...,\n",
      "        [ 7.4178e-02,  4.4542e-03, -1.0555e-03,  ..., -6.6513e-03,\n",
      "         -9.9981e-04, -3.8989e-03],\n",
      "        [ 1.3582e-02, -7.6435e-03, -8.0960e-03,  ..., -2.8574e-03,\n",
      "         -5.5617e-03,  5.0270e-04],\n",
      "        [ 1.5900e-05,  8.3449e-02,  6.6146e-03,  ..., -2.8491e-03,\n",
      "         -3.3395e-03,  2.7161e-02]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.4007, 0.0493, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0000, 0.0070,  ..., 0.0000, 0.0342, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1236]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[84]-[1] lr=[0.4987444935634912] loss=[0.003]\n",
      "[all_10]-[84]-[2] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[3] lr=[0.4987444935634912] loss=[0.003]\n",
      "[all_10]-[84]-[4] lr=[0.4987444935634912] loss=[0.003]\n",
      "[all_10]-[84]-[5] lr=[0.4987444935634912] loss=[0.003]\n",
      "[all_10]-[84]-[6] lr=[0.4987444935634912] loss=[0.004]\n",
      "[all_10]-[84]-[7] lr=[0.4987444935634912] loss=[0.004]\n",
      "[all_10]-[84]-[8] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[9] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[10] lr=[0.4987444935634912] loss=[0.003]\n",
      "[all_10]-[84]-[11] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[12] lr=[0.4987444935634912] loss=[0.004]\n",
      "[all_10]-[84]-[13] lr=[0.4987444935634912] loss=[0.003]\n",
      "[all_10]-[84]-[14] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[15] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[16] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[17] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[18] lr=[0.4987444935634912] loss=[0.003]\n",
      "[all_10]-[84]-[19] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[20] lr=[0.4987444935634912] loss=[0.003]\n",
      "[all_10]-[84]-[21] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[22] lr=[0.4987444935634912] loss=[0.003]\n",
      "[all_10]-[84]-[23] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[24] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[25] lr=[0.4987444935634912] loss=[0.003]\n",
      "[all_10]-[84]-[26] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[27] lr=[0.4987444935634912] loss=[0.003]\n",
      "[all_10]-[84]-[28] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[29] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[30] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[31] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[32] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[33] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[34] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[35] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[36] lr=[0.4987444935634912] loss=[0.003]\n",
      "[all_10]-[84]-[37] lr=[0.4987444935634912] loss=[0.003]\n",
      "[all_10]-[84]-[38] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[39] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[40] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[41] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[42] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[43] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[44] lr=[0.4987444935634912] loss=[0.002]\n",
      "[all_10]-[84]-[45] lr=[0.4987444935634912] loss=[0.003]\n",
      "[all_10]-[84]-[46] lr=[0.4987444935634912] loss=[0.003]\n",
      "[all_10]-[84]-[47] lr=[0.4987444935634912] loss=[0.003]\n",
      "[all_10]-[84]-[48] lr=[0.4987444935634912] loss=[0.002]\n",
      "tensor([[ 6.7250e-03, -7.0499e-03,  3.5725e-02,  ...,  7.3430e-03,\n",
      "          2.7680e-02,  8.9657e-03],\n",
      "        [ 1.9080e-02,  1.6113e-02,  1.5785e-02,  ...,  2.7877e-03,\n",
      "          2.7925e-02,  4.2253e-03],\n",
      "        [-2.6312e-03,  3.9041e-03,  3.2853e-03,  ...,  1.5460e-02,\n",
      "          1.6322e-03,  8.1767e-03],\n",
      "        ...,\n",
      "        [ 2.4344e-03,  7.0253e-03,  2.7921e-03,  ..., -2.9314e-03,\n",
      "          2.6535e-03,  2.6315e-03],\n",
      "        [ 5.2735e-04,  8.1508e-03,  1.5876e-02,  ...,  9.1211e-04,\n",
      "          2.0194e-03,  8.2062e-03],\n",
      "        [ 3.6369e-03,  6.8889e-03,  1.0757e-01,  ...,  8.3124e-04,\n",
      "         -1.2845e-04, -5.6535e-05]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.3713,  ..., 0.3893, 0.2866, 0.0000],\n",
      "        [0.0000, 0.1568, 0.0000,  ..., 0.0000, 0.0590, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0568, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0050, 0.1342, 0.0000,  ..., 0.0000, 0.0000, 0.0110],\n",
      "        [0.0000, 0.0000, 0.0111,  ..., 0.0000, 0.0229, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[85]-[1] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[2] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[3] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[4] lr=[0.4972482600828007] loss=[0.003]\n",
      "[all_10]-[85]-[5] lr=[0.4972482600828007] loss=[0.001]\n",
      "[all_10]-[85]-[6] lr=[0.4972482600828007] loss=[0.003]\n",
      "[all_10]-[85]-[7] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[8] lr=[0.4972482600828007] loss=[0.003]\n",
      "[all_10]-[85]-[9] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[10] lr=[0.4972482600828007] loss=[0.003]\n",
      "[all_10]-[85]-[11] lr=[0.4972482600828007] loss=[0.003]\n",
      "[all_10]-[85]-[12] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[13] lr=[0.4972482600828007] loss=[0.003]\n",
      "[all_10]-[85]-[14] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[15] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[16] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[17] lr=[0.4972482600828007] loss=[0.003]\n",
      "[all_10]-[85]-[18] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[19] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[20] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[21] lr=[0.4972482600828007] loss=[0.003]\n",
      "[all_10]-[85]-[22] lr=[0.4972482600828007] loss=[0.003]\n",
      "[all_10]-[85]-[23] lr=[0.4972482600828007] loss=[0.001]\n",
      "[all_10]-[85]-[24] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[25] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[26] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[27] lr=[0.4972482600828007] loss=[0.003]\n",
      "[all_10]-[85]-[28] lr=[0.4972482600828007] loss=[0.003]\n",
      "[all_10]-[85]-[29] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[30] lr=[0.4972482600828007] loss=[0.003]\n",
      "[all_10]-[85]-[31] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[32] lr=[0.4972482600828007] loss=[0.003]\n",
      "[all_10]-[85]-[33] lr=[0.4972482600828007] loss=[0.003]\n",
      "[all_10]-[85]-[34] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[35] lr=[0.4972482600828007] loss=[0.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[85]-[36] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[37] lr=[0.4972482600828007] loss=[0.003]\n",
      "[all_10]-[85]-[38] lr=[0.4972482600828007] loss=[0.003]\n",
      "[all_10]-[85]-[39] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[40] lr=[0.4972482600828007] loss=[0.003]\n",
      "[all_10]-[85]-[41] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[42] lr=[0.4972482600828007] loss=[0.003]\n",
      "[all_10]-[85]-[43] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[44] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[45] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[46] lr=[0.4972482600828007] loss=[0.002]\n",
      "[all_10]-[85]-[47] lr=[0.4972482600828007] loss=[0.003]\n",
      "[all_10]-[85]-[48] lr=[0.4972482600828007] loss=[0.002]\n",
      "tensor([[ 0.0398, -0.0181, -0.0019,  ..., -0.0021, -0.0089, -0.0106],\n",
      "        [-0.0096, -0.0053, -0.0110,  ..., -0.0151, -0.0037, -0.0090],\n",
      "        [-0.0053, -0.0087, -0.0033,  ..., -0.0052, -0.0169, -0.0166],\n",
      "        ...,\n",
      "        [-0.0084, -0.0073,  0.0793,  ..., -0.0157, -0.0138, -0.0151],\n",
      "        [-0.0138, -0.0185, -0.0194,  ..., -0.0089, -0.0113, -0.0087],\n",
      "        [-0.0062, -0.0063,  0.0217,  ..., -0.0189, -0.0019, -0.0045]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0050,  ..., 0.0224, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0156,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0373, 0.0000,  ..., 0.0000, 0.0323, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.4443,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[86]-[1] lr=[0.4957565153025523] loss=[0.002]\n",
      "[all_10]-[86]-[2] lr=[0.4957565153025523] loss=[0.002]\n",
      "[all_10]-[86]-[3] lr=[0.4957565153025523] loss=[0.002]\n",
      "[all_10]-[86]-[4] lr=[0.4957565153025523] loss=[0.002]\n",
      "[all_10]-[86]-[5] lr=[0.4957565153025523] loss=[0.002]\n",
      "[all_10]-[86]-[6] lr=[0.4957565153025523] loss=[0.002]\n",
      "[all_10]-[86]-[7] lr=[0.4957565153025523] loss=[0.002]\n",
      "[all_10]-[86]-[8] lr=[0.4957565153025523] loss=[0.002]\n",
      "[all_10]-[86]-[9] lr=[0.4957565153025523] loss=[0.002]\n",
      "[all_10]-[86]-[10] lr=[0.4957565153025523] loss=[0.002]\n",
      "[all_10]-[86]-[11] lr=[0.4957565153025523] loss=[0.004]\n",
      "[all_10]-[86]-[12] lr=[0.4957565153025523] loss=[0.002]\n",
      "[all_10]-[86]-[13] lr=[0.4957565153025523] loss=[0.002]\n",
      "[all_10]-[86]-[14] lr=[0.4957565153025523] loss=[0.003]\n",
      "[all_10]-[86]-[15] lr=[0.4957565153025523] loss=[0.002]\n",
      "[all_10]-[86]-[16] lr=[0.4957565153025523] loss=[0.001]\n",
      "[all_10]-[86]-[17] lr=[0.4957565153025523] loss=[0.001]\n",
      "lr adapted to 0.8*0.4957565153025523=0.39660521224204187\n",
      "new inspect loss cutoff: 0.0007883916259743273\n",
      "[all_10]-[86]-[18] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[19] lr=[0.39660521224204187] loss=[0.001]\n",
      "[all_10]-[86]-[20] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[21] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[22] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[23] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[24] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[25] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[26] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[27] lr=[0.39660521224204187] loss=[0.003]\n",
      "[all_10]-[86]-[28] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[29] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[30] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[31] lr=[0.39660521224204187] loss=[0.003]\n",
      "[all_10]-[86]-[32] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[33] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[34] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[35] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[36] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[37] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[38] lr=[0.39660521224204187] loss=[0.003]\n",
      "[all_10]-[86]-[39] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[40] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[41] lr=[0.39660521224204187] loss=[0.001]\n",
      "[all_10]-[86]-[42] lr=[0.39660521224204187] loss=[0.001]\n",
      "[all_10]-[86]-[43] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[44] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[45] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[46] lr=[0.39660521224204187] loss=[0.002]\n",
      "[all_10]-[86]-[47] lr=[0.39660521224204187] loss=[0.004]\n",
      "[all_10]-[86]-[48] lr=[0.39660521224204187] loss=[0.002]\n",
      "tensor([[ 0.0007, -0.0064, -0.0184,  ..., -0.0167, -0.0240, -0.0238],\n",
      "        [-0.0127, -0.0121, -0.0052,  ..., -0.0187, -0.0216, -0.0189],\n",
      "        [-0.0119, -0.0263, -0.0018,  ..., -0.0211, -0.0199, -0.0181],\n",
      "        ...,\n",
      "        [ 0.0013, -0.0154, -0.0006,  ..., -0.0197, -0.0197, -0.0158],\n",
      "        [-0.0003, -0.0134,  0.0004,  ..., -0.0230, -0.0206, -0.0067],\n",
      "        [-0.0133, -0.0257, -0.0195,  ..., -0.0106, -0.0132, -0.0233]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0811, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3710, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1021],\n",
      "        [0.0000, 0.0000, 0.1098,  ..., 0.0000, 0.0965, 0.0000],\n",
      "        ...,\n",
      "        [0.3288, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0962, 0.0000, 0.0612,  ..., 0.0000, 0.0000, 0.1372],\n",
      "        [0.0060, 0.0000, 0.0067,  ..., 0.0000, 0.0470, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[87]-[1] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[2] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[3] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[4] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[5] lr=[0.39541539660531577] loss=[0.001]\n",
      "[all_10]-[87]-[6] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[7] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[8] lr=[0.39541539660531577] loss=[0.003]\n",
      "[all_10]-[87]-[9] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[10] lr=[0.39541539660531577] loss=[0.001]\n",
      "[all_10]-[87]-[11] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[12] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[13] lr=[0.39541539660531577] loss=[0.003]\n",
      "[all_10]-[87]-[14] lr=[0.39541539660531577] loss=[0.003]\n",
      "[all_10]-[87]-[15] lr=[0.39541539660531577] loss=[0.003]\n",
      "[all_10]-[87]-[16] lr=[0.39541539660531577] loss=[0.003]\n",
      "[all_10]-[87]-[17] lr=[0.39541539660531577] loss=[0.003]\n",
      "[all_10]-[87]-[18] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[19] lr=[0.39541539660531577] loss=[0.003]\n",
      "[all_10]-[87]-[20] lr=[0.39541539660531577] loss=[0.003]\n",
      "[all_10]-[87]-[21] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[22] lr=[0.39541539660531577] loss=[0.003]\n",
      "[all_10]-[87]-[23] lr=[0.39541539660531577] loss=[0.003]\n",
      "[all_10]-[87]-[24] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[25] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[26] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[27] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[28] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[29] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[30] lr=[0.39541539660531577] loss=[0.003]\n",
      "[all_10]-[87]-[31] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[32] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[33] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[34] lr=[0.39541539660531577] loss=[0.003]\n",
      "[all_10]-[87]-[35] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[36] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[37] lr=[0.39541539660531577] loss=[0.003]\n",
      "[all_10]-[87]-[38] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[39] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[40] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[41] lr=[0.39541539660531577] loss=[0.003]\n",
      "[all_10]-[87]-[42] lr=[0.39541539660531577] loss=[0.001]\n",
      "[all_10]-[87]-[43] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[44] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[45] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[46] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[47] lr=[0.39541539660531577] loss=[0.002]\n",
      "[all_10]-[87]-[48] lr=[0.39541539660531577] loss=[0.002]\n",
      "tensor([[ 3.0134e-02,  8.2714e-03,  5.9319e-03,  ...,  4.4864e-03,\n",
      "          3.8124e-02,  2.9845e-02],\n",
      "        [ 3.3799e-04, -4.3237e-03,  5.3650e-03,  ...,  3.4402e-03,\n",
      "          5.0703e-02,  7.2109e-03],\n",
      "        [ 1.0537e-03,  6.4784e-01,  2.6229e-03,  ...,  1.1262e-03,\n",
      "          5.3966e-04, -5.7351e-04],\n",
      "        ...,\n",
      "        [ 9.0235e-03,  4.5446e-03,  6.3372e-04,  ...,  1.9580e-02,\n",
      "          6.5921e-03,  9.6525e-04],\n",
      "        [ 8.4489e-03,  6.2333e-03,  9.0130e-03,  ...,  8.1705e-03,\n",
      "         -1.6779e-03,  2.3921e-03],\n",
      "        [ 1.1487e-02,  1.2985e-02,  3.1262e-02,  ...,  1.0608e-02,\n",
      "          2.7581e-02, -7.6565e-04]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0473, 0.0226],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.6917, 0.0386,  ..., 0.0000, 0.0948, 0.0386],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3055, 0.0000, 0.4329,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2346, 0.1751,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[88]-[1] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[2] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[3] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[4] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[5] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[6] lr=[0.39422915041549983] loss=[0.003]\n",
      "[all_10]-[88]-[7] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[8] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[9] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[10] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[11] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[12] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[13] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[14] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[15] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[16] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[17] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[18] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[19] lr=[0.39422915041549983] loss=[0.003]\n",
      "[all_10]-[88]-[20] lr=[0.39422915041549983] loss=[0.003]\n",
      "[all_10]-[88]-[21] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[22] lr=[0.39422915041549983] loss=[0.001]\n",
      "[all_10]-[88]-[23] lr=[0.39422915041549983] loss=[0.003]\n",
      "[all_10]-[88]-[24] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[25] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[26] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[27] lr=[0.39422915041549983] loss=[0.001]\n",
      "[all_10]-[88]-[28] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[29] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[30] lr=[0.39422915041549983] loss=[0.003]\n",
      "[all_10]-[88]-[31] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[32] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[33] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[34] lr=[0.39422915041549983] loss=[0.003]\n",
      "[all_10]-[88]-[35] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[36] lr=[0.39422915041549983] loss=[0.001]\n",
      "[all_10]-[88]-[37] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[38] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[39] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[40] lr=[0.39422915041549983] loss=[0.001]\n",
      "[all_10]-[88]-[41] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[42] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[43] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[44] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[45] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[46] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[47] lr=[0.39422915041549983] loss=[0.002]\n",
      "[all_10]-[88]-[48] lr=[0.39422915041549983] loss=[0.002]\n",
      "tensor([[-9.3727e-04,  1.5270e-03,  2.4947e-02,  ..., -5.8441e-03,\n",
      "          2.3975e-03, -5.6652e-03],\n",
      "        [ 2.6549e-03,  4.3502e-03, -3.1294e-03,  ...,  8.8595e-03,\n",
      "         -2.6301e-05, -7.4560e-03],\n",
      "        [ 7.7628e-03, -1.6771e-03, -3.6306e-03,  ...,  1.8388e-03,\n",
      "          3.6462e-03, -4.7371e-03],\n",
      "        ...,\n",
      "        [ 5.3405e-03, -9.8717e-04, -1.2020e-02,  ..., -3.6114e-03,\n",
      "         -2.3263e-03,  1.7856e-03],\n",
      "        [ 7.8961e-03, -7.0736e-04,  1.2118e-02,  ..., -5.6106e-03,\n",
      "          5.4735e-03, -2.7768e-03],\n",
      "        [ 1.9410e-01,  2.6702e-04,  8.4969e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0622, 0.0000],\n",
      "        [0.0045, 0.0238, 0.0175,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1610, 0.0805, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0138,  ..., 0.0000, 0.0000, 0.0748],\n",
      "        [0.0000, 0.0078, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1954, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[89]-[1] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[2] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[3] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[4] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[5] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[6] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[7] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[8] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[9] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[10] lr=[0.39304646296425333] loss=[0.001]\n",
      "[all_10]-[89]-[11] lr=[0.39304646296425333] loss=[0.001]\n",
      "[all_10]-[89]-[12] lr=[0.39304646296425333] loss=[0.003]\n",
      "[all_10]-[89]-[13] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[14] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[15] lr=[0.39304646296425333] loss=[0.003]\n",
      "[all_10]-[89]-[16] lr=[0.39304646296425333] loss=[0.003]\n",
      "[all_10]-[89]-[17] lr=[0.39304646296425333] loss=[0.001]\n",
      "[all_10]-[89]-[18] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[19] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[20] lr=[0.39304646296425333] loss=[0.003]\n",
      "[all_10]-[89]-[21] lr=[0.39304646296425333] loss=[0.001]\n",
      "[all_10]-[89]-[22] lr=[0.39304646296425333] loss=[0.004]\n",
      "[all_10]-[89]-[23] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[24] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[25] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[26] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[27] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[28] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[29] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[30] lr=[0.39304646296425333] loss=[0.001]\n",
      "[all_10]-[89]-[31] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[32] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[33] lr=[0.39304646296425333] loss=[0.003]\n",
      "[all_10]-[89]-[34] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[35] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[36] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[37] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[38] lr=[0.39304646296425333] loss=[0.003]\n",
      "[all_10]-[89]-[39] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[40] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[41] lr=[0.39304646296425333] loss=[0.003]\n",
      "[all_10]-[89]-[42] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[43] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[44] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[45] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[46] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[47] lr=[0.39304646296425333] loss=[0.002]\n",
      "[all_10]-[89]-[48] lr=[0.39304646296425333] loss=[0.002]\n",
      "tensor([[ 8.6887e-03,  1.0715e-01,  7.3484e-02,  ...,  3.5270e-03,\n",
      "          6.4351e-03,  8.0534e-03],\n",
      "        [ 1.2719e-02, -5.1991e-04,  3.6155e-02,  ...,  7.5250e-03,\n",
      "          6.3597e-03,  1.6634e-02],\n",
      "        [ 1.8000e-02,  1.0634e-01,  8.0605e-01,  ...,  4.3388e-03,\n",
      "          3.5849e-03,  4.7448e-03],\n",
      "        ...,\n",
      "        [ 3.6563e-03, -1.1481e-04,  1.9305e-02,  ...,  1.1248e-02,\n",
      "          1.0578e-02,  9.4506e-03],\n",
      "        [ 2.0994e-02,  2.9757e-02,  4.0427e-02,  ...,  2.3612e-02,\n",
      "          6.2743e-03,  2.6217e-03],\n",
      "        [ 2.2700e-01,  9.1193e-03,  1.6983e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0841, 0.0364,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.5893,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1027, 0.0000,  ..., 0.0000, 0.0128, 0.0000],\n",
      "        [0.1954, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "[all_10]-[90]-[1] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[2] lr=[0.3918673235753606] loss=[0.001]\n",
      "[all_10]-[90]-[3] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[4] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[5] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[6] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[7] lr=[0.3918673235753606] loss=[0.001]\n",
      "[all_10]-[90]-[8] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[9] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[10] lr=[0.3918673235753606] loss=[0.001]\n",
      "[all_10]-[90]-[11] lr=[0.3918673235753606] loss=[0.002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all_10]-[90]-[12] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[13] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[14] lr=[0.3918673235753606] loss=[0.003]\n",
      "[all_10]-[90]-[15] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[16] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[17] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[18] lr=[0.3918673235753606] loss=[0.001]\n",
      "[all_10]-[90]-[19] lr=[0.3918673235753606] loss=[0.003]\n",
      "[all_10]-[90]-[20] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[21] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[22] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[23] lr=[0.3918673235753606] loss=[0.003]\n",
      "[all_10]-[90]-[24] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[25] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[26] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[27] lr=[0.3918673235753606] loss=[0.003]\n",
      "[all_10]-[90]-[28] lr=[0.3918673235753606] loss=[0.003]\n",
      "[all_10]-[90]-[29] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[30] lr=[0.3918673235753606] loss=[0.003]\n",
      "[all_10]-[90]-[31] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[32] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[33] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[34] lr=[0.3918673235753606] loss=[0.003]\n",
      "[all_10]-[90]-[35] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[36] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[37] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[38] lr=[0.3918673235753606] loss=[0.003]\n",
      "[all_10]-[90]-[39] lr=[0.3918673235753606] loss=[0.003]\n",
      "[all_10]-[90]-[40] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[41] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[42] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[43] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[44] lr=[0.3918673235753606] loss=[0.003]\n",
      "[all_10]-[90]-[45] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[46] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[47] lr=[0.3918673235753606] loss=[0.002]\n",
      "[all_10]-[90]-[48] lr=[0.3918673235753606] loss=[0.002]\n",
      "tensor([[-5.4344e-03, -1.0899e-02, -8.6142e-03,  ...,  1.6494e-02,\n",
      "         -1.1411e-02, -1.6796e-02],\n",
      "        [ 1.7880e-01,  4.1440e-01, -1.7616e-02,  ..., -1.9471e-02,\n",
      "         -1.3817e-02, -1.9789e-02],\n",
      "        [-4.6286e-03,  8.3909e-01, -1.4266e-02,  ..., -1.6069e-02,\n",
      "         -1.7429e-02, -1.3210e-02],\n",
      "        ...,\n",
      "        [ 1.0954e-01,  6.2750e-02,  2.3551e-01,  ..., -1.7604e-02,\n",
      "         -1.7029e-02, -1.8461e-02],\n",
      "        [ 4.2703e-04, -1.2938e-02, -1.5924e-02,  ..., -8.7296e-03,\n",
      "         -1.6012e-02, -1.5661e-02],\n",
      "        [-7.5461e-03, -1.0169e-02, -6.6105e-03,  ..., -1.3233e-02,\n",
      "         -1.0996e-02, -1.5955e-02]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.1144,  ..., 0.0517, 0.0321, 0.0000],\n",
      "        [0.0000, 6.0452, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5973, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.3231,  ..., 0.0000, 0.0000, 0.0262],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0451, 0.0451, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 人控训练：每执行一次为一个epoch，觉得训练完成后再继续后面的步骤\n",
    "for ss in range(90):\n",
    "    Mymodel.train()\n",
    "    for ii, batch in enumerate(Myloader, 0):\n",
    "        inputs, sizes, labels, weights, diss, _ = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = Mymodel(x=inputs, sizes=sizes, diss=diss)\n",
    "        loss = criterion(outputs, labels, weights, torch.sum(sizes), loss_ratio)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss.append(loss.item())\n",
    "\n",
    "        if initialize and epoch == 0 and ii == 3 * inspect_num + 20:\n",
    "            inspect_loss = sum(running_loss[-inspect_num:]) / inspect_num\n",
    "            inspect = True\n",
    "            initialize = False\n",
    "            print(\"inspect loss cutoff initialized as: \" + str(inspect_loss))\n",
    "            print(\"first inspect loss cutoff: \" + str(inspect_loss_decay * inspect_loss))\n",
    "\n",
    "        if jj % write_every == write_every - 1:\n",
    "            writer.add_scalars(writer_title, {'loss': sum(running_loss[-write_every:]) / write_every,\n",
    "                                               'lr': 0.01*optimizer.param_groups[0]['lr'],\n",
    "                                               'sigma': 0.01*loss_ratio}, jj)\n",
    "#            writer.add_scalar(writer_title + \"_lr\", optimizer.param_groups[0]['lr'], jj)\n",
    "            print(\"[%s]-[%d]-[%d] lr=[%r] loss=[%.3f]\" % (\n",
    "            j, epoch + 1, ii + 1, optimizer.param_groups[0]['lr'], sum(running_loss[-write_every:]) / write_every))\n",
    "        jj += 1\n",
    "        \n",
    "        #if sum(running_loss[-1:]) > 1e+5:\n",
    "        #    with torch.no_grad():\n",
    "        #        print(outputs[0:500])\n",
    "        #        print(labels[0:500])\n",
    "        # loss每降低一半，相应lr也调整为原来的一半\n",
    "        if inspect:\n",
    "            if sum(running_loss[-inspect_num:]) / inspect_num < inspect_loss_decay * inspect_loss:\n",
    "                lr_0 = lr\n",
    "                lr *= lr_adapt_decay\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group[\"lr\"] = lr\n",
    "                inspect_loss *= inspect_loss_decay\n",
    "                converge_level += 1\n",
    "                print(\"lr adapted to \" + str(lr_adapt_decay) + \"*\" + str(lr_0) + \"=\" + str(lr))\n",
    "                print(\"new inspect loss cutoff: \" + str(inspect_loss_decay * inspect_loss))\n",
    "                if loss_ratio<0.95 and sigma_index<2:\n",
    "                    loss_ratio = loss_ratio+(1-loss_ratio)*0.7\n",
    "                    sigma_index += 1\n",
    "#             if sum(running_loss[-2:])/2 > 2 * inspect_loss / inspect_loss_decay:\n",
    "#                 lr *= 0.1\n",
    "#                 for param_group in optimizer.param_groups:\n",
    "#                     param_group[\"lr\"] = lr\n",
    "#                 break\n",
    "    # 查看output和label：\n",
    "    with torch.no_grad():\n",
    "        print(outputs[0:500])\n",
    "        print(labels[0:500])\n",
    "    # 每个epoch的lr下降：\n",
    "    lr *= lr_epoch_decay\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "    epoch += 1\n",
    "    #每个epoch计算一次验证集loss，并记录：\n",
    "    Mymodel.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = Mymodel(x=val_inputs, sizes=val_sizes, diss=val_diss)\n",
    "#         loss = criterion(val_outputs, val_labels, val_weights, torch.sum(val_sizes), loss_ratio)\n",
    "#         val_loss.append(loss.item())\n",
    "        mTIS_accuracy=sum(val_label_mTIS_indices==torch.argmax(val_outputs,dim=1))/len(val_label_mTIS_indices)\n",
    "    writer.add_scalars(writer_title,{'mTIS_accuracy': 0.01*mTIS_accuracy,'high_confidence_mTIS_accuracy': 0.01*high_mTIS_prediction()},jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d47bccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_mymodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17a83e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(converge_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c953a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "4800/49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ada92",
   "metadata": {},
   "outputs": [],
   "source": [
    "##陷入局部最优，更新极慢，重新设置lr：\n",
    "# lr = 0.7\n",
    "# for param_group in optimizer.param_groups:\n",
    "#         param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c455156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_printoptions(threshold=6000)\n",
    "# with torch.no_grad():\n",
    "#     print(labels[0:5000])\n",
    "# torch.set_printoptions(threshold=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e57376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #after\n",
    "# torch.set_printoptions(precision=10)\n",
    "# with torch.no_grad():\n",
    "#     print(Mymodel.fc0.weight)\n",
    "#     print(Mymodel.fc0.weight.grad)\n",
    "#     print(Mymodel.fc0.bias)\n",
    "#     print(Mymodel.fc0.bias.grad)\n",
    "#     print(Mymodel.fc00.weight)\n",
    "#     print(Mymodel.fc00.weight.grad)\n",
    "#     print(Mymodel.fc00.bias)\n",
    "#     print(Mymodel.fc00.bias.grad)\n",
    "#     print(Mymodel.fc1.weight)\n",
    "#     print(Mymodel.fc1.weight.grad)\n",
    "#     print(Mymodel.fc1.bias)\n",
    "#     print(Mymodel.fc1.bias.grad)\n",
    "#     print(Mymodel.fc2.weight)\n",
    "#     print(Mymodel.fc2.weight.grad)\n",
    "#     print(Mymodel.fc2.bias)\n",
    "#     print(Mymodel.fc2.bias.grad)\n",
    "# torch.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e3f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_theme(style=\"whitegrid\")\n",
    "# print(data)\n",
    "# # Draw a nested violinplot and split the violins for easier comparison\n",
    "# sns.violinplot(data=df,linewidth=1)\n",
    "# sns.stripplot(data=df,color=\".3\",size=5,linewidth=0)\n",
    "# sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2854e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_theme(style=\"ticks\")\n",
    "# data = {\n",
    "# 'xx': [1,2,3,4,1,2,3,4],\n",
    "# 'yy': [12, 13, 14, 15, 17, 15.5, 11, 19],\n",
    "# 'class': [1, 1, 1, 1, 2, 2, 2, 2]\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "# sns.lmplot(x=\"xx\", y=\"yy\", hue=\"class\", data=df,\n",
    "#            palette=\"muted\", height=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fdacc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#预测一条：\n",
    "class testoneMyDataset(Dataset):\n",
    "    def __init__(self, inputset, targetset, weightset, disset, transcriptset):\n",
    "        self.inputset=inputset\n",
    "        self.targetset=targetset\n",
    "        self.weightset=weightset\n",
    "        self.disset=disset\n",
    "        self.transcriptset=transcriptset\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        input = self.inputset[idx]\n",
    "        label = self.targetset[idx]\n",
    "        weights = self.weightset[idx]\n",
    "        diss = self.disset[idx]\n",
    "        transcriptt = self.transcriptset[idx]\n",
    "        return input, label, weights, diss, transcriptt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targetset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40e243da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(val_transcripts)\n",
    "# print(val_weights[:,0])\n",
    "# val_label_mTIS_indices=torch.argmax(val_labels,dim=1)\n",
    "# print(val_label_mTIS_indices)\n",
    "# val_output_mTIS_indices=torch.argmax(val_outputs,dim=1)\n",
    "# print(val_output_mTIS_indices)\n",
    "# val_label_mTIS_codons=[find_TIS(val_transcripts[i])[val_label_mTIS_indices[i]][0] for i in range(len(val_transcripts))]\n",
    "# print(val_label_mTIS_codons)\n",
    "# val_output_mTIS_codons=[find_TIS(val_transcripts[i])[val_output_mTIS_indices[i]][0] for i in range(len(val_transcripts))]\n",
    "# print(val_output_mTIS_codons)\n",
    "# val_label_mTIS_positions=[find_TIS(val_transcripts[i])[val_label_mTIS_indices[i]][1] for i in range(len(val_transcripts))]\n",
    "# print(val_label_mTIS_positions)\n",
    "# val_output_mTIS_positions=[find_TIS(val_transcripts[i])[val_output_mTIS_indices[i]][1] for i in range(len(val_transcripts))]\n",
    "# print(val_output_mTIS_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4afa14dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #统计mTIS预测准确度\n",
    "# print(val_weights[:,0])\n",
    "# weights_cutoff=0.8\n",
    "# print(sum(val_weights[:,0]>weights_cutoff))\n",
    "\n",
    "# mindex=[i for i in range(len(val_transcripts)) if val_weights[i,0]>weights_cutoff]\n",
    "# val_high_transcripts=[val_transcripts[i] for i in mindex]\n",
    "# print(len(val_high_transcripts))\n",
    "# print(val_high_transcripts)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     val_high_outputs=val_outputs[mindex]\n",
    "#     val_high_labels=val_labels[mindex]\n",
    "#     val_high_label_argmax=torch.argmax(val_high_labels,dim=1)\n",
    "#     val_high_output_argmax=torch.argmax(val_high_outputs,dim=1)\n",
    "#     print(val_high_label_argmax)\n",
    "#     print(val_high_output_argmax)\n",
    "#     print(sum(val_high_label_argmax==val_high_output_argmax))\n",
    "#     print(len(val_high_label_argmax))\n",
    "#     print(sum(val_high_label_argmax==val_high_output_argmax)/len(val_high_label_argmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a19e8f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('ENST00000304191.4' in val_transcripts)\n",
    "# print('ENST00000374561.6' in val_transcripts)\n",
    "# print('ENST00000315869.8' in val_transcripts)\n",
    "# print('ENST00000377351.8' in val_transcripts)\n",
    "# print('ENST00000355693.5' in val_transcripts)\n",
    "# print('ENST00000369541.4' in val_transcripts)\n",
    "# print('ENST00000375499.8' in val_transcripts)\n",
    "# print('ENST00000376327.6' in val_transcripts)\n",
    "# print('ENST00000604458.1' in val_transcripts)\n",
    "# print('ENST00000396062.4' in val_transcripts)\n",
    "# print('ENST00000456936.4' in val_transcripts)\n",
    "# print('ENST00000239938.5' in val_transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2471ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 加载状态\n",
    "# def load_Mymodel(writer_title):\n",
    "#     state = torch.load(save_path + \"\\\\\"+run_header+\"\\\\\"+writer_title+\".pkl\")\n",
    "#     Mymodel = MyLSTM(dropout=dropout, hidden_dim=hidden_dim, num_layers=num_layers, proj_size=proj_size)\n",
    "#     Mymodel.to(device)\n",
    "#     optimizer = optim.SGD(Mymodel.parameters(), lr=lr, momentum=momentum)\n",
    "#     Mymodel.load_state_dict(state['state_dict'])\n",
    "#     optimizer.load_state_dict(state['optimizer'])\n",
    "#     epoch = state['epoch']\n",
    "#     jj = state['jj']\n",
    "#     converge_level = state['converge_level']\n",
    "#     running_loss = state['running_loss']\n",
    "#     inspect_loss = state['inspect_loss']\n",
    "#     loss_ratio = state['loss_ratio']\n",
    "#     sigma_index = state['sigma_index']\n",
    "#     val_min_loss = state['val_min_loss']\n",
    "#     print(save_path + \"\\\\\"+run_header+\"\\\\\"+writer_title+\".pkl loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "421af7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ENST00000506618.5' in transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72701abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gao=np.load('D:/sorf_models/model/titer/titer-master/data/pos_seq_test.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b35acc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCCAATAGGAGCCGCGCTGGCTGGAGAGTAATGTTACAGAGCGGAGAGAGTGAGGAGGCTGCGTCTGGCTCCCGCTCTCACAGCCATTGCAGTACATTGAGCTCCATAGAGACAGCACCGGGGCAAGTGAGAGCCGGACGGGCACTGGGCGACTCTGTGCCTCGCTG',\n",
       "       b'$$$$GCCAATAGGAGCCGCGCTGGCTGGAGAGTAATGTTACAGAGCGGAGAGAGTGAGGAGGCTGCGTCTGGCTCCCGCTCTCACAGCCATTGCAGTACATTGAGCTCCATAGAGACAGCACCGGGGCAAGTGAGAGCCGGACGGGCACTGGGCGACTCTGTGCCTCGCTGAGGAAAAATAACTAAACATGGGCAAAGGAGAT',\n",
       "       b'GAGGCTGCGTCTGGCTCCCGCTCTCACAGCCATTGCAGTACATTGAGCTCCATAGAGACAGCACCGGGGCAAGTGAGAGCCGGACGGGCACTGGGCGACTCTGTGCCTCGCTGAGGAAAAATAACTAAACATGGGCAAAGGAGATCCTAAGAAGCCGAGAGGCAAAATGTCATCATATGCATTTTTTGTGCAAACTTGTCGGG',\n",
       "       b'CATTGCAGTACATTGAGCTCCATAGAGACAGCACCGGGGCAAGTGAGAGCCGGACGGGCACTGGGCGACTCTGTGCCTCGCTGAGGAAAAATAACTAAACATGGGCAAAGGAGATCCTAAGAAGCCGAGAGGCAAAATGTCATCATATGCATTTTTTGTGCAAACTTGTCGGGAGGAGCATAAGAAGAAGCACCCAGATGCTT',\n",
       "       b'GCCCGGACGCCAGAAAATGTTCCACGTGGGATACCCTGCGTGGGGTTCACTGTAGTAGCTGCACTAGGTGATTCTTGGAGCGGGCCTGAGAGACAAGGACATGTGGATCCCAGTGGTCGGGCTTCCTCGGCGGCTGAGGCTCTCCGCCTTGGCGGGCGCTGGTCGCTTTTGCATTTTAGGGTCTGAAGCGGCGACGCGAAAGC',\n",
       "       b'CTGGCGGCCCAAGCGGCACGTGGGCCTCGCAGATTGTGCACGCGCCGGAGCAGCGGCGCACCAGCCCCCGGCTCCGGCGCCACCATCTTCGCGCTAAGCTCTGGCCAAGGCCGCTGCGGCATCGCAGTGATCCGGACCAGCGGCCCCGCCAGCGGCCACGCCCTCCGAATTCTCACAGCACCCCGAGACCTGCCCCTTGCTCG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CGGGGCCCCCTGCCCAGACTTGAAGCCACACAGGCAGGTCGGGCAGGCGGGTCGCAGGTTGTAAATCCATGTGGCGGGGGCTTTGGACCCTGGCGGCCCAAGCGGCACGTGGGCCTCGCAGATTGTGCACGCGCCGGAGCAGCGGCGCACCAGCCCCCGGCTCCGGCGCCA',\n",
       "       b'CCCCAGTTTATCATTGGAGGAGCCACCCGCACAGACATCTGCCAAGGAGCCCTGGGTGACTGCTGGCTGCTGGCAGCCATTGCCTCCCTCACCTTGAATGAAGAAATCCTGGCTCGAGTCGTCCCCCTAAACCAGAGCTTCCAGGAAAACTATGCAGGGATCTTTCACTTCCAGTTCTGGCAATACGGCGAGTGGGTGGAGGT',\n",
       "       b'TGGCCGCAGCAGCGCGCCGGGCCCTGGCCGCGCCCCAGCCGAGCGCAGCGCGGAGTCGCCCCGACCTTTCTCTGCGCAGTACGGCCGCCGGGACCGCAGCATGGCGGGCATCGCGGCCAAGCTGGCGAAGGACCGGGAGGCGGCCGAGGGGCTGGGCTCCCACGACAGGGCCATCAAGTACCTCAACCAGGACTACGAGGCGC',\n",
       "       b'TCAGCCTTCAGCACAGAAATCTCCAACATCTCCACTGAACATGAAATTGGGACGTCCCCGAATAAAGAAAGATGAAAAGCAGAGCTTAATTTCTGCTGGAGACTACCGCCATAGGCGCACAGAGCAAGAAGAAGATGAAGAGCTACTGTCTGAGAGTCGGAAAACATCTAATGTGTGTATTAGATTTGAGGTGTCACCTTCAT',\n",
       "       b'CCACCCCTGCTCCATCTAGCTCTTTCCAGTGCAGCCACTGCCGCCGCCCAGGAGCCCTCGTCCCCTGCCTTGTCCCCCTACTCGTTCCCGCTCCCACGGCATGGAGCAGGACACTGCCGCAGTGGCAGCCACCGTGGCAGCCGCGGATGCGACCGCCACTATCGTGGTCATAGAGGACGAGCAGCCCGGGCCGTCCACCTCTC',\n",
       "       b'TATATGACCTGGTTATGACCCATGCTCTTCAGTGGCCCAGTCTTACCGTTCAGTGGCTTCCTGAAGTGACTAAACCTGAAGGAAAAGATTATGCCCTTCATTGGCTAGTGCTGGGGACTCATACGTCTGATGAGCAGAATCATCTGGTGGTTGCTCGAGTACATATTCCCAATGATGATGCACAGTTTGATGCTTCCCATTGT',\n",
       "       b'GAGCAGAATCATCTGGTGGTTGCTCGAGTACATATTCCCAATGATGATGCACAGTTTGATGCTTCCCATTGTGACAGTGACAAGGGTGAATTTGGTGGCTTTGGTTCTGTAACAGGAAAAATTGAATGTGAAATTAAAATCAATCACGAAGGAGAAGTAAACCGTGCTCGTTACATGCCGCAGAATCCTCACATCATTGCTAC',\n",
       "       b'CGCTGGGAAGCGAGCGCCGCGGCTCTTTCTACGCGCGCGCGCGCGTTGACCGCCTCGGGGTCGCGGCCCTTGTCCGGGGGTTGCTGGGGTCCTCAGGCCTATGGCTGCCGAGGCGGGCGTCGTGGGAGCTGGGGCCTCCCCTGATGGGGATTGGAGAGACCAGGCCTGTGGGCTTCTGCTACACGTGCATTTGTCTTCCCGAC',\n",
       "       b'GCGGCCCTGCGAAGCAGCTCCTTCGGGCAGCCCCGGGTCGCTTAGCGGCCAAGGAGGCTTCAGTTCTTTGCCGCCTGCAAGGCGGAGACCAGAAGGCGGAATCCACAGCTGGCGACGCGGGAGCATCTGCTGTCCACCAGCGGAGCACAGGCCATCAAAGCCGCATCTGAACTTGAATTCTGTGCAGCTGATTGCAGAGCTGG',\n",
       "       b'GCGAAGCAGCTCCTTCGGGCAGCCCCGGGTCGCTTAGCGGCCAAGGAGGCTTCAGTTCTTTGCCGCCTGCAAGGCGGAGACCAGAAGGCGGAATCCACAGCTGGCGACGCGGGAGCATCTGCTGTCCACCAGCGGAGCACAGGCCATCAAAGCCGCATCTGAACTTGAATTCTGTGCAGCTGATTGCAGAGCTGGACCCGGAT',\n",
       "       b'CCGTACCCCGGAGAGGAGCTTTCTCACGGAGGGCACTGGTTGCAGAGGCTGGAAGTGAAATAAAGACGCGCTCTTGTTTCAGAGTTCGTCCCCTGCTGAGATAGGAAGGCAGAGCCACCTCCTCTCCTCTCCCACCTGCAGATTAAGCTTTTCTAAAAAGCCTAGGCATCTTCTTATATTCAGATACCCTATCGTCGTCAGTC',\n",
       "       b'GGAAGGCAGAGCCACCTCCTCTCCTCTCCCACCTGCAGATTAAGCTTTTCTAAAAAGCCTAGGCATCTTCTTATATTCAGATACCCTATCGTCGTCAGTCATGGCTAGCATCATTGCACGTGTCGGTAACAGCCGGCGGCTGAATGCACCCTTGCCGCCTTGGGCCCATTCCATGCTGAGGTCCCTGGGGAGAAGTCTCGGTC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCATGCGCGCTCCCCTCTCACGCAGCCAACATGGCTCCAGTGGAGCACGTTGTGGCGGATGCTGGGGCTTTCCTGCGGCATGCGGCTCTGCAGGACATCGGGAAGAACATTTACACCATCCGGGAGGTGGTCA',\n",
       "       b'AGTGGAGCACGTTGTGGCGGATGCTGGGGCTTTCCTGCGGCATGCGGCTCTGCAGGACATCGGGAAGAACATTTACACCATCCGGGAGGTGGTCACTGAGATTCGGGACAAGGCCACACGCAGGCGGCTCGCTGTCCTGCCCTACGAGCTGCGGTTCAAGGAGCCCTTACCGGAATACGTGCGGCTGGTGACTGAGTTTTCAA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$ATTGGGCTGTCAGTCAGAGGCGGCGTGGAGATCGCTGGGAGCGGTTGCGGCGTGCCGGGAGCTGAGTTATAGCTGTGACTTCTGCCCTGCCAGGCCGCACACAAGCTGGCTGACCCGGTTTGTAAAAATGGAATTTCAAGCAGTAGTGATGGCAGTAGGTGGAGGATCTCGGATGAC',\n",
       "       b'GCTGTCAGTCAGAGGCGGCGTGGAGATCGCTGGGAGCGGTTGCGGCGTGCCGGGAGCTGAGTTATAGCTGTGACTTCTGCCCTGCCAGGCCGCACACAAGCTGGCTGACCCGGTTTGTAAAAATGGAATTTCAAGCAGTAGTGATGGCAGTAGGTGGAGGATCTCGGATGACAGACCTAACTTCCAGCATTCCCAAACCTCTG',\n",
       "       b'GAGATCGCTGGGAGCGGTTGCGGCGTGCCGGGAGCTGAGTTATAGCTGTGACTTCTGCCCTGCCAGGCCGCACACAAGCTGGCTGACCCGGTTTGTAAAAATGGAATTTCAAGCAGTAGTGATGGCAGTAGGTGGAGGATCTCGGATGACAGACCTAACTTCCAGCATTCCCAAACCTCTGCTTCCAGTTGGGAACAAACCTT',\n",
       "       b'CTCGCCGCCACCGCCCAGGACCGCCGGCCGGGGGACGAGCTCGGAGCAGCAGCCAGAGTTTATTAACCACTTAACCTCTCAGAACTGAACAAAGACAACATTGTTCCTGGAACGCCCTCTTTTTAAAAAAGGTAGAACTTTAGACTTCATAGCACTGAATTAACCTGCACTGAAAGCTGTTTACCTGCATTTGTTCACTTTTG',\n",
       "       b'GAAAATGCAGGTAGACCCATTCAAAACTCTGCTTTACCCTCTGCATCTATTACATCCACCAGTGCAGCTGCAGAAAGCATAACCCCTACTGTAGAACTAAATGCACTGTGCATGAAACTTGGAAAAAAACCAATGTATAAGCCTGTTGACCCTTACTCTCGGATGCAGTCCACCTATAACTACAACATGAGAGGAGGTGCTTA',\n",
       "       b'CCTCTTTTTAAAAAAGGTAGAACTTTAGACTTCATAGCACTGAATTAACCTGCACTGAAAGCTGTTTACCTGCATTTGTTCACTTTTGTTGAAAGTGACCATGTCTCAAGTTCAAGTGCAAGTTCAGAACCCATCTGCTGCTCTCTCAGGGAGCCAAATACTGAACAAGAACCAGTCTCTTCTCTCACAGCCTTTGATGAGTA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$AAGGGCTCTGTTAGTGCGCCTCTAAGATGGCGACGCCTTTGGCGGTAAATTCGGCTGCTAGTCTATGGGGTCCTTACAAAGACATTTGGCATAAAGTGGGAAATGCTCTTTGGAGAAGACAACCTGAAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCCGGACGGACGCTCGTCTTCGCCCGCCATGGCCGAGAGCGACTGGGACACGGTGACGGTGCTGCGCAAGAAGGGCCCTACGGCCGCCCAGGCCAAATCCAAGCAGGCTATCTTAGCGGCACAGAGACGAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCCGGACGGACGCTCGTCTTCGCCCGCCATGGCCGAGAGCGACTGGGACACGGTGACGGTGCTGCGCAAGAAGGGCCCTACGGCCGCCCAGGCCAAATCCAAGCAGGCTATCTTAGCGGCACAGAGACGAGGAGAAGATGTGGAGACTTCCAAGAAATGGGCTGCTGGCC',\n",
       "       b'CGCAAGCGGAAGCGGAAGTAGTTAGCTGCATACTTGTGCGGTTCCAAGTGTGGAGAAAGCGGCTCTGGGTCTAGATTGAGGGATACTCCCCCTTTCCACCATGGGCAAGAAGGGCAAAGTTGGCAAGAGCCGACGAGACAAGTTTTATCACTTGGCGAAGGAGACGGGTTACCGTTCCCGATCTGCTTTCAAGCTGATCCAGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$CCTATTTCAGTCCAACTCCCACTGCGCAGGCGCTTACAGTGCACCAAGATGGCCGCCCCCGTGGATCTAGAGCTGAAGAAGGCCTTCACAGAGCTTCAAGCCAAAGTTATTGACACTCAACAGAAGGTGAAGCTCGCAGACATACAGATTGAACAGCTAAACAGAACGAAAAAGCATGCAC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCTATTTCAGTCCAACTCCCACTGCGCAGGCGCTTACAGTGCACCAAGATGGCCGCCCCCGTGGATCTAGAGCTGAAGAAGGCCTTCACAGAGCTTCAAGCCAAAGTTATTGACACTCAACAGAAGGTGAAGCTCGCAGACATACAGATTG',\n",
       "       b'GGGGCTCGGACGCTGCGGGGACTCATTTTTCCCGTCAGCGGAGGGAGCGAGCGGTGCTGCGGCCCGCGCCGCCATCTTGGATTTTACTCTCCATTTTTCTCTGGAATTATTTTTGGTGATTAATTTTCTGGGGGGGACTGGGACGCGGGGCCCGGCGGCGCGGCCCCGCATCGCAGCGGCCGGGCAGCGGGGCCTGGGACGCG',\n",
       "       b'AGGAGGAGCGGGGCGGCGCAGGCGGAGAGAACATTGAAAGTATTCTCTAAGCTATTTGAAGAGAGTGACTAAATGCACCTGGGTCAGGCTGTCTGTGGGTATGAAGTGGTTGGGAGAATCCAAGATCATGGTGGTGAATGGCAGGAGAAATGGAGGCAAGTTGTCTAATGACCATCAGCAGAATCAATCAAAATTACAGCACA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GACGGAAACCAGAATCGTTTTGGGTCTGGTCGCCAAGATGGCGTCCTCCGCCTCCGCCCGGACTCCGGCAGGGAAGCGAGTGATAAATCAGGAAGAATTGCGGCGGTTAATGAAGGAGAAGCAGCGTCTGAGCACCAGTC',\n",
       "       b'GCATTTATTGATGCCAATGGGATGAAAATTCTGTATAATACTTCGCAATTGCCTGTTATTCCTGTGACTGGTCCTGTGGCTCAGCTCTACAGCTTACCTCCTGAAGTGGATGACGTAGTAGATGAAAGTGATGACAACGATGATATTGATGTAGAAGCTGAAAACGAAACTGAGAATGAAGATGACCTAGATCAAAATTTTAA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$GCTGCGGCTCTGCGCGGTCCCCGCCAGCGCCCCATCCTGAGCCGATTATCTGCAATTATGAAATGAAGTAACTCAAGATGAGCAAGTTAAAAGTGATACCAGAAAAAAGCCTTACCAATAATTCTAGGATCGTAGGACTCCTGGCTCAACTGGAGAAGATCAATGCTGAGCCTTCAGAAT',\n",
       "       b'CAGGCCCGCGAACTTGGCCATTCAGCCGCCGCTGTCCCCGCTGCGCGCCCTCGCGCCTCTGCCTGAGAAGCCAGGCGCTGTTCCCCCACCCCAGAAGAGGATGGCAAAGGTGGCTAAGGACCTCAACCCAGGAGTTAAAAAGATGTCCCTGGGCCAGCTGCAGTCAGCAAGAGGTGTGGCATGTTTGGGATGCAAGGGGACGT',\n",
       "       b'GGGCCTGGAGCCAATAAGGGGCGGGCTCGGTGCTGATGGACGGTGCTGGTGGCCAGTGGAGAGGCGCTGGCCGCACTTCCCGTCGGGGAGAGAGTGTAATATGGCGAAGACCTACGATTACCTGTTCAAGCTGCTGCTGATCGGGGACTCGGGGGTGGGGAAGACCTGTGTCCTGTTCCGCTTCTCCGAGGACGCCTTCAACT',\n",
       "       b'ATAAGGGGCGGGCTCGGTGCTGATGGACGGTGCTGGTGGCCAGTGGAGAGGCGCTGGCCGCACTTCCCGTCGGGGAGAGAGTGTAATATGGCGAAGACCTACGATTACCTGTTCAAGCTGCTGCTGATCGGGGACTCGGGGGTGGGGAAGACCTGTGTCCTGTTCCGCTTCTCCGAGGACGCCTTCAACTCCACTTTTATCTC',\n",
       "       b'GCGGGGCCGGAAGCGCTACGGTTTGACCCCCGAGTCCCTCTGTTCCCGAAGGGGCGGCCGTCTTTCTCCCGACCCGCTCCGCCTCCTCTCCTTCTTCCCCATTACCCGGAGGCCGAAGCCCCCAGCCAGGGCGGGGCGGCGCAGCCCGAGCTCCCGGACCCGGAAGAAGCGCCATCTCCCGCCTCCACCATGGAGCCCACCGC',\n",
       "       b'CCTTCTTCCCCATTACCCGGAGGCCGAAGCCCCCAGCCAGGGCGGGGCGGCGCAGCCCGAGCTCCCGGACCCGGAAGAAGCGCCATCTCCCGCCTCCACCATGGAGCCCACCGCACCGTCCCTCACCGAGGAGGACCTCACTGAAGTGAAGAAGGACGCCTTAGAAAATTTACGTGTATACCTGTGTGAGAAAATCATAGCTG',\n",
       "       b'AGACCAGTTTTAAGGGGAGGACCGGTGCGAGTGAGGCAGCCCCGAGGCTCTGCTCGCCCACCACCCAATCCTCGCCTCCCTTCTGCTCCACCTTCTCTCTCTGCCCTCACCTCTCCCCCGAAAACCCCCTATTTAGCCAAAGGAAGGAGGTCAGGGGAACGCTCTCCCCTCCCCTTCCAAAAAACAAAAACAGAAAAACCTTT',\n",
       "       b'TCTCTCTGCCCTCACCTCTCCCCCGAAAACCCCCTATTTAGCCAAAGGAAGGAGGTCAGGGGAACGCTCTCCCCTCCCCTTCCAAAAAACAAAAACAGAAAAACCTTTTTCCAGGCCGGGGAAAGCAGGAGGGAGAGGGGCCGCCGGGCTGGCCATGGAGCTGCTGTGCCACGAGGTGGACCCGGTCCGCAGGGCCGTGCGGG',\n",
       "       b'GTCAGGGGAACGCTCTCCCCTCCCCTTCCAAAAAACAAAAACAGAAAAACCTTTTTCCAGGCCGGGGAAAGCAGGAGGGAGAGGGGCCGCCGGGCTGGCCATGGAGCTGCTGTGCCACGAGGTGGACCCGGTCCGCAGGGCCGTGCGGGACCGCAACCTGCTCCGAGACGACCGCGTCCTGCAGAACCTGCTCACCATCGAGG',\n",
       "       b'GCTGTTTCCAGGGTGACAGAGTGGCGACCTCGGTGGTCGATTGAGCAGGTCTGAGAATTGTTCCCAAAGGGTTGTGCGTCACCGAGTCGTTGGCGCTGTCATGGCGGGTGTGCTGAAGAAGACCACTGGCCTTGTGGGATTGGCTGTGTGCAATACTCCTCACGAGAGGCTAAGAATATTGTACACAAAGATTCTTGATGTTC',\n",
       "       b'AGGCCCGGGTACTCCCTGCGCGTCCCGCGGAGCCCGGCTTCCCGGCCCAGTTTCCAGCGCCCGGAATCCTTCCACTGTCTGTCTCTGCCCAGAGCAACCTACGTGCAGTAACGCTGACTCCAGAGCGCACCCGTTGGGCGATGAAGGCGGCACAGCGTCGAAAAAACAAAAGAATAAGAAGAAAACGCGGAACAGGGCCTCTG',\n",
       "       b'CCCGCGCCCCGCGGAACCTAGAGTCGCAGGCGCGTTCTTGAAGGACGGAATTCGGCGTCGGACTCTGCGCCCCGCGTAGTTCCGGTGGCGACTGCGGCGCATGGCGGCCCTGGGACATCTTGCTGGGGAGGCAGCGGCGGCCCCAGGCCCGGGTACTCCCTGCGCGTCCCGCGGAGCCCGGCTTCCCGGCCCAGTTTCCAGCG',\n",
       "       b'GCCTATTAGTGTCATCCTCACCGTCACGGCCGGCGCCTCCTCCTGGATTCATTCACTCGCTCTTTTCATTCACGAAGGTAGTGAGGCCTAGTGGAAAGCCATGGAGAGCGCTCTCCCCGCCGCCGGCTTCCTGTACTGGGTCGGCGCGGGCACCGTGGCCTACCTAGCCCTGCGTATTTCGTACTCGCTCTTCACGGCCCTCC',\n",
       "       b'TTTCATTCACGAAGGTAGTGAGGCCTAGTGGAAAGCCATGGAGAGCGCTCTCCCCGCCGCCGGCTTCCTGTACTGGGTCGGCGCGGGCACCGTGGCCTACCTAGCCCTGCGTATTTCGTACTCGCTCTTCACGGCCCTCCGGGTCTGGGGAGTGGGGAATGAGGCGGGGGTCGGCCCGGGGCTCGGAGAATGGGCAGTTGTCA',\n",
       "       b'GAGACTGCTGGGAGTTACGATAGCCGGAACAAGCATGAGATCATTCGCTGCTTGAAAGCTTTTATGAACAACAAGTTTGGAATCAAGACCATGTTGGAGACAGAAGAAGGAATCCTACTGCTGGTCAGAGCCATGGATCCTGCTGTTCCCAACATGATGATTGATGCAGCTAAGCTGCTTTCTGCTCTTTGTATTCTACCGCA',\n",
       "       b'GCGCGGCGGCTGGCTAAAGAGCGACTGGGCGGCGGCGGGCGCGGAGCTGCCAGGCGGGAGCGGCGTAGGCGCGGGGTCGCCGGCCAGCGTGAACCGGGACATGGAGCCGCCCGGCGGGAGCCTGGGGCCCGGCCGCGGGACCCGGGACAAGAAGAAGGGCCGGAGCCCAGATGAGCTGCCCTCGGCGGGCGGCGACGGCGGCA',\n",
       "       b'AGGGGTTGGGAAGGAAGAGACAAAAAGTAGTTTTTTCCCCTCCTCCTCCTCCTTTCTCTTGCTAATCCCGCCTCCTCCTAAGACTTAGGAAGACTGGTGGATGCGTTTGGGTTGTAGCTAGGCTTTTTCTTTTCTTTCTCTTTTAAAACACATCTAGACAAGGAAAAAACAAGCCTCGGATCTGATTTTTCACTCCTCGTTCT',\n",
       "       b'GACTTAGGAAGACTGGTGGATGCGTTTGGGTTGTAGCTAGGCTTTTTCTTTTCTTTCTCTTTTAAAACACATCTAGACAAGGAAAAAACAAGCCTCGGATCTGATTTTTCACTCCTCGTTCTTGTGCTTGGTTCTTACTGTGTTTGTGTATTTTAAAGGCGAGAAGACGAGGGGAACAAAACCAGCTGGATCCATCCATCACC',\n",
       "       b'AGACGAGGGGAACAAAACCAGCTGGATCCATCCATCACCGTGGGTGGTTTTAATTTTTCGTTTTTTCTCGTTATTTTTTTTTAAACAACCACTCTTCACAATGAACAAACTGTATATCGGAAACCTCAGCGAGAACGCCGCCCCCTCGGACCTAGAAAGTATCTTCAAGGACGCCAAGATCCCGGTGTCGGGACCCTTCCTGG',\n",
       "       b'GCGGCTCAGGGAGGCGACCAATGAGTGCTCTCGCGGAGAGCGACGGGGCAGGCCAATATGGCTTCCTGCACCTGGTGACGCTTGGCGAAACTGAGGTCTCATGGAGAAGCCCCGGAGTATTGAGGAGACCCCATCTTCAGAACCAATGGAGGAAGAGGAAGATGACGACTTGGAGCTGTTTGGTGGCTATGATAGTTTCCGGA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CTGGACTTGTGGTGCGCTGCCAGGGCTCCGCAGCGTTGCCGGTTGTATTCGCTGGATACCAGAGGGCGGAAGTGCAGCAGGGTTCAGCTCCGACCTCCGCGCCGGTGCTTTTTGCGGCTGCGCGGGCTTCCTGGAGTCCTGCTACCGCGTCCCC',\n",
       "       b'CAGCGTTGCCGGTTGTATTCGCTGGATACCAGAGGGCGGAAGTGCAGCAGGGTTCAGCTCCGACCTCCGCGCCGGTGCTTTTTGCGGCTGCGCGGGCTTCCTGGAGTCCTGCTACCGCGTCCCCGCAGGACAGTGTGTCAGGCGGGCAGCTTGCCCCGCCGCCCCACCGGAGCGCGGAATCTGGGCGTCCCCACCAGTGCGGG',\n",
       "       b'GAGCGCGGAATCTGGGCGTCCCCACCAGTGCGGGGAGCCGGAAGGAGGAGCCATAGCTTGGAGTAGGTTTGGCTTTGGTTGAAATAAGAATTTAGCCTGTATGTACTGCTTTAACTCCTGGAAGAATGACAGATGACAAAGATGTGCTTCGAGATGTGTGGTTTGGACGAATTCCAACTTGTTTCACGCTATATCAGGATGAG',\n",
       "       b'CAGTGCGGGGAGCCGGAAGGAGGAGCCATAGCTTGGAGTAGGTTTGGCTTTGGTTGAAATAAGAATTTAGCCTGTATGTACTGCTTTAACTCCTGGAAGAATGACAGATGACAAAGATGTGCTTCGAGATGTGTGGTTTGGACGAATTCCAACTTGTTTCACGCTATATCAGGATGAGATAACTGAAAGGGAAGCAGAACCAT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCGGCCAGGGCCTCCCTCCTTCTCTCTAGGTTTGGCTGCCGCCTTCTAGCCGGGCGTTCGCGGCCCCGCCGGCCCGACTCTCAAGCCTCAGCTCCCAGGCTAGGCTGTGGCCGCCGGTGGCCTGGGGAGAGTGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCGGCCAGGGCCTCCCTCCTTCTCTCTAGGTTTGGCTGCCGCCTTCTAGCCGGGCGTTCGCGGCCCCGCCGGCCCGACTCTCAAGCCTCAGCTCCCAGGCTAGGCTGTGGCCGCCGGTGGCCTGGGGAGAGTGCGGCG',\n",
       "       b'TAAGTCGTTAGCCTCCTCCCTCCGCTTTCAGCAGTGGTCTTTCAGCTCTCTTCTTGTGCGCTGTTGTCGACCCCGACCAGCCCCTTCCAACCCAGTCATCATGTCCCAGCCGGGAATACCGGCCTCCGGCGGCGCCCCAGCCAGCCTCCAGGCCCAGAACGGAGCCGCCTTGGCCTCGGGGTCTCCCTACACCAACGGTCCTG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GTCACGGGTGGCGGGCGCGGGAAGGGGATTTGGATTGTTGCGCCTCTGCTCTGAAGAAAGTGCTGTCTGGCTCCAACTCCAGTTCTTTCCCCTGAGCAGCGCCTGGAACCTAACCCTTCCCACTCTGTCACCTTCTCGATCCCGCCGGCGCTT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GTCACGGGTGGCGGGCGCGGGAAGGGGATTTGGATTGTTGCGCCTCTGCTCTGAAGAAAGTGCTGTCTGGCTCCAACTCCAGTTCTTTCCCCTGAGCAGCGCCTGGAACCTAACCCTTCCCACTCTGTCACCTTCTCGATCCCGCCGGCGCTTTAGAGCCGCAGT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GTCACGGGTGGCGGGCGCGGGAAGGGGATTTGGATTGTTGCGCCTCTGCTCTGAAGAAAGTGCTGTCTGGCTCCAACTCCAGTTCTTTCCCCTGAGCAGCGCCTGGAACCTAACCCTTCCCACTCTGTCACCTTCTCGATCCCGCCGGCGCTTTAGAGCCGCAGTCCAG',\n",
       "       b'CACGGGTGGCGGGCGCGGGAAGGGGATTTGGATTGTTGCGCCTCTGCTCTGAAGAAAGTGCTGTCTGGCTCCAACTCCAGTTCTTTCCCCTGAGCAGCGCCTGGAACCTAACCCTTCCCACTCTGTCACCTTCTCGATCCCGCCGGCGCTTTAGAGCCGCAGTCCAGTCTTGGATCCTTCAGAGCCTCAGCCACTAGCTGCGA',\n",
       "       b'GGGATTTGGATTGTTGCGCCTCTGCTCTGAAGAAAGTGCTGTCTGGCTCCAACTCCAGTTCTTTCCCCTGAGCAGCGCCTGGAACCTAACCCTTCCCACTCTGTCACCTTCTCGATCCCGCCGGCGCTTTAGAGCCGCAGTCCAGTCTTGGATCCTTCAGAGCCTCAGCCACTAGCTGCGATGCATGTGATCAAGCGAGATGG',\n",
       "       b'TCCAACTCCAGTTCTTTCCCCTGAGCAGCGCCTGGAACCTAACCCTTCCCACTCTGTCACCTTCTCGATCCCGCCGGCGCTTTAGAGCCGCAGTCCAGTCTTGGATCCTTCAGAGCCTCAGCCACTAGCTGCGATGCATGTGATCAAGCGAGATGGCCGCCAAGAACGAGTCATGTTTGACAAAATTACATCTCGAATCCAGA',\n",
       "       b'GCAGCGCCTGGAACCTAACCCTTCCCACTCTGTCACCTTCTCGATCCCGCCGGCGCTTTAGAGCCGCAGTCCAGTCTTGGATCCTTCAGAGCCTCAGCCACTAGCTGCGATGCATGTGATCAAGCGAGATGGCCGCCAAGAACGAGTCATGTTTGACAAAATTACATCTCGAATCCAGAAGCTTTGTTATGGACTCAATATGG',\n",
       "       b'GGAACCTAACCCTTCCCACTCTGTCACCTTCTCGATCCCGCCGGCGCTTTAGAGCCGCAGTCCAGTCTTGGATCCTTCAGAGCCTCAGCCACTAGCTGCGATGCATGTGATCAAGCGAGATGGCCGCCAAGAACGAGTCATGTTTGACAAAATTACATCTCGAATCCAGAAGCTTTGTTATGGACTCAATATGGATTTTGTTG',\n",
       "       b'CATGTTTGACAAAATTACATCTCGAATCCAGAAGCTTTGTTATGGACTCAATATGGATTTTGTTGATCCTGCTCAGATCACCATGAAAGTAATCCAAGGCTTGTACAGTGGGGTCACCACAGTGGAACTAGATACTTTGGCTGCTGAAACAGCTGCAACCTTGACTACTAAGCACCCTGACTATGCTATCCTGGCAGCCAGGA',\n",
       "       b'CAATGCTGGTACCAACCGCCCACAACTTTCTAGCTGTTTTCTTCTGAGTATGAAAGATGACAGCATTGAAGGCATTTATGACACTCTAAAGCAATGTGCATTGATTTCTAAGTCTGCTGGAGGAATTGGTGTTGCTGTGAGTTGTATTCGGGCTACTGGCAGCTACATTGCTGGGACTAATGGCAATTCCAATGGCCTTGTAC',\n",
       "       b'$$$$$CGCGAGAGCTCCCGGGGGCCGTTGGGTAGCGTCTTCGCTGTTGCCCTTAGGGACGGCTGTGGGCCTGCTGGGGGTGGGGGCCCGAAGCGCCAGAGATGGCTGCTCAGCGAGGGATGCCCAGCTCCGCCGTGAGGGTCCTGGAAGAGGCGTTGGGCATGGGTTTGACGGCAGCCGGGGACGCGAGGGACACGGCGGACG',\n",
       "       b'$$$$$$$$$$$$$$CTTTACGTCGGCGCGTAACGAGGGGGTGCGTGTGAGGTCATCGCGCGGGCGGGCGGGCGGGGTCTGGCGGTTTGAACGAGACGAAGACGGAACCGGAGCCGGTTGCGGGCAGTGGACGCGGTTCTGCCGAGAGCCGAAGATGGCAGTGAACGTATACTCAACGTCAGTGACCAGTGATAACCTAAGTCG',\n",
       "       b'ATCGCGCGGGCGGGCGGGCGGGGTCTGGCGGTTTGAACGAGACGAAGACGGAACCGGAGCCGGTTGCGGGCAGTGGACGCGGTTCTGCCGAGAGCCGAAGATGGCAGTGAACGTATACTCAACGTCAGTGACCAGTGATAACCTAAGTCGACATGACATGCTGGCCTGGATCAATGAGTCTCTGCAGTTGAATCTGACAAAGA',\n",
       "       b'CCATTTCTGGCTGGGCAGGGCACTCTCAGCAGCTCAACTGCCCAGCGTGACCAGTGGCCACCTCTGCAGTGTCTTCCACAACCTGGTCTTGACTCGTCTGCTGAACAAATCCTCTGACCTCAGGCCGGCTGTGAACGTAGTTCCTGAGAGATAGCAAACATGCCCAACAGTGAGCCCGCATCTCTGCTGGAGCTGTTCAACAG',\n",
       "       b'GGCAGGGCACTCTCAGCAGCTCAACTGCCCAGCGTGACCAGTGGCCACCTCTGCAGTGTCTTCCACAACCTGGTCTTGACTCGTCTGCTGAACAAATCCTCTGACCTCAGGCCGGCTGTGAACGTAGTTCCTGAGAGATAGCAAACATGCCCAACAGTGAGCCCGCATCTCTGCTGGAGCTGTTCAACAGCATCGCCACACAA',\n",
       "       b'ACCTCTGCAGTGTCTTCCACAACCTGGTCTTGACTCGTCTGCTGAACAAATCCTCTGACCTCAGGCCGGCTGTGAACGTAGTTCCTGAGAGATAGCAAACATGCCCAACAGTGAGCCCGCATCTCTGCTGGAGCTGTTCAACAGCATCGCCACACAAGGGGAGCTCGTAAGGTCCCTCAAAGCGGGAAATGCGTCAAAGGATG',\n",
       "       b'TCTGCAGTGTCTTCCACAACCTGGTCTTGACTCGTCTGCTGAACAAATCCTCTGACCTCAGGCCGGCTGTGAACGTAGTTCCTGAGAGATAGCAAACATGCCCAACAGTGAGCCCGCATCTCTGCTGGAGCTGTTCAACAGCATCGCCACACAAGGGGAGCTCGTAAGGTCCCTCAAAGCGGGAAATGCGTCAAAGGATGAAA',\n",
       "       b'TCTGCTGGAGCTGTTCAACAGCATCGCCACACAAGGGGAGCTCGTAAGGTCCCTCAAAGCGGGAAATGCGTCAAAGGATGAAATTGATTCTGCAGTAAAGATGTTGGTGTCATTAAAAATGAGCTACAAAGCTGCCGCGGGGGAGGATTACAAGGCTGACTGTCCTCCAGGGAACCCAGCACCTACCAGTAATCATGGCCCAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GAAGGACGGGGGAGGACCGCTGCTTCCGGCGCCGTAACTGCTGCCATCTTCTCCGCGCTATGGCTGCGTTCGGCCGTCAGGTCCTTGATTGGCACCGCCTGATCCCCCTCACCTGGGCCTGTATGGCTAGGCAGACTCCTCATCTTGGAGAACAGAGAAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GAAGGACGGGGGAGGACCGCTGCTTCCGGCGCCGTAACTGCTGCCATCTTCTCCGCGCTATGGCTGCGTTCGGCCGTCAGGTCCTTGATTGGCACCGCCTGATCCCCCTCACCTGGGCCTGTATGGCTAGGCAGACTCCTCATCTTGGAGAACAGAGAAGGA',\n",
       "       b'AACGGAAGCCGGGAAGGCGATTCATAGCTCGCGGGGTACGGGCGCGCGTGCGCACTCCGCAGCCCGTTCAGGACCCCGGCGCGGGCAGGGCGCCCACGAGCTGGCTGGCTGCTTGCACCCACATCCTTCTTTCTCTGGGACCTGGGGTCGCGGTTACTTGGGCTGGCCGGCGAACCCTTGAGTGGCCTGGCGGGGAGCGGGCC',\n",
       "       b'GAAGCCGGGAAGGCGATTCATAGCTCGCGGGGTACGGGCGCGCGTGCGCACTCCGCAGCCCGTTCAGGACCCCGGCGCGGGCAGGGCGCCCACGAGCTGGCTGGCTGCTTGCACCCACATCCTTCTTTCTCTGGGACCTGGGGTCGCGGTTACTTGGGCTGGCCGGCGAACCCTTGAGTGGCCTGGCGGGGAGCGGGCCTCGC',\n",
       "       b'GGTACGGGCGCGCGTGCGCACTCCGCAGCCCGTTCAGGACCCCGGCGCGGGCAGGGCGCCCACGAGCTGGCTGGCTGCTTGCACCCACATCCTTCTTTCTCTGGGACCTGGGGTCGCGGTTACTTGGGCTGGCCGGCGAACCCTTGAGTGGCCTGGCGGGGAGCGGGCCTCGCGCGCCTGGAGGGCCCTGTGGAACGAAGAGA',\n",
       "       b'GCCTGGCGGGGAGCGGGCCTCGCGCGCCTGGAGGGCCCTGTGGAACGAAGAGAGGCACACAGCATGGCAGAAAACCGAGAGCCCCGCGGTGCTGTGGAGGCTGAACTGGATCCAGTGGAATACACCCTTAGGAAAAGGCTTCCCAGCCGCCTGCCCCGGAGACCCAATGACATTTATGTCAACATGAAGACGGACTTTAAGGC',\n",
       "       b'TCGCGGTTACTTGGGCTGGCCGGCGAACCCTTGAGTGGCCTGGCGGGGAGCGGGCCTCGCGCGCCTGGAGGGCCCTGTGGAACGAAGAGAGGCACACAGCATGGCAGAAAACCGAGAGCCCCGCGGTGCTGTGGAGGCTGAACTGGATCCAGTGGAATACACCCTTAGGAAAAGGCTTCCCAGCCGCCTGCCCCGGAGACCCA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$GCGGGGCCTTCTAAGGCCGAAAGTCTTCGGAGCTTGCGCCAGTCTCTTCGCGGCGTCCACCACTTAGACGCAAGTTGCTGAAGCCGGCCGGGGAGAAGGTGTTGTTGCCGGAGCTGAGACCGGGCGGCCACAGTCCGCAGGGATGAACCTCGAGTTGCTGGAGTCCTTTGGGCAGAA',\n",
       "       b'TCTCTTCGCGGCGTCCACCACTTAGACGCAAGTTGCTGAAGCCGGCCGGGGAGAAGGTGTTGTTGCCGGAGCTGAGACCGGGCGGCCACAGTCCGCAGGGATGAACCTCGAGTTGCTGGAGTCCTTTGGGCAGAACTATCCAGAGGAAGCTGATGGAACTTTGGATTGTATCAGCATGGCTTTGACTTGCACCTTTAACAGGT',\n",
       "       b'GTCAGGCAGTGTGGGGACAGCCCCGAGTTGCCGAAAGTCCCCGGCCCGTTTTCCTCCTGTGAAGACATAGCTGCGGGTGGCTGTGCTGGTGGCGTTCAAGATGTCGACCAAGAATTTCCGAGTCAGTGACGGGGACTGGATTTGCCCTGACAAAAAATGTGGAAATGTAAACTTTGCTAGAAGAACCAGCTGTAATCGATGTG',\n",
       "       b'AGTTGCCGAAAGTCCCCGGCCCGTTTTCCTCCTGTGAAGACATAGCTGCGGGTGGCTGTGCTGGTGGCGTTCAAGATGTCGACCAAGAATTTCCGAGTCAGTGACGGGGACTGGATTTGCCCTGACAAAAAATGTGGAAATGTAAACTTTGCTAGAAGAACCAGCTGTAATCGATGTGGTCGGGAGAAAACAACTGAGGCCAA',\n",
       "       b'CTGCGTAAATGGCGGGGGCGTGTCTTTTGGCTCCTCCGCGTGTAGTTACCTGAGAAACGCGGGAAGTTGGGCCCAGGCAGTGTTGCTGCGGTTGCCTAAGTTGTTTTTCTATTTCTGGAGAGAGCCGTGAGCTTGTCCAGGGGCCCCAATCCTGAGGCCGACCCGGTTTCTGGCGCGGTGCGATGGAGGTAGTGGAGGCCGCC',\n",
       "       b'GGGGCGTGTCTTTTGGCTCCTCCGCGTGTAGTTACCTGAGAAACGCGGGAAGTTGGGCCCAGGCAGTGTTGCTGCGGTTGCCTAAGTTGTTTTTCTATTTCTGGAGAGAGCCGTGAGCTTGTCCAGGGGCCCCAATCCTGAGGCCGACCCGGTTTCTGGCGCGGTGCGATGGAGGTAGTGGAGGCCGCCGCCGCTCAGCTGGA',\n",
       "       b'TTGCTGCGGTTGCCTAAGTTGTTTTTCTATTTCTGGAGAGAGCCGTGAGCTTGTCCAGGGGCCCCAATCCTGAGGCCGACCCGGTTTCTGGCGCGGTGCGATGGAGGTAGTGGAGGCCGCCGCCGCTCAGCTGGAAACTCTGAAATTCAATGGCACCGACTTTGGAGTTGGGGAAGGTCCGGCGGCTCCGTCTCCGGGCTCTG',\n",
       "       b'CCACGCCTGCCCACTAGCCCGACGCCCGCCTGGCGGGAACATGGGCTCGCCCCTCACCAGCGATCTGCAGTCAGTTGGTAGCGCCTGCACGTCGCGCGCGGTGTTCGATTGTCGCTGCCTGGGGAGGAGGAGCCGGAGCCGCCGCCGCCGCCGCCGCCGCCGCGGGCTTCGTTCGTAAGGAAGGGGGCCTAGGCCCGGGCCTG',\n",
       "       b'GTTGCTGCGCGCCGGGGGTCGCTCCTGCTGTGTCTTCCGCTCCAGCTTCGCCCACTTCCCCTTGCCAGCGGGGTGGGCGCGGAGAAGACCTGCCGGAGCCATGGAGGACGAAGTGGTCCGCTTTGCCAAGAAGATGGACAAGATGGTGCAGAAGAAGAACGCGGCTGGAGCATTGGATTTGCTAAAGGAGCTTAAGAATATTC',\n",
       "       b'$$$$$$$$$$$$$ACTTGACAACCGCAGTCTGCAAGAGGCTGAGCTGAGGAGTCGCTGGGCCGGGAGGGGCGGACGTGAGAAGGACGGATTGACGAACTGATGGATTGACGCGCGGGCGGTAGGAGGGAGGACCGACGCCAAACCCAGACCGCCGCCGTCGTGCTCCTGCCGCAGCCCGGAGCCGGCCGCTTCGGGGCCCTGG',\n",
       "       b'GCCCGGAGCCGGCCGCTTCGGGGCCCTGGCCGCCGGCCTCCCAGCCGCGTTCTCCTCCGCCGCTCCTCCGGGCTTGCCCTGGAGCCCTCAGGCTATCAATATGACGGCTGAAGAAACAGTGAATGTAAAAGAGGTTGAAATCATTAAGCTAATTTTGGACTTCCTGAATTCAAAGAAGCTTCACATTAGTATGCTGGCCCTGG',\n",
       "       b'GGTGAGAGGCGGAGGAGCGGTAACTACCCCGGCTGCGCACAGCTCGGCGCTCCTTCCCGCTCCCTCACACACCGGCCTCAGCCCGCACCGGCAGTAGAAGATGGTGAAAGAAACAACTTACTACGATGTTTTGGGGGTCAAACCCAATGCTACTCAGGAAGAATTGAAAAAGGCTTATAGGAAACTGGCTTTGAAGTACCATC',\n",
       "       b'TTTCCCCCCGAGGATCGAGGTGGTGCGCTCTGGACGGGGTTGTGCATTCTCGCCGCGCCCGGGCGGACGATCCAGCGAACAGCCCCGCTTCTAACCCGAGATGCTGCTGCCGGCGCCCGCGCTCCGCCGCGCCCTGCTGTCCCGCCCCTGGACCGGGGCCGGCCTGCGGTGGAAGCACACCTCCTCCCTGAAGGTGGCCAACG',\n",
       "       b'CCTGACCTGAGTGGGTTAGTGATCCAGAGAAACCAGCAGGCCAACTTGGTCAGGAAGGTTCGGGAAGCTGTTGGAGCAGTGTGGGGAATTTCCCACCAGGATGAGTATGATTGGCTGTGATTTTAGATCGTAAAGCTGAAAATTGAAATCATGAAAGTAGACAGGACTAAACTGAAGAAGACACCTACTGAGGCTCCTGCAGA',\n",
       "       b'GTATAATGGCTTGATAGAGGAGTTGGTAGATGTCCTTCAGATAACGGATAAGCAGCTTATGGAGATTAAAGCAGCTTCTTTACGAACATTAACATCAATTGTCCACTTGGAGAGAACTCCCAAACTCAGCAGTATTATTGACTGTACTGGAACTGCCTCCTACCATGGATTTTTGCCAGTGCTTGTAAGGAACTGTATCCAGG',\n",
       "       b'AGGAGAGGAAATGGAAACTGATATGGATGGAGTCCAGTGTATTCCACAACGAGCAGCACTTCTGAAATCCATGTTGAATTTCCTCAAGAAGGCCATCCAAGACCCTGCTTTCTCAGATGGCATACGACATGTGATGGATGGTTCTCTGCCTACCTCCCTGAAACACATCATCAGCAATGCAGAATACTATGGCCCATCACTCT',\n",
       "       b'ATTCGAGAGAGACTAAGCAAGGAGAAGGAGGGGTCTCGAGGAGAAGAGGATACAGGGCAAGAGGAAGGTGGCTCCCGCCGGGAACCTCAAGTCAACCAGCAACAACTGCAACAGCTCATGGACATGGGCTTCACAAGGGAACATGCAATGGAGGCACTGTTGAACACCAGCACCATGGAGCAGGCCACAGAGTACCTTTTAAC',\n",
       "       b'CAGGAAGGTTCGGGAAGCTGTTGGAGCAGTGTGGGGAATTTCCCACCAGGATGAGTATGATTGGCTGTGATTTTAGATCGTAAAGCTGAAAATTGAAATCATGAAAGTAGACAGGACTAAACTGAAGAAGACACCTACTGAGGCTCCTGCAGACTGCAGAGCCTTAATAGACAAACTCAAAGTTTGTAATGATGAGCAACTTC',\n",
       "       b'GGCCACTCGGCCGCAATTAACCCGCGTCTCTGCGCCTTTTTAGGCCCCTCCCCCTCGGTCGTGCCCTTGTCATCTCTTAGGCCCCGTCTCACCCTTTCGGATGCCTCCCCTAGAACCCTACCACTTTCCACCCCTTTCCGTCTGTTATTTCTCCCAAACTTGCGCCCGCACAGGCCCCTCTGGAACACTCCTGCCCCGTAGTG',\n",
       "       b'ACGTGCGGCTGTGCGGTGTGGCTGACGGCAACGCCGCTGCTCTTGGAGAGGTCACTCCGGAGACGGCGTTGGTTTTGGGGTGTGGGGGGTTGGTGGCACTATGTGGCGCGTCTGTGCGCGACGGGCTCAGAATGTAGCCCCATGGGCGGGACTCGAGGCTCGGTGGACGGCCTTGCAGGAGGTACCCGGAACTCCACGAGTGA',\n",
       "       b'CAGCGAGGTCGGCAGCGGCACAGCGAGGTCGGCAGCGGCAGCGAGGTCGGCAGCGGCACAGCGAGGTCGGCAGCGGCAGCGAGGTCGGCAGCGGCGCGCGCTGTGCTCTTCCGCGGACTCTGAATCATGGCGACCACGGCCACGATGGCGACCTCGGGCTCGGCGCGAAAGCGGCTGCTCAAAGAGGAAGACATGACTAAAGT',\n",
       "       b'GGTCGGCAGCGGCAGCGAGGTCGGCAGCGGCACAGCGAGGTCGGCAGCGGCAGCGAGGTCGGCAGCGGCGCGCGCTGTGCTCTTCCGCGGACTCTGAATCATGGCGACCACGGCCACGATGGCGACCTCGGGCTCGGCGCGAAAGCGGCTGCTCAAAGAGGAAGACATGACTAAAGTGGAATTCGAGACCAGCGAGGAGGTGG',\n",
       "       b'GGCAGCGGCAGCGAGGTCGGCAGCGGCACAGCGAGGTCGGCAGCGGCAGCGAGGTCGGCAGCGGCGCGCGCTGTGCTCTTCCGCGGACTCTGAATCATGGCGACCACGGCCACGATGGCGACCTCGGGCTCGGCGCGAAAGCGGCTGCTCAAAGAGGAAGACATGACTAAAGTGGAATTCGAGACCAGCGAGGAGGTGGATGT',\n",
       "       b'ACAGTCTCAGTCCGGCACAGGAAAAACAGCCACCTTCAGTATCTCAGTCCTCCAGTGTTTGGATATTCAGGTTCGTGAAACTCAAGCTTTGATCTTGGCTCCCACAAGAGAGTTGGCTGTGCAGATCCAGAAGGGGCTGCTTGCTCTCGGTGACTACATGAATGTCCAGTGCCATGCCTGCATTGGAGGCACCAATGTTGGCG',\n",
       "       b'TAACATAACTTCCCCTGACCCAAAGTCTTATGCTGAAAGAAAGCTTGACTCAGATGTGTATCCATCTTCAAAGCAAGAAGATGGTTTTCCAATGCAAGAGTTACAGGTGTTGCAGCCACAAGCATCTCTTGAGTCATCAACCCAAAGGCTATCTGATGGAGAAATTAATGCTCAAGAATCAACTTATAAGGTGTCAAAGGCAG',\n",
       "       b'GCTTCCTGGATATGCTCCCACACCTCAGCCTACTGGTCTTTCTGGAATATTTGATACTAGTGTGAACAGTGCCAGCAGTAACACTAAAGAGTCTTCAGTGATGAATTTTCTGTCTACTGCTGAATCCCGAACTGCTCAGGCTGCTGCTTCAGGAACTACTCTCTTACCACAATTCAGGGCTCCATCCTGGCAGACAGGCATGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GTACATAAGGACGTCATTTCCTGCCGCCTGTCTTTTCCGTGCTACCTGCAGAGGGGTCCATACGGCGTTGTTCTGGATTCCCGTCGTAACTTAAAGGGAAATTTTCACAATGTCCGGAGCCCTTGATGTCCTGCAAATGAAGGAGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$GTACATAAGGACGTCATTTCCTGCCGCCTGTCTTTTCCGTGCTACCTGCAGAGGGGTCCATACGGCGTTGTTCTGGATTCCCGTCGTAACTTAAAGGGAAATTTTCACAATGTCCGGAGCCCTTGATGTCCTGCAAATGAAGGAGGAGGATGTCCTTAAGTTCCTTGCAGCAGGA',\n",
       "       b'GACGTCATTTCCTGCCGCCTGTCTTTTCCGTGCTACCTGCAGAGGGGTCCATACGGCGTTGTTCTGGATTCCCGTCGTAACTTAAAGGGAAATTTTCACAATGTCCGGAGCCCTTGATGTCCTGCAAATGAAGGAGGAGGATGTCCTTAAGTTCCTTGCAGCAGGAACCCACTTAGGTGGCACCAATCTTGACTTCCAGATGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCGGTTTCCTCCGCTCGATTGGTTCTACTGTGGGTCTGGACTGATCTCCATGTCCTGTTGTGGGGCTTTTACAGCCTTTGGATTGTGAAAACTGCTGAGAGAGACTTGCAATCCAGTCACATAAGTATAATAAAGAAA',\n",
       "       b'GACTCAATACCAGACACTACAGCAGACTCAACCCTATGCTGTCTACCCTCAGGCAACCCAAACGTATGGACTACCTCCTTTTGGTGCATTGTGGCCAGGTATGAAACCTGAAAGTGGTTTAATTCAGACTCCATCTCCAAGTCAACACAGTGTTCTTACCTGCACTACAGGGTTAACCACAAGCCAGCCAAGCCCAGCACATT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ATGCGGTCCCGGGTTCTGTGGGGCGCTGCCCGGTGGCTCTGGCCCCGCCGGGCCGTTGGCCCAGCCCGCCGGCCCCTGAGCTCCGGTAGCCCGCCGCTGGAGG',\n",
       "       b'CTTGGTAGGCGGTGCCGTGACAAGCCCAACCGGACGGCTGGAGAGGGCGAGAAGGGCAGACGGGACATGCAGCCTCTTCCGCCTGAGCCCCGGAAGGGTGATGTGGCTGCGGCATCGCCGGCCTCGCTATGTCTGCCATTTTCAATTTTCAGAGTCTATTGACTGTAATCTTGCTGCTTATATGTACCTGTGCTTATATTCGA',\n",
       "       b'ACCGGACGGCTGGAGAGGGCGAGAAGGGCAGACGGGACATGCAGCCTCTTCCGCCTGAGCCCCGGAAGGGTGATGTGGCTGCGGCATCGCCGGCCTCGCTATGTCTGCCATTTTCAATTTTCAGAGTCTATTGACTGTAATCTTGCTGCTTATATGTACCTGTGCTTATATTCGATCCTTGGCACCCAGCCTCCTGGACAGAA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$AATGCTAATGAGCGAGTTGCCAGGCGAGACAGGAACTTCTTTCCCCTTCTCTGTGTCAGGATCGCAGAAAGTATGTCCCTTCTCTCACCATGAGCTGGCTCTCCAGTTCCCAGGGAGTGGTACTAACAGCCTACCACCCCAGCGGCAAGGACCAGACCGTCGGGAACAGCCATGC',\n",
       "       b'$$$$$$$$$$$AATGCTAATGAGCGAGTTGCCAGGCGAGACAGGAACTTCTTTCCCCTTCTCTGTGTCAGGATCGCAGAAAGTATGTCCCTTCTCTCACCATGAGCTGGCTCTCCAGTTCCCAGGGAGTGGTACTAACAGCCTACCACCCCAGCGGCAAGGACCAGACCGTCGGGAACAGCCATGCAAAGGCAGGGGAGGAAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCGCGTCGCCGCTCTTCGGTTCTGCTCTGTCCGCCGCCATGGCCCAAGCTGACATCGCGCTGATCGGATTGGCCGTCATGGGCCAGAACTTAATTCTGAACATGAATGACCACGGCTTTGTGGTCTGTG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCGCGTCGCCGCTCTTCGGTTCTGCTCTGTCCGCCGCCATGGCCCAAGCTGACATCGCGCTGATCGGATTGGCCGTCATGGGCCAGAACTTAATTCTGAACATGAATGACCACGGCTTTGTGGTCTGTGCTTTTAATAGGA',\n",
       "       b'GGGAGCGGAGTCAGTGGTGGAGAGGAAGGGGCCCGGTATGGCCCATCGCTCATGCCAGGAGGGAACAAAGAAGCGTGGCCCCACATCAAGACCATCTTCCAAGGCATTGCTGCAAAAGTGGGAACTGGAGAACCCTGCTGTGACTGGGTGGGAGATGAGGGAGCAGGCCACTTCGTGAAGATGGTGCACAACGGGATAGAGTA',\n",
       "       b'GAGGGAGCCTCACCCCCGGGACGCTTTCTGCGCACGCGCATCTCGGTGCATCTGTTGGGCGGGACCGCGGGGCCTGTGACACCGCACGCTGAGCTCTGTGATGTAGCCGCTTGCGGAGACTGCAAGCAGCCGCGGCGCGCCCGGCCCTCCCTCTTCCGCTGCCGCCGTGGGAATGGAAACATCTGCCCCACGTGCCGGAAGCC',\n",
       "       b'CCTGTGACACCGCACGCTGAGCTCTGTGATGTAGCCGCTTGCGGAGACTGCAAGCAGCCGCGGCGCGCCCGGCCCTCCCTCTTCCGCTGCCGCCGTGGGAATGGAAACATCTGCCCCACGTGCCGGAAGCCAAGTGGTGGCGACAACTGCGCGCCACTCCGCGGCCTACCGCGCAGATCCTCTACGTGTGTCCTCGCGAGACA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CGCCAAATTTCTCCCCTGAAGCAGAGGTGGTAGCCAACGGCTCCATGTCTCTGAGGAGCGGCGGGCGGCGGCGCGCGGACCCAGGCGCGGATGGCGAGGCCAGCAGGGATGATGGCGCCACTTCCTCAGTTTCGGCACTCAAGCGCC',\n",
       "       b'CCGTTCGTGGAGGAGTACATCCCCACACAGGAGATCCAGGTCACCAGCATCCACTGGAGCTACAAGACCACGGATGACATCGTGAAGGTTGAAGTCTGGGATGTAGTAGACAAAGGAAAATGCAAAAAGCGAGGCGACGGCTTAAAGATGGAGAACGACCCCCAGGAGGCGGAGTCTGAAATGGCCCTGGATGCTGAGTTCCT',\n",
       "       b'GAACGACCCCCAGGAGGCGGAGTCTGAAATGGCCCTGGATGCTGAGTTCCTGGACGTGTACAAGAACTGCAACGGGGTGGTCATGATGTTCGACATTACCAAGCAGTGGACCTTCAATTACATTCTCCGGGAGCTTCCAAAAGTGCCCACCCACGTGCCAGTGTGCGTGCTGGGAAACTACCGGGACATGGGCGAGCACCGAG',\n",
       "       b'GGAGTCTGAAATGGCCCTGGATGCTGAGTTCCTGGACGTGTACAAGAACTGCAACGGGGTGGTCATGATGTTCGACATTACCAAGCAGTGGACCTTCAATTACATTCTCCGGGAGCTTCCAAAAGTGCCCACCCACGTGCCAGTGTGCGTGCTGGGAAACTACCGGGACATGGGCGAGCACCGAGTCATCCTGCCGGACGACG',\n",
       "       b'GCTTCCAAAAGTGCCCACCCACGTGCCAGTGTGCGTGCTGGGAAACTACCGGGACATGGGCGAGCACCGAGTCATCCTGCCGGACGACGTGCGTGACTTCATCGACAACCTGGACAGCAGACCTCCAGGTTCCTCCTACTTCCGCTATGCTGAGTCTTCCATGAAGAACAGCTTCGGCCTAAAGTACCTTCATAAGTTCTTCA',\n",
       "       b'GGGGGGGCCGGGGCCGCCGGGACATGGTGCCAGTCGCACCCCTTCCCCGCCGCCGCTGAGCTCGCCGGCCGCGCCCGGGCTGGGACGTCCGAGCGGGAAGATGTTTTCCGCCCTGAAGAAGCTGGTGGGGTCGGACCAGGCCCCGGGCCGGGACAAGAACATCCCCGCCGGGCTGCAGTCCATGAACCAGGCGTTGCAGAGGC',\n",
       "       b'GCACCGCGGGCTGGGGCGCAGCCACCCGCCGCTCCTCGAGTCCCCTCGCCCCTTTCCCTTCGTGCCCCCCGGCAGCCTCCAGCGTCGGTCCCCAGGCAGCATGGTGAGGTCTGCTCCCGGACCCTCGCCACCATGTACGTGAGCTACCTCCTGGACAAGGACGTGAGCATGTACCCTAGCTCCGTGCGCCACTCTGGCGGCCT',\n",
       "       b'TCCTCGAGTCCCCTCGCCCCTTTCCCTTCGTGCCCCCCGGCAGCCTCCAGCGTCGGTCCCCAGGCAGCATGGTGAGGTCTGCTCCCGGACCCTCGCCACCATGTACGTGAGCTACCTCCTGGACAAGGACGTGAGCATGTACCCTAGCTCCGTGCGCCACTCTGGCGGCCTCAACCTGGCGCCGCAGAACTTCGTCAGCCCCC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$AAGCGACCGAGGGACTGGGAGTCGTTAGTGAGAGTTTCACTCTTGTTGCCTAGGCTGGAGTGCAATGGTGCGATCTTGGCTCATCACGACCTTCGCCTCCCAGGTTCAAGTGATTGT',\n",
       "       b'GGCTGGAGTGCAATGGTGCGATCTTGGCTCATCACGACCTTCGCCTCCCAGGTTCAAGTGATTGTCCCATTTCAGCCTCCCGAGTAGCTGGGATTACAGGATGACGCGGCATGGCAAGAACTGCACCGCAGGGGCCGTCTACACCTACCACGAGAAGAAGAAGGACACAGCGGCCTCGGGCTATGGGACCCAGAACATTCGAC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCTTTCCCAGAGTGCTCTGCGCCGTGAAGAAGCGGCTCCCGGGGACTGGGGGCATTTTGTGTTGGCTGGAGCTGGAGTAACAAGATGGCGTCGTCCGCGGAGTGACAGGGGTCCCTCTGGGCCGGAGCCGGCGGCAGTGGTGGCAGCGGTATCGCCGCCCTAGCTCAC',\n",
       "       b'$$$$$$$$$$$$$$$$CCTTTCCCAGAGTGCTCTGCGCCGTGAAGAAGCGGCTCCCGGGGACTGGGGGCATTTTGTGTTGGCTGGAGCTGGAGTAACAAGATGGCGTCGTCCGCGGAGTGACAGGGGTCCCTCTGGGCCGGAGCCGGCGGCAGTGGTGGCAGCGGTATCGCCGCCCTAGCTCACCGCGCCCCTTTTCCAGCCC',\n",
       "       b'CCTTCACAAACTGCGGCCTGGCAAAAAGAAACCTGACTGAGCGGCGGTGATCAGGTTCCCCTCTGCTGATTCTGGGCCCCGAACCCCGGTAAAGGCCTCCGTGTTCCGTTTCCTGCCGCCCTCCTCCGTAGCCTTGCCTAGTGTAGGAGCCCCGAGGCCTCCGTCCTCTTCCCAGAGGTGTCGGGGCTTGGCCCCAGCCTCCA',\n",
       "       b'TGACTGAGCGGCGGTGATCAGGTTCCCCTCTGCTGATTCTGGGCCCCGAACCCCGGTAAAGGCCTCCGTGTTCCGTTTCCTGCCGCCCTCCTCCGTAGCCTTGCCTAGTGTAGGAGCCCCGAGGCCTCCGTCCTCTTCCCAGAGGTGTCGGGGCTTGGCCCCAGCCTCCATCTTCGTCTCTCAGGATGGCGAGTAGCAGCGGC',\n",
       "       b'CCCTCCTCCGTAGCCTTGCCTAGTGTAGGAGCCCCGAGGCCTCCGTCCTCTTCCCAGAGGTGTCGGGGCTTGGCCCCAGCCTCCATCTTCGTCTCTCAGGATGGCGAGTAGCAGCGGCTCCAAGGCTGAATTCATTGTCGGAGGGAAATATAAACTGGTACGGAAGATCGGGTCTGGCTCCTTCGGGGACATCTATTTGGCGA',\n",
       "       b'GGCGAGTAGCAGCGGCTCCAAGGCTGAATTCATTGTCGGAGGGAAATATAAACTGGTACGGAAGATCGGGTCTGGCTCCTTCGGGGACATCTATTTGGCGATCAACATCACCAACGGCGAGGAAGTGGCAGTGAAGCTAGAATCTCAGAAGGCCAGGCATCCCCAGTTGCTGTACGAGAGCAAGCTCTATAAGATTCTTCAAG',\n",
       "       b'AGTAGCAGCGGCTCCAAGGCTGAATTCATTGTCGGAGGGAAATATAAACTGGTACGGAAGATCGGGTCTGGCTCCTTCGGGGACATCTATTTGGCGATCAACATCACCAACGGCGAGGAAGTGGCAGTGAAGCTAGAATCTCAGAAGGCCAGGCATCCCCAGTTGCTGTACGAGAGCAAGCTCTATAAGATTCTTCAAGGTGG',\n",
       "       b'CGGAGGGAAATATAAACTGGTACGGAAGATCGGGTCTGGCTCCTTCGGGGACATCTATTTGGCGATCAACATCACCAACGGCGAGGAAGTGGCAGTGAAGCTAGAATCTCAGAAGGCCAGGCATCCCCAGTTGCTGTACGAGAGCAAGCTCTATAAGATTCTTCAAGGTGGGGTTGGCATCCCCCACATACGGTGGTATGGTC',\n",
       "       b'CCAGTTGCTGTACGAGAGCAAGCTCTATAAGATTCTTCAAGGTGGGGTTGGCATCCCCCACATACGGTGGTATGGTCAGGAAAAAGACTACAATGTACTAGTCATGGATCTTCTGGGACCTAGCCTCGAAGACCTCTTCAATTTCTGTTCAAGAAGGTTCACAATGAAAACTGTACTTATGTTAGCTGACCAGATGATCAGTA',\n",
       "       b'CCGCCTGGTCTCGCGGCGCTGGCCTGTGGGCGGAGCGAGCCCTGAAAGGCTATAGGCGAGGGGGCGGCTCCGCGGGGCCGGGCGAGGAGTCCAGAGAGCCATGGCCGCCCTGCGTGTCCTGCTGTCCTGCGTCCGCGGCCCGCTGAGGCCCCCGGTTCGCTGTCCCGCCTGGCGTCCCTTCGCCTCGGGTGCTAACTTTGAGT',\n",
       "       b'$GGTGGGCCCACACAAGCGGCGCACCGTTAAGATGGCGGCTGGGCTGCGGAAACGCGGCCGGTCCGGTTCCGCGGCCCAGGCAGAGGGACTCTGCAAGCAATGGCTGCAGCGCGCCTGGCAAGAGCGGCGCCTGCTGCTGCGGGAGCCGCGCTACACGCTGCTGGTGGCCGCCTGCCTCTGCCTGGCGGAGGTGGGCATCACC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGTGGGCCCACACAAGCGGCGCACCGTTAAGATGGCGGCTGGGCTGCGGAAACGCGGCCGGTCCGGTTCCGCGGCCCAGGCAGAGGGACTCTGCAAGCAATGGCTGCAGCGCGCCTGGCAAGAGCGGCGCCTGC',\n",
       "       b'CTCGGCTATTTATCCCCAGCTGCGGGAGGCCCTGGTGACTCTGCTGCTGCAGTGTCTGGTTTCCCTGTGACCTGCAGGTACTGGGAGTTACATAGCTAAGATGCCAGGACACCCCGAAAGCCGGAAAACGGGACTACTGGCATTCAGTGATGTGGTCATAGAATTCTCTCCAGAGGAGTGGGCATGCCTGGACCCTGCCCAGC',\n",
       "       b'CCTGCCCAGCGAAATTTGTATAGGGATGTGATGTTCGAGAACTACAGAAACCTGGTCTCCCTGGGACTTCCAGGACTATGTTAAAATAGAAGCATTGATAATGGGCACAATATCACTTTGCATTGGTGTCTGTGCATTTGAAGGAGCAAACACCTCTACCAGTTTTTATAAACTGGTTTATACAGCTATTTTATCTTATTCCA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGGAGATTCGGGACCATGGCACCTGTGCACGGCGACGACTCTCTGTCAGATTCAGGGAGTTTTGTATCTTCTCGAGCCCGGCGAGAAAAAAAATCAAAGAAGGGGCGCCAAGAAGCCC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CGGCAAGCAGGTCTAGGAATTCGCCTGGTTCCCACCTCGCGTCCCTTGCCTTCCTTCCTAGTCTACCCACTGTAGTGCCCCCTGCGTCCCGCTCCCTCCTAGCCGACTCAGAGCACAAGAA',\n",
       "       b'CGACGGCGGGCTGTCGTCACGACGACGTGCGGACGCAGCGGCGGGGGCCTTATGTGGAGAAGTCGCTGTGAAGCCACCTATAAATCCATTTACTGAATTTATGGAGAAGGCTGTAAATGATGGAAGTCATTCAGAAGAACTCTTTTGCCATCTTAAAACTATATCAGAGAAAGAAGATTTACCACGGTGTACCAGTGAAAGTC',\n",
       "       b'CGTCAGTGGCACGCACAGCAGCCGCAGCCGCCTCGCGCCCGGTCCCGCGGTCGCAGCTCCAGCCGCCTCCTCCGCGCAGCCGCCGCCTCAGCTGCTCGCTCTGTGGGTCGGTCCTCTCCGGCACTTGGGCTCCAGTCGCGCCCTCCAAGCCCTTCAGGCCGCCCCAGTGTCCTCCTCCTTCTCCGGCCAGACCCAGCCCCGCG',\n",
       "       b'GTCGGTCCTCTCCGGCACTTGGGCTCCAGTCGCGCCCTCCAAGCCCTTCAGGCCGCCCCAGTGTCCTCCTCCTTCTCCGGCCAGACCCAGCCCCGCGAAGATGGTGGACCGCGAGCAACTGGTGCAGAAAGCCCGGCTGGCCGAGCAGGCGGAGCGCTACGACGACATGGCCGCGGCCATGAAGAACGTGACAGAGCTGAATG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CGGAGTTGTCGTGTGTTCTGGATTCATTCCGGCACCACCATGTCGAAGGTTTCCTTTAAGATCACGCTGACGTCGGACCCACGGCTGCCGTACAAAGTACTCAGTGTTCCTGAAAGTACA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CGGAGTTGTCGTGTGTTCTGGATTCATTCCGGCACCACCATGTCGAAGGTTTCCTTTAAGATCACGCTGACGTCGGACCCACGGCTGCCGTACAAAGTACTCAGTGTTCCTGAAAGTACACCTTTCACAGCAGTCTTAAAGT',\n",
       "       b'TTATGGACATACTGCTAGTGGAAAGACCTATGTAACACAAACGTTGTTGAAAACTTTAGAGCTCCCACATGTGTTTGTGAATTGTGTTGAATGCTTTACATTGAGGCTGCTTTTGGAACAAATTTTAAACAAATTGAATCATCTTAGTTCTTCAGAGGATGGATGTTCTACTGAAATAACCTGTGAAACATTTAATGACTTTG',\n",
       "       b'TTCCGGCGGGAGCGTGGGCCGCCAGACTCGGGAGAGGCTCCGTCTTGTGCAAGGGTCCTGTGGGCTGGCTGCACTGGCCTCTGCGGTGGTGCCTGCCAGAATGCCCCACTTGGAAAACGTGGTGCTTTGTCGCGAGTCTCAAGTGTCCATCTTGCAGTCCTTGTTTGGAGAGAGACATCATTTCAGCTTTCCATCCATTTTTA',\n",
       "       b'TGAGCGAAATTCAAGCTCCAAACTCTAAGCTCCAAGCTCCAAGCTCCAAGCTCCAAGCTCCAAACTCCCGCCGGGGTAACTGGAACCCAATCCGAGGGTCATGGAGGCATCCCGAAGGTTTCCGGAAGCCGAGGCCTTGAGCCCAGAGCAGGCTGCTCATTACCTAAGATATGTGAAAGAGGCCAAAGAAGCAACTAAGAATG',\n",
       "       b'CGGAATGAGGCTTCGAGGCCGGCTAGGGGAGGCCGTCGCTCATATCCGACGTCACCAGTTCGCGCCGGCGATAGACGAGGACGCCAACAGCAGCGGAGAAACGTTTCTCTTTCCTCTCAGTTTGCGCACACCATGGCGGCCCCTGCCCAGCAGACTACTCAGCCTGGCGGCGGGAAGCGCAAAGGCAAGGCTCAGTATGTGCT',\n",
       "       b'CCGTCGCTCATATCCGACGTCACCAGTTCGCGCCGGCGATAGACGAGGACGCCAACAGCAGCGGAGAAACGTTTCTCTTTCCTCTCAGTTTGCGCACACCATGGCGGCCCCTGCCCAGCAGACTACTCAGCCTGGCGGCGGGAAGCGCAAAGGCAAGGCTCAGTATGTGCTGGCCAAGCGCGCTCGGCGCTGCGACGCTGGCG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCGAGCGGGCTGGGGGAGGGGAGCGTGGGGCCGACAGTTTTGGGGGTGAAAAGGCAAAAGGCGGGTGAAAGGCTGCCTCCCGAGACTCTCCTTGCTTGGAATTCTGCCCACTCTGCGGAGTTAGCAGTCACGACCTCCAGCACAGGATGTGGTACCACAGATTGTCCCACCTACA',\n",
       "       b'TGAAAAGGCAAAAGGCGGGTGAAAGGCTGCCTCCCGAGACTCTCCTTGCTTGGAATTCTGCCCACTCTGCGGAGTTAGCAGTCACGACCTCCAGCACAGGATGTGGTACCACAGATTGTCCCACCTACACAGCAGGCTTCAGGACTTGCTGAAGGGAGGAGTCATATATCCGGCCCTTCCACAGCCCAACTTCAAAAGCTTAC',\n",
       "       b'CGCGGCCCTGCGGGGTGAGGCTGCCGTTTGCTGAGTGTCCGGCAGGGGTCTGCTCGCTGCCAGCCCGGCCCCTCCTCAGAGCAGCTGCCGCAGCCCGAGGATGTCGGAGGAGATCATCACGCCGGTGTACTGCACTGGGGTGTCAGCCCAAGTGCAGAAGCAGCGGGCCAGGGAGCTGGGCCTGGGCCGCCATGAGAATGCCA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GAGGTCAGAGACTTAAGTCTAAGGCACTGAGCGTATCATGTTAAAGATGAGCGGGTGGCAGCGACAGAGCCAAAATCAGAGCTGGAACCTGAGGAGAGAGTGTTCAAGAAGGAAGTGTATCTTCATACATCACCACACCT',\n",
       "       b'ATATGTAAATAAACAGATGTGGCTGTATTCCAGTACAACTTTACCTACAAAAACAGGCATCAGACCAGCTTGCCAACTTGTGGCATAGACTGTTTGCTACATGGAGCTTGTTCCAGCCACTCCCCATTATCCTGCAGATGTGCTTTTCCAGACTGATCCAACTGCAGAGATGGCAGCTGAGTCATTGCCTTTCTCCTTCGGGA',\n",
       "       b'GACTATCGTGATAGACAAGCGAGATCGACGCTGGCCCTTTAATAGCCCTTTCCCGGGGTCCTGCCCCGCGCGTGCGCACTGTGGTTCTGCGCTTGTCATCATGGCGACGCGGGGCCATGTGCAGGACCCTAACGACAGGCGCCTCCGGCCCATTTACGATTATCTTGACAATGGTAATAATAAAATGGCAATTCAGCAAGCAG',\n",
       "       b'TGCAGAGCTTTCAACCTCCGCGCCGGCTGCGCCTGTTTCTCGGCCAGGGGAGCAAGGCCACGCGGCCTACGCAGCCGAGTCGGAACCAACCGGTTGTTTGGTGAAACCTACCCCAGAGCCTCCCGCGGCCCACAGAGCACAGACAGAATCTCCCTCTGTCACCCAGGCTGGAGTGCAGTGGCATGATCTCGGCTCACTGCAAC',\n",
       "       b'GCTGCTTCCCTTTATAAGGACACTCCCACTGTTGTGCTATAATCATCTCTTGGTATCTCCGGACTCTGCCACTCTGAGCCCTCCTTACAGCCTAGAAAAAATGACAGATCTCGTAGCTGTTTGGGATGTTGCTTTAAGTGACGGAGTCCACAAGATCGAATTTGAACATGGGACTACATCAGGCAAACGAGTAGTATATGTAG',\n",
       "       b'CGGGGTGTGAGCCATCGCGCCTGGCCACTTTCTCCAAAGTTTTAAACCAAAGCCTTCTTCGGCAGAGCTACGACCCTTCCTCTATGGCCCATTCTATCCTATGCTGCTTCCCTTTATAAGGACACTCCCACTGTTGTGCTATAATCATCTCTTGGTATCTCCGGACTCTGCCACTCTGAGCCCTCCTTACAGCCTAGAAAAAA',\n",
       "       b'GGGGCGCTGCCCCGAGACTGGGTGGGGAGGGAAAGAAGGTGGTGCGAAAACGCGTTTGAACTTGGGTCCTGCCGCTGCCCGTAGCCGGCGTCCCCAACATGGCGGCTCCCCAAGACGTCCACGTCCGGATCTGTAACCAAGAGATTGTCAAATTTGACCTGGAGGTGAAGGCGCTTATTCAGGATATCCGTGATTGTTCAGGA',\n",
       "       b'AGGGGGCGCTGCCCCGAGACTGGGTGGGGAGGGAAAGAAGGTGGTGCGAAAACGCGTTTGAACTTGGGTCCTGCCGCTGCCCGTAGCCGGCGTCCCCAACATGGCGGCTCCCCAAGACGTCCACGTCCGGATCTGTAACCAAGAGATTGTCAAATTTGACCTGGAGGTGAAGGCGCTTATTCAGGATATCCGTGATTGTTCAG',\n",
       "       b'CGATGCCGCTATAAAGGCTTGTTTTGCTGCAGGGCTCATGCTCGGGAGCGTGGTTGAGCGGCTGGCGCGGTTGTCCTGGAGCAGGGGCGCAGGAATTCTGATGTGAAACTAACAGTCTGTGAGCCCTGGAACCTCCACTCAGAGAAGATGAAGGATATCGACATAGGAAAAGAGTATATCATCCCCAGTCCTGGGTATAGAAG',\n",
       "       b'GCGTGGTTGAGCGGCTGGCGCGGTTGTCCTGGAGCAGGGGCGCAGGAATTCTGATGTGAAACTAACAGTCTGTGAGCCCTGGAACCTCCACTCAGAGAAGATGAAGGATATCGACATAGGAAAAGAGTATATCATCCCCAGTCCTGGGTATAGAAGTGTGAGGGAGAGAACCAGCACTTCTGGGACGCACAGAGACCGTGAAG',\n",
       "       b'CACGTCGTTCCCCGCCCTCCCGCCGCCGCCCGCCCTCGCTCTCTCGCGCTACCCTCCCGCCGCCCGCGGTCCTCCGTCGGTTCTCTCGTTAGTCCACGGTCTGGTCTTCAGCTACCCGCCTTCGTCTCCGAGTTTGCGACTCGCGGACCGGCGTCCCCGGCGCGAAGAGGCTGGACTCGGATTCGTTGCCTGAGCAATGGCTG',\n",
       "       b'CCTCGCTCTCTCGCGCTACCCTCCCGCCGCCCGCGGTCCTCCGTCGGTTCTCTCGTTAGTCCACGGTCTGGTCTTCAGCTACCCGCCTTCGTCTCCGAGTTTGCGACTCGCGGACCGGCGTCCCCGGCGCGAAGAGGCTGGACTCGGATTCGTTGCCTGAGCAATGGCTGCCATCCGGAAGAAACTGGTGATTGTTGGTGATG',\n",
       "       b'CCTCCGTCGGTTCTCTCGTTAGTCCACGGTCTGGTCTTCAGCTACCCGCCTTCGTCTCCGAGTTTGCGACTCGCGGACCGGCGTCCCCGGCGCGAAGAGGCTGGACTCGGATTCGTTGCCTGAGCAATGGCTGCCATCCGGAAGAAACTGGTGATTGTTGGTGATGGAGCCTGTGGAAAGACATGCTTGCTCATAGTCTTCAG',\n",
       "       b'CGGTCTGGTCTTCAGCTACCCGCCTTCGTCTCCGAGTTTGCGACTCGCGGACCGGCGTCCCCGGCGCGAAGAGGCTGGACTCGGATTCGTTGCCTGAGCAATGGCTGCCATCCGGAAGAAACTGGTGATTGTTGGTGATGGAGCCTGTGGAAAGACATGCTTGCTCATAGTCTTCAGCAAGGACCAGTTCCCAGAGGTGTATG',\n",
       "       b'$$GGTCCGGGTTCGCTTGCCTCGTCAGCGTCCGCGTTTTTCCCGGCCCCCCCCAACCCCCCCGGACAGGACCCCCTTGAGCTTGTCCCTCAGCTGCCACCATGAGCGACCAAGATCACTCCATGGATGAAATGACAGCTGTGGTGAAAATTGAAAAAGGAGTTGGTGGCAATAATGGGGGCAATGGTAATGGTGGTGGTGCCT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$GTCTCTCCCTTCAGCCCGAGCTCCGGGTCTCGTCTTCACTGCTCTGTGTCCTCTTCTTCTAGAGGCCCAGCCTCTATGGCCCTCTGACCTGCAGGTATTGGCGATCCATAGCTAAGACGCCAGGTCCCCCGGAAACCTAGAAATGGAACCATTGAAATTTAGGGATGTGGCCATAGAA',\n",
       "       b'TCTGTGTCCTCTTCTTCTAGAGGCCCAGCCTCTATGGCCCTCTGACCTGCAGGTATTGGCGATCCATAGCTAAGACGCCAGGTCCCCCGGAAACCTAGAAATGGAACCATTGAAATTTAGGGATGTGGCCATAGAATTCTCTCTGGAGGAGTGGCAATGCCTGGACACTATACAGCAGAATTTATATAGGAATGTGATGTTAG',\n",
       "       b'$$$$$$$CAGGCGCAGTCCCGACGAGCAACGCGTTTGTAGAGGGGTGGGTGCGCACGCTCTGTCCCTGCGTGACCTTCCGACCCCGCTGTCCTCACCGCAATGGCGGCTGTGAGGGTCCTGGTGGCCTCGAGGCTCGCTGCGGCATCTGCATTCACGTCCCTGTCCCCCGGCGGTCGGACGCCTTCCCAGCGCGCAGCCCTTC',\n",
       "       b'CAGGCGCAGTCCCGACGAGCAACGCGTTTGTAGAGGGGTGGGTGCGCACGCTCTGTCCCTGCGTGACCTTCCGACCCCGCTGTCCTCACCGCAATGGCGGCTGTGAGGGTCCTGGTGGCCTCGAGGCTCGCTGCGGCATCTGCATTCACGTCCCTGTCCCCCGGCGGTCGGACGCCTTCCCAGCGCGCAGCCCTTCACCTCTC',\n",
       "       b'TCCCGGAAGTGCGTGCTGTGGGCGGTGCCGCGCGGACCCCCGGGAAGTGTCTCTGTGGGCGGCCGCCGGGTTGAGCTGCGGCACACGTGCGACGGCCGTGATGAAGTTCGCTTACCGGTTTTCAAATTTGCTGGGTACGGTGTACCGGCGTGGGAACCTAAATTTTACCTGCGATGGAAATTCAGTTATCAGTCCCGTGGGCA',\n",
       "       b'ACTATGCACTGGGGGGACATAAGGATGCCATCGTGGCCTGCTTCTTTGAATCCAACAGCCTGGACCTGTACTCACTCAGCCAGGACGGAGTGCTGTGCATGTGGCAGTGTGACACGCCCCCCGAGGGCTTGCGGCTGAAGCCCCCTGCGGGCTGGAAAGCAGACCTGTTGCAGCGGGAGGAGGAAGAGGAGGAGGAGGAGGAC',\n",
       "       b'CAACGGCCGGGGGAGGAGAAGGCGGCAGCGGCGATTCTAGGCGGCCCAGGCGGCGGGGAGGAGGAGAAGGAGGAGGGTGGCGGCCGGGCTTGGCTTCGGCTCCTTGAGGAGTTGGCGGCGGCGCGACCCGGGGAACCGGCATTGATGTCCAGCTCGCCGCTGTCCAAGAAACGTCGCGTGTCCGGGCCTGATCCAAAGCCGGG',\n",
       "       b'CCCAGGCGGCGGGGAGGAGGAGAAGGAGGAGGGTGGCGGCCGGGCTTGGCTTCGGCTCCTTGAGGAGTTGGCGGCGGCGCGACCCGGGGAACCGGCATTGATGTCCAGCTCGCCGCTGTCCAAGAAACGTCGCGTGTCCGGGCCTGATCCAAAGCCGGGTTCTAACTGCTCCCCTGCCCAGTCCGTGTTGTCCGAAGTGCCCT',\n",
       "       b'GCTTCGGCTCCTTGAGGAGTTGGCGGCGGCGCGACCCGGGGAACCGGCATTGATGTCCAGCTCGCCGCTGTCCAAGAAACGTCGCGTGTCCGGGCCTGATCCAAAGCCGGGTTCTAACTGCTCCCCTGCCCAGTCCGTGTTGTCCGAAGTGCCCTCGGTGCCAACCAACGGAATGGCCAAGAACGGCAGTGAAGCAGACATAG',\n",
       "       b'GATGTCCAGCTCGCCGCTGTCCAAGAAACGTCGCGTGTCCGGGCCTGATCCAAAGCCGGGTTCTAACTGCTCCCCTGCCCAGTCCGTGTTGTCCGAAGTGCCCTCGGTGCCAACCAACGGAATGGCCAAGAACGGCAGTGAAGCAGACATAGACGAGGGCCTTTACTCCCGGCAGCTGTATGTGTTGGGCCATGAGGCAATGA',\n",
       "       b'CAAGAAACGTCGCGTGTCCGGGCCTGATCCAAAGCCGGGTTCTAACTGCTCCCCTGCCCAGTCCGTGTTGTCCGAAGTGCCCTCGGTGCCAACCAACGGAATGGCCAAGAACGGCAGTGAAGCAGACATAGACGAGGGCCTTTACTCCCGGCAGCTGTATGTGTTGGGCCATGAGGCAATGAAGCGGCTCCAGACATCCAGTG',\n",
       "       b'GAACGGCAGTGAAGCAGACATAGACGAGGGCCTTTACTCCCGGCAGCTGTATGTGTTGGGCCATGAGGCAATGAAGCGGCTCCAGACATCCAGTGTCCTGGTATCAGGCCTGCGGGGCCTGGGCGTGGAGATCGCTAAGAACATCATCCTTGGTGGGGTCAAGGCTGTTACCCTACATGACCAGGGCACTGCCCAGTGGGCTG',\n",
       "       b'CGGCTCCAGACATCCAGTGTCCTGGTATCAGGCCTGCGGGGCCTGGGCGTGGAGATCGCTAAGAACATCATCCTTGGTGGGGTCAAGGCTGTTACCCTACATGACCAGGGCACTGCCCAGTGGGCTGATCTTTCCTCCCAGTTCTACCTGCGGGAGGAGGACATCGGTAAAAACCGGGCCGAGGTATCACAGCCCCGCCTCGC',\n",
       "       b'AGAAGTACAGGGCATGGTTGAACTCAACGGAAATCAGCCCATGGAGATCAAAGTCCTGGGTCCTTATACCTTTAGCATCTGTGACACCTCCAACTTCTCCGACTACATCCGTGGAGGCATCGTCAGTCAGGTCAAAGTACCTAAGAAGATTAGCTTTAAATCCTTGGTGGCCTCACTGGCAGAACCTGACTTTGTGGTGACGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CGCGGAGCTTGTGGCGCCAGAATTCGGAGCGCGGAAGAGCCAGAGCTGCGAGCGCCTGGAGCTGGATCTCTCTCCGGTCGCGCACGCCGAGGCCAGTAGGGAGAGAAGATGGTGGTTCTCCGCAGCAGCTTGGAGCTGCACAACCACTCCGCGGCCTCGGCCAC',\n",
       "       b'TTGTGGCGCCAGAATTCGGAGCGCGGAAGAGCCAGAGCTGCGAGCGCCTGGAGCTGGATCTCTCTCCGGTCGCGCACGCCGAGGCCAGTAGGGAGAGAAGATGGTGGTTCTCCGCAGCAGCTTGGAGCTGCACAACCACTCCGCGGCCTCGGCCACGGGCTCCTTGGACCTGTCCAGTGACTTCCTCAGTCTGGAGCACATCG',\n",
       "       b'CCGGGCCGCGAGACCCCGCTCGCCCGGCCACTCGTGCTCCCACACGGACGGGCGCGCCGCCAACCCGGTGCTGACTGGGTTACTTTTTTAAACACTAGGAATGGTAATTTCTACTCTTCTGGACTTCAAACTAAGAAGTTAAAGAGACTTCTCTGTAAATAAACAAATCTCTTCTGCTGTCCTTTTGCATTTGGAGACAGCTT',\n",
       "       b'GAGACTTCTCTGTAAATAAACAAATCTCTTCTGCTGTCCTTTTGCATTTGGAGACAGCTTTATTTCACCATATCCAAGGAGTATAACTAGTGCTGTCATTATGAATGTGACAAGTTTATTTTCCTTTACAAGTCCAGCTGTGAAGAGACTTCTTGGGTGGAAACAGGGCGATGAAGAAGAAAAATGGGCAGAGAAAGCTGTTG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ATTTCCGGGGTAAGATGGCTGCAGTCCGTATGCTGAGAACCTGGAGCAGGAATGCGGGGAAGCTGATTTGTGTTCGCTATTTTCAAACATGTGGTAATGTTCATGTTTTGAAGCCAA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGACGTCGCTTCCGGAGCAGCATGGCGGCCACTGAGGATGAGAGGCTAGCAGGGAGCGGTGAGGGAGAGCGGCTGGATTTCTTACGGGATCGGCACGTGCGATTTTTCCAGCGCTGCCTCCAGGTT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGACGTCGCTTCCGGAGCAGCATGGCGGCCACTGAGGATGAGAGGCTAGCAGGGAGCGGTGAGGGAGAGCGGCTGGATTTCTTACGGGATCGGCACGTGCGATTTTTCCAGCGCTGCCTCCAGG',\n",
       "       b'CGCCTGACTGGGCTCCTCCCCGGGCCCGCCCCGACAGGTTTGTCTTGTGACCGCGGGCGGCCGCTGCTTCTTTCCCGAGCTTGGAACTTCGTTATCCGCGATGCGTTTCCTGGCAGCTACATTCCTGCTCCTGGCGCTCAGCACCGCTGCCCAGGCCGAACCGGTGCAGTTCAAGGACTGCGGTTCTGTGGATGGAGTTATAA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGGCGGGAGCGGGGAAAACAAAAGGAGACGAAGGACGCATGCGTTTGGTGAGTCCCGGATTCTGGTGGGTTCTTCCGCTCAGGCTGGGTGAAGCGCTTCCGGGTCGCCGCCGGCAGCAGCCTCCCGGCGCGATGAAGACAC',\n",
       "       b'GCGCGATGAAGACACTGAGGCTCAGAGAGGTTAAGTGACTCAGCCAAGGTCAAACAGCTAGTAAGTGGTGGAGCCAGGACTCAAAGCCAGTCTAGGAGCCATGTCCACTTTGTTCCCCTCACTCTTCCCTCGTGTGACTGAGACTCTGTGGTTTAATCTGGATCGACCCTGTGTGGAAGAGACAGAGCTGCAGCAGCAGGAAC',\n",
       "       b'AGTGAAAGTACAGCCGCGCCGCCCCAAGTCAGCCTGGACACATAAATCAGCACGCGGCCGGAGAACCCCGCAATCTCTGCGCCCACAAAATACACCGACGATGCCCGATCTACTTTAAGGGCTGAAACCCACGGGCCTGAGAGACTATAAGAGCGTTCCCTACCGCCATGGAACAACGGGGACAGAACGCCCCGGCCGCTTCG',\n",
       "       b'CCGCAATCTCTGCGCCCACAAAATACACCGACGATGCCCGATCTACTTTAAGGGCTGAAACCCACGGGCCTGAGAGACTATAAGAGCGTTCCCTACCGCCATGGAACAACGGGGACAGAACGCCCCGGCCGCTTCGGGGGCCCGGAAAAGGCACGGCCCAGGACCCAGGGAGGCGCGGGGAGCCAGGCCTGGGCCCCGGGTCC',\n",
       "       b'GCCTCTTTCTCTCTTGCTCAGCAGGGAGTCCAGAGCCCTGGAGGAAAGCCAGCTCAGCTCCGCATCGGCGTCGGCGGTTGGGACGCACACACTCTGCGTCATGGAGGGCTGAGGCCGATGATGAATTCCGGAGTGCCTGTCAGGCTTGCTGTGTCACTCGGCCCGCTCGGCGCGCCCCTTCCCAGCCGCCCTTCCGTACCGGC',\n",
       "       b'TGCAGGCTCTTCTCCCGCCGCGGCCCGGCGCTCTCCGAGTCGCCCCTGCGGACTGGTCTCGCACAGTGCCTGGGCACCGGGCGCCAGACAGACACTGGCCATGACGAGCGGCGCAACCAGGTACCGGCTGAGCTGCTCGCTCCGGGGCCACGAGCTGGACGTACGGGGCCTGGTGTGCTGCGCCTATCCGCCGGGAGCCTTTG',\n",
       "       b'CTTAGGACCGCTTACTTTGCTTACTCGTTTTCTATTCCTCGCGTACTGCCTCGTCCACCACTCCAGGACCAAAAGAGGAAGATAGTCTTGGGACCCTTGCATGGTGTTTCAAAGGGTGGTGAAGAACTAAGGTAGAAGAATACATGTTCACTTCCAGTGAACAAGAGCATGTTCCCAAACTCAATTTTGGGTCGCCCACCCTT',\n",
       "       b'CCAAAAGAGGAAGATAGTCTTGGGACCCTTGCATGGTGTTTCAAAGGGTGGTGAAGAACTAAGGTAGAAGAATACATGTTCACTTCCAGTGAACAAGAGCATGTTCCCAAACTCAATTTTGGGTCGCCCACCCTTCACTCCAAATCATCAACAACATAATAACTTCTTTACCCTGTCACCTACTGTTTATTCACACCAGCAGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGTTTGCACGCCGGACCGGAGAGCGCGGAGGCAGCCATGGTGCGGTTCAAGCACAGGTACCTGCTCTGCGAACTGGTGTCTGACGACCCCCGCTGCCGCCTAAGCCTCGATGACCGAGTTCTGAGCAGCCTCGTACGGG',\n",
       "       b'GCGGACCGTTGGGCGGTTCCGCGGGGCGTTGTCCGGAGAGCTGCGAGGCCGGGGTTCCCAGGGTTCACGCCACACTCTAGGAAGTGCCTGAGCTAGTGAGCTGGCCAACGAGCTCCGCGGGCTGGGACCATGGGCTGCTTCTTCTCCAAGAGACGGAAGGCTGACAAGGAGTCGCGGCCCGAGAACGAGGAGGAGCGGCCAAA',\n",
       "       b'TGTCCGGAGAGCTGCGAGGCCGGGGTTCCCAGGGTTCACGCCACACTCTAGGAAGTGCCTGAGCTAGTGAGCTGGCCAACGAGCTCCGCGGGCTGGGACCATGGGCTGCTTCTTCTCCAAGAGACGGAAGGCTGACAAGGAGTCGCGGCCCGAGAACGAGGAGGAGCGGCCAAAGCAGTACAGCTGGGATCAGCGCGAGAAGG',\n",
       "       b'$$$$$$$$$$$$$GGATACGTCGACAATAGATGACGGGGCTCACGTTGTACGTTCACATCAGGTCCCGGCCCGCCGGAACCTGGGCGATCCACGATGCCGAGTTTGCCACGCTGCGACAGCCCATAGGCTTGCCCCCCCGGGCATTCGGGTGGACTACGAACACAAACTGAAGCCCTAGGACTTGTCGCCCGTTTGCGCTCTC',\n",
       "       b'TCCGAAAACTAAGAGGTAGGTGGTAGCCCATTCATCTGGTTACTGATACTGGCCGGCATCAGTGGACTGTCGGCAGGTCCTTGAGCAACTGGTGTGTGAAATGGGACGGACGTCAAAGGACAAGCGGGATGTCTACTACCGCCTGGCCAAGGAGAATGGCTGGCGTGCTCGCAGCGCCTTCAAACTGCTACAACTGGATAAGG',\n",
       "       b'GCGGGGCCCGCCCCTGGGACCCTCCGGGCCGGGCGGTTTGGCCCCTTAGCGCCCGGGCGTCGGGGCGGTAAAAGGCCGGCAGAAGGGAGGCACTTGAGAAATGTCTTTCCTCCAGGACCCAAGTTTCTTCACCATGGGGATGTGGTCCATTGGTGCAGGAGCCCTGGGGGCTGCTGCCTTGGCATTGCTGCTTGCCAACACAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCTCTCGCGTCCTTTGCTGGGTCCAGACACCGGTACGTCCGGGCGGGTTTTTAGTCTCCCAAGCGAGAGCGTCGCATTCACCCGCGTGGGTCTGCGGGCGCCCCAGACCCCAGAGGACC',\n",
       "       b'CTCCTTCCGCTCCGCCCGCCTGGAGTCCTTCTGGCCGGATTCCGCGGCATCCTTCCATAGACCCTCGTTGTTGCTTCCTCCTTGTGGTTCCGTTGCAAACATTTTTAAAGGGCTGGTTATTCTTCCTGAAATGAGTTTGGTGATTAGAAATCTGCAGCGAGTCATCCCCATCAGGAGAGCGCCACTTCGCAGTAAGATCGAGA',\n",
       "       b'CGCCCGCCTGGAGTCCTTCTGGCCGGATTCCGCGGCATCCTTCCATAGACCCTCGTTGTTGCTTCCTCCTTGTGGTTCCGTTGCAAACATTTTTAAAGGGCTGGTTATTCTTCCTGAAATGAGTTTGGTGATTAGAAATCTGCAGCGAGTCATCCCCATCAGGAGAGCGCCACTTCGCAGTAAGATCGAGATTGTAAGGAGGA',\n",
       "       b'CTGGCCGGATTCCGCGGCATCCTTCCATAGACCCTCGTTGTTGCTTCCTCCTTGTGGTTCCGTTGCAAACATTTTTAAAGGGCTGGTTATTCTTCCTGAAATGAGTTTGGTGATTAGAAATCTGCAGCGAGTCATCCCCATCAGGAGAGCGCCACTTCGCAGTAAGATCGAGATTGTAAGGAGGATTTTAGGAGTGCAGAAAT',\n",
       "       b'CCGGCCCGCGTCCCGTCAGGCGCCGCGCGGGGTTAGCGCGGGGTCAGCGGAGGTCAGCGGGGGTCAGCAGCAGCGGCTCCGAGGGCGCGGCGGACGCAGGATGTACACGCTGCTGTCGGGCTTGTACAAGTACATGTTTCAGAAGGACGAGTACTGCATCCTGATCCTGGGCCTGGACAATGCTGGGAAGACGACCTTCCTGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$AGGCCCCGCTTCGCGCTAACGCTTGCGATGGTTGAATTCCCCTCCTCACGCCAGCCTAGGAGAAGAAGTTCGTAGTCCCAGAGGTGAGGCAGGAGGCGGCAGTTTCTGGCGGGTGAGGGCGGAGCTGAAG',\n",
       "       b'ACGGTCGGTGGGGCGGAGAAGGGGGCTGGCCCCAGGAGGAGGAGGAAACCCTTCCGAGAAAACAGCAACAAGCTGAGCTGCTGTGACAGAGGGGAACAAGATGGCGGCGCCGAAGGGGAGCCTCTGGGTGAGGACCCAACTGGGGCTCCCGCCGCTGCTGCTGCTGACCATGGCCTTGGCCGGAGGTTCGGGGACCGCTTCGG',\n",
       "       b'$$$$$$$$$$$$$$$$$GGCGGCTTCCGGGATTTGGCGGTGGCCTTTGTTGGCTGCAGTAAGAGCTCAGTCTCTTCACCAGGGGCTCCCAGTCCTTCCATCTGGGAGGCCAAGGCGGCTTCGCGTTCTGAGAATAGACAGAACCTCTGTTACTCTGTGACCGGCAGGCACCGGGAGATCCGTAGCTCAGACGCCAGGACATCC',\n",
       "       b'TGCAGTAAGAGCTCAGTCTCTTCACCAGGGGCTCCCAGTCCTTCCATCTGGGAGGCCAAGGCGGCTTCGCGTTCTGAGAATAGACAGAACCTCTGTTACTCTGTGACCGGCAGGCACCGGGAGATCCGTAGCTCAGACGCCAGGACATCCCGGAAGCTGGGAAATGGGACTGTTGACATTCAGGGATGTGGCCATAGAATTCT',\n",
       "       b'GCTTCGCGTTCTGAGAATAGACAGAACCTCTGTTACTCTGTGACCGGCAGGCACCGGGAGATCCGTAGCTCAGACGCCAGGACATCCCGGAAGCTGGGAAATGGGACTGTTGACATTCAGGGATGTGGCCATAGAATTCTCTCGGGAGGAGTGGGAACACCTGGACTCAGATCAGAAGCTTTTATATGGGGATGTGATGTTAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGGAGCGCACGACGTGCGCGCACCCTCTCCCCTCGTCCACCGCTGCCGCCTCCTTCTTCTGCCGCTCCTGGTGCTGCTTGTGTGCTCGTTTGGTGCGGACCTGGTACCTCTTTTGTGAAGCGGCAGCTGAGGAGACTCCGGCGCTCGCCATGGCCGACGAAAAGCCCAAG',\n",
       "       b'CTCCTTCTTCTGCCGCTCCTGGTGCTGCTTGTGTGCTCGTTTGGTGCGGACCTGGTACCTCTTTTGTGAAGCGGCAGCTGAGGAGACTCCGGCGCTCGCCATGGCCGACGAAAAGCCCAAGGAAGGAGTCAAGACTGAGAACAACGATCATATTAATTTGAAGGTGGCGGGGCAGGATGGTTCTGTGGTGCAGTTTAAGATTA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$AGGGGAGGCCATTTTCCGTTTCTGGGAGGAGTGAGGGGCAACGGGTCGGAGAAAAAGGAAAAAAGAAGGGCTCAGCGCCTCCCCGCCGGGCCGTGGACAGAGGGGCACAGTTTCGGCAGGCGGGTGAGGTCGCTGAGGGCCCG',\n",
       "       b'GGACAGAGGGGCACAGTTTCGGCAGGCGGGTGAGGTCGCTGAGGGCCCGCCGGAGATGTTTTCCTTGTCGAGCACGGTGCAACCCCAGGTTACAGTTCCTCTGAGTCATCTCATCAATGCCTTCCATACACCAAAAAACACTTCTGTTTCTCTCAGTGGAGTGTCAGTTTCTCAAAACCAGCATCGAGATGTAGTTCCTGAGC',\n",
       "       b'GTTTTCCTTGTCGAGCACGGTGCAACCCCAGGTTACAGTTCCTCTGAGTCATCTCATCAATGCCTTCCATACACCAAAAAACACTTCTGTTTCTCTCAGTGGAGTGTCAGTTTCTCAAAACCAGCATCGAGATGTAGTTCCTGAGCATGAGGCTCCCAGCAGTGAGTGTATGTTCAGTGACTTCCTGACGAAGCTTAACATTG',\n",
       "       b'GTTACAGTTCCTCTGAGTCATCTCATCAATGCCTTCCATACACCAAAAAACACTTCTGTTTCTCTCAGTGGAGTGTCAGTTTCTCAAAACCAGCATCGAGATGTAGTTCCTGAGCATGAGGCTCCCAGCAGTGAGTGTATGTTCAGTGACTTCCTGACGAAGCTTAACATTGTTTCAATTGGCAAAGGAAAAATATTCGAAGG',\n",
       "       b'TTAAGGGACCTTGGATTATCTGAACTAAAAATTGGACAGATTGATCAGCTGGTAGAAAATCTACTTCCTGGATTTTGTAAAGGCAAAAACATTTCTTCCCATTGGCATACATCCCATGTCTCTGCACAATCCTTCTTTGAAAATAAATATGGTAACTTAGATATATTTAGTACATTACGTTCCTCTTGCTTGTATCGACATCA',\n",
       "       b'AGAAAAAGGAAAAAAGAAGGGCTCAGCGCCTCCCCGCCGGGCCGTGGACAGAGGGGCACAGTTTCGGCAGGCGGGTGAGGTCGCTGAGGGCCCGCCGGAGATGTTTTCCTTGTCGAGCACGGTGCAACCCCAGGTTACAGTTCCTCTGAGTCATCTCATCAATGCCTTCCATACACCAAAAAACACTTCTGTTTCTCTCAGTG',\n",
       "       b'GGGGCCACGCCCCCTCTGCCCCCCTGCGAGGGCATCCTGGGCTTTCTCCCACCGCTTTCCGAGCCCGCTTGCACCTCGGCGATCCCCGACTCCCTTCTTTATGGCGTCGCTCCTGTGCTGTGGGCCGAAGCTGGCCGCCTGCGGCATCGTCCTCAGCGCCTGGGGAGTGATCATGTTGATAATGCTCGGAATATTTTTCAATG',\n",
       "       b'GTCAAGGAAGGTTTCCCCAGGAGCAGTTTTGGTTTCAGACGGCGCCGTCTCCCGCGAAAGTCCTGAGAGGAGCCCAGCCTTTTCCGCCTGCCGCCCCCGGATGGGATGGTTGAGGCCGGGGCCACGCCCCCTCTGCCCCCCTGCGAGGGCATCCTGGGCTTTCTCCCACCGCTTTCCGAGCCCGCTTGCACCTCGGCGATCCC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GATGACACATCCGAAAAATAGGAAGTGGCCACTACGGAAGCTGTTCTGGGCCAGAAAGACTTCCAGTTTGGAGTCGTTTGCTGCGGGGAGGGAATGAATGGGCGCTGGGAACACGCCCGCGAGGTGGGGACGCGCCGGCCGTAGCGAGGTCCTTAGCGTGTGAGTGGCCG',\n",
       "       b'ATGAATGGGCGCTGGGAACACGCCCGCGAGGTGGGGACGCGCCGGCCGTAGCGAGGTCCTTAGCGTGTGAGTGGCCGGGGTCGGGTCGCTTCCCCGCAGCATGGAGGACGATGCACCAGTGATCTACGGGCTGGAGTTCCAGGCACGTGCCTTAACACCTCAAACTGCAGAAACAGATGCCATTCGGTTTTTGGTTGGGACGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GTGGGCGGTGCACTGGGTCAGTCCCGCGATAGCTTCAGGCCTGGCGGCGGCTTCCAAGCTAAGGAACGGTTTGGGGCAGTGTCGTTCCCGGAGGTCGGCCGCCGTTACCCGCTCACCAGCTACGCGGCGCGTCAGGTCCGCGG',\n",
       "       b'CGGAGGCGCGGGCTCGGGGCGCCTGCGGGACGGACACTGCCCATCTCTAAGATAAGAACCTGGAAAGGGGACTCTGTTGGCCATTGGAAATTGCAGAATAATGTCTCAGGTGACATTTAGTGATGTGGCTATAGACTTCTCTCATGAAGAGTGGGCATGCCTAGATTCTGCTCAGAGGGACTTATACAAGGATGTGATGGTCC',\n",
       "       b'AGACCGGGACGAGACCGGGGCTGTGGTGCGGAGAGAGGCTGAGACGGAGAAGAGGAGAGGCAGAGAGGGCGCGGGGACCGTCAGCAGCACCTTAGCTACAATCGTTCAGCTATTCTCGGAAGAGAGAAGGGAGAGGGAGGAGGCCGGGGCGGGAGTGGGGGCTGTCACCCTCGGACCCCGGCGTGAGAGGGGCCGTGCGGCCG',\n",
       "       b'GCAGAGCCGCTGGAGGACCCCAGGCGGAAGCGGAGGCGCTGGGGCACCATAGTGACCCCTACCAGGCCAGGCCCCACTCTCAGGGCCCCCAGGGGCCACCATGCCAGCTGGGGGCCGGGCCGGGAGCCTGAAGGACCCAGATGTGGCTGAGCTCTTCTTCAAGGATGACCCAGAAAAGCTCTTCTCTGACCTCCGGGAAATTG',\n",
       "       b'TACTGGCTCCAGAAGTGATGATGCTGGGTGGAAGTCGCAGCATGTGAAGAGTTGCCGGTTGTTATGGGATTAAAAAAGATGAAAGGGTTATCTTATGATGAGGCTTTTGCTATGGCTAATGATCCCTTGGAAGGCTTCCATGAAGTAAACCTTGCTTCACCTACTTCTCCGGACCTTCTTGGTGTGTATGAATCAGGAACTCA',\n",
       "       b'TTGACAACTCGCCCCGACCGCCCAGGAAGCGCGAGCTTACTGGCTCCAGAAGTGATGATGCTGGGTGGAAGTCGCAGCATGTGAAGAGTTGCCGGTTGTTATGGGATTAAAAAAGATGAAAGGGTTATCTTATGATGAGGCTTTTGCTATGGCTAATGATCCCTTGGAAGGCTTCCATGAAGTAAACCTTGCTTCACCTACTT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GAGAGCGGCGCCTGATGACGACCGGGAGGGCGGGGCCCGTCTGGGGCGCCGGCGGGTGCGTTTGAATCTGGTCCGAGCGCGGGAAACGGCGGGTCCCCGAGCCCAGGGTTACAAAATAAATGCCATTTGAACAGTGCCATCTGTCATGGAAAAACGTGAGACGTTTGTAC',\n",
       "       b'GACCGGGAGGGCGGGGCCCGTCTGGGGCGCCGGCGGGTGCGTTTGAATCTGGTCCGAGCGCGGGAAACGGCGGGTCCCCGAGCCCAGGGTTACAAAATAAATGCCATTTGAACAGTGCCATCTGTCATGGAAAAACGTGAGACGTTTGTACAAGCCGTGTCTAAGGAGCTGGTTGGAGAGTTTTTGCAATTTGTTCAACTTGA',\n",
       "       b'GCGCCGGCGGGTGCGTTTGAATCTGGTCCGAGCGCGGGAAACGGCGGGTCCCCGAGCCCAGGGTTACAAAATAAATGCCATTTGAACAGTGCCATCTGTCATGGAAAAACGTGAGACGTTTGTACAAGCCGTGTCTAAGGAGCTGGTTGGAGAGTTTTTGCAATTTGTTCAACTTGATAAAGAGGCCTCTGATCCTTTCAGCC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TCCGCCGGCTCACGTGACCGTCTTTGGGCCGGCGCGAACCATGGCCGGCATGGTGGACTTCCAGGATGAGGAGCAGGTCAAGTCCTTTTTGGAGAACATGGAGGTGGAGTGCAACTACCACTGCTACCACGAGAAGGACCCGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TCCGCCGGCTCACGTGACCGTCTTTGGGCCGGCGCGAACCATGGCCGGCATGGTGGACTTCCAGGATGAGGAGCAGGTCAAGTCCTTTTTGGAGAACATGGAGGTGGAGTGCAACTACCACTGCTACCACGAGAAGGACCCGGACGGTTGCTATC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGCACTGCAGCACCAGCCGTCTGCAGCTCCGGCCGCCACTTGCGCCTCTCCAGCCTCCGCAGGCCCAACCGCCGCCAGCACCATGGCCAGCACCATTTCCGCCTACAAGGAGAAGATGAAGGAGCTGTCGGTGCTGTCGCTC',\n",
       "       b'$$$$$$$$$$$$$$$$$$GGCACTGCAGCACCAGCCGTCTGCAGCTCCGGCCGCCACTTGCGCCTCTCCAGCCTCCGCAGGCCCAACCGCCGCCAGCACCATGGCCAGCACCATTTCCGCCTACAAGGAGAAGATGAAGGAGCTGTCGGTGCTGTCGCTCATCTGCTCCTGCTTCTACACACAGCCGCACCCCAATACCGTCT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GAGAGTTCCCAAGCGGTAGGCGGCGGCGCCGGGAGAGAAGCGCCGCCTAGCTGCGCTTCCGCAAAGATGGCGGCGGCTGCGGGTAGCTGCGCGCGGGTGGCGGCCTGGGGCGGAAAACTGCGACGGGGGCTCGCTGTCAGCCGACAGGCTGTGCGGAGTCCCGGCCCCT',\n",
       "       b'AGGCGTCGCTGAAGGATGGGGTGGTCCTCTGCAGGCTGCTGGAGCGCCTGCTCCCCGGGACCATCGAGAAAGTCTACCCCGAGCCCCGGAGCGAGAGCGAGTGCCTGAGCAACATCCGCGAGTTCCTGCGCGGCTGCGGGGCTTCCCTGCGGCTGGAGCTCCTGTTTCCTCCTTCCCAGCCTCCTCAGCATCTGGTAACCACC',\n",
       "       b'ATGGGCGAGGCGGCGGCGGCGGCGGCGGGGGCCGCGGGCCGGGCCGCCGCTCCGAGGTGAAGGCGCGCGCCCCTCCCCGCCTGCCTCCCGGGCCGCAGCGATGAATTCCGCCGAGCAAACCGTTACGTGGCTCATCACTCTGGGGGTGCTGGAGTCGCCCAAAAAAACCATCTCGGACCCGGAGGGCTTTCTGCAGGCGTCGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGGGACTACGGGTCGGCGTTGGGCTCAGTGGGCTCGAAACAAAGGGCTGTCCGGTGGGGATTCGTCGCGGCGCCTTCTGAGTGGTCGGGTCGAGGCTTCTCGGCCTAGCAGTGCCCTCGCTGCGCGATCTCAGGCGGGTTCTCCTCGGC',\n",
       "       b'GGTCGGCGTTGGGCTCAGTGGGCTCGAAACAAAGGGCTGTCCGGTGGGGATTCGTCGCGGCGCCTTCTGAGTGGTCGGGTCGAGGCTTCTCGGCCTAGCAGTGCCCTCGCTGCGCGATCTCAGGCGGGTTCTCCTCGGCTCCGCGCAGCCCGCGCCGCGGTGGGGGACCCGGCGCAGCGGCACCTGCTGCCGAGGGACCCCGC',\n",
       "       b'TGGGCTCAGTGGGCTCGAAACAAAGGGCTGTCCGGTGGGGATTCGTCGCGGCGCCTTCTGAGTGGTCGGGTCGAGGCTTCTCGGCCTAGCAGTGCCCTCGCTGCGCGATCTCAGGCGGGTTCTCCTCGGCTCCGCGCAGCCCGCGCCGCGGTGGGGGACCCGGCGCAGCGGCACCTGCTGCCGAGGGACCCCGCGGCCCGCCC',\n",
       "       b'GCGGGTTCTCCTCGGCTCCGCGCAGCCCGCGCCGCGGTGGGGGACCCGGCGCAGCGGCACCTGCTGCCGAGGGACCCCGCGGCCCGCCCCGGTGCTCGTGATGGGGCTGATCTTCGCCAAACTGTGGAGCCTCTTCTGTAACCAAGAACACAAAGTAATTATAGTGGGACTGGATAATGCAGGGAAAACCACCATTCTTTACC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$AAGGAGGGAGGCGGTGGTAGCGGCGGCGGCTGCTGAGGAGGAGGAGGGGGAGCGGAGGGAGGTGTTTCTGTCAGTTCCGGCTGTTTGTTCGGGAAGTGGATCCGCCGCTGCCGGAGCAGCCCGAAGGGAGCTGCGGATCGCGAGGCCAGTACCGACCCCGCCCGCCCGCGCGCACCGCCCCCG',\n",
       "       b'CGGGAAGTGGATCCGCCGCTGCCGGAGCAGCCCGAAGGGAGCTGCGGATCGCGAGGCCAGTACCGACCCCGCCCGCCCGCGCGCACCGCCCCCGCCCGCCATGGCCCGGGACTACGACCACCTCTTCAAGCTGCTCATCATCGGCGACAGCGGTGTGGGCAAGAGCAGTTTACTGTTGCGTTTTGCAGACAACACTTTCTCAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$AACGGTAGTGGTGGCTTGTTGGGATCCGTTGAGTGATGGGAGAGTGTGCTCTTTAACTTCGGAGAGAGATGCGCTCTCGTGTAGCCGTCAGGGCCTGCCATAAGGTCTGCAGGTGCCTGTTGTCTGGGTTTGGGGGTC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$AACGGTAGTGGTGGCTTGTTGGGATCCGTTGAGTGATGGGAGAGTGTGCTCTTTAACTTCGGAGAGAGATGCGCTCTCGTGTAGCCGTCAGGGCCTGCCATAAGGTCTGCAGGTGCCTGTTGTCTGGGTTTGGGGGTCGAGTAGATGCGGGGCAGCCGGAGCTGTTGACGG',\n",
       "       b'GTGCCGTTGCCGAGGAGACTAGGAGGGGGAGGAGAGGGGATCTCGCGAAAGGAAAGAGGTCGGGAGCGCTCGCGAGATCTCGGACCACCCAACCTGAAAGGTGCTTAGGAAGTTGAAAGGCCCAGAGGAGGCCTCCGGGCAAATGGCCGGAGCTGGACCGACCATGCTGCTACGAGAAGAGAATGGCTGTTGCAGTCGGCGTC',\n",
       "       b'GACCACCCAACCTGAAAGGTGCTTAGGAAGTTGAAAGGCCCAGAGGAGGCCTCCGGGCAAATGGCCGGAGCTGGACCGACCATGCTGCTACGAGAAGAGAATGGCTGTTGCAGTCGGCGTCAGAGCAGCTCCAGTGCTGGGGTTAGCACGGGCTCTGGTTCTGGGACTGAGGGGCAGTCAAGCAGCAAGATGGAGGGGGTGGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TTTCCGGCGTGGGTCCGGGCAAGAACCGCTTGTAGTTTGGTTTAAATTCTGCACGGGAGGACCTTCTGAGTTTACCTGTTGGGCTCCTGGCTGCGCAGGCACAGCAGCTACACAGAAGAGATGGGAGAAGAGGCTAATGATGACAAGAAGC',\n",
       "       b'AAGAACCGCTTGTAGTTTGGTTTAAATTCTGCACGGGAGGACCTTCTGAGTTTACCTGTTGGGCTCCTGGCTGCGCAGGCACAGCAGCTACACAGAAGAGATGGGAGAAGAGGCTAATGATGACAAGAAGCCAACCACTAAATTTGAACTAGAGCGAGAAACAGAACTTCGCTTTGAGGTGGAGGCATCTCAGTCAGTTCAGT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CTAGTTAAGGCGGCACAGGGCCGAGGCGTAGTGTGGGTGACTCCTCCGTTCCTTGGGTCCCGTCGTCTGTGATACTGCAGCGCAGCCATGGCAGAACCGCAGCCCCCGTCCGGCGGCCTCACGGACGAGGCCGCC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$CTAGTTAAGGCGGCACAGGGCCGAGGCGTAGTGTGGGTGACTCCTCCGTTCCTTGGGTCCCGTCGTCTGTGATACTGCAGCGCAGCCATGGCAGAACCGCAGCCCCCGTCCGGCGGCCTCACGGACGAGGCCGCCCTCAGTTGCTGCTCCGACGCGGACCCCAGTACCAAGGATTTT',\n",
       "       b'CAGCGCAGCCATGGCAGAACCGCAGCCCCCGTCCGGCGGCCTCACGGACGAGGCCGCCCTCAGTTGCTGCTCCGACGCGGACCCCAGTACCAAGGATTTTCTATTGCAGCAGACCATGCTACGAGTGAAGGATCCTAAGAAGTCACTGGATTTTTATACTAGAGTTCTTGGAATGACGCTAATCCAAAAATGTGATTTTCCCA',\n",
       "       b'CTCCGACGCGGACCCCAGTACCAAGGATTTTCTATTGCAGCAGACCATGCTACGAGTGAAGGATCCTAAGAAGTCACTGGATTTTTATACTAGAGTTCTTGGAATGACGCTAATCCAAAAATGTGATTTTCCCATTATGAAGTTTTCACTCTACTTCTTGGCTTATGAGGATAAAAATGACATCCCTAAAGAAAAAGATGAAA',\n",
       "       b'$$$$$$$$$$$$$CTAGTTAAGGCGGCACAGGGCCGAGGCGTAGTGTGGGTGACTCCTCCGTTCCTTGGGTCCCGTCGTCTGTGATACTGCAGCGCAGCCATGGCAGAACCGCAGCCCCCGTCCGGCGGCCTCACGGACGAGGCCGCCCTCAGTTGCTGCTCCGACGCGGACCCCAGTACCAAGGATTTTCTATTGCAGCAGA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$ATTCACTAAGGACCGAGCACCAAATAACCAAGGAAAAGGAAGTGAGTTAAGGACGTACTCGTCTTGGTGAGAGCGTGAGCTGCTGAGATTTGGGAGTCTGCGCTAGGCCCGCTTGGAGTTCTGAGCCGATGGAAGAGTTCACTCATGTTTGCACCCGCGGTGATGCGTGCTTTTCGCAAGAA',\n",
       "       b'$$$$$$$$$$$$$ATTCACTAAGGACCGAGCACCAAATAACCAAGGAAAAGGAAGTGAGTTAAGGACGTACTCGTCTTGGTGAGAGCGTGAGCTGCTGAGATTTGGGAGTCTGCGCTAGGCCCGCTTGGAGTTCTGAGCCGATGGAAGAGTTCACTCATGTTTGCACCCGCGGTGATGCGTGCTTTTCGCAAGAACAAGACTC',\n",
       "       b'CAAGGAAAAGGAAGTGAGTTAAGGACGTACTCGTCTTGGTGAGAGCGTGAGCTGCTGAGATTTGGGAGTCTGCGCTAGGCCCGCTTGGAGTTCTGAGCCGATGGAAGAGTTCACTCATGTTTGCACCCGCGGTGATGCGTGCTTTTCGCAAGAACAAGACTCTCGGCTATGGAGTCCCCATGTTGTTGCTGATTGTTGGAGGT',\n",
       "       b'ATGTTTGCACCCGCGGTGATGCGTGCTTTTCGCAAGAACAAGACTCTCGGCTATGGAGTCCCCATGTTGTTGCTGATTGTTGGAGGTTCTTTTGGTCTTCGTGAGTTTTCTCAAATCCGATATGATGCTGTGAAGAGTAAAATGGATCCTGAGCTTGAAAAAAAACTGAAAGAGAATAAAATATCTTTAGAGTCGGAATATGA',\n",
       "       b'AGTTAAGGACGTACTCGTCTTGGTGAGAGCGTGAGCTGCTGAGATTTGGGAGTCTGCGCTAGGCCCGCTTGGAGTTCTGAGCCGATGGAAGAGTTCACTCATGTTTGCACCCGCGGTGATGCGTGCTTTTCGCAAGAACAAGACTCTCGGCTATGGAGTCCCCATGTTGTTGCTGATTGTTGGAGGTTCTTTTGGTCTTCGTG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCGGAAGGCGCGGGAGCTTGCGTGCTGCTGGGCCTGAGCTGTCTGTCTCGTTTCTGTCCGCGCGCCCTGCATCCCGGCCCCGGGCGCCCGCTGGAGGTCGCCGAGGAGCCACAGGGCTGACTGGTCTGCTGCCCGGGCCCA',\n",
       "       b'GTGGCCGGCCATTTAGGGGGACGCTGCGACCACCGCCTGCGCCCCTCCGGACTGGTTCCTTGGGCCCCGGAAGCTCGCGGCGGGCCCTGCGGGAGGCGGCATGCTCCCGCGGAGGCTGCTGGCCGCCTGGCTGGCGGGGACGCGGGGCGGGGGCCTGCTGGCGCTTCTGGCCAATCAGTGCCGCTTCGTCACGGGCCTGCGCG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$AAAGGCCAGCGGCGCAAAATGGCGGCGGCGATGACCTTCTGCCGGCTGCTGAACCGGTGTGGCGAGGCGGCGCGGAGCCTGCCCCTGGGCGCCAGGTGTTTCGGGGTGCGGGTCTCGCCGA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$AAAGGCCAGCGGCGCAAAATGGCGGCGGCGATGACCTTCTGCCGGCTGCTGAACCGGTGTGGCGAGGCGGCGCGGAGCCTGCCCCTGGGCGCCAGGTGTTTCGGGGTGCGGGTCTCGCCGACCGGGGAGAAGGTCACGCACACTGGCC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCGCCGGTGGCGGGACTCTGGGGAAAATGGCTGCGTCTTCGAGTGGTGAGAAGGAGAAGGAGCGGCTGGGAGGCGGTTTGGGAGTGGCGGGTGGTAACAGCACACGAGAGCGGCTGCTGTCTGCGCTTG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$CGGAGAGCGCTGAGCCGGGCCGCACCCGCCGAGCCGTCCCTTCTCCCTGTGATCAGTTACCAACTACCTGTTGATGTGTGTGGTTACAGACTTCTTTCTATGCTTTGTACAACTCTACAGACCGTATCTTGATACTGATGGACATTGTGTGGGCCAGAGGCAGGGATGGTTGGCTA',\n",
       "       b'CCCTTCTCCCTGTGATCAGTTACCAACTACCTGTTGATGTGTGTGGTTACAGACTTCTTTCTATGCTTTGTACAACTCTACAGACCGTATCTTGATACTGATGGACATTGTGTGGGCCAGAGGCAGGGATGGTTGGCTATGACCCCAAACCAGATGGCAGGAATAACACCAAGTTCCAGGTGGCAGTGGCTGGGTCTGTGTCT',\n",
       "       b'ACCAAGTTCCAGGTGGCAGTGGCTGGGTCTGTGTCTGGACTTGTTACTCGGGCGCTGATCAGTCCCTTCGACGTCATCAAGATCCGTTTCCAGCTTCAGCATGAGCGCCTGTCTCGCAGTGACCCCAGCGCAAAGTACCATGGCATCCTCCAGGCCTCTAGGCAGATTCTGCAGGAGGAGGGTCCGACAGCTTTCTGGAAAGG',\n",
       "       b'ACCTGTTGATGTGTGTGGTTACAGACTTCTTTCTATGCTTTGTACAACTCTACAGACCGTATCTTGATACTGATGGACATTGTGTGGGCCAGAGGCAGGGATGGTTGGCTATGACCCCAAACCAGATGGCAGGAATAACACCAAGTTCCAGGTGGCAGTGGCTGGGTCTGTGTCTGGACTTGTTACTCGGGCGCTGATCAGTC',\n",
       "       b'CCCTCCGTAAAGATGGCCGGGGCAGTCGGCACGAGGGAGGCGGGGATGCGCCTGCGCAACAAGTTCGGCGGGGAAGATGGCGGATGACAAGGATTCTCTGCCTAAGCTTAAGGACCTGGCATTTCTCAAGAACCAGCTGGAAAGCCTGCAGCGGCGTGTAGAAGACGAAGTCAACAGTGGAGTGGGCCAGGATGGCTCGCTGT',\n",
       "       b'ATGGCCGGGGCAGTCGGCACGAGGGAGGCGGGGATGCGCCTGCGCAACAAGTTCGGCGGGGAAGATGGCGGATGACAAGGATTCTCTGCCTAAGCTTAAGGACCTGGCATTTCTCAAGAACCAGCTGGAAAGCCTGCAGCGGCGTGTAGAAGACGAAGTCAACAGTGGAGTGGGCCAGGATGGCTCGCTGTTGTCCTCCCCGT',\n",
       "       b'GAAAGCCTGCAGCGGCGTGTAGAAGACGAAGTCAACAGTGGAGTGGGCCAGGATGGCTCGCTGTTGTCCTCCCCGTTCCTCAAGGGATTCCTGGCTGGCTATGTGGTGGCCAAACTGAGGGCATCAGCAGTATTGGGCTTTGCTGTGGGCACCTGCACTGGCATCTATGCGGCTCAGGCATATGCTGTGCCCAACGTGGAGAA',\n",
       "       b'TGTGGGCACCTGCACTGGCATCTATGCGGCTCAGGCATATGCTGTGCCCAACGTGGAGAAGACATTAAGGGACTATTTGCAGTTGCTACGCAAGGGGCCCGACTAGCTCTAGGTGCCATGGAAGAGGCAGGATGAGCAGCTCAGCCTTCAGGTGGAGACACTTTATCTGGATTCCCCAGCTGTCATCCATTTGCTATCTCCAA',\n",
       "       b'CCACGGCTTCTCCTTCCTGGGAGCTGGCTCCATAACTTGATTTTCCCCAAACGTGTTGCAATCCCTGCTGCCCCTTAGCCACCCAGGGTCTTGTGTGGGTATGAGTGTAGAGGATGGGGGTATGCCAGGCCTGGGCCGTCCCAGGCAGGCCCGCTGGACCCTGATGCTACTCCTATCCACTGCCATGTACGGTGCCCATGCCC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ATGCCAAGCATAGCCCTCATGTCAGCGCTGCCGGCTTGCAGCGGGCTGTGAGAGGGGCCGGCGCCGCTTTGTCCTAGGAAACGGGCTGCGCGTTTCTCTTTTTCACTCTTTTCCATTTCCAGGA',\n",
       "       b'GAAGTTGAAGAGCCAGGAGCTACTCAGCAACAATTGATTTTTGAAACTTAACTCTTTTGGGGCAAAAGCAAAGAGCTGGTTTTCTTTGCTAGCCCAATAAATGCTATTTATGAAGATGGACCTGTTGAACTATCAGTACTTGGACAAGATGAACAACAATATCGGCATTCTGTGCTACGAAGGCGAAGCTGCTCTCAGGGGAG',\n",
       "       b'CGAGGGAGTTACGCACGTCCTGATTCTCCTGGAGTCTCCAGCCCGCCCAGTGGCCGCAGTCACCCAGGTCCAGAGGCGGCGGTATCACAGGCTCTCCGACATGTCTATGCTGGCTGAACGTCGGCGGAAGCAGAAGTGGGCTGTGGATCCTCAGAACACTGCCTGGAGTAATGACGATTCCAAGTTTGGCCAGCGGATGCTAG',\n",
       "       b'CGCCAGCCCCACCCCTCCGCCGGCCGGGCCGACCCCGCCGTACTATCCCCTGCGGCGCGAGCCCGGGGCGGCTCCAAGCGCCCCCCAGCAGACCCCCATCATGGGCAGCCAGAGCTCCAAGGCTCCCCGGGGCGACGTGACCGCCGAGGAGGCAGCAGGCGCTTCCCCCGCGAAGGCCAACGGCCAGGAGAATGGCCACGTGA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCAGCCTCGAGGCCGGGCGTCTTCGGTCATCTCCGGCGCTTCTAGGGCTGGTTCCCGTCATCTTCGGGAGCCGTGGAGGTACGAACTTAAGACATGCCTATTTTATTAATTTACTTCCAAACGCAACGAAAGGTCCATGGACAATTTGTGGGCCATTTAATTCAGGGCCCCCAAT',\n",
       "       b'ATTTACTTCCAAACGCAACGAAAGGTCCATGGACAATTTGTGGGCCATTTAATTCAGGGCCCCCAATTCGTACGTGGAGAAGTGGGAATGCAAAAGTACTTTGACCTTTAACCTTCGGTCCGGCGCGGTGGAGGGAAACGCCTCCGTCTCTATATAAGGAATTTTCCGGTCTCTTCGGGTCCTTTTTCCTCTCTTCAGCGTGG',\n",
       "       b'AAAGTACTTTGACCTTTAACCTTCGGTCCGGCGCGGTGGAGGGAAACGCCTCCGTCTCTATATAAGGAATTTTCCGGTCTCTTCGGGTCCTTTTTCCTCTCTTCAGCGTGGGGCGCCCACAATTTGCGCGCTCTCTTTCTGCTGCTCCCCAGCTCTCGGATACAGCCGACACCATGGGTTTCGGAGACCTGAAAAGCCCTGCC',\n",
       "       b'CCGGTCTCTTCGGGTCCTTTTTCCTCTCTTCAGCGTGGGGCGCCCACAATTTGCGCGCTCTCTTTCTGCTGCTCCCCAGCTCTCGGATACAGCCGACACCATGGGTTTCGGAGACCTGAAAAGCCCTGCCGGCCTCCAGGTGCTCAACGATTACCTGGCGGACAAGAGCTACATCGAGGGGTATGTGCCATCACAAGCAGATG',\n",
       "       b'GAGATGGGGGCGGCGGCGGCGGAAGCGGATCGCACTCTCTTTGTGGGCAACCTTGAAACGAAAGTGACCGAGGAGCTCCTTTTCGAGCTTTTCCACCAGGCTGGGCCAGTAATAAAGGTGAAAATTCCAAAAGATAAGGATGGTAAACCAAAGCAGTTTGCGTTTGTGAATTTCAAACATGAAGTGTCTGTTCCTTATGCAAT',\n",
       "       b'TGTGACGCCAGGGAGCGTGAGGACGTGGGGCTTCCGTGAATGCGCAGTGGGTGCGTCGGCCACGACCTTTTGGCCAGGTTAGGGAGGGGGCGACGCTGAGATGGGGGCGGCGGCGGCGGAAGCGGATCGCACTCTCTTTGTGGGCAACCTTGAAACGAAAGTGACCGAGGAGCTCCTTTTCGAGCTTTTCCACCAGGCTGGGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$ACTTTAGCCAGCGCAGGGCGCACCCCGCCCCCTCCCACTCTCCCTGCCCCTCGGACCCCATACTCTACCTCATCCTTCTGGCCAGGCGAAGCCCACGACGTTGACATGCCGGAGATCCGCCTCCGCCATGTCGTGTCCTGCAGCAGCCAGGACTCGTTGGAGAAGGAGGAGCAGATACAC',\n",
       "       b'AGCCAGCGCAGGGCGCACCCCGCCCCCTCCCACTCTCCCTGCCCCTCGGACCCCATACTCTACCTCATCCTTCTGGCCAGGCGAAGCCCACGACGTTGACATGCCGGAGATCCGCCTCCGCCATGTCGTGTCCTGCAGCAGCCAGGACTCGTTGGAGAAGGAGGAGCAGATACACAGTGTGGACATTGGGAATGATGGCTCAG',\n",
       "       b'GACACAAGAATGGGAGGAAAGGCGGACTCTCAGGAACTTCATTCTTCACGTGGTTTATGGTGATTGCATTGCTGGGCGTCTGGACATCTGTAGCTGTCGTTTGGTTTGATCTTGTTGACTATGAGGAAGTTCTAGGAAAACTAGGAATCTATGATGCTGATGGTGATGGAGATTTTGATGTGGATGATGCCAAAGTTTTATTA',\n",
       "       b'ACAAGAATGGGAGGAAAGGCGGACTCTCAGGAACTTCATTCTTCACGTGGTTTATGGTGATTGCATTGCTGGGCGTCTGGACATCTGTAGCTGTCGTTTGGTTTGATCTTGTTGACTATGAGGAAGTTCTAGGAAAACTAGGAATCTATGATGCTGATGGTGATGGAGATTTTGATGTGGATGATGCCAAAGTTTTATTAGGA',\n",
       "       b'CTCCAGCGGCCCGCCGCCGCCAGCGGTTCCCGCGTCGCGTGTGTACCCCCGCGCACTGAAGGAGGTCCGCCAGCCCTCACCAGCCCCCGCGGACCGTGCAATGGCCCAGCGTAAGAATGCCAAGAGCAGCGGCAACAGCAGCAGCAGCGGCTCCGGCAGCGGTAGCACGAGTGCGGGCAGCAGCAGCCCCGGGGCCCGGAGAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GTGGCGCGGACGCCTGCTCAGTGCGCGCCGGCCGGGCAACCCTATGCTGGCGTAATCGGGTTCCTCCGAGCCGCCGTAGGACTGGTTCCGGCGGGCTGGTGAGGAATGGAGCCGGTAGGCTGCTGCGGCGAGTGCCGCGGCTCCTC',\n",
       "       b'AATCGGGTTCCTCCGAGCCGCCGTAGGACTGGTTCCGGCGGGCTGGTGAGGAATGGAGCCGGTAGGCTGCTGCGGCGAGTGCCGCGGCTCCTCCGTAGACCCGCGGAGCACCTTCGTGTTGAGTAACCTGGCGGAGGTGGTGGAGCGTGTGCTCACCTTCCTGCCCGCCAAGGCGTTGCTGCGGGTGGCCTGCGTGTGCCGCT',\n",
       "       b'GCGGACGCCTGCTCAGTGCGCGCCGGCCGGGCAACCCTATGCTGGCGTAATCGGGTTCCTCCGAGCCGCCGTAGGACTGGTTCCGGCGGGCTGGTGAGGAATGGAGCCGGTAGGCTGCTGCGGCGAGTGCCGCGGCTCCTCCGTAGACCCGCGGAGCACCTTCGTGTTGAGTAACCTGGCGGAGGTGGTGGAGCGTGTGCTCA',\n",
       "       b'CTCGCAACTCGTTTTGACGTTTTCTGGTCGGCGGTAAAAGCTCGGTTCCCGGCCCTCCCGGAAGTTGTTGCACAGTTGTTTCCGGGAAGCGGGACTCCAAATGGGTCGCAGTCGCAGCCGCTCTCCACGGAGGGAACGTAGGCGTTCCCGGTCCACATCCCGGGAGAGAGAACGCAGGCGCCGAGAAAGGTCCAGGTCTCGGG',\n",
       "       b'GAGCCCAGCGGCGGGTGTGAGAGTCCGTAAGGAGCAGCTTCCAGGATCCTGAGATCCGGAGCAGCCGGGGTCGGAGCGGCTCCTCAAGAGTTACTGATCTATGAAATGGCAGAGAATGGAAAAAATTGTGACCAGAGACGTGTAGCAATGAACAAGGAACATCATAATGGAAATTTCACAGACCCCTCTTCAGTGAATGAAAA',\n",
       "       b'CAGCGGCGGGTGTGAGAGTCCGTAAGGAGCAGCTTCCAGGATCCTGAGATCCGGAGCAGCCGGGGTCGGAGCGGCTCCTCAAGAGTTACTGATCTATGAAATGGCAGAGAATGGAAAAAATTGTGACCAGAGACGTGTAGCAATGAACAAGGAACATCATAATGGAAATTTCACAGACCCCTCTTCAGTGAATGAAAAGAAGA',\n",
       "       b'$$$$$$$$$$$$$$$$$$GTCCTGGGTATGTCCACGCGCAATAAGGAGGGGCGAAAGGACATTTTTTTTTTTCTTGCTCCCGCCTCTGTTCTTCCCCCACCTGCCACGTACAGAGCCCAAGTTCTCGCTAGGCTTGTTGGGTCAGCGCGATTGGCCGGGGCCCGCGCGAGCCTGCGAGCGAGGTGCGGCGGTCGCGAAGGGCA',\n",
       "       b'GTCCGCCCATTCAGCGGAGACCTGCGGAGAGGCGGCGGCCGCGGCCTCCGCAAGCCGTCTTTCTCTAGAGTTGTATATATAGAACATCCTGGAGTCCACCATGAACGGACAGTTGGATCTAAGTGGGAAGCTAATCATCAAAGCTCAACTTGGGGAGGATATTCGGCGAATTCCTATTCATAATGAAGATATTACTTATGATG',\n",
       "       b'CCCCTCCCTTGTCCGTCTTCTAACTCTTCCCCACGCCAGGTCCGTCAAGCCTAAGTCCTTGAGTTCCGGGTCCGGGCAGCAGAGAAAGGAAGTCCTCTCCCTGGAGGCCTATCTCCCTCAGAACTGCGCGAGAAGCGAGACCTTAGAAGGCAGGGCTTCCCGCGAAGGACCGGAAAGGAGCGCCTACTAAGGACGCCGTCGAG',\n",
       "       b'AGCGAGACCTTAGAAGGCAGGGCTTCCCGCGAAGGACCGGAAAGGAGCGCCTACTAAGGACGCCGTCGAGGTCCGGGGCGCCTCAACTCTATAGCTCTAACTGGCTAGAAGTGCCCAACGTGGAATGTTTCTTTTTTAAAGGCGGCTCTTGAAGCGACCCGGAAGCGGAAGTGGAAGAAAGTTCTAGTGGCTTGAGGTATCCG',\n",
       "       b'AGTGGAAGAAAGTTCTAGTGGCTTGAGGTATCCGCAGGAGCGGCCGGGTGGCGGGAGGAACCGTTACGGGAACTGAAGTTGCGGATTAAGCCTGATCAAGATGACAACCTCCCAAAAGCACCGAGACTTCGTGGCAGAGCCCATGGGGGAGAAGCCAGTGGGGAGCCTGGCTGGGATTGGTGAAGTCCTGGGCAAGAAGCTGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TTTCCTGTCGCTGCTTGGTAACAATGGGGAAGATAATGGCTGCCTGAGCAACGTCTCCGAGCAGGCGCTGGGCTAGAGGCGGGTCTCAACCAGCTACTCATTGGAGGCGGGCTTGAGAGCGGCGGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TTTCCTGTCGCTGCTTGGTAACAATGGGGAAGATAATGGCTGCCTGAGCAACGTCTCCGAGCAGGCGCTGGGCTAGAGGCGGGTCTCAACCAGCTACTCATTGGAGGCGGGCTTGAGAGCGGCGGCCAGGGAGGTGCG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TTTCCTGTCGCTGCTTGGTAACAATGGGGAAGATAATGGCTGCCTGAGCAACGTCTCCGAGCAGGCGCTGGGCTAGAGGCGGGTCTCAACCAGCTACTCATTGGAGGCGGGCTTGAGAGCGGCGGCCAGGGAGGTGCGGAGCAG',\n",
       "       b'AGCCTCGGCGGCGGCGGCCGAACCAACCGAGTCGGATCCTGACCCTAAAACCTAAGCAGAGTGAAGAAAACTAAAATCCAGTTTATTGTATTTCAATACTATGTCATAACAGTCAGGTATTTTCCACTTGTTCATCAATATGGAAAACTCAGATTCCAATGACAAAGGAAGTGGTGATCAGTCTGCAGCACAGCGCAGAAGTC',\n",
       "       b'TGACCCTAAAACCTAAGCAGAGTGAAGAAAACTAAAATCCAGTTTATTGTATTTCAATACTATGTCATAACAGTCAGGTATTTTCCACTTGTTCATCAATATGGAAAACTCAGATTCCAATGACAAAGGAAGTGGTGATCAGTCTGCAGCACAGCGCAGAAGTCAGATGGACCGATTGGATCGAGAAGAAGCTTTCTATCAAT',\n",
       "       b'GCAGCGAGCTCCGCATTCGAACCTCCCTCGCAAAGACAGTCTCCGCCCCACAATGCACCGCGGCGGGCAGCCTTTGAAAAAGCGGCGCGGCTCGTTCAAGATGGCGGAGCTCGACCAGTTGCCTGACGAGAGCTCTTCAGCAAAAGCCCTTGTCAGTTTAAAAGAAGGAAGCTTATCTAACACGTGGAATGAAAAGTACAGTT',\n",
       "       b'GCCCGCCTCAGCCAGCCGCGGCGGGAGCAGCGCAGCGCGGCGCCGCGGGCAGCGAGCTCCGCATTCGAACCTCCCTCGCAAAGACAGTCTCCGCCCCACAATGCACCGCGGCGGGCAGCCTTTGAAAAAGCGGCGCGGCTCGTTCAAGATGGCGGAGCTCGACCAGTTGCCTGACGAGAGCTCTTCAGCAAAAGCCCTTGTCA',\n",
       "       b'$$$$$$$$$$$$$$$$ACTTTCTTGAGTGGCCAATCCGGTTGTAGGCTCACCTCCCCCTTCTACTCAGAGCACTGCTGCGGCCGCCGCCATTTTAGCGTTTTGTCAGAAGCGTCCGCGCCGCGAGGAGGAGGCCCTGCTGGTTTCTGTGCGGGCTCTTGTCAGGATGGTGAAGCTGTTCATCGGAAACCTGCCCCGGGAGGCT',\n",
       "       b'TGCTGCGGCCGCCGCCATTTTAGCGTTTTGTCAGAAGCGTCCGCGCCGCGAGGAGGAGGCCCTGCTGGTTTCTGTGCGGGCTCTTGTCAGGATGGTGAAGCTGTTCATCGGAAACCTGCCCCGGGAGGCTACAGAGCAGGAGATTCGCTCACTCTTCGAGCAGTATGGGAAGGTGCTGGAATGTGACATCATTAAGAATTACG',\n",
       "       b'GACGGCAGCTGAGGATGCCATACGCAACCTGCACCATTACAAGCTTCATGGGGTGAACATCAACGTGGAAGCCAGCAAGAATAAGAGCAAAACCTCAACAAAGTTGCATGTGGGCAACATCAGTCCCACCTGCACCAATAAGGAGCTTCGAGCCAAGTTTGAGGAGTATGGTCCGGTCATCGAATGTGACATCGTGAAAGATT',\n",
       "       b'TCAGAGCACTGCTGCGGCCGCCGCCATTTTAGCGTTTTGTCAGAAGCGTCCGCGCCGCGAGGAGGAGGCCCTGCTGGTTTCTGTGCGGGCTCTTGTCAGGATGGTGAAGCTGTTCATCGGAAACCTGCCCCGGGAGGCTACAGAGCAGGAGATTCGCTCACTCTTCGAGCAGTATGGGAAGGTGCTGGAATGTGACATCATTA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGAGGAGGTGGCGGCCTGGGTCTGACGCGGCCCTGTTCGAGGGGGCCTCTCTTGTTTATTTATTTATTTTCCGTGGGTGCCTCCGAGTGTGCGCGCGCTCTCGCTACCCGGCGGGGAGGGGGTGGGGGGAGGGCCCGGGAAAAGGGGGAGTTGGAGCCGGGGTC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGAGGAGGTGGCGGCCTGGGTCTGACGCGGCCCTGTTCGAGGGGGCCTCTCTTGTTTATTTATTTATTTTCCGTGGGTGCCTCCGAGTGTGCGCGCGCTCTCGCTACCCGGCGGGGAGGGGGTGGGGGGAGGGCCCGGGAAAAGGGGGAGTTGGAGCCGGGGTCGAAACGCCGCG',\n",
       "       b'GGGAGTTGGAGCCGGGGTCGAAACGCCGCGTGACTTGTAGGTGAGAGAACGCCGAGCCGTCGCCGCAGCCTCCGCCGCCGAGAAGCCCTTGTTCCCGCTGCTGGGAAGGAGAGTCTGTGCCGACAAGATGGCGGACGGGGAGCTGAACGTGGACAGCCTCATCACCCGGCTGCTGGAGGTACGAGGATGTCGTCCAGGAAAGA',\n",
       "       b'ATTATTTGAATATGGAGGTTTCCCACCAGAAGCCAACTATCTTTTCTTAGGAGATTATGTGGACAGAGGAAAGCAGTCTTTGGAAACCATTTGTTTGCTATTGGCTTATAAAATCAAATATCCAGAGAACTTCTTTCTCTTAAGAGGAAACCATGAGTGTGCTAGCATCAATCGCATTTATGGATTCTATGATGAATGCAAAC',\n",
       "       b'GCGTGACTTGTAGGTGAGAGAACGCCGAGCCGTCGCCGCAGCCTCCGCCGCCGAGAAGCCCTTGTTCCCGCTGCTGGGAAGGAGAGTCTGTGCCGACAAGATGGCGGACGGGGAGCTGAACGTGGACAGCCTCATCACCCGGCTGCTGGAGGTACGAGGATGTCGTCCAGGAAAGATTGTGCAGATGACTGAAGCAGAAGTTC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CACTTCTGCCGCCCCTGTTTCAAGGGATAAGAAACCCTGCGACAAAACCTCCTCCTTTTCCAAGCGGCTGCCGAAGATGGCGGAGGTGCAGGTCCTGGTGCTTGATGGTCGAGGCCATCTCCTGGGCCGCCTGGCGGCCATCGTGGCTAAACAGGTACTGCTGGGCCGGA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$CACTTCTGCCGCCCCTGTTTCAAGGGATAAGAAACCCTGCGACAAAACCTCCTCCTTTTCCAAGCGGCTGCCGAAGATGGCGGAGGTGCAGGTCCTGGTGCTTGATGGTCGAGGCCATCTCCTGGGCCGCCTGGCGGCCATCGTGGCTAAACAGGTACTGCTGGGCCGGAAGGTGGTGG',\n",
       "       b'$$$$$$$$$$$$$$$GGCGGGGCCTGGCCCCGCTCTCCCAGGGTGCCCCGCGCGCGCGCGCGCCGGCAGTTCGGCCACGTCCCTGGCCACGTCGCGGGCGATCTCGCCATCTTCGCCGCTTCCTCTCAGGGGCCGCCGCCTCCTGAGCCGCCCAGCCCCGGGGCCGCCGCGCTGCGCCGACCGCCACCGCCGCCGCCGCCATG',\n",
       "       b'ATCTCGCCATCTTCGCCGCTTCCTCTCAGGGGCCGCCGCCTCCTGAGCCGCCCAGCCCCGGGGCCGCCGCGCTGCGCCGACCGCCACCGCCGCCGCCGCCATGAACATTTTCCGGCTGACTGGGGACCTGTCCCACCTGGCGGCCATCGTCATCCTGCTGCTGAAGATCTGGAAGACGCGCTCCTGCGCCGGTATTTCTGGGA',\n",
       "       b'TTTGAGGTAACGGCCCAAAGAGGTGGAAGCGCTTTTCCCGCCCGGCCGCGGGGCGTGGCTCTGCGCGCAGCTTGATGACGACTTTCGGCGCCGTGGCGGAATGGCGGCTTCCATCTCTGAGGCGAGCGACGCTATGGATCCCACAGTGGTTTGCTAAGAAGGCCATTTTCAACTCTCCACTGGAGGCTGCTATGGCGTTCCCT',\n",
       "       b'TTTCCCGCCCGGCCGCGGGGCGTGGCTCTGCGCGCAGCTTGATGACGACTTTCGGCGCCGTGGCGGAATGGCGGCTTCCATCTCTGAGGCGAGCGACGCTATGGATCCCACAGTGGTTTGCTAAGAAGGCCATTTTCAACTCTCCACTGGAGGCTGCTATGGCGTTCCCTCACCTGCAGCAGCCCAGCTTTCTACTGGCTAGC',\n",
       "       b'CCGGCCTTCGCTTTGCGCACGCGCCTTTTGAGGTAACGGCCCAAAGAGGTGGAAGCGCTTTTCCCGCCCGGCCGCGGGGCGTGGCTCTGCGCGCAGCTTGATGACGACTTTCGGCGCCGTGGCGGAATGGCGGCTTCCATCTCTGAGGCGAGCGACGCTATGGATCCCACAGTGGTTTGCTAAGAAGGCCATTTTCAACTCTC',\n",
       "       b'GCACAGCCCGCCGCGCTCGCCTCTCCGCCCCGCGTCCAGCTCGCCCAGCTCGCCCAGCGTCCGCCGCGCCTCGGCCAAGGCTTCAACGGACCACACCAAAATGCCATCTCAAATGGAACACGCCATGGAAACCATGATGTTTACATTTCACAAATTCGCTGGGGATAAAGGCTACTTAACAAAGGAGGACCTGAGAGTACTCA',\n",
       "       b'CGGGCCCAGCGCCACGTCACCGCCCAGCAGCCCTCCCGATTGGCGGGCGGGGCGGCTATAAAGGGAGGGCGCAGGCGGCGCCCGGATCTCTTCCGCCGCCATTTTAAATCCAGCTCCATACAACGCTCCGCCGCCGCTGCTGCCGCGACCCGGACTGCGCGCCAGCACCCCCCTGCCGACAGCTCCGTCACTATGGAGGATAT',\n",
       "       b'CCGCCGCCATTTTAAATCCAGCTCCATACAACGCTCCGCCGCCGCTGCTGCCGCGACCCGGACTGCGCGCCAGCACCCCCCTGCCGACAGCTCCGTCACTATGGAGGATATGAACGAGTACAGCAATATAGAGGAATTCGCAGAGGGATCCAAGATCAACGCGAGCAAGAATCAGCAGGATGACGGTAAAATGTTTATTGGAG',\n",
       "       b'CCAGGAATTTACGCCCCTTCGTTTTTCTCTTCTGATTCTTCTCTTCTCCCAAGCCCGCGTCCCCTCACGCGTGGCCTCTCTCCTTGCCGGGAGGGCCGCGATGGAGGTCCCGCCCAGGCTTTCCCATGTGCCGCCGCCATTGTTCCCCTCCGCTCCCGCTACTTTAGCCTCCCGCAGCCTCTCCCATTGGCGGCCGCGGCCGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ATTGACAAACAGAGCGGTCGCGGCGGCGACTCTCGGCGTGCGGTGATAGCCAAGCCATGGGAGACAAGAAGAGCCCCACCAGGCCGAAGCGGCAGCCGAAGCC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ATTGACAAACAGAGCGGTCGCGGCGGCGACTCTCGGCGTGCGGTGATAGCCAAGCCATGGGAGACAAGAAGAGCCCCACCAGGCCGAAGCGGCAGCCGAAGCCGTCCTCGGATGAGGGTTACTGGGACTGTAGCGTCTGCACCTTCCGGAACAGCGCCG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TGCCATGGCAAAAGAACTCCCGGATAATCCGAATTCGTGGTCCTCAGAATTGGTTTAGGGTTGTTTCGCGGTTCTTCCCGTATTCTGCCTCCGAGGCCCAGTGGGGCTGGCTGTGGGCCCCCTGTGCTGTTTGAGGCGTGAAACTCACCTCAGGAAATGTATC',\n",
       "       b'AACTCACCTCAGGAAATGTATCTGATCCATTAGCGTGGATTCATATTATTTGGTGATGGAGAATCTTCAGCTGTGTTAAGTGTTACCGTCAGTTTCAGAGATGGCTTCTTTGCAAAGGAAAGGGCTGCAGGCAAGGATTCTCACCTCTGAAGAAGAGGAGAAACTGAAAAGAGACCAAACTTTGGTGTCTGATTTTAAACAGC',\n",
       "       b'$$$$$$$$$ATCGACGGAAGTGCACCTGACTGAGCGGAAGTAGGAGCTCTCAGAGGCTAAGAAGGTGGAGACCGGAGAAGCTGTGAGGTTCTTTAGCGTCACCTCCCTCACTGGGCAGCATGGGGGAGAAGTCAGAGAACTGTGGGGTTCCAGAGGATCTGTTAAATGGTTTGAAGGTTACAGATACTCAGGAAGCCGAGTGT',\n",
       "       b'GTGCACCTGACTGAGCGGAAGTAGGAGCTCTCAGAGGCTAAGAAGGTGGAGACCGGAGAAGCTGTGAGGTTCTTTAGCGTCACCTCCCTCACTGGGCAGCATGGGGGAGAAGTCAGAGAACTGTGGGGTTCCAGAGGATCTGTTAAATGGTTTGAAGGTTACAGATACTCAGGAAGCCGAGTGTGCTGGCCCTCCAGTTCCTG',\n",
       "       b'AATTTCAGTATTTGCTGTCAAAATGGCTTTAGCCACATTGTGTGGAGGGAAGATCATGGACAAATTAAGATATATTTTCTCAATGATTTCTGACTCCAGTGGGGTGATGGTTTATGGACGATATGACCAATTCCTTCGGGAAGTTCTCAAACTACCCACGGCAGTTTTTGAAGGTCCTTCATTTGGTTACACAGAACAGTCAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$AATGATTGAAGATAGTGGGAAAAGAGGAAATACCATGGCAGAAAGAAGACAGCTGTTTGCAGAGATGAGGGCTCAAGATCTGGATCGCATCCGACTCTCCACCT',\n",
       "       b'$$$$$$$$$$$$$$$CCCCCAGTGAAGGTGCGCGCGTGGCGGAGGCTGGTTTTCCGTCTGGTGAGGGGTTACTTCCGGGTCGGACGGCGCTAGCTGCAGCATCGGAGTGTGGCAGTGCTGGGCTGGCCGGCGGGCTGGGCTGCGGCCCGCGCGCGGCCGGCGATGCAGGGGGGCAACTCCGGGGTCCGCAAGCGCGAAGAGGA',\n",
       "       b'GAGGGGTTACTTCCGGGTCGGACGGCGCTAGCTGCAGCATCGGAGTGTGGCAGTGCTGGGCTGGCCGGCGGGCTGGGCTGCGGCCCGCGCGCGGCCGGCGATGCAGGGGGGCAACTCCGGGGTCCGCAAGCGCGAAGAGGAGGGCGACGGGGCTGGGGCTGTGGCTGCGCCGCCGGCCATCGACTTTCCCGCCGAGGGCCCGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GTCGCGACCCTGGTCCGGACCTGACCTGAATTGCGACCCCAACCTGGACTGCTCCCCTGACCGCAACCCCTACCCCCGCCCACCAGTATGGCCCGGCACGTGTTCCTAACGGGGCCCCCAGGA',\n",
       "       b'$$$$$$$$$$$$$GTCGCGACCCTGGTCCGGACCTGACCTGAATTGCGACCCCAACCTGGACTGCTCCCCTGACCGCAACCCCTACCCCCGCCCACCAGTATGGCCCGGCACGTGTTCCTAACGGGGCCCCCAGGAGTTGGAAAAACAACATTGATCCATAAAGCCAGTGAGGTTTTAAAATCCTCTGGTGTGCCTGTTGATG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCTGGCTGCGCACGCGCGCCGCCTCATTTCCGGTGCTCTCTCTCGCTGGGTCGCTCGGGTCGGCTTCGGTCGCTACCGCTCCCGCTCTGCCACCCCCGCCAACCGCCGCTCGGGCCTCCGTCGCTGCCGCGTCGCTTTCTCGCTCCTT',\n",
       "       b'TGGGTCGCTCGGGTCGGCTTCGGTCGCTACCGCTCCCGCTCTGCCACCCCCGCCAACCGCCGCTCGGGCCTCCGTCGCTGCCGCGTCGCTTTCTCGCTCCTTGGATCGCACATCCTCCCAGATGCAGCGCCGGGACGACCCCGCCGCGCGCATGAGCCGGTCTTCGGGCCGTAGCGGCTCCATGGACCCCTCCGGTGCCCACC',\n",
       "       b'GGTCGCTACCGCTCCCGCTCTGCCACCCCCGCCAACCGCCGCTCGGGCCTCCGTCGCTGCCGCGTCGCTTTCTCGCTCCTTGGATCGCACATCCTCCCAGATGCAGCGCCGGGACGACCCCGCCGCGCGCATGAGCCGGTCTTCGGGCCGTAGCGGCTCCATGGACCCCTCCGGTGCCCACCCCTCGGTGCGTCAGACGCCGT',\n",
       "       b'CCAGATGCAGCGCCGGGACGACCCCGCCGCGCGCATGAGCCGGTCTTCGGGCCGTAGCGGCTCCATGGACCCCTCCGGTGCCCACCCCTCGGTGCGTCAGACGCCGTCTCGGCAGCCGCCGCTGCCTCACCGGTCCCGGGGAGGCGGAGGGGGATCCCGCGGGGGCGCCCGGGCCTCGCCCGCCACGCAGCCGCCACCGCTGC',\n",
       "       b'GCCGCCACCGCTGCTGCCGCCCTCGGCCACGGGTCCCGACGCGACAGTGGGCGGGCCAGCGCCGACCCCGCTGCTGCCCCCCTCGGCCACAGCCTCGGTCAAGATGGAGCCAGAGAACAAGTACCTGCCCGAACTCATGGCCGAGAAGGACTCGCTCGACCCGTCCTTCACTCACGCCATGCAGCTGCTGACGGCAGAAATTG',\n",
       "       b'GCGGTGCCTCGGGTGGCGGGAAGAGGAGGCGCGAGAATGGAGGTGGAGGCCGTCTGTGGTGGCGCGGGCGAGGTGGAGGCCCAGGACTCTGACCCTGCCCCTGCCTTCAGCAAGGCCCCCGGCAGCGCCGGCCACTACGAACTGCCGTGGGTTGAAAAATATAGGCCAGTAAAGCTGAATGAAATTGTCGGGAATGAAGACAC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGGGCTTGCGTGGCGGCGTCAAGGGGCGGTGCCTCGGGTGGCGGGAAGAGGAGGCGCGAGAATGGAGGTGGAGGCCGTCTGTGGTGGCGCGGGCGAGGTGGAGGCCCAGGACTCTGACCCTGCCCCTGCCTTCAGCAAGGCCCCCGGCAGCGCCGGCCACTACG',\n",
       "       b'TGAGTTTTGAGCTGATTGAGAAATAAGAACCTACAGATGAAGAAGCAAGACAGTACCTTTAAAAAAATTAGCTTTTTATTCAGATTCTCTTTGTGGCCAGATGGGTTTGTATGGACAGGCTTGTCCATCTGTAACTTCATTAAGGATGACATCTGAACTGGAGAGCAGCCTAACGTCTATGGACTGGTTACCACAGCTCACCA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$CCGGTCTGGCTTGGGCAGGCTGCCCGGGCCGTGGCAGGAAGCCGGAAGCAGCCGCGGCCCCAGTTCGGGAGACATGGCGGGCGTTAAAGCTCTCGTGGCATTATCCTTCAGTGGGGCTATTGGACTGACTTTTCTTATGCTGGGATGTGCCTTAGAGGATTATGGGTGTACTTCTC',\n",
       "       b'AAAGCTCTCGTGGCATTATCCTTCAGTGGGGCTATTGGACTGACTTTTCTTATGCTGGGATGTGCCTTAGAGGATTATGGGTGTACTTCTCTGAAGTAAGATGATTTGTCAAAAATTCTGTGTGGTTTTGTTACATTGGGAATTTATTTATGTGATAACTGCGTTTAACTTGTCATATCCAATTACTCCTTGGAGATTTAAGT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$GAGCCATTGATTGGTCGACGCCCCCAGAGGGTTACAATTCAAACGCGGGCGGGCGGGCCCGCAGTCCTGCAGTTGCAGTCGTGTTCTCCGAGTTCCTGTCTCTCTGCCAACGCCGCCCGGATGGCTTCCCAAAACCGCGACCCAGCCGCCACTAGCGTCGCCGCCGCCCGTAAAGGAGCTGAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$GAGCCATTGATTGGTCGACGCCCCCAGAGGGTTACAATTCAAACGCGGGCGGGCGGGCCCGCAGTCCTGCAGTTGCAGTCGTGTTCTCCGAGTTCCTGTCTCTCTGCCAACGCCGCCCGGATGGCTTCCCAAAACCGCGACCCAGCCGCCACTAGCGTCGCCGCCGCCCGTAAAGGAGCTGAGCC',\n",
       "       b'CCCCCAGAGGGTTACAATTCAAACGCGGGCGGGCGGGCCCGCAGTCCTGCAGTTGCAGTCGTGTTCTCCGAGTTCCTGTCTCTCTGCCAACGCCGCCCGGATGGCTTCCCAAAACCGCGACCCAGCCGCCACTAGCGTCGCCGCCGCCCGTAAAGGAGCTGAGCCGAGCGGGGGCGCCGCCCGGGGTCCGGTGGGCAAAAGGC',\n",
       "       b'CACTAGCGTCGCCGCCGCCCGTAAAGGAGCTGAGCCGAGCGGGGGCGCCGCCCGGGGTCCGGTGGGCAAAAGGCTACAGCAGGAGCTGATGACCCTCATGATGTCTGGCGATAAAGGGATTTCTGCCTTCCCTGAATCAGACAACCTTTTCAAATGGGTAGGGACCATCCATGGAGCAGCTGGAACAGTATATGAAGACCTGA',\n",
       "       b'GGGGCTGTGCGGGAGCATCGCGAGAGTTACATTAACTGTGGCGGCGGGAAGGCGGAGCCTGCAGCTGGCTGGGCGGTTAGGAGGGCCCGGGGCCGAGACGATGGCTGACCACAACCCTGACAGCGACTCCACGCCGCGCACGCTGCTGCGACGCGTGCTGGATACAGCGGACCCGCGCACCCCGCGGCGACCCCGGAGTGCTC',\n",
       "       b'TCAGGCCCAGTCCGCGGTGCCCCGGCGGGTGATGCCAAATACAGCCATGAAGAAAAAGGTGCTGCTGATGGGGAAGAGCGGGTCGGGGAAGACCAGCATGAGGTCGATAATCTTCGCCAATTACATTGCTCGCGACACCCGGCGCCTGGGGGCCACCATTGACGTGGAACACTCCCACGTCCGATTCCTAGGGAACCTGGTGC',\n",
       "       b'GCGAGGCGCGGCCTGCGAGTCCCCGGCAGCCCCCGACCCCTCCCTCGGCGCTGCGTGTAGGCCGCGCCCTCAGGCCCAGTCCGCGGTGCCCCGGCGGGTGATGCCAAATACAGCCATGAAGAAAAAGGTGCTGCTGATGGGGAAGAGCGGGTCGGGGAAGACCAGCATGAGGTCGATAATCTTCGCCAATTACATTGCTCGCG',\n",
       "       b'CTCTCCCCGAGTTGCCTCCTTTCTCCGGGTGCCGTACTGCCTTTTTTCCCCTCTTTCATTCTTTCTCTCCGTCTTTTTCTCCCCCCTCTGCGCACGAAGGATGTGCTTCTAGGTGGTGATCTGCCCTCCTCTCTCTCTTTTATCATTTCTCCCCCGCCGCCGGCGAGTTGACTCTTTCCCTATGTGTGTGAGGCGGCGGCGGC',\n",
       "       b'TCCGTCTTTTTCTCCCCCCTCTGCGCACGAAGGATGTGCTTCTAGGTGGTGATCTGCCCTCCTCTCTCTCTTTTATCATTTCTCCCCCGCCGCCGGCGAGTTGACTCTTTCCCTATGTGTGTGAGGCGGCGGCGGCAGCAGCAGCAGCAGCGGCTCCGGCGGCGGCAGCAGCGGCAGCAGCGACTTCAGCGGCGGCGGCGGCG',\n",
       "       b'AAAAGGCGGCGCGCCGGAGCCCGAGACCCGGGGAGCCGCCGCCGCCCCGCCGCCGCCCGCAGCCAGGGGAGCAGGAAGTCCGGACGCAGCCCCCATAGATATGGCAATGGTAGTCAGCACGTGGCGCGACCCCCAGGACGAGGTGCCCGGCTCACAGGGCAGCCAGGCCTCGCAGGCGCCGCCCGTGCCCGGCCCGCCGCCCG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCAGGCGCGGTGGTCGGACGACAGACCGTGTGTTTCCAAAATGGCGGCAGCGATGGATGTGGATACCCCGAGCGGCACCAACAGCGGCGCGGGCAAGAAGCGCTTTGAAGTGAAAAAGTGGAATGCAGTAGCCCTCTGGGCCT',\n",
       "       b'AAGATGGCCCGGTGCAGAGGACGGTTTGTCTGCCCAGTAATCCTGTTCAAGGGCAAGCACATTTGCAGGTCGGCCACACTGGCTGGATGGGGAGAGCTGTATGGACGCTCAGGCTACAACTATTTTTTCTCAGGGGGTGCAGATGATGCCTGGGCAGATGTGGAGGACGTCACGGAGGAGGACTGTGCTCTTCGAAGTGGTGA',\n",
       "       b'CGGTGGCTGAGGCGGTTCCGGAGGTTCTAGTGTCGGAGTTGGGTGCAGGCAGGTGCCATGGGCCCGCTTGAGGCACACTGAGGGGACGCGGGGCTGGGCCATGGCCGGCGCTCGGGCCGCCGCCGCCGCTGCCTCGGCGGGGTCCTCGGCCTCTTCAGGCAACCAGCCGCCTCAGGAGCTGGGGCTTGGGGAGCTGCTGGAGG',\n",
       "       b'GCTCTTGGTTCCCTACAGAAAGGGGCGGAGCCTGGACTGGGGGGCAGGCTCAGATTCAGGTTAAATTGTGGATTGAGCTCGCAGTTACAGACAGCTGACCATGGAAGCGAATGGGTTGGGACCTCAGGGTTTTCCGGAGCTGAAGAATGACACATTCCTGCGAGCAGCCTGGGGAGAGGAAACAGACTACACTCCCGTTTGGT',\n",
       "       b'TCTTGGTTCCCTACAGAAAGGGGCGGAGCCTGGACTGGGGGGCAGGCTCAGATTCAGGTTAAATTGTGGATTGAGCTCGCAGTTACAGACAGCTGACCATGGAAGCGAATGGGTTGGGACCTCAGGGTTTTCCGGAGCTGAAGAATGACACATTCCTGCGAGCAGCCTGGGGAGAGGAAACAGACTACACTCCCGTTTGGTGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CTGCTCGTTGAGTGAAGAAAATCCACCGGCATCGCCTGAGCCCCGCTACCGAGAAGGGCGCCGCTTCCTCCGGGGAGGGGGATAAAGATCCCCCGCCGCCGGC',\n",
       "       b'AAAATCCACCGGCATCGCCTGAGCCCCGCTACCGAGAAGGGCGCCGCTTCCTCCGGGGAGGGGGATAAAGATCCCCCGCCGCCGGCCCATGAGGATATTGCCGTGAAAGGCACAGCGACTGCAGCAGGAACCGGACCCGGCACCGGAGCGGCGGCGGCGGCGGCAGCAGCGGTACCGCCTCCTCACCCGGCGGCGGCAGCAGC',\n",
       "       b'CCTCCTCACCCGAACATCAGGGCCCTCCAGACTCAGGCGCCCCAACAAATTCCTAGAGGACCTGTGCAACAACCTCTTGAGGATCGAATCTTCACTCCCGCTGTCTCAGCAGTCTACAGCACGGTAACACAAGTGGCAAGACAGCCGGGAACCCCTACCCCATCCCCTTATTCAGCACATGAAATAAACAAGGGGCATCCAAA',\n",
       "       b'GATCGAATCTTCACTCCCGCTGTCTCAGCAGTCTACAGCACGGTAACACAAGTGGCAAGACAGCCGGGAACCCCTACCCCATCCCCTTATTCAGCACATGAAATAAACAAGGGGCATCCAAATCTTGCGGCAACGCCCCCGGGACATGCATCGTCCCCTGGACTCTCTCAAACCCCTTATCCCTCTGGACAGAATGCAGGTCC',\n",
       "       b'GGTATACCCTCAAACCCCTCAGACAATGAATTCACAACCTCAAACCCGTTCTCCGTTTTTCCAGAGGCCTCAAATACAGCCTCCTAGAGCTACCATCCCGAACAGCAGTCCTTCCATTCGTCCTGGTGCACAGACACCCACTGCAGTGTACCAGGCTAATCAGCACATCATGATGGTTAACCATCTGCCCATGCCGTACCCAG',\n",
       "       b'GTTAAAGTCTCCTTCCCCAGTCCTTAGGCTAGTCCTCAGTGGAGAGAAGAAAGAACAAGAAGGCCAGACATCTGAAACTACTGCAATAGTATCCATAGCAGAGCTTCCTCTGCCTCCATCACCTACCACTGTTTCTTCTGTTGCTCGAAGTACAATTGCAGCCCCCACCTCTTCTGCTCTTAGTAGCCAACCAATATTCACCA',\n",
       "       b'TACTGCAATAGTATCCATAGCAGAGCTTCCTCTGCCTCCATCACCTACCACTGTTTCTTCTGTTGCTCGAAGTACAATTGCAGCCCCCACCTCTTCTGCTCTTAGTAGCCAACCAATATTCACCACTGCTATAGATGACAGATGTGAACTCTCATCCCCAAGAGAAGACACAATTCCTATACCCAGCCTCACATCTTGCACAG',\n",
       "       b'AATAGTATCCATAGCAGAGCTTCCTCTGCCTCCATCACCTACCACTGTTTCTTCTGTTGCTCGAAGTACAATTGCAGCCCCCACCTCTTCTGCTCTTAGTAGCCAACCAATATTCACCACTGCTATAGATGACAGATGTGAACTCTCATCCCCAAGAGAAGACACAATTCCTATACCCAGCCTCACATCTTGCACAGAAACAT',\n",
       "       b'GTATCCATAGCAGAGCTTCCTCTGCCTCCATCACCTACCACTGTTTCTTCTGTTGCTCGAAGTACAATTGCAGCCCCCACCTCTTCTGCTCTTAGTAGCCAACCAATATTCACCACTGCTATAGATGACAGATGTGAACTCTCATCCCCAAGAGAAGACACAATTCCTATACCCAGCCTCACATCTTGCACAGAAACATCAGA',\n",
       "       b'TCCACTGGTTTCTAGTACTAACCTAATTAATGAAATAAATGGAGTTAGCGAAAAATTATCAGCCACGGAGAGCATTGTGGAAATAGTAAAACAGGAAGTATTGCCATTGACTCTTGAATTGGAGATTCTCGAAAATCCCCCAGAAGAAATGAAACTGGAGTGTATCCCAGCTCCCATCACCCCTTCCACAGTTCCTTCCTTTC',\n",
       "       b'TGAAATAAATGGAGTTAGCGAAAAATTATCAGCCACGGAGAGCATTGTGGAAATAGTAAAACAGGAAGTATTGCCATTGACTCTTGAATTGGAGATTCTCGAAAATCCCCCAGAAGAAATGAAACTGGAGTGTATCCCAGCTCCCATCACCCCTTCCACAGTTCCTTCCTTTCCTCCAACTCCTCCAACTCCTCCAGCTTCTC',\n",
       "       b'CCCGGGACATGCATCGTCCCCTGGACTCTCTCAAACCCCTTATCCCTCTGGACAGAATGCAGGTCCAACCACGCTGGTATACCCTCAAACCCCTCAGACAATGAATTCACAACCTCAAACCCGTTCTCCGTTTTTCCAGAGGCCTCAAATACAGCCTCCTAGAGCTACCATCCCGAACAGCAGTCCTTCCATTCGTCCTGGTG',\n",
       "       b'AAGAACAGTGGGAAGAAAGAATACAGAACTGGCATGAAGAACATAGAGGAATGTTAAGGGAGGATTCTATGATGGAATACCTGAAGATTGCACAAGATCTAGAAATGTATGGAGTCAACTATTTTGAAATAAAAAATAAAAAAGGAACTGAATTGTGGCTAGGTGTTGATGCTTTGGGTCTGAATATTTATGAGCATGACGAC',\n",
       "       b'CCACACGCCGGCGGGCAGAAGCCGCCCGCTCTCCGGAAAGTGATAACAGAATTCATTGAAGTGGAGAATTTTTAAAGAAGGTAACAAAAAGAGAAAGAAAATGCCGAAACCAATCAACGTAAGAGTAACTACAATGGATGCTGAGCTGGAATTTGCCATTCAGCCCAATACAACTGGCAAACAACTTTTTGACCAGGTGGTGA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TACGCCTCGGTGCAGCCCCCGGCGAAGCCCAGCGCAGCTCAGCTAAACTCAGCGGAGCCAGCGCGGCGCGATGGAAGGTCGAGTGCAGCTGATGAAGGCCCTCCTGGCTCGGCCCCTCCGGCCCGCGGCGCGTCGCTGGAGGAACCCGATTCCCTTTCCCGAGACGTTTGATG',\n",
       "       b'$$$$$$$$$$$$$$$$GACGTCATCGCCGCGGGGCGGAGGCGACAGTGTCTAGCGGGAGCTCCGCGTGTAGCTACGCCGGCCGCCTGGCTTTGAGACAACGTGATTCTCCGCAGCTGGTCGCCTACCCGTGATGTTCTGCCCACGTCGAGACCTGAGCTGAAATGGCAGACGATCTCGGAGACGAGTGGTGGGAGAACCAGCC',\n",
       "       b'GGGCGGAGGCGACAGTGTCTAGCGGGAGCTCCGCGTGTAGCTACGCCGGCCGCCTGGCTTTGAGACAACGTGATTCTCCGCAGCTGGTCGCCTACCCGTGATGTTCTGCCCACGTCGAGACCTGAGCTGAAATGGCAGACGATCTCGGAGACGAGTGGTGGGAGAACCAGCCGACTGGAGCAGGCAGCAGCCCAGAAGCATCA',\n",
       "       b'AGCTCCGCGTGTAGCTACGCCGGCCGCCTGGCTTTGAGACAACGTGATTCTCCGCAGCTGGTCGCCTACCCGTGATGTTCTGCCCACGTCGAGACCTGAGCTGAAATGGCAGACGATCTCGGAGACGAGTGGTGGGAGAACCAGCCGACTGGAGCAGGCAGCAGCCCAGAAGCATCAGATGGTGAAGGAGAAGGAGACACAGA',\n",
       "       b'TCAGAGAAAACCAAACAGCCTAAAGAATGTTTTTTGATACAACCAAAGGAAAGAAAAGAGAATACCACCAAGACCAGGAAAAGAAGAAAGAAGAAAATTACTGATGTTCTTGCAAAATCAGAACCAAAACCAGGGTTACCTGAAGACCTACAGAAGCTGATGAAGGACTATTATAGCAGCAGACGCTTGGTGATTGAATTAGA',\n",
       "       b'CGCGTGTAGCTACGCCGGCCGCCTGGCTTTGAGACAACGTGATTCTCCGCAGCTGGTCGCCTACCCGTGATGTTCTGCCCACGTCGAGACCTGAGCTGAAATGGCAGACGATCTCGGAGACGAGTGGTGGGAGAACCAGCCGACTGGAGCAGGCAGCAGCCCAGAAGCATCAGATGGTGAAGGAGAAGGAGACACAGAAGTGA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$GGGCGGCCCCTTTCTTGAGCGCAGAAACACTTACTTTTCCCCCTACCCTGCTCCTCCTCCTCCACAGCCGTCTTTCTCTTTGCCTCAGCCACTTCCTTCCTTGGCCTCACCCTCCCCAGTGCACTGAAGAAGGTAACCGGGTCCAGACCCACGCGGCGCCAGTTCTCCGGCGGGAAGGAAAA',\n",
       "       b'GAAACACTTACTTTTCCCCCTACCCTGCTCCTCCTCCTCCACAGCCGTCTTTCTCTTTGCCTCAGCCACTTCCTTCCTTGGCCTCACCCTCCCCAGTGCACTGAAGAAGGTAACCGGGTCCAGACCCACGCGGCGCCAGTTCTCCGGCGGGAAGGAAAACCGCGCAGAGAGGCAGCAATGAATGTGGATCACGAGGTTAACCT',\n",
       "       b'TTGGCCTCACCCTCCCCAGTGCACTGAAGAAGGTAACCGGGTCCAGACCCACGCGGCGCCAGTTCTCCGGCGGGAAGGAAAACCGCGCAGAGAGGCAGCAATGAATGTGGATCACGAGGTTAACCTCTTAGTGGAGGAAATTCATCGTTTGGGTTCAAAAAATGCTGATGGAAAGTTAAGCGTGAAATTTGGGGTCCTCTTCC',\n",
       "       b'CCGCCCCTCTCGAGGCGGGGCGGGGCCTCCGCGTTCGCTACAAAAGCCGCGCGGCGGCTGCGACCGGGACGGCCCGTTTTCCGCCAGCTCGCCGCTCGCTATGGCGTCGCTCACCGTGAAGGCCTACCTTCTGGGCAAGGAGGACGCGGCGCGCGAGATTCGCCGCTTCAGCTTCTGCTGCAGCCCCGAGCCTGAGGCGGAAG',\n",
       "       b'ACCACCGCCCACCGTGTGCTCAGGAGGCGCCCCGCAACATGGTGCACCCCAATGTGATCTGCGATGGCTGCAATGGGCCTGTGGTAGGAACCCGCTACAAGTGCAGCGTCTGCCCAGACTACGACTTGTGTAGCGTCTGCGAGGGAAAGGGCTTGCACCGGGGGCACACCAAGCTCGCATTCCCCAGCCCCTTCGGGCACCTG',\n",
       "       b'CCGCCTTGGGGGCGTGGCCGCGCGCTGGTCGGCTGGGGCGGGGCCTGCTTCTGGCCTCATCTAGCCCCGCCCCAGGCGAGGGCGCCGCACCCACACCGCGCTGCGCAGTTTTGTTCTGCTCCAGCTGTTCGAAGGTGATCCAGACGCAAGATGGCTGTCCTCTCTAAGGAATATGGTTTTGTGCTTCTAACTGGTGCTGCCAG',\n",
       "       b'CTGGCCTCATCTAGCCCCGCCCCAGGCGAGGGCGCCGCACCCACACCGCGCTGCGCAGTTTTGTTCTGCTCCAGCTGTTCGAAGGTGATCCAGACGCAAGATGGCTGTCCTCTCTAAGGAATATGGTTTTGTGCTTCTAACTGGTGCTGCCAGCTTTATAATGGTGGCCCACCTAGCCATCAATGTTTCCAAGGCCCGCAAGA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TGGGCTGAGGGGCAGCGGCTTAGGCTCCGGCGTCTGCAGGGGTCGCCGAGCTAACCCGTGGCTAGGCGAGTGGGGCGGGGCGGCCGGCACCATGTCGAGGCAGGCGAACCGTGGCACCGAGAGCAAGAAAATGAGCTCTGAGCTCTTCACCCTGACCTAT',\n",
       "       b'$$$$$$$$$TGGGCTGAGGGGCAGCGGCTTAGGCTCCGGCGTCTGCAGGGGTCGCCGAGCTAACCCGTGGCTAGGCGAGTGGGGCGGGGCGGCCGGCACCATGTCGAGGCAGGCGAACCGTGGCACCGAGAGCAAGAAAATGAGCTCTGAGCTCTTCACCCTGACCTATGGTGCCCTGGTCACCCAGCTATGTAAGGACTATG',\n",
       "       b'AGGGGTCGCCGAGCTAACCCGTGGCTAGGCGAGTGGGGCGGGGCGGCCGGCACCATGTCGAGGCAGGCGAACCGTGGCACCGAGAGCAAGAAAATGAGCTCTGAGCTCTTCACCCTGACCTATGGTGCCCTGGTCACCCAGCTATGTAAGGACTATGAAAATGATGAAGATGTGAATAAACAGCTGGACAAAATGGGCTTTAA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$GAAAGGAGCGGGGCATCCCAACGGCGCCACCTTTAAGCGTCACGGGTGGGGCTGCAGCTTCTGGACCTAGGACTTTGAACATGTCGCGCCTGAAGCGGATAGCGGGGCAGGATCTCCGCGCTGGTTTCAAAGCAGGTGGAAGAGACTGCGGTACCTCGGTACCCCAAGGGCTGTTGAAGGCAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$GCAGTCCAGATGTCGTCAGCACCAGCGCCTGGGCTGGAGGACAGAGAAGCCTTTTCCGTTGCCGGTGCCGGCCTAGCGTCCTGGAATTACTTCAATCAAGAGCGAGAACCCGAGCAGCGCCATGAGCAACACTACCGTCGTCCCCAGCACTGCAGGTCCGGGCCCCAGCGGCGGGCCCGGTGG',\n",
       "       b'CCAGCGCCTGGGCTGGAGGACAGAGAAGCCTTTTCCGTTGCCGGTGCCGGCCTAGCGTCCTGGAATTACTTCAATCAAGAGCGAGAACCCGAGCAGCGCCATGAGCAACACTACCGTCGTCCCCAGCACTGCAGGTCCGGGCCCCAGCGGCGGGCCCGGTGGCGGAGGTGGTGGTGGCGGCGGAGGCGGCGGCACCGAGGTAA',\n",
       "       b'CCGGGCCCCAGCGGCGGGCCCGGTGGCGGAGGTGGTGGTGGCGGCGGAGGCGGCGGCACCGAGGTAATCCAGGTGACTAATGTCTCCCCGAGCGCTAGCTCTGAGCAGATGCGGACTCTCTTCGGTTTCCTAGGCAAGATCGACGAACTGCGCCTCTTCCCGCCGGATGATTCGCCTTTGCCAGTCTCATCTCGTGTCTGCTT',\n",
       "       b'CAGCTGAGGGACGGCCTGTCGTACGGTGCGGATGGTGGTGGCCTGCGAGGCTCATTTCTAGCAAGGAACAAGGCTTTCCCGCTTTGATTTTATAAATATTATGTTTACAAAGCTGTAATATATAGAAATTGATAAGACGTGTCCCTGTCCCTGGAAACGCAGGCACCGCGTGTTTGGAAAGACATTCATCTGGGCTGTTTGAC',\n",
       "       b'TTTTAGACTGACTGTGGGTTCACTGGAATAAAAAGGAAGAAACAAAGAGCATTGCAGGCATCGGGACTGTCACATTTGACAAGATCAAAGCTGCAGGAAAATGGACAGTGAGGTTCAGAGAGATGGAAGGATCTTGGATTTGATTGATGATGCTTGGCGAGAAGACAAGCTGCCTTATGAGGATGTCGCAATACCACTGAATG',\n",
       "       b'TGGATCCCCAGACAGGAAGCCCTCAAAGAAATCCAAGACAGACAACTCTTCTCTTAGTTCACCACTAAATCCTAAGTTATGGTGTCACGTACACTTGAAGAAGTCATTGAGTGGCTCGCCACTCAAAGTGAAGAACTCAAAGAATTCCAAATCTCCTGAAGAACATCTAGAAGAAATGATGAAGATGATGTCGCCCAATAAGC',\n",
       "       b'CCCACCCCCGGGCGCCTGGCGCTCGCTCCGGGCCGCGGGGCCTAGTGCTGCGCCGCGGGGCCGGCCCCAGCAGCCGCCAGTCCCCACCGCCGCCGCCGCGATGGCGCCGCTCCTGGGCCGCAAGCCCTTCCCGCTGGTGAAGCCGTTGCCCGGAGAGGAGCCGCTCTTCACCATCCCGCACACTCAGGAGGCCTTCCGCACCC',\n",
       "       b'TCCCTTCTGGTCGCCAGTGGACGCCGACGTCATGACGTCGCGTTCCGTAGGGCTCTTCCCGGGCTTTGGTGGGTCACGTGAACCACTTTTCGCGCGAAACCTGGTTGTTGCTGTAGTGGCGGAGAGGATCGTGGTACTGCTATGGCGGAATCATCGGAATCCTTCACCATGGCATCCAGCCCGGCCCAGCGTCGGCGAGGCAA',\n",
       "       b'AGTGGACGCCGACGTCATGACGTCGCGTTCCGTAGGGCTCTTCCCGGGCTTTGGTGGGTCACGTGAACCACTTTTCGCGCGAAACCTGGTTGTTGCTGTAGTGGCGGAGAGGATCGTGGTACTGCTATGGCGGAATCATCGGAATCCTTCACCATGGCATCCAGCCCGGCCCAGCGTCGGCGAGGCAATGATCCTCTCACCTC',\n",
       "       b'GTTCCGTAGGGCTCTTCCCGGGCTTTGGTGGGTCACGTGAACCACTTTTCGCGCGAAACCTGGTTGTTGCTGTAGTGGCGGAGAGGATCGTGGTACTGCTATGGCGGAATCATCGGAATCCTTCACCATGGCATCCAGCCCGGCCCAGCGTCGGCGAGGCAATGATCCTCTCACCTCCAGCCCTGGCCGAAGCTCCCGGCGTA',\n",
       "       b'TGAGGCACCGGCGGAGCTGCTGCAGATCTTTGATGAGGCTGCCCTGGAGGTGGTACTGGCCATGTACCCCAAGTACGACCGCATCACCAACCACATCCATGTCCGCATCTCCCACCTGCCTCTGGTGGAGGAGCTGCGCTCGCTGAGGCAGCTGCATCTGAACCAGCTGATCCGCACCAGTGGGGTGGTGACCAGCTGCACTG',\n",
       "       b'GGGGTTAGGTTGAGGGGGGGCGTCGGTCCGTTCTGGGCGGGGGATGACTCACAGCCCATCCCATCTCCCAGACGCCGCCCGCCCGCGCAGTGCTAGCTCCATGGCTTAGCGGAGGAGGCGGCAGTGGCGAGCTGGGGGGAGGGGGGACTCTTATTTTGTTAGGGGGACCGGGCCGAGGCCCGACCGGCCTGGCAGGGCTCGCC',\n",
       "       b'GCGGCAGTGGCGAGCTGGGGGGAGGGGGGACTCTTATTTTGTTAGGGGGACCGGGCCGAGGCCCGACCGGCCTGGCAGGGCTCGCCCGGGGCCGGGCGTCATGTCTCATGCGGCCGAACCAGCTCGGGATGGCGTAGAGGCCAGCGCGGAGGGCCCTCGAGCCGTGTTCGTGCTGTTGGAGGAGCGCAGGCCGGCCGACTCGG',\n",
       "       b'GTCCCTCGCGTCGGGCCCGACAGCGCCTGCGCACTGCGCCGCCGGCTGGGGTGCTGGGGGCGGGGCAGGGGCAGGTGTAGCCTCTGTGCCTCGTTGTCCCCTGGCGCTACCCGGACATCTCTCAGGGTGCCGGCACCATGAAGATCTGGACTTCGGAGCACGTCTTTGACCACCCGTGGGAAACTGTTACAACAGCTGCAATG',\n",
       "       b'GCCGCCGGCTGGGGTGCTGGGGGCGGGGCAGGGGCAGGTGTAGCCTCTGTGCCTCGTTGTCCCCTGGCGCTACCCGGACATCTCTCAGGGTGCCGGCACCATGAAGATCTGGACTTCGGAGCACGTCTTTGACCACCCGTGGGAAACTGTTACAACAGCTGCAATGCAGAAATACCCAAACCCTATGAACCCAAGTGTGGTTG',\n",
       "       b'CAGGGGCAGGTGTAGCCTCTGTGCCTCGTTGTCCCCTGGCGCTACCCGGACATCTCTCAGGGTGCCGGCACCATGAAGATCTGGACTTCGGAGCACGTCTTTGACCACCCGTGGGAAACTGTTACAACAGCTGCAATGCAGAAATACCCAAACCCTATGAACCCAAGTGTGGTTGGAGTTGATGTGTTGGACAGACATATAGA',\n",
       "       b'CTTCCAGTTCCCCACCGGATGAAGCGGAAGTGCGTCATGTCGAGGCGCCAAGGCGCTCGTTTGGCGCGCGCGCCCTAGGCGGCGGATCTAAGCTAACTTCTTGGATCTTTTCTTGTTTCTCCTTGGTTTTTGACTTTTTCTGGACCCTGGTGTCTACGATTTCCGAGATGCCGTCTTCTTTGTTGGGCGCGGCGATGCCGGCC',\n",
       "       b'GCCAAGGCGCTCGTTTGGCGCGCGCGCCCTAGGCGGCGGATCTAAGCTAACTTCTTGGATCTTTTCTTGTTTCTCCTTGGTTTTTGACTTTTTCTGGACCCTGGTGTCTACGATTTCCGAGATGCCGTCTTCTTTGTTGGGCGCGGCGATGCCGGCCTCTACATCTGCCGCAGCCCTGCAGGAAGCTCTGGAAAATGCTGGAC',\n",
       "       b'GCGCGCCCTAGGCGGCGGATCTAAGCTAACTTCTTGGATCTTTTCTTGTTTCTCCTTGGTTTTTGACTTTTTCTGGACCCTGGTGTCTACGATTTCCGAGATGCCGTCTTCTTTGTTGGGCGCGGCGATGCCGGCCTCTACATCTGCCGCAGCCCTGCAGGAAGCTCTGGAAAATGCTGGACGGCTCATCGACCGTCAGTTGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GTTAACTTCCTGACCCAGGAAGTGGCAGCAACAGAGGGGACTAGCAGCGAATATACTTTACACCAAATCTCAGAAGATTCAGAACTTAGATGAGTGGGGCCCAGGACAGGAACCCTGGAGCCTTGGAAGGAGGGGAGCCCCATCTCCCCAGAAGA',\n",
       "       b'ACATAGAGGTGCAGGTGAGGTGTATTTTCATCACGGTGGAAAATTCTGGCTGCTTCATCTCCATCTCTAGAGCCAATATTGGAGCTTTTCAATAAAAGCTATGGCCTCAACCACCAGCACCAAGAAGATGATGGAGGAAGCCACCTGCTCCATCTGCCTGAGCCTGATGACGAACCCAGTAAGCATCAACTGTGGACACAGCT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TCTCGCACTCTGTTCTTCCGCCGCTCCGCCGTCGCGTTTCTCTGCCGGTGAGCGCCCCGCCCCGGGGCCTGAGCTGGACGTCGCAGGCCTGCGCCCCCCGACCCCGGCTGGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TCTCGCACTCTGTTCTTCCGCCGCTCCGCCGTCGCGTTTCTCTGCCGGTGAGCGCCCCGCCCCGGGGCCTGAGCTGGACGTCGCAGGCCTGCGCCCCCCGACCCCGGCTGGCCCCGCTTCCAGCTGCCGAGGCCTCGTCGCGCC',\n",
       "       b'GCTGGACGTCGCAGGCCTGCGCCCCCCGACCCCGGCTGGCCCCGCTTCCAGCTGCCGAGGCCTCGTCGCGCCTTCCCCGGGAACAAAAGGCGGGGTCGCAATGGAAGAAGAGATCGCCGCGCTGGTCATTGACAATGGCTCCGGCATGTGCAAAGCTGGTTTTGCTGGGGACGACGCTCCCCGAGCCGTGTTTCCTTCCATCG',\n",
       "       b'CCCGACCCCGGCTGGCCCCGCTTCCAGCTGCCGAGGCCTCGTCGCGCCTTCCCCGGGAACAAAAGGCGGGGTCGCAATGGAAGAAGAGATCGCCGCGCTGGTCATTGACAATGGCTCCGGCATGTGCAAAGCTGGTTTTGCTGGGGACGACGCTCCCCGAGCCGTGTTTCCTTCCATCGTCGGGCGCCCCAGACACCAGGGCG',\n",
       "       b'GCTGGCCCCGCTTCCAGCTGCCGAGGCCTCGTCGCGCCTTCCCCGGGAACAAAAGGCGGGGTCGCAATGGAAGAAGAGATCGCCGCGCTGGTCATTGACAATGGCTCCGGCATGTGCAAAGCTGGTTTTGCTGGGGACGACGCTCCCCGAGCCGTGTTTCCTTCCATCGTCGGGCGCCCCAGACACCAGGGCGTCATGGTGGG',\n",
       "       b'TGCCGAGGCCTCGTCGCGCCTTCCCCGGGAACAAAAGGCGGGGTCGCAATGGAAGAAGAGATCGCCGCGCTGGTCATTGACAATGGCTCCGGCATGTGCAAAGCTGGTTTTGCTGGGGACGACGCTCCCCGAGCCGTGTTTCCTTCCATCGTCGGGCGCCCCAGACACCAGGGCGTCATGGTGGGCATGGGCCAGAAGGACTC',\n",
       "       b'TACAACGAGCTGCGCGTGGCCCCGGAGGAGCACCCAGTGCTGCTGACCGAGGCCCCCCTGAACCCCAAGGCCAACAGAGAGAAGATGACTCAGATTATGTTTGAGACCTTCAACACCCCGGCCATGTACGTGGCCATCCAGGCCGTGCTGTCCCTCTACGCCTCTGGGCGCACCACTGGCATTGTCATGGACTCTGGAGACGG',\n",
       "       b'CAACCGTGTGCATTTATTGGGATAGGAAATAGTGACCAAGAAATGCAGCAGCTAAACTTGGAAGGAAAGAACTATTGCACAGCCAAAACATTGTATATATCTGACTCAGACAAGCGAAAGCACTTCATGTTGTCTGTAAAGATGTTCTATGGCAACAGTGATGACATTGGTGTGTTCCTCAGCAAGCGGATAAAAGTCATCTC',\n",
       "       b'AGGAAAGGAAAGAGCAAAGGAGGGGAAAGATGGGGGGCTGCAGTCTCCACGTACGTCCCTCAAAGCGCGTCCTAAAACCCGGATAACCGGAGCGCTCCCCATGGACCACACGGAGGGCTCGCCCGCGGAGGAGCCGCCTGCGCATGCTCCATCGCCTGGGAAATTTGGTGAGCGGCCTCCACCTAAACGACTTACTAGGGAAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CTGGGTGTACAGCGTCCTCGAAACCACGAGCAAGTGAGCAGATCCTCCGAGGCACCAGGGACTCCAGCCCATGCCATGGCGGATTCTGAGCGCCTCTCGGCTCCTGGCTGCTGGGCCGCCTGCACCAA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$CTGGGTGTACAGCGTCCTCGAAACCACGAGCAAGTGAGCAGATCCTCCGAGGCACCAGGGACTCCAGCCCATGCCATGGCGGATTCTGAGCGCCTCTCGGCTCCTGGCTGCTGGGCCGCCTGCACCAACTTCTCGCGCACTCGAAAGGGAATCCTCCTGTTTGCTGAGATTATATTAT',\n",
       "       b'CACCAAAGCCAATGGGAAGGGCCGGGAGCGCGCGGCGCGGGAGATTTAAAGGCTGCTGGAGTGAGGGGTCGCCCGTGCACCCTGTCCCAGCCGTCCTGTCCTGGCTGCTCGCTCTGCTTCGCTGCGCCTCCACTATGCTCTCCCTCCGTGTCCCGCTCGCGCCCATCACGGACCCGCAGCAGCTGCAGCTCTCGCCGCTGAAG',\n",
       "       b'GCGCGGGAGATTTAAAGGCTGCTGGAGTGAGGGGTCGCCCGTGCACCCTGTCCCAGCCGTCCTGTCCTGGCTGCTCGCTCTGCTTCGCTGCGCCTCCACTATGCTCTCCCTCCGTGTCCCGCTCGCGCCCATCACGGACCCGCAGCAGCTGCAGCTCTCGCCGCTGAAGGGGCTCAGCTTGGTCGACAAGGAGAACACGCCGC',\n",
       "       b'CCCCGGGGGTCTCCGGAAGGCGCCGGCGGAGGCTCCCGCGCTGCGCTTGAAAATCGCGCGCGGCCCCGCGGCCAGCCTGGGTAGGGGCAAGGCGCAGCCAATGGGAAGGGTCGGAGGCATGGCACAGCCAATGGGAAGGGCCGGGGCACCAAAGCCAATGGGAAGGGCCGGGAGCGCGCGGCGCGGGAGATTTAAAGGCTGCT',\n",
       "       b'ATCTCCCTTGCTTGGAGAGCCAGCCCTGTCTGAGCCTGGGGAACCACCTCTGTCCCCTCTGCCCGAGGAGCTGCCGTTGTCCCCATCTGGGGAGCCATCCTTGTCGCCTCAGCTGATGCCACCAGATCCCCTTCCTCCTCCACTCTCACCCATCATCACAGCTGCGGCCCCACCGGCCCTGTCTCCTTTGGGGGAGTTAGAGT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ATGGACAGCCAGAAGCTGGCTGGTGAGGATAAAGATTCAGAACCGGCAGCTGATGGACCTGCAGCTTCTGAGGACCCAAGTGCCACTGAGTCAGACCTGCCCA',\n",
       "       b'GAAGGGCTCCAGGATGGAGGCCGACCTGACTTCTCCGCCTCGGTGGGCTGGGTCGGCGGCTGGAGCATTACCCCTACTGCGGGTCCCGCTGCTGGCAGCGCTGGAAACTGGGTGGACGGCATGGGTTGGTCTCAGGATTTGTTCCGCGCCTTGTGGAGATCGCTGTCAAGGGAAGTGAAGGAGCACGTGGGCACGGACCAATT',\n",
       "       b'CCGACCTGACTTCTCCGCCTCGGTGGGCTGGGTCGGCGGCTGGAGCATTACCCCTACTGCGGGTCCCGCTGCTGGCAGCGCTGGAAACTGGGTGGACGGCATGGGTTGGTCTCAGGATTTGTTCCGCGCCTTGTGGAGATCGCTGTCAAGGGAAGTGAAGGAGCACGTGGGCACGGACCAATTCGGGAACAAATACTACTACA',\n",
       "       b'CGGAGCCTCCTCCTGCTGCTGCTGCGCCCCATCCCCCCGCGGCCGGCCAGTTCCAGCCCGCACCCCGCGTCGGTGCCCGCGCCCCTCCCCGGGCCCCGCCATGGGCCTCACCGTGTCCGCGCTCTTTTCGCGGATCTTCGGGAAGAAGCAGATGCGGATTCTCATGGTTGGCTTGGATGCGGCTGGCAAGACCACAATCCTGT',\n",
       "       b'CCTAACGCTCCGCCCAACAAACCATAGAGTACCGGAAAAAGCTCGAGCAGAGGGGTCGGAAAGGGAAAACAACTACGGCTGCGGTGTGGTTGGTGGTGAGATGACGACCTTAGTGCTGGATAATGGAGCTTACAACGCCAAAATCGGTTACAGCCATGAAAATGTGTCGGTTATTCCTAATTGTCAGTTCCGGTCAAAAACAG',\n",
       "       b'CATAGAGTACCGGAAAAAGCTCGAGCAGAGGGGTCGGAAAGGGAAAACAACTACGGCTGCGGTGTGGTTGGTGGTGAGATGACGACCTTAGTGCTGGATAATGGAGCTTACAACGCCAAAATCGGTTACAGCCATGAAAATGTGTCGGTTATTCCTAATTGTCAGTTCCGGTCAAAAACAGCACGTCTTAAAACTTTTACTGC',\n",
       "       b'TTGCGTAGCAACGGCAGGCGGTGCGTGACGTGCGCAGCCGCGTTCCGTCCTGAGGCGCGCCCGCCCCGGGGTAAGCTCGCGCCGCCGCGTCAGCTCAGCGCTGGGTCTCTCGGTCCCGCAGCCGTGAGGAGGACGGTCTGCATACTCGCTGCCCGCCGGCTCCCTCCCCCGCGTCCCTGCGACCGCCGCGGCGAAGATGGCCT',\n",
       "       b'CGCAGCCGCGTTCCGTCCTGAGGCGCGCCCGCCCCGGGGTAAGCTCGCGCCGCCGCGTCAGCTCAGCGCTGGGTCTCTCGGTCCCGCAGCCGTGAGGAGGACGGTCTGCATACTCGCTGCCCGCCGGCTCCCTCCCCCGCGTCCCTGCGACCGCCGCGGCGAAGATGGCCTCAGGAGTGCAAGTAGCTGATGAAGTATGTCGC',\n",
       "       b'AGCGCTGGGTCTCTCGGTCCCGCAGCCGTGAGGAGGACGGTCTGCATACTCGCTGCCCGCCGGCTCCCTCCCCCGCGTCCCTGCGACCGCCGCGGCGAAGATGGCCTCAGGAGTGCAAGTAGCTGATGAAGTATGTCGCATTTTTTATGACATGAAAGTTCGTAAATGCTCCACACCAGAAGAAATCAAGAAAAGAAAGAAGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$TTTCCGCGACCGCCCCGCCCACTCCCAGGAAGGCCCGGGTGCCCAGAGCTCGCGGTGGACTCCGACCCGGCGCAACATGGCCGCAGCCTCGCCTCTGCGCGACTGCCAGGCCTGGAAGGATGCGAGGCTCCCGCTCTCCACCACAAGCAACGAAGCCTGCAAGCTGTTCGATGCCACGC',\n",
       "       b'$AAGCGCACTGGGTCGCATCGAGGCCCCGCCCCCTGAGCCTGGGTAGCGGCGCGAGGGCCGGGAGAACCGTTCGCGGAGGAAAGGCGAACTAGTGTTGGGATGGCCACCAACTGGGGGAGCCTCTTGCAGGATAAACAGCAGCTAGAGGAGCTGGCACGGCAGGCCGTGGACCGGGCCCTGGCTGAGGGAGTATTGCTGAGGA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ACATGGCCTCTGCCCCTTCCCAAGCAGAGGCAACATGGCGGCCTTAGCAAGCTATAGCTGCGAGATTTGAATTACTCCACTCGTAGCTATTGCATTCCTGACGATGGCCTCTGTGGCTTCGTGCGATTCGCGTCCGA',\n",
       "       b'TGGCCTCTGCCCCTTCCCAAGCAGAGGCAACATGGCGGCCTTAGCAAGCTATAGCTGCGAGATTTGAATTACTCCACTCGTAGCTATTGCATTCCTGACGATGGCCTCTGTGGCTTCGTGCGATTCGCGTCCGAGCTCAGACGAGCTCCCTGGAGACCCCTCTTCACAAGAAGAAGATGAGGACTATGATTTTGAAGATCGGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CAAGGGCCCTTTACATTGCGTTCTTAACGGTTCAGTCACCTTAACCGTTATTATTCACTTGCGGGCGAGAAGTCCGAGCTAGGGATCCTGAAAAGGAGGGAACAATTGTTGTAGCAGGTCTAAAAGTTCAGGTCCAGGAAATGGAAACATTGCTT',\n",
       "       b'GGTCTAAAAGTTCAGGTCCAGGAAATGGAAACATTGCTTTGCTTTTCCTGAATTGTCCAGTGACCTATCCCAGGCCTTCCTTTCCAGTGAACAATGGACCATGCAGGTGGACCCTCCTCTTCACGGGCCTCCAAATGACTTTCTCATTTTTCAAATCATTCCTCTGCACTCACTTTCTATAATGCCCCGGTTTCTCTGGATTC',\n",
       "       b'CCCCGGTTTGTTTGGGCTGTGGGCGGTGCGCAGCGGAGAGCCCGGGAAAAGCGGGAAATGGCGGCGCCGAGCGCGGGGTCTTGGTCCACCTTCCAGCACAAGGAGCTGATGGCCGCTGACAGGGGACGCAGGATATTGGGAGTGTGTGGCATGCATCCTCATCATCAGGAAACTCTAAAAAAGAACCGAGTGGTGCTAGCCAA',\n",
       "       b'GTGCGTCCGCGTCTGAGGGGAGGGATGTGGGGGAAGCGACGGCCCCCGGTTTGTTTGGGCTGTGGGCGGTGCGCAGCGGAGAGCCCGGGAAAAGCGGGAAATGGCGGCGCCGAGCGCGGGGTCTTGGTCCACCTTCCAGCACAAGGAGCTGATGGCCGCTGACAGGGGACGCAGGATATTGGGAGTGTGTGGCATGCATCCTC',\n",
       "       b'CCACACGGCGGGGTCGCCCGTCCATCTCCGGCTCGCCCGCGGGGCCCATCGTCGACGTTAGCGGCCGTTCTCCGAGCCGACTGACCCATCCTTGGCGCTGCCGCCGCGCGCTTGTTCTCCTCCCTCGCCCCGCCTTCATCCTCCCCGTTCACGGAAACGACAGCTGCGGCTGCGGGGCTGGCGCCGCCTCCCTCCACCTACCA',\n",
       "       b'ACGTCTGCCCTCGCCGCTCTAGCCCTGCGCCCCAGCCCGGCCGCGGCACCTCCGCCTCGCCGCCGCTAGGTCGGCCGGCTCCGCCCGGCTGCCGCCTAGGATGAATATCATGGACTTCAACGTGAAGAAGCTGGCGGCCGACGCAGGCACCTTCCTCAGTCGCGCCGTGCAGTTCACAGAAGAAAAGCTTGGCCAGGCTGAGA',\n",
       "       b'GCATGGTGAGTAGGTTGGTCCGAAGTTTGAACCGGACAGAAGCGCTGGTCGGCGTCTGGCGGTTGTTTTTAGAGGTAATACACCTAGTTTGTGGCTCAGCATGTCAATTGTAACAGTGCAACTTGGTCAGTGTGGCAATCAGATTGGTTTTGAAGTTTTTGATGCTTTGCTTAGTGACTCACACAGTTCCCAGGGACTCTGCT',\n",
       "       b'GCCATGGACATCGTGAAAGGACTGGCTGGTCACCTGAAATCCAACAGTCCCCGCCTGATGGATGAAGCTGTGCTGGCACTGCGGAACCTGGCACGCCAGTGCAGTGACTCTTCGGCCATGGAATCCCTGACCAAGCACCTATTTGCTATCCTCGGAGGCTCGGAAGGAAAACTAACTGTTGTAGCCCAGAAGATGAGCGTCCT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CAGCCCCGGCAGGATGGCGGCGGACACGCAGGTTTCCGAGACACTAAAGCGTTTTGCAGGGAAGGTGACAACAGCCAGTGTAAAGGAACGGAGAGAAATCCTCAGTGAACTTGGGA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CGCCTCGGCGGCGCGGCATAGCCCGGCTCGGCCTGTAAAGCAGTCTCAAGCCTGCCGCAGGGAGAAGATGGCGGTCGCCGTGAGAACTTTGCAGGAACAGCTGGAAAAGGCCAAAGAGAGTCTTAAGAACGTGGATGAGAACATTCGCAAGCTCACCGGGCGGGATCCGA',\n",
       "       b'TTAAGAACGTGGATGAGAACATTCGCAAGCTCACCGGGCGGGATCCGAATGACGTGAGGCCCATCCAAGCCAGATTGCTGGCCCTTTCTGGTCCTGGTGGAGGTAGAGGACGTGGTAGTTTATTACTGAGGCGTGGATTCTCAGATAGTGGAGGAGGACCCCCAGCCAAACAGAGAGACCTTGAAGGGGCAGTCAGTAGGCTG',\n",
       "       b'GTCAGTAGGCTGGGCGGGGAGCGTCGGACCAGAAGAGAATCACGCCAGGAAAGCGACCCGGAGGATGATGATGTTAAAAAGCCAGCATTGCAGTCTTCAGTTGTAGCTACCTCCAAAGAGCGCACACGTAGAGACCTTATCCAGGATCAAAATATGGATGAAAAGGGAAAGCAAAGGAACCGGCGAATATTTGGCTTGTTGAT',\n",
       "       b'AGCGACCCGGAGGATGATGATGTTAAAAAGCCAGCATTGCAGTCTTCAGTTGTAGCTACCTCCAAAGAGCGCACACGTAGAGACCTTATCCAGGATCAAAATATGGATGAAAAGGGAAAGCAAAGGAACCGGCGAATATTTGGCTTGTTGATGGGTACCCTTCAAAAATTTAAACAAGAATCCACTGTTGCTACTGAAAGGCA',\n",
       "       b'CCCAGGCACGCTTGCTGCTTCCGGACACAGCTGTGGGCGGAGCTAGTAGGGGCGGGGCTACGTGATTGACACTTCTCTCCTCAGACTTCAAGGGCTACCACTGGACCCTTCCCCTGTCTTGAACCCTGAGCCGGCACCATGCACGGACGCCTGAAGGTGAAGACGTCAGAAGAGCAGGCGGAGGCCAAAAGGCTAGAGCGAGA',\n",
       "       b'GGAGCTAGTAGGGGCGGGGCTACGTGATTGACACTTCTCTCCTCAGACTTCAAGGGCTACCACTGGACCCTTCCCCTGTCTTGAACCCTGAGCCGGCACCATGCACGGACGCCTGAAGGTGAAGACGTCAGAAGAGCAGGCGGAGGCCAAAAGGCTAGAGCGAGAGCAGAAGCTGAAGCTATACCAGTCAGCCACCCAGGCCG',\n",
       "       b'TCGTAAGTTTTCGGCAGTTTCCGGGGAGACTCGGGGACTCCGCGTCTCGCTCTCTGTGTTCCAATCGCCCGGTGCGGTGGTGCAGGGTCTCGGGCTAGTCATGGCGTCCCCGTCTCGGAGACTGCAGACTAAACCAGTCATTACTTGTTTCAAGAGCGTTCTGCTAATCTACACTTTTATTTTCTGGATCACTGGCGTTATCC',\n",
       "       b'GGAAGGATGCTTCAGCTCATCTTAGGCTGTGCTGTGAACTGTGAACAGAAGCAAGAGTACATCCAAGCCATTATGATGATGGAGGAATCTGTTCAACATGTTGTCATGACAGCCATTCAAGAGCTGATGAGTAAAGAATCTCCTGTCTCTGCTGGAAATGATGCCTATGTTGACCTTGATCGTCAGCTGAAGAAAACTACAGA',\n",
       "       b'GGCCTGAGGCCGAGTCAGCTGCGCGGGCCCCCGGATCCCCCGACAGAGCGGCGGCGGTGTCTGGCCAGGCGGTAGGCGCTGCCTGGCCGCGGCGGGGAAGATGTTCAGCGTAGAGTCGCTGGAGCGGGCGGAGCTGTGCGAGAGCCTCCTCACTTGGATCCAGACATTTAATGTGGATGCACCATGCCAGACCGTGGAAGATT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TAGTCTTTGGCCGCCGCCGAACCCCGCGCGCCACTCGCTCGCTCAGAGGGAGGAGAAAGTGGCGAGTTCCGGATCCCTGCCTAGCGCGGCCCAACCTTTACTCCAGAGATCATGGCTGCCGAGGATGTGGTGGCGACTGGCGCCGACCCAAGCGATCTG',\n",
       "       b'CGCCGCCGAACCCCGCGCGCCACTCGCTCGCTCAGAGGGAGGAGAAAGTGGCGAGTTCCGGATCCCTGCCTAGCGCGGCCCAACCTTTACTCCAGAGATCATGGCTGCCGAGGATGTGGTGGCGACTGGCGCCGACCCAAGCGATCTGGAGAGCGGCGGGCTGCTGCATGAGATTTTCACGTCGCCGCTCAACCTGCTGCTGC',\n",
       "       b'GCCGCACTTTACGGCAGTGTGGCTGGAGCCGCGGCTGACGGGCCCGCGGTCTGGGCGTGAGTGCAGGGAAGTGGAGTATTTGCTGGGCCGGGTACCATGGACGTGGGCGAACTTCTGAGCTACCAGCCCAATAGGGGCACAAAACGTCCCCGGGATGATGAAGAGGAGGAGCAGAAGATGCGTCGGAAACAAACTGGTACTCG',\n",
       "       b'GCTGGACCTAAATGACATCATTCAGGAGATGCACGTGGTGGCCACCATGCCAGACCTGTACCACCTTCTGGTGGAGCTGAATGCTGTACAGTCGCTTCTCGGCTTGCTCGGACACGATAATACAGATGTGTCCATAGCTGTGGTCGATTTGCTTCAGGAATTAACAGATATAGACACCCTCCATGAGAGTGAAGAGGGAGCAG',\n",
       "       b'GCTCGCCGCACTTTACGGCAGTGTGGCTGGAGCCGCGGCTGACGGGCCCGCGGTCTGGGCGTGAGTGCAGGGAAGTGGAGTATTTGCTGGGCCGGGTACCATGGACGTGGGCGAACTTCTGAGCTACCAGCCCAATAGGGGCACAAAACGTCCCCGGGATGATGAAGAGGAGGAGCAGAAGATGCGTCGGAAACAAACTGGTA',\n",
       "       b'TGCCCGCCTGCTTGCTCTCTGGCTGTGCTCCTGCTTAAAGAAATCAGTCCTTCCTTTCCGACTTAGTCCTCGGGAAGAAGTTTCAGACTACAAGGTATCATTGGAACATTTCAAGATCATCAAATCAAATTCCACAGGGATTGGTGACCAACCAGAAGGCTCAGACATCTGATTGCTGACCTGTCCAGACATCATCTGGTCTC',\n",
       "       b'ATCAAATTCCACAGGGATTGGTGACCAACCAGAAGGCTCAGACATCTGATTGCTGACCTGTCCAGACATCATCTGGTCTCCCTGAACCTGAAATCACACCATGGATGATTTTGAGCGTCGCAGAGAACTTAGAAGGCAAAAGAGGGAGGAGATGCGACTCGAAGCAGAAAGAATCGCCTACCAGAGGAATGACGATGATGAAG',\n",
       "       b'AGTTTTCCAGTTTTTGGCAAAGCGGAAATACTTAAGGCCCCTGGGTTGACTGGGTTCTTTGTTTTATCTACCGGCTTCTGCTTTACGACAGGTCACAAACATGTCAGACAAAAGTGAATTAAAGGCTGAGTTGGAACGTAAGAAGCAGCGACTGGCCCAAATCAGAGAGGAAAAGAAGAGAAAAGAAGAAGAAAGGAAAAAAA',\n",
       "       b'TTTCCGCCCGGAAGTCGGCGTCTTGAGTCATAGGAGTGAGCCACGCCCGGGCTGTGGGAATAAGATGGCGGGGAAGAAGAATGTTCTGTCGTCTCTCGCAGTTTACGCGGAAGATTCAGAGCCCGAGTCTGATGGCGAGGCTGGAATCGAGGCGGTGGGCAGCGCGGCTGAGGAGAAAGGCGGATTGGTATCTGATGCCTATG',\n",
       "       b'GGCGCGGGGGTCTCCTGGGATCCGAAAGAACCTGCCTTTCCGCCCGGAAGTCGGCGTCTTGAGTCATAGGAGTGAGCCACGCCCGGGCTGTGGGAATAAGATGGCGGGGAAGAAGAATGTTCTGTCGTCTCTCGCAGTTTACGCGGAAGATTCAGAGCCCGAGTCTGATGGCGAGGCTGGAATCGAGGCGGTGGGCAGCGCGG',\n",
       "       b'$$$$$$$$$$$$$$$$ACTTCCGCTGGGGGCGGAGCGGGGCGGGGCTGAGTGGGTGGCGACCTAGCTGCTGCGCCAGTGTTTGTGTTGGAAGCTCAGCTGATGCAGGCCGGTTGGAGTGGACGTCATTGCCGGGAACGAGCGAGTCGCCGCTGCAGCCCTAGTGACTGCGGCCTGCATCCCGATTGTCTTCTCCTCCAAGGTC',\n",
       "       b'AGTGATGGTATTAAGAGGTAAGACCATGAATTATGGCATTTCTTAAATGAAGCGTTCAAGAAGTGAGAGAATGTCATAGAAAATAAATGATTTTTAAGTTATGTCTATTAATCTGACTGTAGATATATATATTTACCTCCTTAGTAATGCAAGAAGTGTTTGTGGGAAGCAGAGAAGCAAGCAACTGTATTTCTTGTTCTCAC',\n",
       "       b'$$$$$$$$$$$$$$$$$$GCGGCGGAGCTGGCGCTGGGAGGGGAGGAGCGCGCAGCCCGCGCGCCGCAGGGCCGGGCGGAAAGTTTTTCCTGACGGAGTTTTGGCTGCGGCAGCGGCGGCGGCGGCCGGAGCGGGCCATGGACGCGCTCAAGTCGGCGGGGCGGGCGCTGATCCGGAGCCCCAGCTTGGCCAAGCAGAGCTGG',\n",
       "       b'GAGGGGAGGAGCGCGCAGCCCGCGCGCCGCAGGGCCGGGCGGAAAGTTTTTCCTGACGGAGTTTTGGCTGCGGCAGCGGCGGCGGCGGCCGGAGCGGGCCATGGACGCGCTCAAGTCGGCGGGGCGGGCGCTGATCCGGAGCCCCAGCTTGGCCAAGCAGAGCTGGGGGGGCGGTGGCCGGCACCGCAAGCTGCCTGAGAACT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$AGGAAGGAACACACAAGTAGTTATCTTTCAGGCTGTCTTTGAATACTTCCATGACCCTGAACACTAGCTGAGGAGAGTTTCAACCACTGCTAACAGTAATGACTTTACATGAGTTTGGAACTGGTCTCTAGTGGGAAGTTGTGGGAGGATGAA',\n",
       "       b'CCATGACCCTGAACACTAGCTGAGGAGAGTTTCAACCACTGCTAACAGTAATGACTTTACATGAGTTTGGAACTGGTCTCTAGTGGGAAGTTGTGGGAGGATGAACACAGAAGAGCTGGAGTTATTGAGTGACTCCAAATACAGAAACTATGTAGCAGCAATTGACAAAGCACTAAAGAATTTTGAATACTCCAGTGAATGGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCGGGGTTTGTAGCGGAGGAGGAGCGGGCGCCATGGCGGTTCTACTGGAGACCACTTTAGGCGACGTCGTCATCGACTTGTACACCGAAGAACGGCCGCGTGCCTGCTTGAATTTCTTGAAACTGTGCAAAATAA',\n",
       "       b'CGACCGGGCGATTTTGGTTAAAATATTCAAAATGGCGGACGGAGGAGCAGCGAGTCAAGATGAGAGTTCAGCCGCGGCGGCAGCAGCAGCAGACTCAAGAATGAACAATCCGTCAGAAACCAGTAAACCATCTATGGAGAGTGGAGATGGCAACACAGGCACACAAACCAATGGTCTGGACTTTCAGAAGCAGCCTGTGCCTG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGGAGGGGGGAGGGGAGCCAGAGCGAGGGAGGGTTTATCGACCGGGCGATTTTGGTTAAAATATTCAAAATGGCGGACGGAGGAGCAGCGAGTCAAGATGAGAGTTCAGCCGCGGCGGCAGCAGCAGCAGACTCAAGAATGAACAATCCGTCAGAAACCAGTAAACCATCTA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CTCCGCAGAAGATTTGTTGCCGTCATGTCGGCTGCGATTGCAGCTCTGGCCGCTTCCTATGGTTCGGGTTCAGGGTCCGAATCGGACTCGGACAGTGAGAGCAGTCGGTGTCCGCTGCCAGCCGCCG',\n",
       "       b'GGTAGTCTGTCCGACCGTACCATTAGGCGCCTGGGCCGGAGGAGGGGTTTTCAGGGTCGTAGGACGCCGTTGGGCACCACGCTCGGAGAAGGACAGGACAATGGCGGCCTTAGGGTCCCCGTCGCACACTTTTCGAGGACTTCTGCGGGAGTTGCGCTACCTGAGCGCGGCCACCGGCCGACCCTATCGCGACACCGCGGCCT',\n",
       "       b'GGCCGCCGTCGGGGAGCCCCAACACACGGTCCACAGCTCATCATGATGGACTTGGAGCTGCCGCCGCCGGGACTCCCGTCCCAGCAGGACATGGATTTGATTGACATACTTTGGAGGCAAGATATAGATCTTGGAGTAAGTCGAGAAGTATTTGACTTCAGTCAGCGACGGAAAGAGTATGAGCTGGAAAAACAGAAAAAACT',\n",
       "       b'CCGCCGCCGCCGCCACCAGAGCCGCCCTGTCCGCGCCGCGCCTCGGCAGCCGGAACAGGGCCGCCGTCGGGGAGCCCCAACACACGGTCCACAGCTCATCATGATGGACTTGGAGCTGCCGCCGCCGGGACTCCCGTCCCAGCAGGACATGGATTTGATTGACATACTTTGGAGGCAAGATATAGATCTTGGAGTAAGTCGAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ACTGCGGGGTGTGCGGCGGCCCAAGCGGTTTCAAACGGCTTAGAGCAGGCCGCTTGGTTCTGACCCAGCTGAGGAAATACTCTTAATTCTAAGGAAAACCTGGAAGCACAATGGGAGATGACAGTGAGTGGTTGAAA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$ACTGCGGGGTGTGCGGCGGCCCAAGCGGTTTCAAACGGCTTAGAGCAGGCCGCTTGGTTCTGACCCAGCTGAGGAAATACTCTTAATTCTAAGGAAAACCTGGAAGCACAATGGGAGATGACAGTGAGTGGTTGAAACTGCCAGTTGATCAGAAATGTGAACACAAGCTGTGGAAAGCA',\n",
       "       b'$ACTGCGGGGTGTGCGGCGGCCCAAGCGGTTTCAAACGGCTTAGAGCAGGCCGCTTGGTTCTGACCCAGCTGAGGAAATACTCTTAATTCTAAGGAAAACCTGGAAGCACAATGGGAGATGACAGTGAGTGGTTGAAACTGCCAGTTGATCAGAAATGTGAACACAAGCTGTGGAAAGCAAGGTTAAGTGGGTATGAAGAGGC',\n",
       "       b'GTGCGGCGGCCCAAGCGGTTTCAAACGGCTTAGAGCAGGCCGCTTGGTTCTGACCCAGCTGAGGAAATACTCTTAATTCTAAGGAAAACCTGGAAGCACAATGGGAGATGACAGTGAGTGGTTGAAACTGCCAGTTGATCAGAAATGTGAACACAAGCTGTGGAAAGCAAGGTTAAGTGGGTATGAAGAGGCCCTGAAGATCT',\n",
       "       b'GCTGGTTTTAATGCTCTCCGTGGGCGGGCTTCGGTTGAGTTTGGTCCGCTTTTCCTTTCTGCTCCTCAGGGGAGCATTGCTTCCTTCTCTCGCAGTGACCATGACGAAATTAGCGCAGTGGCTTTGGGGACTAGCGATCCTGGGCTCCACCTGGGTGGCCCTGACCACGGGAGCCTTGGGCCTGGAGCTGCCCTTGTCCTGCC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$GGCCCTTCCACCTTTTGTGGGCACTCAAGTTCGGACCTCTGGGATCGGCGATTCCCCTCTGGCCAGGGCTGGTTTTAATGCTCTCCGTGGGCGGGCTTCGGTTGAGTTTGGTCCGCTTTTCCTTTCTGCTCCTCAGGGGAGCATTGCTTCCTTCTCTCGCAGTGACCATGACGAAATTAG',\n",
       "       b'GTGAAGAGCTTTGCATTGTGGGAAGTCTTTCCTTTCTCGTTCCCCGGCCATCTTAGCGGCTGCTGTTGGTTGGGGGCCGTCCCGCTCCTAAGGCAGGAAGATGGTGGCCGCAAAGAAGACGAAAAAGTCGCTGGAGTCGATCAACTCTAGGCTCCAACTCGTTATGAAAAGTGGGAAGTACGTCCTGGGGTACAAGCAGACTC',\n",
       "       b'TGGCCCAGGGCCAGCCCCGCCTCCTCCCCGGGCGGAAGCTGTGTCAGTTGCCGGAAGTCGGCGTGAGGTGGGGCTTATGCGGCGGCGTGGTGAAATAGATATGGCGACCGAGGGGGATGTGGAGCTGGAGTTGGAGACTGAGACCAGTGGACCAGAGCGGCCTCCGGAGAAGCCACGGAAACATGACAGCGGTGCGGCGGACT',\n",
       "       b'TGAGGTGGGGCTTATGCGGCGGCGTGGTGAAATAGATATGGCGACCGAGGGGGATGTGGAGCTGGAGTTGGAGACTGAGACCAGTGGACCAGAGCGGCCTCCGGAGAAGCCACGGAAACATGACAGCGGTGCGGCGGACTTGGAGCGGGTCACCGACTATGCAGAGGAGAAGGAGATCCAGAGTTCCAATCTGGAGACGGCCA',\n",
       "       b'TAGAACTGGAGCAGAAAGAAGGTGTGGCCCAGGGCCAGCCCCGCCTCCTCCCCGGGCGGAAGCTGTGTCAGTTGCCGGAAGTCGGCGTGAGGTGGGGCTTATGCGGCGGCGTGGTGAAATAGATATGGCGACCGAGGGGGATGTGGAGCTGGAGTTGGAGACTGAGACCAGTGGACCAGAGCGGCCTCCGGAGAAGCCACGGA',\n",
       "       b'CAGCGGCGGATTGGCGGGCACGCCCCCTCGCCCGCGGCCCCCTCCCCGCCTCTCTCCACCGCCTCCTCTGGCTCCCCGGTCAGAGGGCCGGAGCGAGAAGATGGCGAAGACGTACGATTATCTCTTCAAGCTCCTGCTGATCGGCGACTCGGGGGTAGGCAAGACCTGCCTCCTGTTCCGCTTCTCAGAGGACGCCTTCAACA',\n",
       "       b'$$$$$$$$$$$$ATTCACGCGCCGGAAGTGCATTTGCAGAGTGAGACAAAGCGGAGAACGCTGGTGGGCCTGTTGTGGAGTACGCTTTGGACTGAGAAGCATCGAGGCTATAGGACGCAGCTGTTGCCATGACGGCCCAGGGGGGCCTGGTGGCTAACCGAGGCCGGCGCTTCAAGTGGGCCATTGAGCTAAGCGGGCCTGGA',\n",
       "       b'TGCATTTGCAGAGTGAGACAAAGCGGAGAACGCTGGTGGGCCTGTTGTGGAGTACGCTTTGGACTGAGAAGCATCGAGGCTATAGGACGCAGCTGTTGCCATGACGGCCCAGGGGGGCCTGGTGGCTAACCGAGGCCGGCGCTTCAAGTGGGCCATTGAGCTAAGCGGGCCTGGAGGAGGCAGCAGGGGTCGAAGTGACCGGG',\n",
       "       b'ACCAAAGCCACCACCAAAGACAGACATCTTGAAGAGTCTAGATACTATGGATGATCCAGACACCGTGGGAAGCATACCTGTTTTCAAAACTGAGTGGATCATGACCCATGAAGAGCACCATGCAGCCAAAACCCTGGGGATTGGCAAAGCCATTGCTGTCTTAACCTCTGGTGGAGATGCCCAAGGTATGAATGCTGCTGTCA',\n",
       "       b'ACAGACATCTTGAAGAGTCTAGATACTATGGATGATCCAGACACCGTGGGAAGCATACCTGTTTTCAAAACTGAGTGGATCATGACCCATGAAGAGCACCATGCAGCCAAAACCCTGGGGATTGGCAAAGCCATTGCTGTCTTAACCTCTGGTGGAGATGCCCAAGGTATGAATGCTGCTGTCAGGGCTGTGGTTCGAGTTGG',\n",
       "       b'ATGCGAAGGGGTTTCCGGCCGGGCGCGGAACGCAAAACCCGGGAACCGCCGCGAACCGGAACCGCCTTCACAGCACCGGAAGAGTCGCTAGGAGGCAGCCATGCATAAAGACGAGTTTCATCTGAAATTTTTCATGTGTGTGATTCAGTCTCGCCAGTTAGTCAGGACTCCTCAGAGAACAGCTGGGGAAGCTTCTACTTCCA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CTACTACAGTGGCGGAGCCGTACAGGACCTGTTTCACTGCAGGGGGATCCAAAACAAGCCCCGTGGAGCAGCAGCCAGAGCAACAGCAGCCGCAAGACATTGTTTCTCTCC',\n",
       "       b'GGATCCCCTACAGAAATCAAATGTGACTTTCCGTTTATCAGACTAAAATCAGAGCCATCCAGACAGTGAAACAGTCACCGTGGAGGGGGGACGGCGAAAAATGAAATCCAACCAAGAGCGGAGCAACGAATGCCTGCCTCCCAAGAAGCGCGAGATCCCCGCCACCAGCCGGTCCTCCGAGGAGAAGGCCCCTACCCTGCCCA',\n",
       "       b'GCATGGCGGCGGCACCTCACCACTGATTCGTTGAATTCCTTCCCGGTAATCTTGGGCACTAGCGGGCGGAGTTGAAGGGCGCTTGGACCCCAGCGGCGATCTGTGTTTGGGTTCGCGCTCTGGGAGAATTTTGGCTTTGCTCGCCTTCCTCTTTCAGAAGACTCGAAATCGGCCAGCAGGTCTGCGAGATTTGAAACGCGACT',\n",
       "       b'CCACTGATTCGTTGAATTCCTTCCCGGTAATCTTGGGCACTAGCGGGCGGAGTTGAAGGGCGCTTGGACCCCAGCGGCGATCTGTGTTTGGGTTCGCGCTCTGGGAGAATTTTGGCTTTGCTCGCCTTCCTCTTTCAGAAGACTCGAAATCGGCCAGCAGGTCTGCGAGATTTGAAACGCGACTGTTACTCCTTGTTTTCCGG',\n",
       "       b'GGAGTTGAAGGGCGCTTGGACCCCAGCGGCGATCTGTGTTTGGGTTCGCGCTCTGGGAGAATTTTGGCTTTGCTCGCCTTCCTCTTTCAGAAGACTCGAAATCGGCCAGCAGGTCTGCGAGATTTGAAACGCGACTGTTACTCCTTGTTTTCCGGTTCTGGCCGCGGGAGCCTCTCGAGAAGCGTGGAAAGAGGAGAAGGGCG',\n",
       "       b'AGAATTTTGGCTTTGCTCGCCTTCCTCTTTCAGAAGACTCGAAATCGGCCAGCAGGTCTGCGAGATTTGAAACGCGACTGTTACTCCTTGTTTTCCGGTTCTGGCCGCGGGAGCCTCTCGAGAAGCGTGGAAAGAGGAGAAGGGCGTATACCTTGTGACCGCCTCTGGTTGTCTTGGGCTCGCGCCTGGCGCCGCTACGTGGA',\n",
       "       b'GCGTATACCTTGTGACCGCCTCTGGTTGTCTTGGGCTCGCGCCTGGCGCCGCTACGTGGAGTCGCTCTCTCGTCGTCACTTTTGGCTGCCGACTTGTTGAGTAGAAGTGCAGACTGATGCTTTAAGACTCAGGGAGAGGTCTTTCCCTTATCTCCACCCCAGCAAGCACCCCAGAGACCTTGGAGATTTGTCTTGTTTCTAGA',\n",
       "       b'ATGCTTTAAGACTCAGGGAGAGGTCTTTCCCTTATCTCCACCCCAGCAAGCACCCCAGAGACCTTGGAGATTTGTCTTGTTTCTAGACACGTGTACTCCAATGTTGTGCGGAGGAGGCCTTAAATATTCGAGAAGAGAGTGGGAACTCCTGGAATTTTAAGGGATTTCTGTGTATTTCCAAAACTGACTTTTAACTACCGGCA',\n",
       "       b'CCTGGAATTTTAAGGGATTTCTGTGTATTTCCAAAACTGACTTTTAACTACCGGCAGCGTGGGATTTCGTGATTGTTTTTCGCCATCGTGTGGCTCCAACATGTACTTCCCTTCTTGGTTAAGTCAGCTGTACAGGGGTTTATCCAGACCCATCAGAAGGACCACCCAACCGATCTGGGGTTCTCTCTACAGAAGTCTGTTGC',\n",
       "       b'AGGCCGGGCTGCCGAAGTGTGAGGGGAGGAGCCCGAGCCGTCGCTGCTGCCGCCGCTAAGGGAGAGGAGCATGTCTGCAACTCGAGCCAAGAAAGTGAAGATGGCCACCAAATCATGCCCCGAGTGCGACCAACAGGTTCCTGTTGCATGTAAATCATGTCCTTGTGGTTACATATTTATTAGCAGAAAACTTTTAAATGCAA',\n",
       "       b'GTTTGAGGCCCGCGGGGACTGGGCGGGCGGAGGCCGGGCTGCCGAAGTGTGAGGGGAGGAGCCCGAGCCGTCGCTGCTGCCGCCGCTAAGGGAGAGGAGCATGTCTGCAACTCGAGCCAAGAAAGTGAAGATGGCCACCAAATCATGCCCCGAGTGCGACCAACAGGTTCCTGTTGCATGTAAATCATGTCCTTGTGGTTACA',\n",
       "       b'TTTAGAGGTGCTTTTGCAGGTTTTGCATGTCCTCTTGGGGATGTGCCAGGCCTTGGAGATTCAAGACAAAGAATACCTTTGCAAGTATGCTATCCCATGCCTGATAGGAATCTCGCGAGCATTTGGGCGTTACAGCAACATGGAAGAGTCTCTCCTCTCAAAGCTCTTTCCCAAAATCCCTCCTCATTCCCTCCGTGTCCTGG',\n",
       "       b'$$$$$$$$$$$$$CGGATGCACCTACGCCTGCGCCCTGAGGTCGGGCGCTCGCGGGCCAGGAGCGGGGAGCCGGCGGGCAGCGCCGCGGCTCGTGAGGTGATGGCGGCGGCCCCGGCCCGGGGAGGCGGAGGCGGAGGCGGAGGCGGCGGCGGCTGCTCCGGCTCCGGCTCCAGCGCCTCGCGGGGCTTCTATTTCAACACGG',\n",
       "       b'$$$$$$$$$$$TCCTGCAGCCGCCGCCGCTGCAGTGGTCGTCCCTGCCCTCCCCGGCCCCGGGGTGCACCCCGCAAGGCTCCCGCTGGTGTCCCTGGAGCATGGGAGGCTGCTGAGCGTGAGTGGCGGTGTCTGGCAGGAGCTGCGTGGCAGGGAGGGCGTCCATGGCTGCAGCCAACAAGGGTAAGTGCCTTCCTGGCGTGG',\n",
       "       b'GTGCACCCCGCAAGGCTCCCGCTGGTGTCCCTGGAGCATGGGAGGCTGCTGAGCGTGAGTGGCGGTGTCTGGCAGGAGCTGCGTGGCAGGGAGGGCGTCCATGGCTGCAGCCAACAAGGGTAAGTGCCTTCCTGGCGTGGTAGGACTTGCACAAGCTCTTCCGGTGGGCCCTGGTAGGAGGGCCATTGCTGCAGGCAACAAGC',\n",
       "       b'CGTCAGTCAGGAGGCGGAAGCGCAGCGGGGGCGGGAAGGTTGTAGTGCCGCGAGTTGAGCTCCTCTTGCCTAAGTGGTCGCGCCCCCTTTAAGAGCAGCGATTGTAAGGAGAGGCGGTCCCGGTGTCCTCGGGTCCCAGGTGATTGTGAAGTGCTGACCAATTGCCACTGGACATACTTGAAACAAAATAGGAAAATGGCAGC',\n",
       "       b'CAGCGATTGTAAGGAGAGGCGGTCCCGGTGTCCTCGGGTCCCAGGTGATTGTGAAGTGCTGACCAATTGCCACTGGACATACTTGAAACAAAATAGGAAAATGGCAGCAAACTCTTCAGGACAAGGTTTTCAAAACAAAAATAGAGTTGCAATCTTGGCAGAACTGGACAAAGAGAAAAGAAAACTACTTATGCAGAACCAGT',\n",
       "       b'GGCTAATCCCCACTTCCGACCCTCTCAGGCCTTTTCCGCTTCTCTTTTACCTCCCCAGGTCCGCCCGTCTGCGCCCCTCACAGGAAGCCGGAGGGTCGCTCTGATCCCGAATCTCCCACAGGCGTGAACCTGCTCTGCTGTGTATCTTTGCGGGGTGGCCTGCGCTGAGGCCTGCCGCGCGCGGTGAGTCCGCGCAGACCTGA',\n",
       "       b'CCTTTTCCGCTTCTCTTTTACCTCCCCAGGTCCGCCCGTCTGCGCCCCTCACAGGAAGCCGGAGGGTCGCTCTGATCCCGAATCTCCCACAGGCGTGAACCTGCTCTGCTGTGTATCTTTGCGGGGTGGCCTGCGCTGAGGCCTGCCGCGCGCGGTGAGTCCGCGCAGACCTGACCCTGCGTCTCGCAGCTCGGTTGAGGCCG',\n",
       "       b'TGCGGGGTGGCCTGCGCTGAGGCCTGCCGCGCGCGGTGAGTCCGCGCAGACCTGACCCTGCGTCTCGCAGCTCGGTTGAGGCCGCCGCCGCCTTCTCGGGATGCCGCGGCCGGGGTCCGCGCAGCGCTGGGCGGCCGTCGCGGGCCGTTGGGGGTGCAGGCTGCTCGCACTGCTGCTACTGGTGCCTGGACCCGGCGGCGCCT',\n",
       "       b'CGGCTGCTGGGGTGCTCCGGATTTTGCGGGGTTCGTCGGGCCTGTGGAAGAAGCGCCGCGCACGGACTTCGGCAGAGGTAGAGCAGGTCTCTCTGCAGCCATGTCGGCCAAGGCAATTTCAGAGCAGACGGGCAAAGAACTCCTTTACAAGTTCATCTGTACCACCTCAGCCATCCAGAATCGGTTCAAGTATGCTCGGGTCA',\n",
       "       b'ATGCTCGGGTCACTCCTGACACAGACTGGGCCCGCTTGCTGCAGGACCACCCCTGGCTGCTCAGCCAGAACTTGGTAGTCAAGCCAGACCAGCTGATCAAACGTCGTGGAAAACTTGGTCTCGTTGGGGTCAACCTCACTCTGGATGGGGTCAAGTCCTGGCTGAAGCCACGGCTGGGACAGGAAGCCACAGTTGGCAAGGCC',\n",
       "       b'CGCACCCGCAGCAGCACCCGCAGCAGCACCCGCAGAACCAGGCGCACGGCAAGGGCGGCCACCGCGGCGGCGGCGGCGGCGGCGGCAAGTCCTCCTCCTCCTCCTCCGCCTCCGCCGCCGCTGCCGCCGCCGCCGCCTCGTCCTCGGCGTCCTGCTCGCGCAGGCTCGGCAGGGCGCTCAACTTTCTCTTCTACCTCGCCCTG',\n",
       "       b'CCGCTCGCCCAGTCCCGGGGGAGCCCCTGCAAGTTTCCCGGGCCGCGCGCCGCGCTCGCTCGCCTCCCAGCCCGCGGCCCGAGCCGCCGCCGCGCCCGCCATGCCCTCGGCCAAACAAAGGGGCTCCAAGGGCGGCCACGGCGCCGCGAGCCCCTCGGAGAAGGGTGCCCACCCGTCGGGCGGCGCGGATGACGTGGCGAAGA',\n",
       "       b'GGTGGGTGGGGAATGTGGGGAGATTTGAATTTGAAACCGGTAGGGAGTGATAATCCGCATTCAGTTGTCGAGGAGTGCCAGTCACCTTCAGTTTCTGGAGCTGGCCGTCAACATGTCCTTTCCTAAGGCGCCCTTGAAACGATTCAATGACCCTTCTGGTTGTGCACCATCTCCAGGTGCTTATGATGTTAAAACTTTAGAAG',\n",
       "       b'ATGTGGGGAGATTTGAATTTGAAACCGGTAGGGAGTGATAATCCGCATTCAGTTGTCGAGGAGTGCCAGTCACCTTCAGTTTCTGGAGCTGGCCGTCAACATGTCCTTTCCTAAGGCGCCCTTGAAACGATTCAATGACCCTTCTGGTTGTGCACCATCTCCAGGTGCTTATGATGTTAAAACTTTAGAAGTATTGAAAGGAC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCGGGCCGGGCCGGGCAGTCTGGGACGCGCCGCCGCCATGATCATCCCTGTACGCTGCTTCACTTGTGGCAAGATCGTCGGCAACAAGTGGGAGGCTTACCTGGGGCTGCTGCAGGCCGAGTACACCGAGGGGGATGCGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCGGGCCGGGCCGGGCAGTCTGGGACGCGCCGCCGCCATGATCATCCCTGTACGCTGCTTCACTTGTGGCAAGATCGTCGGCAACAAGTGGGAGGCTTACCTGGGGCTGCTGCAGGCCGAGTACACCGAGGGGGATGCGCTGGATGCCCTGGGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCGGGCCGGGCCGGGCAGTCTGGGACGCGCCGCCGCCATGATCATCCCTGTACGCTGCTTCACTTGTGGCAAGATCGTCGGCAACAAGTGGGAGGCTTACCTGGGGCTGCTGCAGGCCGAGTACACCGAGGGGGATGCGCTGGATGCCCTGGGCCTGAAGCGCTAC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$CCGGGCCGGGCCGGGCAGTCTGGGACGCGCCGCCGCCATGATCATCCCTGTACGCTGCTTCACTTGTGGCAAGATCGTCGGCAACAAGTGGGAGGCTTACCTGGGGCTGCTGCAGGCCGAGTACACCGAGGGGGATGCGCTGGATGCCCTGGGCCTGAAGCGCTACTGCTGCCGCC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCCGGGTGCCGCTGGCACCTCTATGATCACTGGAGTCTCGCGGGTCCCTCGGGCTGCACAGGGACAAGTAAAGGCTACATCCAGATGCCGGGAATGCACTGACGCCCATTCCTG',\n",
       "       b'$$$$$$$$$$$$$$$$GCCGGGTGCCGCTGGCACCTCTATGATCACTGGAGTCTCGCGGGTCCCTCGGGCTGCACAGGGACAAGTAAAGGCTACATCCAGATGCCGGGAATGCACTGACGCCCATTCCTGGAAACTGGGCTCCCACTCAGCCCCTGGGAGCAGCAGCCGCCAGCCCCTCGGGACCTCCATCTCCACCCTGCTG',\n",
       "       b'GCCGCCAGCCCCTCGGGACCTCCATCTCCACCCTGCTGAGCCACCCGGGTTGGGCCAGGATCCCGGCAGGCTGATCCCGTCCTCCACTGAGACCTGAAAAATGGCTTCGGGGCAAGGCCCAGGTCCTCCCAGGCAGGAGTGCGGAGAGCCTGCCCTGCCCTCTGCTTCTGAGGAGCAGGTAGCCCAGGACACAGAGGAGGTTT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGGCGCATGCGCAGCGAGGTTCCACGTGAGCGCCTGCGTTTCTCCTCAAACCTAACGATGCCGCCGGAGCGGAGGAGACGAATGAAACTGGACCGGAGAACCGGAGCGAAGCCGAAGCGGAAGCCCGGAATGAGGCCGGACTGGAAAGCCGGAGCGGGGC',\n",
       "       b'GAAATGGTTGACATGATGAACAATCGGTTTCGGAAGGATATGATGAAAAATGCTAGTGAAAGTAAACTTTCGAAAGACAACCTTAAAAAGAGACTTAAAGAAGAATTCCAACATGCCATGGGAGGAGTACCTGCCTGGGCAGAGACTACTAAGCGGAAAACATCTTCAGATGATGAAAGTGAAGAGGATGAAGATGATTTGTT',\n",
       "       b'AGACGCCACTGGGAGCTTGGGAGAGTGGGACGTGGACAGGAACGTAAAGACCGAAGGGTGGGTTTCGAAGGAGCGGATTTCGAAGTTGCACCGGTTGAGGATGGCTGACATTCTCTCTCAGTCAGAGACCCTGGCGTCGCAAGACCTCAGTGGGGACTTCAAGAAGCCAGCTCTGCCGGTGTCCCCAGCGGCGCGGAGTAAGG',\n",
       "       b'AACAGGAAGTCATTACGATCCCGTTGTAACCTCTAAATATGTCCCCGTTCTGCACAGCATCCCGATAACCGTTTTGTTTTTCTCATATTATGACCTTCTCATGTTAGCACCACTTCGCAACGCTCCAGGTCGTGAAGGAGCAACTTCACCATCGCCGCCTACAGACGCCACTGGGAGCTTGGGAGAGTGGGACGTGGACAGGA',\n",
       "       b'GCGCCTTCCGGATCGCAGCTCTCGCGGCAGTCGCCTGAGACTTAAGGTTATTGCTTGGCCGCGGCCTGGTATTCCGGCGATTCGTTTCTTGCTCGGCTTCCTGGAGCTGTGGTCCGTGTGGGCTTCCACCTCAGACAGTTGCGCTGGCTCAGCGGGGCCGGAACATGGCTGCGTCCGGTCTGGATCATCTCAAAAATGGCTAC',\n",
       "       b'CCTGGTATTCCGGCGATTCGTTTCTTGCTCGGCTTCCTGGAGCTGTGGTCCGTGTGGGCTTCCACCTCAGACAGTTGCGCTGGCTCAGCGGGGCCGGAACATGGCTGCGTCCGGTCTGGATCATCTCAAAAATGGCTACAGAAGAAGATTTTGTCGACCTTCCAGGGCACGTGACATTAACACAGAGCAAGGCCAGAATGTTC',\n",
       "       b'CCGGTCACGTGGACGTTTGGTCACGTGACTGCGTCCGTGGTCCTCCCGTAGGAACCGGCGGACTCGGTTGGCGTTGTGGGGCAGGGGGTGGTGGAGCAAGATGGCGGCTCATCTGTCCTACGGCCGAGTGAACCTAAACGTGTTGCGCGAGGCGGTGCGTCGCGAGCTGCGCGAGTTCCTGGACAAGTGCGCAGGAAGCAAGG',\n",
       "       b'CGCACGGGCCGACCTCCCGGGGGACACTGGGACAGGAGCGCGGCAGCCACTGCGCTGGGGATGGCGTAGCAGCGACGCGGTGACGCCACAAAAATGGCGGACGCTGGAAAGCGCCGTTCCTGACTCTAATGTACTTAGACACTTGAAGCCACAAAAGGATTTATCCCCGAGGTTCCTCATCTGCTCGCGAGGATGCCTTTTCT',\n",
       "       b'AATGGCGGACGCTGGAAAGCGCCGTTCCTGACTCTAATGTACTTAGACACTTGAAGCCACAAAAGGATTTATCCCCGAGGTTCCTCATCTGCTCGCGAGGATGCCTTTTCTCTTCTGCCTTGCGAAATAACAGCAGCCTAGCTGTTGCCCGTGACCAGTGAGAAAGGCAGCGTCGCGGGCTGATTAGGTTTCACCCAAAGGGT',\n",
       "       b'GCGCCGAATTGGTTTCTAACGAGAACTTTTAAAATGATCCGTTCCAAAAAAGGGTAGGAGCCGCGAGACCCTCCAACTGCCCAGAGAAAACAAGTCTCGTCTGGCAAAGTTCTCGGCCCACGCGGTCCGCGGCCAAGGGCCAACGGTCCCTCGCCCCACGTTGCCGCAGCACTGCGCGTGCGCGAGCCGCTGTCAAACGCGCT',\n",
       "       b'ACGTTGCCGCAGCACTGCGCGTGCGCGAGCCGCTGTCAAACGCGCTGACGGAGGCCGAGAAGAAAAAAAGGCGGGAGCCGTCAATCCCGGGTTGAGCAAAATGGCGCGGGAGAAGGAGATGCAGGAGTTCACCCGTAGCTTCTTCCGAGGCCGCCCGGACCTCAGCACGCTTACGCATTCCATCGTGCGGCGGAGGTACTTAG',\n",
       "       b'GCTACAATTCTGGCTTCATGCCCGCCTCCAAAAGTGCTTCCTCTCGAGGGGTTGTGGTTCTTACTGCGCAGGCGCAAAAGCAAGTCCTCTTCCGGGCAAAATGGCGATGGGACTAATGTGCGGACGCCGGGAGCTTCTGCGCTTGCTACAGTCCGGGCGTCGGGTCCACAGCGTCGCAGGGCCCTCGCAATGGCTTGGGAAAC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ATGGTAACGTGGCTTTACAGATTTTTACCCACTTCAAATATGGCCGCCAAGCTCCGTTCTCTTTTACCGCCTGATCTGCGGCTACAATTCTGGCTTCATGCCC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ATGCTGTCCGGTCACCGTGACAATGCAGCTGAGGAACCCAGAACTACATCTGGGCTGCGCGCTTGCGCTTCGCTTCCTGGCCCTCGTTTCCTGGGACATCCCTGGGGCTAGAGCACTGGACAATG',\n",
       "       b'ATGCAGCTGAGGAACCCAGAACTACATCTGGGCTGCGCGCTTGCGCTTCGCTTCCTGGCCCTCGTTTCCTGGGACATCCCTGGGGCTAGAGCACTGGACAATGGATTGGCAAGGACGCCTACCATGGGCTGGCTGCACTGGGAGCGCTTCATGTGCAACCTTGACTGCCAGGAAGAGCCAGATTCCTGCATCAGTGAGAAGCT',\n",
       "       b'AGTTGGTGGGCAAGTCGGGGATCCCAGAAAGAGAAGCGTGACCCGGAAGCGGAAACGGGTGTCCGTCCCAGCTCCGGCCTGCCAGTGAGCTTCTACCATCATGGACCTATTGTTCGGGCGCCGGAAGACGCCAGAGGAGCTACTGCGGCAGAACCAGAGGGCCCTGAACCGTGCCATGCGGGAGCTGGACCGCGAGCGACAGA',\n",
       "       b'GCAAGGCCGGAAGCTCCACGTCCGCACCCGCCCCTTCCGTTTCGCTTCCGCCTACCTCGCCCAGGCTGCCAGACCGGAAGCGCTCCGCTGTACCTGGATCCTGCTCCTCTGGGTTGAAACCCGGGCGCCGCCAAGATGCCGGCTTACCACTCTTCTCTCATGGATCCTGATACCAAACTCATCGGAAACATGGCACTGTTGCC',\n",
       "       b'TCCGTTTCGCTTCCGCCTACCTCGCCCAGGCTGCCAGACCGGAAGCGCTCCGCTGTACCTGGATCCTGCTCCTCTGGGTTGAAACCCGGGCGCCGCCAAGATGCCGGCTTACCACTCTTCTCTCATGGATCCTGATACCAAACTCATCGGAAACATGGCACTGTTGCCTATCAGAAGTCAATTCAAAGGACCTGCCCCCAGAG',\n",
       "       b'CTTCCGCCTACCTCGCCCAGGCTGCCAGACCGGAAGCGCTCCGCTGTACCTGGATCCTGCTCCTCTGGGTTGAAACCCGGGCGCCGCCAAGATGCCGGCTTACCACTCTTCTCTCATGGATCCTGATACCAAACTCATCGGAAACATGGCACTGTTGCCTATCAGAAGTCAATTCAAAGGACCTGCCCCCAGAGAGACAAAAG',\n",
       "       b'CCCAGGCTGCCAGACCGGAAGCGCTCCGCTGTACCTGGATCCTGCTCCTCTGGGTTGAAACCCGGGCGCCGCCAAGATGCCGGCTTACCACTCTTCTCTCATGGATCCTGATACCAAACTCATCGGAAACATGGCACTGTTGCCTATCAGAAGTCAATTCAAAGGACCTGCCCCCAGAGAGACAAAAGATACAGATATTGTGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ACGGCCGAAAAGATGGCGGTCTTGGCACCTCTAATTGCTCTCGTGTATTCGGTGCCGCGACTTTCACGATGGCTCGCCCAACCTTACTACCTTCTGTCGGCCCTGCTCTCTGCTG',\n",
       "       b'TTTTTGCTCCGGCCACGTGAGGAGGGTGGGCGGGGCGTTAAAGTTCATATCCCAGTGTCCTTTGAATCGACTTCCTTTTTTCTTTTTTCCGGCGTTCAAGATGTCGAAGCGAGGACGTGGTGGGTCCTCTGGTGCGAAATTCCGGATTTCCTTGGGTCTTCCGGTAGGAGCTGTAATCAATTGTGCTGACAACACAGGAGCCA',\n",
       "       b'TAAAGTTCATATCCCAGTGTCCTTTGAATCGACTTCCTTTTTTCTTTTTTCCGGCGTTCAAGATGTCGAAGCGAGGACGTGGTGGGTCCTCTGGTGCGAAATTCCGGATTTCCTTGGGTCTTCCGGTAGGAGCTGTAATCAATTGTGCTGACAACACAGGAGCCAAAAACCTGTATATCATCTCCGTGAAGGGGATCAAGGGA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CAGCGCCGGGGCGGAGGGTACGATGGAGAATTTCACGGCACTGTTTGGGGCTCAGGCTGACCCACCACCGCCCCCAACCGCACTCGGCTTCGGACCAGGAAAGCCTCCACCCCCGCCACCGCCTC',\n",
       "       b'TCTCCTCAGAGACTGGCTAGCCAAGCATCTAGACCCACAAGGTCCCCTAGCGGCAGCGGCTCTAGAAGTAGATCCTCCAGTAGTGATTCAATCAGCAGCAGCAGTAGTACCAGCAGTGACAGCAGTGATTCCAGCAGTAGTTCAAGTGATGATTCTCCAGCTCGATCAGTTCAGTCTGCAGCAGTCCCTGCACCCACTTCCCA',\n",
       "       b'TTCTCCAGCTCGATCAGTTCAGTCTGCAGCAGTCCCTGCACCCACTTCCCAGTTGCTTTCATCTCTGGAAAAAGATGAGCCCCGTAAAAGTTTTGGCATCAAGGTCCAGAATCTTCCAGTACGCTCTACAGATACAAGCCTTAAAGATGGCCTTTTCCATGAATTTAAGAAATTTGGAAAAGTAACTTCAGTGCAGATACATG',\n",
       "       b'TTTCGCCCCTTGGATGAAAGGATAGATGAATTTCACCCCAAAGCAACAAGAACTCTCTTTATTGGCAACCTTGAAAAAACCACTACTTACCATGACCTTCGCAACATCTTCCAGCGCTTTGGAGAAATTGTGGATATTGACATTAAGAAAGTAAATGGAGTTCCTCAGTATGCGTTTCTGCAATACTGTGATATTGCTAGCGT',\n",
       "       b'TGTGGATATTGACATTAAGAAAGTAAATGGAGTTCCTCAGTATGCGTTTCTGCAATACTGTGATATTGCTAGCGTTTGTAAAGCTATTAAGAAGATGGATGGGGAATATCTTGGAAATAATCGCCTCAAGCTGGGTTTTGGAAAGAGCATGCCTACAAACTGCGTGTGGCTAGATGGGCTTTCTTCGAATGTGTCAGATCAGT',\n",
       "       b'ATCGCCTCAAGCTGGGTTTTGGAAAGAGCATGCCTACAAACTGCGTGTGGCTAGATGGGCTTTCTTCGAATGTGTCAGATCAGTATTTAACACGACATTTCTGCCGATATGGGCCTGTGGTAAAGGTGGTGTTTGACCGCTTAAAAGGCATGGCCCTGGTTCTCTACAATGAAATTGAATATGCACAAGCAGCTGTAAAAGAG',\n",
       "       b'GAGAGGTTGCCGAGTGATTCTGAGAGGAGGCTTTACAGCCGATCCTCAGACCGGAGTGGAAGCTGTAGCTCACTCTCCCCTCCAAGATATGAGAAACTGGACAAGTCTCGTTTGGAGCGCTATACAAAAAATGAAAAGACAGATAAAGAACGAACTTTTGATCCGGAGAGAGTGGAGAGAGAGAGACGCTTAATACGGAAGGA',\n",
       "       b'CCGCCGCCGCCGCCCCGGCACCCGCCTCCCGGCGCTGACGGTCTCGTACGAAGCCGGCGAGGGGGAGCCAGCAGCGGCGGTCGCCGGCACGCCGCCCAGCATGGTCCGGGAAACCAGGCATCTCTGGGTGGGCAACTTACCCGAGAACGTGCGGGAAGAGAAGATCATCGAGCATTTCAAACGATATGGCCGCGTGGAAAGTG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCGCAGTCGGGGCGCCTTCCCGGTATAGGCGCCTTTTACCCCAGCGTGTCCTGAGTCTTTGGTTCGCGAAGTGCCGTTAGGCCAAGCAGGTGCTAAAAGCCCGGGGTCGTGGACCCCGGCCAGGTCTTAGCAGCATGGAGGCGCAGGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCGCAGTCGGGGCGCCTTCCCGGTATAGGCGCCTTTTACCCCAGCGTGTCCTGAGTCTTTGGTTCGCGAAGTGCCGTTAGGCCAAGCAGGTGCTAAAAGCCCGGGGTCGTGGACCCCGGCCAGGTCTTAGCAGCATGGAGGCGCAGGGTGTAGCGGAGGGCGCGGGGCCGG',\n",
       "       b'TTTACCCCAGCGTGTCCTGAGTCTTTGGTTCGCGAAGTGCCGTTAGGCCAAGCAGGTGCTAAAAGCCCGGGGTCGTGGACCCCGGCCAGGTCTTAGCAGCATGGAGGCGCAGGGTGTAGCGGAGGGCGCGGGGCCGGGCGCCGCCAGCGGCGTGCCCCACCCCGCGGCCCTAGCCCCGGCTGCGGCTCCCACCTTGGCGCCAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$AATTGGCAACCCGGAAGCGGTCGGTAGTGCGGCGCTGTTTAAAGATGGCGGCGGAGGAACCTCAGCAGCAGAAGCAGGAGCCGCTGGGCAGCGACTCCGAAGGTGTTAACTGTCTGGCCTATGATGAAGCCATCATGGCTCAGCAGG',\n",
       "       b'CGAAAAGATGTAGGAAAGAAGAATGGATATTATTGCATGTACTCACCAGTTCTTTTGCTGGGTCAGCCTTTATGCCAAGGGAGACCAAATTTTGAGGAAGGTGGACCAACATCAGTAGGGAGAAAGCATGAATTTATACGCTCAGAAAGTGAAAATTGGCGCATCTTTAGAGAGGAACAAAATGGAGAAGATGAAGATGGAGG',\n",
       "       b'GATCTGAACAAAGTCTGCTCAAATCTCCTGCTGTGAACCAGCAGAATTTTTGAACAGGTTTCTTCACATATAAAAATCTATTGTAAAAATACGGAAAAGAATGGCAGCGGAAACGCAGACACTGAACTTTGGGCCTGAATGGCTCCGAGCTCTGTCCAGTGGTGGGAGTATTACATCCCCTCCTCTTTCTCCAGCATTGCCGA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCTCTGTTGTCGTTTGGCAGCGGATAGAGGACACGACCAAGATGGCGGCGGTGTCTGGCTTGGTGCGGAGACCCCTTCGGGAGGTCTCCGGGCTGCTGAAGAGGCGCTTTCACTGGACCGCGCCGGCTGCGCTGCAGGTGACAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCTCTGTTGTCGTTTGGCAGCGGATAGAGGACACGACCAAGATGGCGGCGGTGTCTGGCTTGGTGCGGAGACCCCTTCGGGAGGTCTCCGGGCTGCTGAAGAGGCGCTTTCACTGGACCGCGCCGGCTGCGCTGCAGGTGACAGTTC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCTTCCGGCGGCGCCTCAGGTCGCGGGGCGCCTAGGCCTGGGTTGTCCTTTGCATCTGCACGTGTTCGCAGTCGTTTCCGCGATGCTGCCTCTGCTGCGCTGCGTGCCCCGTGTGCTGGGCTCCTCCGTCGCCGGCCTCCGCGCT',\n",
       "       b'$$$$$$$$$$$$$$$$$$GCTTCCGGCGGCGCCTCAGGTCGCGGGGCGCCTAGGCCTGGGTTGTCCTTTGCATCTGCACGTGTTCGCAGTCGTTTCCGCGATGCTGCCTCTGCTGCGCTGCGTGCCCCGTGTGCTGGGCTCCTCCGTCGCCGGCCTCCGCGCTGCCGCGCCCGCCTCGCCTTTCCGGCAGCTCCTGCAGCCGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCCGGTGGCGGCAGGATACAGCGGCTTCTGCGCGACTTATAAGAGCTCCTTGTGCGGCGCCATTTTAAGCCTCTCGGTCTGTGGCAGCAGCGTTGGCCCGGCCCCGGGAGCGGAGAGCGAGGGGAGGCGGAGACGGAGGAAGGTCTGAGGAGCAGCTTCAGTCC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$GCCGGTGGCGGCAGGATACAGCGGCTTCTGCGCGACTTATAAGAGCTCCTTGTGCGGCGCCATTTTAAGCCTCTCGGTCTGTGGCAGCAGCGTTGGCCCGGCCCCGGGAGCGGAGAGCGAGGGGAGGCGGAGACGGAGGAAGGTCTGAGGAGCAGCTTCAGTCCCCGCCGAGCCGCCACCG',\n",
       "       b'CTTCAGTCCCCGCCGAGCCGCCACCGCAGGTCGAGGACGGTCGGACTCCCGCGGCGGGAGGAGCCTGTTCCCCTGAGGGTATTTGAAGTATACCATACAACTGTTTTGAAAATCCAGCGTGGACAATGGCTACTCAAGCTGATTTGATGGAGTTGGACATGGCCATGGAACCAGACAGAAAAGCGGCTGTTAGTCACTGGCAG',\n",
       "       b'GCAGGTCGAGGACGGTCGGACTCCCGCGGCGGGAGGAGCCTGTTCCCCTGAGGGTATTTGAAGTATACCATACAACTGTTTTGAAAATCCAGCGTGGACAATGGCTACTCAAGCTGATTTGATGGAGTTGGACATGGCCATGGAACCAGACAGAAAAGCGGCTGTTAGTCACTGGCAGCAACAGTCTTACCTGGACTCTGGAA',\n",
       "       b'GAATACAAATGATGTAGAAACAGCTCGTTGTACCGCTGGGACCTTGCATAACCTTTCCCATCATCGTGAGGGCTTACTGGCCATCTTTAAGTCTGGAGGCATTCCTGCCCTGGTGAAAATGCTTGGTTCACCAGTGGATTCTGTGTTGTTTTATGCCATTACAACTCTCCACAACCTTTTATTACATCAAGAAGGAGCTAAAA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGCGCCGTGACGCTCAGCCGGGCCTTGTGGAGTGCGGGTCTCTGCTGCGGACGCCGGGGGCCGGCGCGGCGTTGGCCGCCCCCGGCCTCGCCGAGTGCAGCGCGCCCGAAGGCCAGTGCCTGCGCTCCG',\n",
       "       b'GGAGGCGCACAACATCCTCAGCAAACGGGGATTCAGCGTCCGATCCTTTGGAACAGGGACTCACGTGAAGCTTCCAGGACCAGCTCCCGACAAGCCCAATGTTTATGATTTCAAAACCACATATGACCAGATGTACAATGATCTTCTTAGGAAAGACAAAGAACTCTATACACAGAATGGGATTTTACATATGCTGGACAGAA',\n",
       "       b'AGGCGCACAACATCCTCAGCAAACGGGGATTCAGCGTCCGATCCTTTGGAACAGGGACTCACGTGAAGCTTCCAGGACCAGCTCCCGACAAGCCCAATGTTTATGATTTCAAAACCACATATGACCAGATGTACAATGATCTTCTTAGGAAAGACAAAGAACTCTATACACAGAATGGGATTTTACATATGCTGGACAGAAAT',\n",
       "       b'GCCCGCTTCCGGCCACCGCGGCCGCCATTTTGTTCGCGCGGAAGCGCCGCGGTAGGGTGGGAACCCAAGCGGGAGAGCCGCGGGATTTGCGGCCGCCGCCATGCCGTCGTCCCCGCTGCGGGTGGCGGTGGTGTGCTCGAGCAACCAGAACCGGAGCATGGAGGCGCACAACATCCTCAGCAAACGGGGATTCAGCGTCCGAT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$GACCTCACGGGCTATTTAAAGGTACGCGCCGCGGCCAAGGCCGCACCGTACTGGGCGGGGGTCTGGGGAGCGCAGCAGCCATGGCAAGCCGTCTCCTGCTCAACAACGGCGCCAAGATGCCCATCCTGGGGTTGGGTACCTGGAAGTCCCCTCCAGGGCAGGTGACTGAGGCCGTGAAGGTGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GACCCCAAGATGGCGGCGCCCAGCGAAGTGGCCGCGATAGCCCCTGGCGAAGGCGATGGCGGAGGCGGCGGCTTTGGCTCCTGGCTGGACGGACGGTTGGAGGCACTGGGAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ATTTTGCGAACGGCGAGCAGCGGCGGCGGCGCGGAGAGACGCAGCGGAGGTTTTCCTGGTTTCGGACCCCAGCGGCCGGATGGTGAAATCCTCCCTGCAGCGGATCCTCAATAGCCACTGCTTCGCCAGAGAGAAGGAAGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ATTTTGCGAACGGCGAGCAGCGGCGGCGGCGCGGAGAGACGCAGCGGAGGTTTTCCTGGTTTCGGACCCCAGCGGCCGGATGGTGAAATCCTCCCTGCAGCGGATCCTCAATAGCCACTGCTTCGCCAGAGAGAAGGAAGGGGATAAACCCAGCGCCA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$ATTTTGCGAACGGCGAGCAGCGGCGGCGGCGCGGAGAGACGCAGCGGAGGTTTTCCTGGTTTCGGACCCCAGCGGCCGGATGGTGAAATCCTCCCTGCAGCGGATCCTCAATAGCCACTGCTTCGCCAGAGAGAAGGAAGGGGATAAACCCAGCGCCACCATCCACGCCAGCCGCACCATGC',\n",
       "       b'ACGCAGCGGAGGTTTTCCTGGTTTCGGACCCCAGCGGCCGGATGGTGAAATCCTCCCTGCAGCGGATCCTCAATAGCCACTGCTTCGCCAGAGAGAAGGAAGGGGATAAACCCAGCGCCACCATCCACGCCAGCCGCACCATGCCGCTCCTAAGCCTGCACAGCCGCGGCGGCAGCAGCAGTGAGAGTTCCAGGGTCTCCCTC',\n",
       "       b'ATCCAGCCGGCTCCCTCCGGCCGCGAACTGCCCCTCCCCGCCCCGCCTCCCGGCGCGGGTGGCCGAGGCGTAGCGCTGCGACCCCCGCACCCCTGCGAACATGGCGCTGCGAGTGGTGCGGAGCGTGCGGGCCCTGCTCTGCACCCTGCGCGCGGTCCCGTCACCCGCCGCGCCCTGCCCGCCGAGGCCCTGGCAGCTGGGGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCAACCTCCTGGTTCCAAGTGGGAGACATGGTGCTGTCGGAGCTAGCGGCGCGCCTCAACTGCGCCGAGTACAAGAACTGGGTGAAGGCGGGCCACTGCCTGTTACTGCTGCGCAGCTGCCTGCAGGGTT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TGCAAATGAATGCCTTCCACTGAACCGAGGTAGACGGGGTCGAGTTTCTTGCGCGATGGTGGGCTTGTATGTGTGTGTGTGTGTGTGTGTGTGGGGGGGGGGGGTGAC',\n",
       "       b'CTGCACCTTCAGGCTTAACGCCACGTGGGCTCCTTTGCTGTCCTCCAGGCACTGTTATAGAAGAATGGAAGAAGATACAGATTATAGAATCAGGTTTAGTTCTTTGTGTTTCTTTAATGATCACGTTGGATTTCATGGCACTATAAAAAGCTCACCAAGTGACTTTATTGTTATTGAAATTGATGAACAGGGACAGTTAGTTA',\n",
       "       b'CCCACTGTCAGCAGCAGTCTCTGTTGAATGGGAATACTGCACCTTCAGGCTTAACGCCACGTGGGCTCCTTTGCTGTCCTCCAGGCACTGTTATAGAAGAATGGAAGAAGATACAGATTATAGAATCAGGTTTAGTTCTTTGTGTTTCTTTAATGATCACGTTGGATTTCATGGCACTATAAAAAGCTCACCAAGTGACTTTA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CGGAAGTTGCAGCCGGGAAGCCTGCGAGGTCGGTTCCGCCCGACTCTAACATGGCGGCGCCCTTTGTCTGCTCTGGAGTGCCGTCCCCGGCCTTCTCGCGGCCGTGATGCACCTCCCTCTGCGGTGGGGTCCGGGACATGGCAGGTAATGAGC',\n",
       "       b'GGACATGGCAGGTAATGAGCCGGACGAGGGGAGCCAAGCTGGAGTTTACACAGGCAAACTGTCAGAAAAGAGTAGCCTGGGCTGTCTGGAAATCTGAGCCATGGACTTTCCCCAGCACAGCCAGCATGTCTTGGAACAGCTGAACCAGCAGCGGCAGCTGGGGCTTCTCTGTGACTGCACCTTTGTGGTGGACGGTGTTCACT',\n",
       "       b'CCAATCCCAAAAAGCCAGGACGAGTTACCAACCAGCTGCAATACCTACACAAGGTAGTGATGAAGGCTCTGTGGAAACATCAGTTCGCATGGCCATTCCGGCAGCCTGTGGATGCTGTCAAACTGGGTCTACCGGATTATCACAAAATTATAAAACAGCCTATGGACATGGGTACTATTAAGAGGAGACTTGAAAACAATTAT',\n",
       "       b'TACATTTACAACAAGCCCACTGATGATATTGTCCTAATGGCACAAACGCTGGAAAAGATATTCCTACAGAAGGTTGCATCAATGCCACAAGAAGAACAAGAGCTGGTAGTGACCATCCCTAAGAACAGCCACAAGAAGGGGGCCAAGTTGGCAGCGCTCCAGGGCAGTGTTACCAGTGCCCATCAGGTGCCTGCCGTCTCTTC',\n",
       "       b'TATTGTCCTAATGGCACAAACGCTGGAAAAGATATTCCTACAGAAGGTTGCATCAATGCCACAAGAAGAACAAGAGCTGGTAGTGACCATCCCTAAGAACAGCCACAAGAAGGGGGCCAAGTTGGCAGCGCTCCAGGGCAGTGTTACCAGTGCCCATCAGGTGCCTGCCGTCTCTTCTGTGTCACACACAGCCCTGTATACTC',\n",
       "       b'CCCCCCAACTTAGCGGGTTATGCTGGACCGGGCGGTGAGGGGAACCGAGGCCACCCGGACTTTCCGCGGCTGAGGGCAGCGCCGGTTCCTTGCGGTCAAGATGCTGCAAAACGTGACTCCCCACAATAAGCTCCCTGGGGAAGGGAATGCAGGGTTGCTGGGGCTGGGCCCAGAAGCAGCAGCACCAGGGAAGAGGATTCGAA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$AGCGCGGTGAGTTTGAAACTGCTCGCACTTGGCTTCAAAGCTGGCTCTTGGAAATTGAGCGGAGAGCGACGCGGTTGTTGTAGCTGCCGCTGCGGCCGCCGCGGAATAATAAGCCGGGATCTACCATACCCATTGACTAACTA',\n",
       "       b'GGCTCTTGGAAATTGAGCGGAGAGCGACGCGGTTGTTGTAGCTGCCGCTGCGGCCGCCGCGGAATAATAAGCCGGGATCTACCATACCCATTGACTAACTATGGAAGATTATACCAAAATAGAGAAAATTGGAGAAGGTACCTATGGAGTTGTGTATAAGGGTAGACACAAAACTACAGGTCAAGTGGTAGCCATGAAAAAAA',\n",
       "       b'ACTGCAATTCGGGAAATTTCTCTATTAAAGGAACTTCGTCATCCAAATATAGTCAGTCTTCAGGATGTGCTTATGCAGGATTCCAGGTTATATCTCATCTTTGAGTTTCTTTCCATGGATCTGAAGAAATACTTGGATTCTATCCCTCCTGGTCAGTACATGGATTCTTCACTTGTTAAGAGTTATTTATACCAAATCCTACA',\n",
       "       b'GCCGGCGGCCGGAAGTCTATCCCGCAGAAGCGCAGCCATTCACGGCCTCACGCAATGCGACACTTCCGCCTGCACGAGTTCTTCCGGGGCGGAGGTCACCATGGCAGCTGCCTTGGCTCGGCTTGGTCTGCGGCCTGTCAAACAGGTTCGGGTTCAGTTCTGTCCCTTCGAGAAAAACGTGGAATCGACGAGGACCTTCCTGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$GCGAGACGGGTGCGCTTACGCCACGGCGTCTGCTGGCGGCCGCGGAGACGCAGAGTCTTGAGCAGCGCGGCAGGCACCATGTTCCTGACTGCGCTCCTCTGGCGCGGCCGCATTCCCGGCCGTCAGTGGATCGGGAAGCACCGGCGGCCGCGGTTCGTGTCGTTGCGCGCCAAGCAGAACA',\n",
       "       b'GGTGGGGGCGCCGCGCCCAGTGAGGGCCCGGAAGTGGGTCGCGCGGAGATTGCTGGGCGGTTCTTGCCGGAAGCGGAGAGCGGCTGATCGCAGTCCGGAGGTGGTCCATTATGGCTGACATGCAAAATCTGGTAGAAAGATTGGAGAGGGCAGTGGGCCGCCTGGAGGCAGTATCTCATACCTCTGACATGCACCGTGGGTAT',\n",
       "       b'GTGAGGGCCCGGAAGTGGGTCGCGCGGAGATTGCTGGGCGGTTCTTGCCGGAAGCGGAGAGCGGCTGATCGCAGTCCGGAGGTGGTCCATTATGGCTGACATGCAAAATCTGGTAGAAAGATTGGAGAGGGCAGTGGGCCGCCTGGAGGCAGTATCTCATACCTCTGACATGCACCGTGGGTATGCAGACAGTCCTTCAAAAG',\n",
       "       b'GCTTGCTGGTCCTGTGGCAGAGTACTTGAAGATCAGTAAAGAGATTGGGGGAGACGTGCAGAAACATGCGGAGATGGTCCACACAGGTTTGAAGTTGGAGCGAGCTCTGTTGGTTACAGCTTCTCAGTGTCAACAGCCAGCAGAAAATAAGCTTTCCGATTTGTTGGCACCCATCTCAGAGCAGATCAAAGAAGTGATAACCT',\n",
       "       b'GAAACATGCGGAGATGGTCCACACAGGTTTGAAGTTGGAGCGAGCTCTGTTGGTTACAGCTTCTCAGTGTCAACAGCCAGCAGAAAATAAGCTTTCCGATTTGTTGGCACCCATCTCAGAGCAGATCAAAGAAGTGATAACCTTTCGGGAGAAGAACCGAGGCAGCAAGTTGTTTAATCACCTGTCAGCTGTCAGCGAAAGTA',\n",
       "       b'CCGCGCCCAGTGAGGGCCCGGAAGTGGGTCGCGCGGAGATTGCTGGGCGGTTCTTGCCGGAAGCGGAGAGCGGCTGATCGCAGTCCGGAGGTGGTCCATTATGGCTGACATGCAAAATCTGGTAGAAAGATTGGAGAGGGCAGTGGGCCGCCTGGAGGCAGTATCTCATACCTCTGACATGCACCGTGGGTATGCAGACAGTC',\n",
       "       b'ACTGAGTCGTCTTTCCTTTGCCCGCTTCTGTGGACTGTTCGAACGCCCAGGGGTGGGCCAAACCCGTTTCTTAGGAAACCAGGAATCCAGGGAAGGCAGAATGGCTTCCTTTGGGTGGAAGAGGAAAATTGGTGAGAAGGTCTCAAAGGTCACTTCCCAGCAGTTTGAAGCTGAAGCTGCTGATGAGAAGGATGTAGTTGACA',\n",
       "       b'CCCAGGCAGGTTCGCCGGTGCGAGCGTAAAGGGGCGGAGCTAGGACTGCCTTGGGCGGTACAAATAGCAGGGAACCGCGCGGTCGCTCAGCAGTGACGTGACACGCAGCCCACGGTCTGTACTGACGCGCCCTCGCTTCTTCCTCTTTCTCGACTCCATCTTCGCGGTAGCTGGGACCGCCGTTCAGTCGCCAATATGCAGCT',\n",
       "       b'GGTGCGAGCGTAAAGGGGCGGAGCTAGGACTGCCTTGGGCGGTACAAATAGCAGGGAACCGCGCGGTCGCTCAGCAGTGACGTGACACGCAGCCCACGGTCTGTACTGACGCGCCCTCGCTTCTTCCTCTTTCTCGACTCCATCTTCGCGGTAGCTGGGACCGCCGTTCAGTCGCCAATATGCAGCTCTTTGTCCGCGCCCAG',\n",
       "       b'GAGCGTAAAGGGGCGGAGCTAGGACTGCCTTGGGCGGTACAAATAGCAGGGAACCGCGCGGTCGCTCAGCAGTGACGTGACACGCAGCCCACGGTCTGTACTGACGCGCCCTCGCTTCTTCCTCTTTCTCGACTCCATCTTCGCGGTAGCTGGGACCGCCGTTCAGTCGCCAATATGCAGCTCTTTGTCCGCGCCCAGGAGCT',\n",
       "       b'GGAACCGCGCGGTCGCTCAGCAGTGACGTGACACGCAGCCCACGGTCTGTACTGACGCGCCCTCGCTTCTTCCTCTTTCTCGACTCCATCTTCGCGGTAGCTGGGACCGCCGTTCAGTCGCCAATATGCAGCTCTTTGTCCGCGCCCAGGAGCTACACACCTTCGAGGTGACCGGCCAGGAAACGGTCGCCCAGATCAAGGCT',\n",
       "       b'ACGTGACACGCAGCCCACGGTCTGTACTGACGCGCCCTCGCTTCTTCCTCTTTCTCGACTCCATCTTCGCGGTAGCTGGGACCGCCGTTCAGTCGCCAATATGCAGCTCTTTGTCCGCGCCCAGGAGCTACACACCTTCGAGGTGACCGGCCAGGAAACGGTCGCCCAGATCAAGGCTCATGTAGCCTCACTGGAGGGCATTG',\n",
       "       b'AGGTCCCCACGTGTTGGGCGGGGAGCTGAAGTACACGCAATGCGCAGCGAGGCCTCGGGTTTTGCCGGCGCAGCGCGGGAGGTGGTCGCGGACGAAAGTGATAAAATCTGGGTGGGTGAAGAAGGGTCAGGGGGCCGGCGAGGGCCTGGGGGGGCAGCTCCGGCTCATGCTCCCCTCCTCAGCGCGCCCATGGGGTCCAGACG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$AGGGAACTTGACCCGTTAGCAGCCGCAGCCATGGCGGCGCGTTCGCCTCCCTCACCGCACCCTTCGCCCCCAGCGCGACAGCTGGGCCCCAGGTCCCCACGTGTTGGGCGGGGAGCTGAAGTACACGCAATGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TTATTCATGGGCTCACCGCTGAGGTTCGACGGGCGGGTGGTACTGGTCACCGGCGCGGGGGCAGGTGAGCATGCGAAGGTTGGAGGCCGCGCCCCTTGCTGAGGCGCAG',\n",
       "       b'GGCCGCGCCCCTTGCTGAGGCGCAGCTGGCTGCTCTTTTCGGGCCGGCATACGCGCGCAGCCGCAGCTGAGGTCACCCCGCTGAGGTGGTGGGGAGGGGAATGGTTATTCTTGAGGCACCGCATCTCTTGAGGAGGAAAGAGCCGGAAACACCTGGTCTCTCAAGCAGGATTGGGCCGAGCCTATGCCCTGGCTTTTGCAGAA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGCTTGCTGGGAGACACATAACCTCGATTTTCTTCCGCCATCCGGCTAAATAGTCCCATGTGCACTTTGTTCCATGGATAAATAAACACTAGGAACGCATTTCCACCCTAGATTTCAGCAGAAATGCTGAATGTAAAGGAATATTTGAGTAAAGTGAGTT',\n",
       "       b'CCTAGATTTCAGCAGAAATGCTGAATGTAAAGGAATATTTGAGTAAAGTGAGTTGCCGTTCTTGAAGCACCGTCTCCTCTCTCCGGTCCGTGCCTCCAAGATGACAAAGAAAAGAAGGAACAATGGTCGTGCCAAAAAGGGCCGCGGCCACGTGCAGCCTATTCGCTGCACTAACTGTGCCCGATGCGTGCCCAAGGACAAGG',\n",
       "       b'CCGCTGCAGTGAGTCCGTCACGGCTCCGGCGCGAGCGCGAGGCTGCAGCCCCCGAGTTTCCCGGCCGTCTTCGCCCCCTCTCCCCCTCCTTTCTTCTTCTCTGCCTCTCCTGCCTCTCGCCGCTGCTCCTCCCGCGCTCTCCGGCTCTGAATCTCGACCTTAATTTATTTCCCCCTACCCTGCCCGCTCCCTCGCGTGCCCAA',\n",
       "       b'GGCCCCGCGGCGCCGCCTCCCCTCCCCCACGCGCGCCCCCTCCCCGCCGGCGACCCGAGGGCCGCAGCTGGGCCGCCGCCGCCGTTTCCTGCGAGCCAGCCTGAGCGCAACACTTCTCCGAGCCAGCGAGCCAGCGAGCCGCCGACCCGCCGAGCAAAATGGGAAATGAGGCAAGTTATCCTTTGGAAATGTGCTCACACTTT',\n",
       "       b'GGGCCGCAGCTGGGCCGCCGCCGCCGTTTCCTGCGAGCCAGCCTGAGCGCAACACTTCTCCGAGCCAGCGAGCCAGCGAGCCGCCGACCCGCCGAGCAAAATGGGAAATGAGGCAAGTTATCCTTTGGAAATGTGCTCACACTTTGATGCGGATGAAATTAAAAGGCTAGGAAAGAGATTTAAGAAGCTTGATTTGGACAATT',\n",
       "       b'CGTTTCCTGCGAGCCAGCCTGAGCGCAACACTTCTCCGAGCCAGCGAGCCAGCGAGCCGCCGACCCGCCGAGCAAAATGGGAAATGAGGCAAGTTATCCTTTGGAAATGTGCTCACACTTTGATGCGGATGAAATTAAAAGGCTAGGAAAGAGATTTAAGAAGCTTGATTTGGACAATTCTGGTTCTTTGAGTGTGGAAGAGT',\n",
       "       b'TCCGCCCGCGCGTCACGTGACCCCAGCGCCTACTTGGGCTGAGGAGCCGCCGCGTCCCCTCGCCGAGTCCCCTCGCCAGATTCCCTCCGTCGCCGCCAAGATGATGTGCGGGGCGCCCTCCGCCACGCAGCCGGCCACCGCCGAGACCCAGCACATCGCCGACCAGGTGAGGTCCCAGCTTGAAGAGAAAGAAAACAAGAAGT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CTAGACGCCGTACGTGCCAGATGGTGTTACCTGGAGCTTAAAAAGCTGCACGCAAGTGTTAAACTTCTGACAATGGCCAAGAACAAATTAAGAGGGCCGAAGTCCAGGAATGTATTTCACATA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$CTAGACGCCGTACGTGCCAGATGGTGTTACCTGGAGCTTAAAAAGCTGCACGCAAGTGTTAAACTTCTGACAATGGCCAAGAACAAATTAAGAGGGCCGAAGTCCAGGAATGTATTTCACATAGCCAGCCAAAAAAACTTTAAGGCTAAAAACAAAGCAAAACCAGTTACCACTA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CACGACGATGGCGGCAATGGCGGTGGCGCTGCGGGGATTAGGAGGGCGCTTCCGGTGGCGGACGCAGGCCGTGGCGGGCGGGGTGCGGGGCGCGGCGCGGGGCGCAGCAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$CGCGATTCCGCACGTCCCTTACCCGCTTCACTAGTCCCGGCATTCTTCGCTGTTTTCCTAACTCGCCCGCTTGACTAGCGCCCTGGAACAGCCATTTGGGTCGTGGAGTGCGAGCACGGCCGGCCAATCGCCGAGTCAGAGGGCCAGGAGGGGCGCGGCCATTCGCCGCCCGGCCCCTGCTCCGT',\n",
       "       b'CGCCGAGTCAGAGGGCCAGGAGGGGCGCGGCCATTCGCCGCCCGGCCCCTGCTCCGTGGCTGGTTTTCTCCGCGGGCGCCTCGGGCGGAACCTGGAGATAATGGGCAGCACCTGGGGGAGCCCTGGCTGGGTGCGGCTCGCTCTTTGCCTGACGGGCTTAGTGCTCTCGCTCTACGCGCTGCACGTGAAGGCGGCGCGCGCCC',\n",
       "       b'$$$$$$$$$$CTCTTACCGCCCTTTTCCGGGGCAAGGGAAGCTAGTAGCGGAGCCGGAAGTGAGGCACCCTCGGGCTCGAGACAGCGGCGACGTTTAAAGCTGAGCGACCCAGTGCCACTGGAGACGGTCAGCTTCTCCACTCAGGCTCCTCCAGCCCGAGCCAGAAGACCCCCTCCCCCAGAATTCTGGGGGCCGATGGAAG',\n",
       "       b'AGGGAGTTGCCAGAAGCCCCGCCCCTAGGAGTGATCGGAAAGCCTCACCCATCCGGGTGAGGAACCCGGAGGGACCGCCTCCGGGCGGAGCCCGCCGACCATGGCTACGCCCCTGGTGGCGGGTCCCGCAGCTCTACGCTTCGCCGCCGCGGCTAGCTGGCAGGTTGTGCGCGGACGCTGCGTGGAACATTTTCCGCGAGTAC',\n",
       "       b'CGGCGCGCGACGATGTCGCACCGCGGCGTGCGCGGTGTCGGCAGTAGCTGCGGCGCAGGGGCGGAGCGAAGGCTGCGGCGGCGTCGGGTACGCGCACACGTTGCATCTTCTTCCTTTCGCGGGGTCCTCCGTAGTTCTGGCACGAGCCAGGCGTACTGACAGGTGGACCAGCGGACTGGTGGAGATGGCGACGCTCTCTCTGA',\n",
       "       b'GTCGGCAGTAGCTGCGGCGCAGGGGCGGAGCGAAGGCTGCGGCGGCGTCGGGTACGCGCACACGTTGCATCTTCTTCCTTTCGCGGGGTCCTCCGTAGTTCTGGCACGAGCCAGGCGTACTGACAGGTGGACCAGCGGACTGGTGGAGATGGCGACGCTCTCTCTGACCGTGAATTCAGGAGACCCTCCGCTAGGAGCTTTGC',\n",
       "       b'CGGGTACGCGCACACGTTGCATCTTCTTCCTTTCGCGGGGTCCTCCGTAGTTCTGGCACGAGCCAGGCGTACTGACAGGTGGACCAGCGGACTGGTGGAGATGGCGACGCTCTCTCTGACCGTGAATTCAGGAGACCCTCCGCTAGGAGCTTTGCTGGCAGTAGAACACGTGAAAGACGATGTCAGCATTTCCGTTGAAGAAG',\n",
       "       b'GTCCTCCGTAGTTCTGGCACGAGCCAGGCGTACTGACAGGTGGACCAGCGGACTGGTGGAGATGGCGACGCTCTCTCTGACCGTGAATTCAGGAGACCCTCCGCTAGGAGCTTTGCTGGCAGTAGAACACGTGAAAGACGATGTCAGCATTTCCGTTGAAGAAGGGAAAGAGAATATTCTTCATGTTTCTGAAAATGTGATAT',\n",
       "       b'AGGCTCTCCTAGCAGCATCCATCGCCGCCACCCTATCTTCACTGGCTTCATTCACCTTCTCCTTCTCTCTTCGTTGCTGAGCGACAAGCTTCCTAGCGCTATGACTGTCGTCTCCGTCCCGCAGCGGGAGCCGCTCGTCCTGGGTGGCCGCCTTGCGCCGCTTGGCTTTTCCTCCCGAGGTTACTTTGGGGCCCTCCCGATGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CGCGGCAACGCAGGGGCGGAACCGCATGACTGGCAGTGGCATCAGCGATGGCGGCTGCGTCGGGGTCGGTTCTGCAGCGCTGTATCGTGTCGCCGGCAGGGAGGCATAGCGCCTCTCTGATCTTCCTGCATGGCTCAGGTGATTCTGGAC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGAGTGTAGGCCAGGGGGTTGGCGGTGCCGTGTCATGGAGGCTCAGTCTCTGAGCAGCCATTGAAGGGGAAGGAACTGCGGGTGTGTGTGTGTATGTGTGTGTGTATGTGTGTGCGCGCGTGCGTGCGTGTGTGTGCGCGCGCTAGTGTGTGGACAAGGAGGT',\n",
       "       b'GTGTGTGCGCGCGTGCGTGCGTGTGTGTGCGCGCGCTAGTGTGTGGACAAGGAGGTGGGGGCAGCTGAGTTAGAGTCCCAACTCTTGGACTCCATTTGCTATTCTCTTCTTTCTCCCCCACACCTATCTGGTGGTGGTAGTGGGCGTTTATATTTGCGTTCCTTTTCATTCATTTCTAAATCTCTTAAAAATTTTGGGTTGGG',\n",
       "       b'TGTGTGGACAAGGAGGTGGGGGCAGCTGAGTTAGAGTCCCAACTCTTGGACTCCATTTGCTATTCTCTTCTTTCTCCCCCACACCTATCTGGTGGTGGTAGTGGGCGTTTATATTTGCGTTCCTTTTCATTCATTTCTAAATCTCTTAAAAATTTTGGGTTGGGGGTATTGGGGAAGGCAGGAAAGGGAAAAGGAGAGTAGTA',\n",
       "       b'AGTTAGAGTCCCAACTCTTGGACTCCATTTGCTATTCTCTTCTTTCTCCCCCACACCTATCTGGTGGTGGTAGTGGGCGTTTATATTTGCGTTCCTTTTCATTCATTTCTAAATCTCTTAAAAATTTTGGGTTGGGGGTATTGGGGAAGGCAGGAAAGGGAAAAGGAGAGTAGTAGCTGAAGAGCAAGAGGAGGACATGGAGA',\n",
       "       b'GACAGAGTTAGTCCTTGATAATTGCCTGTGTGTCAATGGGGAAATTGAAGGCCTGAATGATACTTTCAAAGAACTAGAATTTCTGAGTATGGCTAATGTGGAACTAAGTTCGCTGGCCCGGCTTCCCAGCTTAAATAAACTTCGAAAATTGGAGCTTAGTGATAATATAATTTCTGGAGGCTTGGAAGTCCTGGCAGAGAAAT',\n",
       "       b'TTTCATTCATTTCTAAATCTCTTAAAAATTTTGGGTTGGGGGTATTGGGGAAGGCAGGAAAGGGAAAAGGAGAGTAGTAGCTGAAGAGCAAGAGGAGGACATGGAGATGAAGAAGAAGATTAACCTGGAGTTAAGGAACAGATCCCCGGAGGAGGTGACAGAGTTAGTCCTTGATAATTGCCTGTGTGTCAATGGGGAAATTG',\n",
       "       b'CCCTGGTTGTCAGATGTTGGAAAGCAGTAGGACGGAACATACTCTTCGTGGTTGTGTATCCGTTCTGGGGTGCAGCAATTAACATTGGACTTTGGTTCCTGTGACTCTTGCCTGTGTCGATAGAGTTAAACTGGAGCTCTGCTTTGAAAGATAAATAAAGCACAGCCTCTCAACTGGACATAAATGGATCTAAAGACAGCAGT',\n",
       "       b'ATTGGACTTTGGTTCCTGTGACTCTTGCCTGTGTCGATAGAGTTAAACTGGAGCTCTGCTTTGAAAGATAAATAAAGCACAGCCTCTCAACTGGACATAAATGGATCTAAAGACAGCAGTATTTAACGCAGCTCGGGATGGCAAACTCCGGCTTCTCACCAAATTGTTGGCAAGCAAATCCAAAGAGGAGGTTTCCTCCTTGA',\n",
       "       b'CCCCCTACTCCGGCGCCTCCTTTGCGACGCTCCCTGGAGAAAAGCACGCCCACTGCACGCGCTCAGTCGCTACTTCCGCTCTCGAGTGTCTCCAAGCAAGATGGCGGAGGAGCCGCAGTCTGTGTTGCAGCTTCCTACTTCAATTGCTGCTGGAGGGGAAGGACTTACGGATGTCTCCCCAGAAACAACCACCCCGGAGCCCC',\n",
       "       b'ACAGACACGTTGCCCACCGCTCCTCTCCCGAGGTCTGTAGTCGCGGAGAAACACATGTTGCGTTACTAACGTTCAGAGGTCTGCGACAGCTTCGATTTGAATGACTAGCCGGGAACACCAAGTTTCACTGTGTAATTGCGTCCCCCTACTCCGGCGCCTCCTTTGCGACGCTCCCTGGAGAAAAGCACGCCCACTGCACGCGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GTCATTTCCGGCGCGCCGGCCACGGTGCTTCCGGGTTCTGGTGTAGGAGCGGCGTCTTCTCGCGCGGATGGTGAAGCTGAATTTGGTACGCTGGACCCTCGGACAGACAGCAAGAGAGAGACAAGCCCGAGGCCTGACTTCTAGCACTCCTGAGTTTGAGCCCTATGAGC',\n",
       "       b'ATCGTGACCACCAAGGATCCAGATATAATTCTTTCCTCAGTAATAGAAAAAAGAATCTGGGATCTAAGAAGATACCTACTCATTTTCTAAGTGACTGGCCATGTCATTGTCCCACTTATACCGGGATGGGGAAGGCCGCATTGATGATGATGATGACGAGCGGGAGAACTTTGAGATCACTGACTGGGATCTCCAGAATGAGT',\n",
       "       b'TGGCAGGCGACTCCCCGCCCCTGCCCCGCCCCCCTGGGCGAAGAGCGCGGACTTGTGGGGCCGCTGGCTGCAGACTGGAGCTGCGCGGGTCAGGGAGATAATGGCTGCGCGGCCGATCACCCTCGGCATTGACCTGGGCACCACATCTGTGAAGGCAGCTCTGCTGAGGGCCGCGCCCGACGACCCATCCGGGTTCGCAGTGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGCCCTCTTCCCGGACTATAAAGAGAGCCGCCGGCTTCTGGGCTCCACCACGCTTTTCATCTGTCCCGCTGCGTGTTTTCCTCTTGATCGGGAACTCCTGCTTCTCCTTGCCTCGAAATGGACCCCAACTGCTCCTGCTCGCCTGTTGGCTCCTGTGCCTGTGCCGGCTCC',\n",
       "       b'ATAAAGAGAGCCGCCGGCTTCTGGGCTCCACCACGCTTTTCATCTGTCCCGCTGCGTGTTTTCCTCTTGATCGGGAACTCCTGCTTCTCCTTGCCTCGAAATGGACCCCAACTGCTCCTGCTCGCCTGTTGGCTCCTGTGCCTGTGCCGGCTCCTGCAAATGCAAAGAGTGCAAATGCACCTCCTGCAAGAAGAGCTGCTGCT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$AACTCGGGAACGGGAACAGGAGGCCGTTGGAAAACTTTGGGCAAGATGGCCCGGCGGTGATTTCCGCGGCGGTCTCTCCTGCGCCCGGCCTCTGCGGCGCAGGCCCAGCCCCCGAGCCTCGCACGTTCGGCAGCCCCGGCCTGGCCCC',\n",
       "       b'TCCGCGGCGGTCTCTCCTGCGCCCGGCCTCTGCGGCGCAGGCCCAGCCCCCGAGCCTCGCACGTTCGGCAGCCCCGGCCTGGCCCCGGCCCCTCCTGCCCATGGCGGTGGCCGAGCTGTACACGCAGTACAACAGGGTCTGGATTCCCGATCCTGAAGAAGTTTGGAAGTCTGCTGAAATAGCCAAGGACTACAGAGTTGGTG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CGCGCTCTTCCTTTCCAACTTGGACGCTGCAGAATGGCTCCCGCAAAGAAGGGTGGCGAGAAGAAAAAGGGCCGTTCTGCCATCAACGAAGTGGTAACCCGAGAATACACCATCAACATTCACAAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CGCGCTCTTCCTTTCCAACTTGGACGCTGCAGAATGGCTCCCGCAAAGAAGGGTGGCGAGAAGAAAAAGGGCCGTTCTGCCATCAACGAAGTGGTAACCCGAGAATACACCATCAACATTCACAAGCGCATCCATG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$AAGAGGCAGGAAGCGCAGCAACTCGTGTCTGAGCGCCCGGCGGAAAACCGAAGTTGGAAGTGTCTCTTAGCAGCGCGCGGAGAAGAACGGGGAGCCAGCATCATGGCAGAACAGGATGTGGAAAACGATCTTTTGGATTACGATGAAGAGGAAGAGCCCCAG',\n",
       "       b'GAGGCAGGAAGCGCAGCAACTCGTGTCTGAGCGCCCGGCGGAAAACCGAAGTTGGAAGTGTCTCTTAGCAGCGCGCGGAGAAGAACGGGGAGCCAGCATCATGGCAGAACAGGATGTGGAAAACGATCTTTTGGATTACGATGAAGAGGAAGAGCCCCAGGCTCCTCAAGAGAGCACACCAGCTCCCCCTAAGAAAGACATCA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGGTCACGTGGTGGCTGGGCCGGGGAAATGGCGGCTTCAGGAGAGAGCGGGACTTCAGGCGGCGGAGGCAGCACCGAGGAAGCATTTATGACCTTCTACAGTGAGGTGAAACAAATAGAGAAGAGAGACT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$CTCCAGCAGCACCCGAGAGGGTCAGGAGAAAAGCGGAGGAAGCTGGGTAGGCCCTGAGGGGCCTCGGTAAGCCATCATGACCACCCGGCAAGCCACGAAGGATCCCCTCCTCCGGGGTGTATCTCCTACCCCTAGCAAGATTCCGGTACGCTCTCAGAAACGCACGCCTTTCCCCACTG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GAAGAGACCGGTTGCCGCCATGATAGAACAGCAGAAGCGTAAGGGCCCAGAGTTGCCGCTGGTTCCAGTCAAGCGGCAGCGGCATGAGTTGCTGTTGGGAGCGGGGTCTGGCCCAGGAGCCG',\n",
       "       b'CTGCTCGGCGGCGGCGACGTGAGCGCGCAGGGGGGCGGCGGCCTCGCCTCGTCTCTCTCTCTGCGCCTGGGTCGGGTGGGTGACGCCGAGAGCCAGAGAGATGTCGGATTTCGACAGTAACCCGTTTGCCGACCCGGATCTCAACAATCCCTTCAAGGATCCATCAGTTACACAAGTGACAAGAAATGTTCCACCAGGACTTG',\n",
       "       b'TCCCTCCCCTCCAGAAGTCGGAGTGCTGTTTTTGTTGTTGGTGAAAGGTGAGGGGAACAGCTGATCCGTCTGTTGGGAGGACAGATATCTCAAGGCCAGGATGGAAGAATCACCACTAAGCCGGGCACCATCCCGTGGTGGAGTCAACTTTCTCAATGTAGCCCGGACCTACATCCCCAACACCAAGGTGGAATGTCACTACA',\n",
       "       b'GTCTCCGTCCTCACCTCCCCGCCCCCTCCCAGCTTCGCGTCTCCTAGCTCGACGCGCCCGCTATAATCACGTGATTGCCTCATCCGGGTCTTTTGCGTTCTCTTTCCCTCTCCCAACATGGCGGCCTCAGCAAAAAAGAAGAATAAGAAGGGGAAGACTATCTCCCTAACAGACTTTCTGGCTGAGGATGGGGGTACTGGTGG',\n",
       "       b'CACCTCCCCGCCCCCTCCCAGCTTCGCGTCTCCTAGCTCGACGCGCCCGCTATAATCACGTGATTGCCTCATCCGGGTCTTTTGCGTTCTCTTTCCCTCTCCCAACATGGCGGCCTCAGCAAAAAAGAAGAATAAGAAGGGGAAGACTATCTCCCTAACAGACTTTCTGGCTGAGGATGGGGGTACTGGTGGAGGAAGCACCT',\n",
       "       b'CCCGCCCCCTCCCAGCTTCGCGTCTCCTAGCTCGACGCGCCCGCTATAATCACGTGATTGCCTCATCCGGGTCTTTTGCGTTCTCTTTCCCTCTCCCAACATGGCGGCCTCAGCAAAAAAGAAGAATAAGAAGGGGAAGACTATCTCCCTAACAGACTTTCTGGCTGAGGATGGGGGTACTGGTGGAGGAAGCACCTATGTTT',\n",
       "       b'GGGCGGGGCTGGGAGTATTTGAGGCTCGGAGCCACCGCCCCGCCGGCGCCCGCAGCACCTCCTCGCCAGCAGCCGTCCGGAGCCAGCCAACGAGCGGAAAATGGCAGACAATTTTTCGCTCCATGATGCGTTATCTGGGTCTGGAAACCCAAACCCTCAAGGATGGCCTGGCGCATGGGGGAACCAGCCTGCTGGGGCAGGGG',\n",
       "       b'$$$$$$$$$$$GACGGCACGGGGCGGGGCCTCGGGGACCCCGGCAAGCCCGCGCACTTGGCAGGAGCTGTAGCTACCGCCGTCCGCGCCTCCAAGGTTTCACGGCTTCCTCAGCAGAGACTCGGGCTCGTCCGCCATGTCCGCCGCAGACGAGGTTGACGGGCTGGGCGTGGCCCGGCCGCACTATGGCTCTGTCCTGGATAA',\n",
       "       b'GACCCCGGCAAGCCCGCGCACTTGGCAGGAGCTGTAGCTACCGCCGTCCGCGCCTCCAAGGTTTCACGGCTTCCTCAGCAGAGACTCGGGCTCGTCCGCCATGTCCGCCGCAGACGAGGTTGACGGGCTGGGCGTGGCCCGGCCGCACTATGGCTCTGTCCTGGATAATGAAAGACTTACTGCAGAGGAGATGGATGAAAGGA',\n",
       "       b'CCGCCGGACCCTCCCGCCGGCCCGCGCCGCTGCACTCGCCCTCTCCTCTCGCCCCCCGGCAAACTTTCGGCCCCTCCCCGCCCCTCGCCCGTTATTCGTCGTGGCTCAAGCCCGGCCACGCCGCCCCAAGGGCTCCTCCCGACCTCCCGGCCTGCCGCTCCGGCCACTGCGGGATCCAGAAACATGTCGACCACACTTCTGTC',\n",
       "       b'CTCGCCCGTTATTCGTCGTGGCTCAAGCCCGGCCACGCCGCCCCAAGGGCTCCTCCCGACCTCCCGGCCTGCCGCTCCGGCCACTGCGGGATCCAGAAACATGTCGACCACACTTCTGTCCGCCTTCTACGATGTCGACTTCTTGTGCAAGACAGAGAAATCCCTGGCCAACCTCAACCTGAACAACATGCTGGACAAGAAGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GTCGCGGAACCCGGAAGCGGGGGTGCAGCGCGGCAGAATGAGGGTTGATTCCTCGGCTGACCCCACAATGTCGCAGGAGCAAGGGCCGGGGTCCTCCACGCCTCCCAGTTCTCCGACACTTCTTGACGCTCTGCTCCAGA',\n",
       "       b'GGAAGTTATTTGGGACCAAAAAGACATACAGGTGTGAGTTTATTTGGGAGGGAGGAAGGAATCCTCATCAGATGTGCAGGAATGTTGGAAAAGCCTAAAGATTAGACTGTAAGAAAAGAAAATAGAAGCCATGTTTCGAAGACCTGTATTACAGGTACTTCGTCAGTTTGTAAGACATGAGTCCGAAACAACTACCAGTTTGG',\n",
       "       b'GGTGTGAGTTTATTTGGGAGGGAGGAAGGAATCCTCATCAGATGTGCAGGAATGTTGGAAAAGCCTAAAGATTAGACTGTAAGAAAAGAAAATAGAAGCCATGTTTCGAAGACCTGTATTACAGGTACTTCGTCAGTTTGTAAGACATGAGTCCGAAACAACTACCAGTTTGGTTCTTGAAAGATCCCTGAATCGTGTGCACT',\n",
       "       b'CCGTCGGGCGCTCCTTCCTCAGCGGCGGGAAGCTGGCGGCAGCGGCGGTGGCGGTGGCTGAGCAGAGGACCCGGCGGGCGGCCTCGCGGGTCAGGACACAATGTTTGCACGAGGACTGAAGAGGAAATGTGTTGGCCACGAGGAAGACGTGGAGGGAGCCCTGGCCGGCTTGAAGACAGTGTCCTCATACAGCCTGCAGCGGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCAGGTGGCGGAGATTGCACCGGAAGACGCTTCCTGGGTTTGAGGAGTTCAGTGACTGCTATTGAACCACCAAAAGTCCATTATGAAACTGTATTGCCTGTCAGGGCACCCAACCTTACCATGCAATGTGCTCAAATTCAAATCAACCACCATTATGTTGGAC',\n",
       "       b'$$$$$$$$$$$$$$$$$$GCAGGTGGCGGAGATTGCACCGGAAGACGCTTCCTGGGTTTGAGGAGTTCAGTGACTGCTATTGAACCACCAAAAGTCCATTATGAAACTGTATTGCCTGTCAGGGCACCCAACCTTACCATGCAATGTGCTCAAATTCAAATCAACCACCATTATGTTGGACTGCGGACTGGACATGACTTCTA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$CGTGGTCGGCTGGCCGGGCGGCTAGGAGTTCCCGGAAGTGCCCGCGCAGCCGGTTTCCGGTGCAGGTGGGGAAAATGGCGGTGTCTACAGTGTTCTCGACTTCGTCGCTGATGCTTGCTCTGTCAAGGCACAGCCTATTGTCTCCTTTGCTCAGTGTGACATCATTCAGACGCTTCT',\n",
       "       b'GCCTGCAGGCCCCGCCCCGGCTGCGGAGGCTCAGTCACAGCCCTCCCCTCCTCGCTCCCTCCCCTCCTCTCCCCGCCCAGTTCTTCTCTTCCCGTCTGAGGTGGCGGTCGGTCTCGCCTTGTCGCCAGCTCCATTTTCCTCTCTTTCTCTTCCCCTTTCCTTCGCGCCCAAGAGCGCCTCCCAGCCTCGTAGGGTGGTCACGG',\n",
       "       b'AGTCACAGCCCTCCCCTCCTCGCTCCCTCCCCTCCTCTCCCCGCCCAGTTCTTCTCTTCCCGTCTGAGGTGGCGGTCGGTCTCGCCTTGTCGCCAGCTCCATTTTCCTCTCTTTCTCTTCCCCTTTCCTTCGCGCCCAAGAGCGCCTCCCAGCCTCGTAGGGTGGTCACGGAGCCCCTGCGCCTTTTCCTTGCTCGGGTCCTG',\n",
       "       b'CCTTCGCGCCCAAGAGCGCCTCCCAGCCTCGTAGGGTGGTCACGGAGCCCCTGCGCCTTTTCCTTGCTCGGGTCCTGCGTCCGCGCCTGCCCCGCCATGAATGAGGAGTACGACGTGATCGTGCTGGGCACCGGCCTGACGGAATGTATCCTGTCAGGTATAATGTCAGTGAATGGCAAGAAAGTTCTTCATATGGATCGAAA',\n",
       "       b'CTTTCCTTCGCGCCCAAGAGCGCCTCCCAGCCTCGTAGGGTGGTCACGGAGCCCCTGCGCCTTTTCCTTGCTCGGGTCCTGCGTCCGCGCCTGCCCCGCCATGAATGAGGAGTACGACGTGATCGTGCTGGGCACCGGCCTGACGGAATGTATCCTGTCAGGTATAATGTCAGTGAATGGCAAGAAAGTTCTTCATATGGATC',\n",
       "       b'AGTCTGCGAGTGAGCGCTCAGCCCGGCACCTGTTCCTCCAGCGCCGCCGCCTTCCCACCCCTCGGACCCGCGCCGCTCGCGGCGCCCGCCCGTTCCTGCGATGAATCCGGCCCTAGGCAACCAGACGGACGTGGCGGGCCTGTTCCTGGCCAACAGCAGCGAGGCGCTGGAGCGAGCCGTGCGCTGCTGCACCCAGGCGTCCG',\n",
       "       b'TCCGGTGCGAACCGCCTCGGCCGTTCCCTCGCGGAGCTTACTGAGCGCGGCCGCCGAGCCCAGCTCCGCCGCCGAGCGCCTGTGCCGGCACGGCTACACCATGGAGCGCCCGGATAAGGCGGCGCTGAACGCACTGCAGCCTCCTGAGTTCAGAAATGAAAGCTCATTAGCATCTACACTGAAGACGCTCCTGTTCTTCACAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$AGTCTCCGGCGAGTTGTTGCCTGGGCTGGACGTGGTTTTGTCTGCTGCGCCCGCTCTTCGCGCTCTCGTTTCATTTTCTGCAGCGCGCCAGCAGGATGGCCCACAAGCAGATCTACTACTCGGACAAG',\n",
       "       b'$$$$$AGTCTCCGGCGAGTTGTTGCCTGGGCTGGACGTGGTTTTGTCTGCTGCGCCCGCTCTTCGCGCTCTCGTTTCATTTTCTGCAGCGCGCCAGCAGGATGGCCCACAAGCAGATCTACTACTCGGACAAGTACTTCGACGAACACTACGAGTACCGGCATGTTATGTTACCCAGAGAACTTTCCAAACAAGTACCTAAAA',\n",
       "       b'TCTGCTGCGCCCGCTCTTCGCGCTCTCGTTTCATTTTCTGCAGCGCGCCAGCAGGATGGCCCACAAGCAGATCTACTACTCGGACAAGTACTTCGACGAACACTACGAGTACCGGCATGTTATGTTACCCAGAGAACTTTCCAAACAAGTACCTAAAACTCATCTGATGTCTGAAGAGGAGTGGAGGAGACTTGGTGTCCAAC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$AGTGCTGCTTACCCATCATGGAAGCAATGTGGCTCCTGTGTGTGGCGTTGGCGGTCTTGGCATGGGGCTTCCTCTGGGTTTGGGACTCCTCAGAACGAATGAAGAGTCGGGAGCAGGGAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$GGGCGGTGAGGGGGCGGGCCCGTACGCCGATTCCATATGGGCGCCGGCGCGGAGCGCCGCGGGGCAGCGCGGGGTCGCCATGGCTGAGCTGCAGCAGCTCCGGGTGCAGGAGGCGGTGGAGTCCATGGTGAAGAGTCTGGAAAGAGAGAACATCCGGAAGATGCAGGGTCTCATGTTCCGGT',\n",
       "       b'CGGGCAGACAGCACCAAGAACTGGACAGAGAAGATCTTGAGGCAGACAGAGGTGCTGCTGCAGCCCAACCCCAGTGCCCGAGTGGAGGAGTTCCTGTATGAGAAGCTGGACAGGAAGGTCCCCTCAAGGGTCACCAACGGGGAGCTGCTGGCTCAGTACATGGCAGACGCGGCCAGTGAGCTGGGGCCGACCACCCCCTATGG',\n",
       "       b'GTGCCCCGCAGCAGGTGGGCGGGGTGCGGTTGGCGGCGGCGGCTGGGCCGGGGGCTGCCGGCTGCGCTCGGGCCGTGCGCGGCGGCCGTGCGGGCACGCCATGGACTTCAACATGAAGAAGCTGGCGTCGGACGCGGGCATCTTCTTCACCCGGGCGGTGCAGTTCACGGAGGAGAAATTTGGCCAGGCTGAGAAGACTGAGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$CGGTCCTGTCCCGCAGCGTCCCGCCAGCCAGCTCCTTGCACCCTTCGCGGCCGAGGCGCTCCCTGGTGCTCCCCGCGCAGCCATGGCTCAGCACTTCTCCCTGGCCGCCTGCGACGTGGTCGGATTCGACCTGGACCACACTCTGTGTCGCTACAACCTGCCCGAGAGCGCCCCGCTCATTTATA',\n",
       "       b'$$$GCGGCAGAGGCGTCTGCGGTGACAGCTCAGTCAGTTGAGCTCTGTGTGCCAGGCGCTCGCGAGGGGGTAGCTCTTCTAGTAGTGCTCGGCGTCAGACATGGCGGAGGCGATGGATTTGGGCAAAGACCCCAACGGGCCCACCCATTCCTCGACTCTGTTCGTGAGGGACGACGGCAGCTCCATGTCCTTCTACGTGCGGC',\n",
       "       b'CTCTGCGGCTTTCCTTGACCTCTGACCCGCCGACCACGCTTGATCCCCGGCCGCGGGGCCAGGAAGTCGGAGTTTGAGCCCCGGAGGCAGAGCGGCTGCCATGGCCAAGTACCTGGCCCAGATCATTGTGATGGGCGTGCAGGTGGTGGGCAGGGCCTTTGCACGGGCCTTGCGGCAGGAGTTTGCAGCCAGCCGGGCCGCAG',\n",
       "       b'AGGCTTGGGAGGCAAGAGGAGGCCTCCTGACCTTTCACACTGCCTTTTTAATATTAAGATGAAGTCACACTCCACAACTTTCTTCCAGCCAGGCCCAGACATGTCCGTCCTTGTAAGTTAAAAGCTTCCATGGGAGCCTTCCTTCCTAATCAAGATGCAAATAATACGGCACTCCGAACAGACACTAAAAACAGCTCTCATCT',\n",
       "       b'TAAGATGAAGTCACACTCCACAACTTTCTTCCAGCCAGGCCCAGACATGTCCGTCCTTGTAAGTTAAAAGCTTCCATGGGAGCCTTCCTTCCTAATCAAGATGCAAATAATACGGCACTCCGAACAGACACTAAAAACAGCTCTCATCTCAAAGAACCCAGTGCTTGTATCACAGTATGAGAAATTAAATGCTGGGGAACAAC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCGTCTGCGCCTGCGCGCAAGAGAGGCGGGGCCAGCGCTCGGCATGGCGGAGCCAGATCTGGAGTGCGAGCAGATCCGTCTGAAGTGTATTCGTAAGGAGGGCTTCTTCACGGTGCCTCCGGAACACAGGCTGGGACGATGCCGGA',\n",
       "       b'CGTCCCCGGCACCGGAAGTGACCCTGGCGGGTTTGTCTTCAAATTCTCGGCGAGCAGGAGCCGCGCCGGCAGGTGGTGTTGACGATTGAACTGGGCAGTACTGGGGCCGTGAGCGGAGAGCAAAGTGGGCTGGACTGGGTCAGGCCCTCCTTCCTCGCTGCCGGGATCTCCACTCCGCCAATCCCCTGTGCCTGGCGTTGGGC',\n",
       "       b'CCTCCTTCCTCGCTGCCGGGATCTCCACTCCGCCAATCCCCTGTGCCTGGCGTTGGGCGGTTTCCCGAGGAGCTTGGGCCGCCGCAGCTTACAGTTGAACATGAGTCTTCTTATGATTAGTGAGAATGTAAAATTGGCTCGTGAATATGCATTGCTGGGAAACTATGACTCTGCGATGGTCTATTATCAGGGAGTTCTTGACC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCCAGCCCTCGGAAACGGAAGTGAGCGGCGGGGTCGACTGACGGTAACGGGGCAGAGAGGCTGTTCGCAGAGCTGCGGAAGATGAATGCCAGAGGACTTGGATCTGAGCTAAAGGACAGTATTCCAGTTACTGAACTTTCAGCAAGTGGACCTTTTGAAAGTCATGATCTTCTTC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$GCCAGCCCTCGGAAACGGAAGTGAGCGGCGGGGTCGACTGACGGTAACGGGGCAGAGAGGCTGTTCGCAGAGCTGCGGAAGATGAATGCCAGAGGACTTGGATCTGAGCTAAAGGACAGTATTCCAGTTACTGAACTTTCAGCAAGTGGACCTTTTGAAAGTCATGATCTTCTTCGGAAAGGTT',\n",
       "       b'CCGCGGAGTCGGGGACGGTAGAAGGGGCCGCGCGTGCGCAGTGGCGTCCGCTGTGCTTCCGGTGCGCCGGGCGCGGACGCGGGCACGCACACACGCAAGCACGCCTCCACTTAACTCGCGCCGCCGCGGCAGCTCGAGTCCACCAGCAGCGCCGTCCGCTTGACCGAGATGCTGCGGGCCTGTCAGTTATCGGGTGTGACCGC',\n",
       "       b'GGGCGCGGACGCGGGCACGCACACACGCAAGCACGCCTCCACTTAACTCGCGCCGCCGCGGCAGCTCGAGTCCACCAGCAGCGCCGTCCGCTTGACCGAGATGCTGCGGGCCTGTCAGTTATCGGGTGTGACCGCCGCCGCCCAGAGTTGTCTCTGTGGGAAGTTTGTCCTCCGTCCATTGCGACCATGCCGCAGATACTCTA',\n",
       "       b'CAGCAGCGCCGTCCGCTTGACCGAGATGCTGCGGGCCTGTCAGTTATCGGGTGTGACCGCCGCCGCCCAGAGTTGTCTCTGTGGGAAGTTTGTCCTCCGTCCATTGCGACCATGCCGCAGATACTCTACTTCAGGCAGCTCTGGGTTGACTACTGGCAAAATTGCTGGAGCTGGCCTTTTGTTTGTTGGTGGAGGTATTGGTG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCTTCCAGCCATGTGGGTTCAGCGGAAAGAGAAGCAAAACCACTCTTCCTAAAATGTTAGAAGCTGCTCTTCGCTTACCTTGGGGCCTTTGCATTGGGAGCTGTTTTTCACATCAAAGAATATGTGCTGAATGGAATTTTAGTATTTTGCTGTCGT',\n",
       "       b'GTTCGGCTGAAAGAAGACATGAAAAAGATAGTGGCAGTGCCATTAAATGAACAGAAGGATTTTACCTATCAGAAGTTATTTGGAGTCAGTCTCCAAGAACTTGAACGGCAGGGGCTCACCGAGAATGGCATTCCAGCAGTAGTGTGGAATATAGTGGAATATTTGACGCAGCATGGACTTACCCAAGAAGGTCTTTTTAGGGT',\n",
       "       b'CACATCAAAGAATATGTGCTGAATGGAATTTTAGTATTTTGCTGTCGTTTTAATATTTTCGTCTGGTCTTCCTCAGTTCTTCCAGACGCTTTCTGAGAGAATGGGGGCAGGAGCTCTAGCCATCTGTCAAAGTAAAGCAGCGGTTCGGCTGAAAGAAGACATGAAAAAGATAGTGGCAGTGCCATTAAATGAACAGAAGGATT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$AGACCGGCGCGTGAGGAACCTACCGGTACCGGCCGCGCGCTGGTAGTCGCCGGTGTGGCTGCACCTCACCAATCCCGTGCGCCGCGGCTGGGCCGTCGGAGAGTGCGTGTGCTTCTCTCCTGCACGCGGTGCTTGGGCTCGGCCAGGCGGGGTCCGC',\n",
       "       b'AGTAATGTAGACAGAAGTTCTCAAATTTGCATATTACATCAACTGGAACCAGCAGTGAATCTTAATGTTCACTTAAATCAGAACTTGCATAAGAAAGAGAATGGGAGTCTGGTTAAATAAAGATGACTATATCAGAGACTTGAAAAGGATCATTCTCTGTTTTCTGATAGTGTATATGGCCATTTTAGTGGGCACAGATCAGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$AGACGCCTCGAAGAATCCGCTATCGGCTGTCTGCACAACCGGAATCATGTCGAGTTTGGCGGTGAGAGACCCGGCAATGGATCGATCACTGCGTTCCGTGTTCGTGGGGAACATTCCATATGAGGCAACTGAGGAGCAGTTAAAGGACA',\n",
       "       b'CGCAGGGTCGGTGTGGGCGCAGGCTGCAGCGCCGCGACTCGTGCGGGTAGGCGTCTGCGCTCGGTTTGAGGGCTCGGCGCGGGGTTTCCTGTTCCTCCTTCTGCGCGGCTGCAGCTCGGGACTTCGGCCTGACCCAGCCCCCATGGCTTCAGAAGAGCTACAGAAAGATCTAGAAGAGGTAAAGGTGTTGCTGGAAAAGGCTA',\n",
       "       b'CGGTGTGGGCGCAGGCTGCAGCGCCGCGACTCGTGCGGGTAGGCGTCTGCGCTCGGTTTGAGGGCTCGGCGCGGGGTTTCCTGTTCCTCCTTCTGCGCGGCTGCAGCTCGGGACTTCGGCCTGACCCAGCCCCCATGGCTTCAGAAGAGCTACAGAAAGATCTAGAAGAGGTAAAGGTGTTGCTGGAAAAGGCTACTAGGAAA',\n",
       "       b'TGCGCTCGGTTTGAGGGCTCGGCGCGGGGTTTCCTGTTCCTCCTTCTGCGCGGCTGCAGCTCGGGACTTCGGCCTGACCCAGCCCCCATGGCTTCAGAAGAGCTACAGAAAGATCTAGAAGAGGTAAAGGTGTTGCTGGAAAAGGCTACTAGGAAAAGAGTACGTGATGCCCTTACAGCTGAAAAATCCAAGATTGAGACAGA',\n",
       "       b'GCGGGTAGGCGTCTGCGCTCGGTTTGAGGGCTCGGCGCGGGGTTTCCTGTTCCTCCTTCTGCGCGGCTGCAGCTCGGGACTTCGGCCTGACCCAGCCCCCATGGCTTCAGAAGAGCTACAGAAAGATCTAGAAGAGGTAAAGGTGTTGCTGGAAAAGGCTACTAGGAAAAGAGTACGTGATGCCCTTACAGCTGAAAAATCCA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GAGGCAGTGTGTTTCCGCCCAGAGCTGGAGTCTCCCAGCTGCCAGCCGACCCCGAACCCGCACTCCCGCCAACCGCGCTTTTTGTGGGCGGTCGGAAACCACAGCCTCCGTTGGATATGTTCGGTGC',\n",
       "       b'GCCCAGAGCTGGAGTCTCCCAGCTGCCAGCCGACCCCGAACCCGCACTCCCGCCAACCGCGCTTTTTGTGGGCGGTCGGAAACCACAGCCTCCGTTGGATATGTTCGGTGCATGTTATAAACAACCACTTAAACCCTCCGGATCTGAGCCTCCCGCAGAGGAATGCAGAATGACGCCACGGCACGCAGGATGTGATGTCACCG',\n",
       "       b'$$$$$$$$$$$$$$AGAAGCAGTCAGCCCAGGGCTCTCGGATGCAGGGAGCCTGGGCCCAAACAGCAGCTTCCGGAGTCGGAAGGAGCTGAGGAAGAAGACTGACTGAAGGAGCTTGCGACTTTTCCGCCTCGGCAACCGGACCCAGCAGCAAGCAGGACGGGCGGCGCTCTGCTACTGGTCCCGTTAAGCCAGAGTAGCCCA',\n",
       "       b'CTCGGCAACCGGACCCAGCAGCAAGCAGGACGGGCGGCGCTCTGCTACTGGTCCCGTTAAGCCAGAGTAGCCCAAGCCCTGAAGTCACTGCTCATCCGGAATGGAAATCCCGCCGACCAACTACCCAGCCTCCAGGGCGGCCTTGGTGGCACAGAACTACATCAACTACCAGCAGGGGACCCCGCACAGGGTGTTTGAGGTGC',\n",
       "       b'CAAGCTGGAGGCACAGTTGGTGGATCTGAAATCTGAACTGACAGAAACCCAAGCAGAGAAAGTTGTTTTGGAGAAAGAAGTACATGATCAGCTTTTACAGCTGCACTCTATTCAGCTGCAGCTTCATGCTAAAACTGGTCAAAGTGCTGACTCTGGTACCATTAAGGCAAAATTGTCTGGCCCCTCTGTGGAGGAGCTGGAAA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$TCAGTCCCAGCAGTTCCCTTCGTGCGCGGGGGGCGGCGAGGGTCTTCAGCAGTCGGGAGAGGCCCTTGACGGCGCCATGTCGGCGGGCGGTCCATGCCCAGCAGCAGCCGGAGGGGGCCCAGGGGGCGCCTCCTGCTCCGTGGGGGCCCCTGGCGGGGTATCCATGTTCCGGTGGCTGG',\n",
       "       b'GCTGCGCCTGTGCATGCGCAGGGAGGGGAGACCTTGGCGGAGCGGCGGAGGCGCCCAGCGGAGGTGAAAGTATTGGCGGAAAGGAAAATACAGCGGAAAAATGCAGAGCTGGAGTCGTGTGTACTGCTCCTTGGCCAAGAGAGGCCATTTCAATCGAATATCTCATGGCCTACAGGGACTTTCTGCAGTGCCTCTGAGAACTT',\n",
       "       b'GGCCCATGGAAAAGATTTTGCATCTAGAGGAATTGAAATGTCCGAAGTTCGCTTGAATTTAGACAAGATGATGGAGCAGAAGAGTACTGCAGTAAAAGCTTTAACAGGTGGAATTGCCCACTTATTCAAACAGAATAAGGTTGTTCATGTCAATGGATATGGAAAGATAACTGGCAAAAATCAAGTCACTGCTACGAAAGCTG',\n",
       "       b'GCTCCAAAATAACTTTATTTTTGGGGGAGAAAGCACATCACGAACCAGTCAAAATCGTGGTTTATTTCTGTAACGTGAAGACTTCTGCTCTTTTTTCTTTGTTTGTTTTTTTCGTAAACATCTGGGTGTATATCAAACGGCAAGATGTCCAGTAATGTCCCGGCGGATATGATAAATTTGCGCCTCATTTTGGTAAGCGGAAA',\n",
       "       b'CCAGTCAAAATCGTGGTTTATTTCTGTAACGTGAAGACTTCTGCTCTTTTTTCTTTGTTTGTTTTTTTCGTAAACATCTGGGTGTATATCAAACGGCAAGATGTCCAGTAATGTCCCGGCGGATATGATAAATTTGCGCCTCATTTTGGTAAGCGGAAAAACAAAAGAGTTCCTGTTTTCTCCTAACGATTCTGCTTCTGACA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ATTAGGCCTGCCGAGAGGAGTGTTTTCTTGCATCCAGAAAAGACCTGAGAGGCGGACGACACCTGTGCTCCGCAGAGCAGAACGTGGGAGGAACGGCGGGATGTTAAGGTAGGAGCTCAAGAAGCAGAGAGTCTACCTGCCCGACGC',\n",
       "       b'GTTTTTCCCCGACCCAGTGAAAGAGTGTTAAGACTTCGACCTAGGACACATTGAGAACCAAGGCCAAGACTGGACAGGGCCATATAACTGGGCTTCAACCATGGCTGGGACTAAGAATAAGACAAGAGCCCAGGCCAAAACTGAAAAAAAGGCTGCTATACAAGCTAAAGCTGGAGCAGAGAGGGAGGCTACTGGTGTTGTTA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GAAGTCACTATCTCCCGGGTGAACGGAGCTTTCGCAGCTGGAGAAGGCTCATCCACCTGCAGACATGGGGCGCAGAAAGTCAAAACGAAAGCCGCCTCCCAAGAAGAAGATGACAGGCACCCTCGAGACCCAGTTCACCT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GAAGTCACTATCTCCCGGGTGAACGGAGCTTTCGCAGCTGGAGAAGGCTCATCCACCTGCAGACATGGGGCGCAGAAAGTCAAAACGAAAGCCGCCTCCCAAGAAGAAGATGACAGGCACCCTCGAGACCCAGTTCACCTGCCCCTTCTGCAACCACGAGAAATCCT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GAAGAGGGCGGCGACGGTGGTGGTGACTGAGCGGAGCCCGGTGACAGGATGGCTGGGCACAGATTGGTGTTGGTATTAGGAGATCTGCACATCCCACACCGGTGCAACAGTTTGCCAGCTAAATTCAAAAAACTCCTGGTGCCAGGAAAAA',\n",
       "       b'CGACGGTGGTGGTGACTGAGCGGAGCCCGGTGACAGGATGGCTGGGCACAGATTGGTGTTGGTATTAGGAGATCTGCACATCCCACACCGGTGCAACAGTTTGCCAGCTAAATTCAAAAAACTCCTGGTGCCAGGAAAAATTCAGCACATTCTCTGCACAGGAAACCTTTGCACCAAAGAGAGTTATGACTATCTCAAGACTC',\n",
       "       b'$$$$$$$$$AGTTGGCAGGCTGCTGCGGGAGGCGGCGGCGGTAGGAAGCCGGAGACAGCAGGGTGACAGAATTGGAAAATATTTAACTCTTAACAAATGAATTCCCCACTTGAACTCTGCCGAATTCCTGTGCCACCTCCTCCTTTAGAAAACTGATCTTAATACAGAGATAAAAGAGGAGTAGAAGGTAAAAGAAAATGCTG',\n",
       "       b'TGAATTCCCCACTTGAACTCTGCCGAATTCCTGTGCCACCTCCTCCTTTAGAAAACTGATCTTAATACAGAGATAAAAGAGGAGTAGAAGGTAAAAGAAAATGCTGGGAACTGACCGTTGTGTTGTGGAAGAATGGTTATCAGAATTCAAGGCATTACCTGACACTCAGATCACCAGTTATGCAGCAACTTTACACCGGAAAA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCAGTTGTTGTTGGTTGGGGGCCTTTTGGCCGGTGACGGAGACTGCCCAGGTGTGGTCACCATGTTCCTCTCCGCGGTCTTCTTTGCCAAGAGCAAGTCAAAAAACATTCTGGTGAGAATGGTGAGCGAAGCTGGGACAGGTTTCTGCTTCAACACCAAGAGAA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$GCAGTTGTTGTTGGTTGGGGGCCTTTTGGCCGGTGACGGAGACTGCCCAGGTGTGGTCACCATGTTCCTCTCCGCGGTCTTCTTTGCCAAGAGCAAGTCAAAAAACATTCTGGTGAGAATGGTGAGCGAAGCTGGGACAGGTTTCTGCTTCAACACCAAGAGAAACCGACTGCGGGAAAAACTG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TCAAAATTTCAACGATACTGAATGAGTCCCGCGGCGGGTTGGCTCGCGCTTCGTTGTCAGATCTGAGGCGAGGCTAGGTGAGCCGTGGGAAGAAAAGAGGGAGCAGCTAGGGCGCGGGTCTCCC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TCAAAATTTCAACGATACTGAATGAGTCCCGCGGCGGGTTGGCTCGCGCTTCGTTGTCAGATCTGAGGCGAGGCTAGGTGAGCCGTGGGAAGAAAAGAGGGAGCAGCTAGGGCGCGGGTCTCCCTCCTCCCGGAGTTTGGAACGGCTGAAGTTCACCTTCCAGCC',\n",
       "       b'GCTCGCGCTTCGTTGTCAGATCTGAGGCGAGGCTAGGTGAGCCGTGGGAAGAAAAGAGGGAGCAGCTAGGGCGCGGGTCTCCCTCCTCCCGGAGTTTGGAACGGCTGAAGTTCACCTTCCAGCCCCTAGCGCCGTTCGCGCCGCTAGGCCTGGCTTCTGAGGCGGTTGCGGTGCTCGGTCGCCGCCTAGGCGGGGCAGGGTGC',\n",
       "       b'TGTAGGCCTGATAGACTGATTAAACCACAGAAGGTGACCTGCTGAGAAAAGTGGTACAAATACTGGGAAAAACCTGCTCTTCTGCGTTAAGTGGGAGACAATGTCACAAGTTAAAAGCTCTTATTCCTATGATGCCCCCTCGGATTTCATCAATTTTTCATCCTTGGATGATGAAGGAGATACTCAAAACATAGATTCATGGT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ACTGGGGTGGTGCTTAGCCGGCGCCAGACCGACCCTCGACTTCGGAGAGGCAGCGCGGTTCCTCTGGGTGCTTCCGCCTCCCCTTCTCCTGCTTCTCCAGCCTCTTCGGCCTCCTCGCCCGCCGCGGGAACCCGAGACCCCAGTGTATGCCCCACCCCTGACCCCG',\n",
       "       b'$$$$$$$$$$$$ACTGGGGTGGTGCTTAGCCGGCGCCAGACCGACCCTCGACTTCGGAGAGGCAGCGCGGTTCCTCTGGGTGCTTCCGCCTCCCCTTCTCCTGCTTCTCCAGCCTCTTCGGCCTCCTCGCCCGCCGCGGGAACCCGAGACCCCAGTGTATGCCCCACCCCTGACCCCGCTCGCGACATGTCCACCCCGGCTCG',\n",
       "       b'GGTGGTGCTTAGCCGGCGCCAGACCGACCCTCGACTTCGGAGAGGCAGCGCGGTTCCTCTGGGTGCTTCCGCCTCCCCTTCTCCTGCTTCTCCAGCCTCTTCGGCCTCCTCGCCCGCCGCGGGAACCCGAGACCCCAGTGTATGCCCCACCCCTGACCCCGCTCGCGACATGTCCACCCCGGCTCGGCGGCGCCTCATGCGGG',\n",
       "       b'CGCCTCCCCTTCTCCTGCTTCTCCAGCCTCTTCGGCCTCCTCGCCCGCCGCGGGAACCCGAGACCCCAGTGTATGCCCCACCCCTGACCCCGCTCGCGACATGTCCACCCCGGCTCGGCGGCGCCTCATGCGGGACTTCAAGAGGTTGCAGGAGGATCCTCCAGCCGGAGTCAGCGGGGCTCCGTCCGAGAACAACATAATGG',\n",
       "       b'ACCCAGTTGAAGGCCTTTACGAAGTGAAAGAGGCCGGGAGTCGCCCCCTACCCGCTTCTCGTAGTCCTGGGAGCACAGCAGAAGTGTTTTTCTTTTTTTAATGAACAAGTAAACCATACAAATTGTCAACATGGGACGGAGATCTACATCATCCACCAAGAGTGGAAAATTTATGAACCCCACAGACCAAGCCCGAAAGGAAG',\n",
       "       b'AGGCCGGGAGTCGCCCCCTACCCGCTTCTCGTAGTCCTGGGAGCACAGCAGAAGTGTTTTTCTTTTTTTAATGAACAAGTAAACCATACAAATTGTCAACATGGGACGGAGATCTACATCATCCACCAAGAGTGGAAAATTTATGAACCCCACAGACCAAGCCCGAAAGGAAGCCCGGAAGAGAGAATTAAAGAAGAACAAAA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCGGGTGGAGGGGCAAGGCGAGTGTGTGTCCTTATCCTAGCAATTGGGGCGCGGGCCTGTGAGCCAGTTGGAGTTGCGGCGGCGGGAACGATTGGGCTGAGCAGAGGACGACATGTTGCTTTTCGTGGAGCAGGTAGCATCTAAA',\n",
       "       b'GCAAGGCGAGTGTGTGTCCTTATCCTAGCAATTGGGGCGCGGGCCTGTGAGCCAGTTGGAGTTGCGGCGGCGGGAACGATTGGGCTGAGCAGAGGACGACATGTTGCTTTTCGTGGAGCAGGTAGCATCTAAAGGAACTGGTTTAAATCCTAATGCCAAAGTATGGCAAGAAATTGCTCCTGGAAATACTGATGCCACCCCAG',\n",
       "       b'GGAATCCCAGTGGATGAAAATGCTGTACATGTTCTTGTTGATAACAATGGGCAAGGTCTAGGACAGGCATTGGTTCAGTTTAAAAATGAAGATGATGCACATGGCCCACTGCGTGACCTTGGTTCAGCTGTCCATTTCCTGTGACCATCTCATTGACAAGGACATCGGCTCCAAGTCTGACCCACTCTGCGTCCTTTTACAGG',\n",
       "       b'CTTCAGTTCCTAGAAGGAATCCCAGTGGATGAAAATGCTGTACATGTTCTTGTTGATAACAATGGGCAAGGTCTAGGACAGGCATTGGTTCAGTTTAAAAATGAAGATGATGCACATGGCCCACTGCGTGACCTTGGTTCAGCTGTCCATTTCCTGTGACCATCTCATTGACAAGGACATCGGCTCCAAGTCTGACCCACTCT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TGGCAGACGTGGAGCGGCGCGCATGCGCAGCAGCTCACTCTGCTGAAGGGCTGAGAGGCGCACCCGGGCGGCCAGCTGGGCTCGGAGCGGAACGGGGTCAGGATGGACGAGGACGTGCTAACCACCCTGAAGATCCTCATCATCG',\n",
       "       b'GCAGACGTGGAGCGGCGCGCATGCGCAGCAGCTCACTCTGCTGAAGGGCTGAGAGGCGCACCCGGGCGGCCAGCTGGGCTCGGAGCGGAACGGGGTCAGGATGGACGAGGACGTGCTAACCACCCTGAAGATCCTCATCATCGGCGAGAGTGGGGTGGGCAAGTCCAGCCTGCTCTTGAGGTTCACAGATGATACGTTTGATC',\n",
       "       b'CGGCGCGCATGCGCAGCAGCTCACTCTGCTGAAGGGCTGAGAGGCGCACCCGGGCGGCCAGCTGGGCTCGGAGCGGAACGGGGTCAGGATGGACGAGGACGTGCTAACCACCCTGAAGATCCTCATCATCGGCGAGAGTGGGGTGGGCAAGTCCAGCCTGCTCTTGAGGTTCACAGATGATACGTTTGATCCAGAACTTGCAG',\n",
       "       b'AACGGGGTCAGGATGGACGAGGACGTGCTAACCACCCTGAAGATCCTCATCATCGGCGAGAGTGGGGTGGGCAAGTCCAGCCTGCTCTTGAGGTTCACAGATGATACGTTTGATCCAGAACTTGCAGCAACAATAGGTGTTGACTTTAAGGTGAAAACAATTTCAGTGGATGGAAATAAGGCTAAACTTGCAATATGGGATAC',\n",
       "       b'TCACAGATGATACGTTTGATCCAGAACTTGCAGCAACAATAGGTGTTGACTTTAAGGTGAAAACAATTTCAGTGGATGGAAATAAGGCTAAACTTGCAATATGGGATACTGCTGGTCAAGAGAGGTTTAGAACATTAACTCCCAGCTATTATAGAGGTGCACAGGGTGTTATATTAGTTTATGATGTCACAAGAAGAGATACA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCGGAAACGTGCACTTGCAAGCTGCCCGCAATACGTCATGGCGACCAAACGCCTTTTCGGGGCTACCCGGACGTGGGCCGGCTGGGGGGCCTGGGAGCTCCTAAACCCCGCCACTTCCGGAAGA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCGGAAACGTGCACTTGCAAGCTGCCCGCAATACGTCATGGCGACCAAACGCCTTTTCGGGGCTACCCGGACGTGGGCCGGCTGGGGGGCCTGGGAGCTCCTAAACCCCGCCACTTCCGGAAGACTCCTGGCCCGGGATT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCGGAAACGTGCACTTGCAAGCTGCCCGCAATACGTCATGGCGACCAAACGCCTTTTCGGGGCTACCCGGACGTGGGCCGGCTGGGGGGCCTGGGAGCTCCTAAACCCCGCCACTTCCGGAAGACTCCTGGCCCGGGATTATGCCAAGAAA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCTCACGTGGCCGTCAAGCCCTCTAGTGCCTTAGATTCCAGCGAGCTACGCAAGCAATCCTGGCCCAGCCGAGCTTGCTTCCCCAAATCCCGTAATCCTTGACCTTATTCCCCCAAAGAAGCGGCCTC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCTCACGTGGCCGTCAAGCCCTCTAGTGCCTTAGATTCCAGCGAGCTACGCAAGCAATCCTGGCCCAGCCGAGCTTGCTTCCCCAAATCCCGTAATCCTTGACCTTATTCCCCCAAAGAAGCGGCCTCCCGGGAAGGAGCGCCCTGGCGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCTCACGTGGCCGTCAAGCCCTCTAGTGCCTTAGATTCCAGCGAGCTACGCAAGCAATCCTGGCCCAGCCGAGCTTGCTTCCCCAAATCCCGTAATCCTTGACCTTATTCCCCCAAAGAAGCGGCCTCCCGGGAAGGAGCGCCCTGGCGGAGAAGACTCGAA',\n",
       "       b'$$$$$$CCTCACGTGGCCGTCAAGCCCTCTAGTGCCTTAGATTCCAGCGAGCTACGCAAGCAATCCTGGCCCAGCCGAGCTTGCTTCCCCAAATCCCGTAATCCTTGACCTTATTCCCCCAAAGAAGCGGCCTCCCGGGAAGGAGCGCCCTGGCGGAGAAGACTCGAACGGCTCCCACAGCCGGGCGTTGGGGGAAAGGCATG',\n",
       "       b'AGGGGTGTCTCAGAATCTCCGGCCTGTGAAACTGTGAGGGGATTCGGCCAAGACGTCCTCTTCCCTCTGCCTCCCACCCAGGCCACTCTTCACCTCCACCATGAGCCTGGACATCCAGAGCCTGGACATCCAGTGTGAGGAGCTGAGCGACGCTAGATGGGCCGAGCTCCTCCCTCTGCTCCAGCAGTGCCAAGTGGTCAGGC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TGAGTTTACGCAGACGCAGAAAACGCAGGCAAACCTGAGGTCCTCAGAATGGCGGGCACAGGTTTGGTGGCTGGAGAGGTTGTGGTGGATGCGCTGCCGTATTTTGATCAAGGTTATGAAGCCCCTGGTGTGCGGGA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TGAGTTTACGCAGACGCAGAAAACGCAGGCAAACCTGAGGTCCTCAGAATGGCGGGCACAGGTTTGGTGGCTGGAGAGGTTGTGGTGGATGCGCTGCCGTATTTTGATCAAGGTTATGAAGCCCCTGGTGTGCGGGAAGCGGCTGCAGCGC',\n",
       "       b'$$$$$$$$GGTCTTGGCGGGTCGGTGAGTCTTGGCGGCTGTTAACGCGCGCTTTGGGAACAGGAAGGTTGAGAGAGAGGTGCTGGGGTCTGCGTCTATCTCTGTCGCTCTTTTCAGCCCCTCCTGGTATTCCCCTCCTAACCTGGGTTTTTTACACGCCCGCGTGGCTTCCTGCTCGACCTCCCTGAGTCTGATCCTGGTTTC',\n",
       "       b'TAACGCGCGCTTTGGGAACAGGAAGGTTGAGAGAGAGGTGCTGGGGTCTGCGTCTATCTCTGTCGCTCTTTTCAGCCCCTCCTGGTATTCCCCTCCTAACCTGGGTTTTTTACACGCCCGCGTGGCTTCCTGCTCGACCTCCCTGAGTCTGATCCTGGTTTCCACCTCCAGCCCTGGGAAATTTCCTTTCTCCAGACTCGCCC',\n",
       "       b'GAGTCTGATCCTGGTTTCCACCTCCAGCCCTGGGAAATTTCCTTTCTCCAGACTCGCCCTCCCCACCCGGGCCTCGGACTTTCACCCCAGCTTCTCTCTCCTGGCCAGTGATTACCCACCCCCAATCCCACCCCGCCCCGCCGCGCAACTACCTCCTCCCTTCACCCGGACTGGGACCATCATCCCCACTCCACTCCGCCCAG',\n",
       "       b'CCCCCTCTACAGATTAGACCCTGGTCCTACACTCTTAGCCGCTGCCTGCTTTTGACCTTTGGCTCATGGGTACTTGACGTTTTAAACTCCTAGGCCCAGGATGAGGAGGAGCTTGGCTCCCAGCCAGCTGGCCAAGAGAAAACCTGAAGGCAGGTCCTGTGATGATGAAGACTGGCAACCTGGCCTAGTGACTCCTAGGAAAC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCGGAAGGGGTTCGCACGCCAAGAACCGCCATGCCTGGGGATCACCGCCGCATCCGCGGCCCTGAAGAATCGCAGCCGCCGCAGCTGTACGCGGCCGACGAGGAGGAGGCGCCCGGCACCCGCGACCCAACGC',\n",
       "       b'GGAGGTGGATGCAGCAGTAGTCCCCAGCGTGATGGCCTGCGGAGTGACTGGGAGTGTTTCCGTCGCTCTCCATCCCCTTGTCATTCTCAACATCTCAGACCACTGGATCCGCATGCGCTCCCAGGAGGGGCGGCCTGTGCAGGTGATTGGGGCTCTGATTGGCAAGCAGGAGGGCCGAAATATCGAGGTGATGAACTCCTTTG',\n",
       "       b'GATTGGCAAGCAGGAGGGCCGAAATATCGAGGTGATGAACTCCTTTGAGCTGCTGTCCCACACCGTGGAAGAGAAGATTATCATTGACAAGGAATATTATTACACCAAGGAGGAGCAGTTTAAACAGGTGTTCAAGGAGCTGGAGTTTCTGGGTTGGTATACCACAGGGGGGCCACCTGACCCCTCGGACATCCACGTCCATA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GAAGGGGGCGGGGCCGAGGCTGGCGGGCGCGGGGAAAATGGCGGCGGCGGCGGCGGCGGCTGCAGCTACGAACGGGACCGGAGGAAGCAGCGGGATGGAGGTGGATGCAGCAGTAGTCCCCAGCGTGATGGCCTGCGGAG',\n",
       "       b'CTTTGTCGCTAGCTCCCGGCCCTTCTGCCCCGCCGCCTTCCCTCAGTCAGCGTTGCCCACTCCTCTCCGGCCGGGCGCCCCTGCCTCCATTTCCCGCTCTCTGTCCACCACACACACGGCCCCCCCGATCATGGATCCGGGCAGTGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGGAGCAGCAGCGGCAGCAGCAGCAGCG',\n",
       "       b'AGTTGGCGGCGCCGCCAATAACCACGGAGCCGGCAGCGGCGCGGGAGGCCGTGCGGCACCTGTGGAATCCTCTCAAGAGGAACAGTCATTGTGTGAAGGTTCAAATTCAGCTGTTAGCATGGAACTTTCAGAACCTATTGTAGAAAATGGAGAGACAGAAATGTCTCCAGAAGAATCATGGGAGCACAAAGAAGAAATAAGTG',\n",
       "       b'TAACCACGGAGCCGGCAGCGGCGCGGGAGGCCGTGCGGCACCTGTGGAATCCTCTCAAGAGGAACAGTCATTGTGTGAAGGTTCAAATTCAGCTGTTAGCATGGAACTTTCAGAACCTATTGTAGAAAATGGAGAGACAGAAATGTCTCCAGAAGAATCATGGGAGCACAAAGAAGAAATAAGTGAAGCAGAGCCAGGGGGTG',\n",
       "       b'CGCCGCCTTCCCTCAGTCAGCGTTGCCCACTCCTCTCCGGCCGGGCGCCCCTGCCTCCATTTCCCGCTCTCTGTCCACCACACACACGGCCCCCCCGATCATGGATCCGGGCAGTGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGGAGCAGCAGCGGCAGCAGCAGCAGCGACTCGGCGCCTGACTGCTGGGACCAGGCGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGTGGGCGGGGCCACGCCGTGACGCATCCGTGCGTCTGTGGAAGGCTGCGTTTCCGGCCTGAGAAACCGTCATGTTTCTGGGGAGTCACCTCAGCTGGCAGTTACCACCGTGTTAGAAAGCAGCCTCAGGACCGGCCACCTCCATCACTGGCGTCACCATGGGGGCTGTGCTGG',\n",
       "       b'CTGAGAAACCGTCATGTTTCTGGGGAGTCACCTCAGCTGGCAGTTACCACCGTGTTAGAAAGCAGCCTCAGGACCGGCCACCTCCATCACTGGCGTCACCATGGGGGCTGTGCTGGGTGTCTTCTCCCTCGCCAGCTGGGTTCCATGCCTCTGCAGCGGTGCCTCATGTTTGCTGTGTAGTTGCTGTCCTAACAGTAAGAATT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CGCAGCGCCATGCGCAGACTCAGTTCCTGGAGAAAGATGGCGACAGCCGAGAAGCAGAAACACGACGGGCGGGTGAAGATCGGCCACTACATTCTGGGTGACACGCTGGGGGTCGGCACCTTCGGCAAAGTGAAGGTTG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CGCAGCGCCATGCGCAGACTCAGTTCCTGGAGAAAGATGGCGACAGCCGAGAAGCAGAAACACGACGGGCGGGTGAAGATCGGCCACTACATTCTGGGTGACACGCTGGGGG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCCGGGGCCGGGCCGGGCCGGGGGCGCGCGCTCTGCGAGCTGGATGTCCAGGCTGCGGGCGCTGCTGGGCCTCGGGCTGCTGGTTGCGGGCTCGCGCGTGCCGCGGATCAAAAGCCAGACCATCGCCTGTCGCTCGGGACCC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GCCGGGGCCGGGCCGGGCCGGGGGCGCGCGCTCTGCGAGCTGGATGTCCAGGCTGCGGGCGCTGCTGGGCCTCGGGCTGCTGGTTGCGGGCTCGCGCGTGCCGCGGATCAAAAGCCAGACCATCGCCTGTCGCTCGGGACCCACCT',\n",
       "       b'GGGCGCGCGCTCTGCGAGCTGGATGTCCAGGCTGCGGGCGCTGCTGGGCCTCGGGCTGCTGGTTGCGGGCTCGCGCGTGCCGCGGATCAAAAGCCAGACCATCGCCTGTCGCTCGGGACCCACCTGGTGGGGACCGCAGCGGCTGAACTCGGGTGGCCGCTGGGACTCAGAGGTCATGGCGAGCACGGTGGTGAAGTACCTGA',\n",
       "       b'GCCGCCCGCCGGCATGAGCTACGACCGCGCCATCACCGTCTTCTCGCCCGACGGCCACCTCTTCCAAGTGGAGTACGCGCAGGAGGCCGTCAAGAAGGGCTCGACCGCGGTTGGTGTTCGAGGAAGAGACATTGTTGTTCTTGGTGTGGAGAAGAAGTCAGTGGCCAAACTGCAGGATGAAAGAACAGTGCGGAAGATCTGTG',\n",
       "       b'GGCGCGGGCGTAGTGGCGCCGGGAGTCGCGGGTGCGCGCGGGCCGTGAGTGTGCGCTTTTGAGAGTCGCGGCGGAAGGAGCCCGGCCGCCGCCCGCCGGCATGAGCTACGACCGCGCCATCACCGTCTTCTCGCCCGACGGCCACCTCTTCCAAGTGGAGTACGCGCAGGAGGCCGTCAAGAAGGGCTCGACCGCGGTTGGTG',\n",
       "       b'TCGCCTTATCTGCTTCTGGCTCATTTTTACCACTGCTCTCCCCTTCCCCGGTCCCCCTGGTGTCCTTTCCACAGTTAAAGGCTACTTTCTCTTGAAGCACATGAGGAGAAGCCTTAGCAACCTCAATACCGAAGTTCTTCGCGCGCTCGCTCTTTCTGCCTCCGCCCGAACTATGCCTGAGTCCCTCACAGGAGTTGGATAGT',\n",
       "       b'TGGACTTCCGCCTCCCGGCCTCCGGAAGGCAGTGCGCACGCGCTCGCTGCGACTCCGGCGCGGTTGACTTCCGCTCCCACTGTGCTCTGCGAGCCGAATCATGGATCACACTGACAATGAGTTACAAGGCACTAATAGTTCTGGATCCTTGGGTGGTCTTGATGTTCGCAGACGAATTCCTATAAAGCTCATCTCCAAACAAG',\n",
       "       b'GAGCAGTTTCTGGCACATGGTAGAATTGGGCTATTTGCTGAAGCTTCTTGGTGGCCCTTGCTAGCCCAGGAAGAAACTTACATTTTGATTTTTTTGTACCATGGCTTTGGTTCACAAATTGCTGCGTGGTACTTATTTTCTCAGAAAATTCTCTAAGCCAACTTCTGCCTTGTATCCATTTTTGGGTATTCGCTTTGCAGAGT',\n",
       "       b'CAGGCGGTGGCGAAGAGACGCCGAGCGGGCCGAGTGCGGCCGAGCAAAGCCGGAGCCGGAGCGGGGCCGCAGGAGACGGGCCGGGTCCGGACGGGCCGAGATGCCCTATAAACTGAAAAAGGAGAAGGAGCCCCCCAAGGTTGCCAAATGCACAGCCAAGCCTAGCAGCTCGGGCAAGGATGGTGGAGGCGAGAACACTGAGG',\n",
       "       b'GGCGGGGTGGACACGCGTCCCGGCGCCCCGGGCTCCCTGGGATATGTAGTTCGCGACAGGACGAGCGGAAATACTGCCAGGATTTTACCACCTCTCGCCCATTTATTTACTTCTCGGTCACCGCTTTCGGGGGACAGATAAACACCACAGATGCCCATCAAAGGGGCGCACGGGTCTGGAGGCGCAGCTCAGGTTTTTGCGTT',\n",
       "       b'GCTTTTATAGCATGCTGTAAACAATTGTCAAAGTTGTTTATCAAGAAACAGATAGAGTTGCAACTTGTTTCTAGTAATAGAAACTTTTACACTGCATTCAATGCCTAACGTTGCAGAAACAGAAAGGTCAAATGATTCTGGAAATGGTGAGCACAAATCTGAGAGAAAGTCACCTGAAGAGAATCTACAAGGTGCTGTAAAAT',\n",
       "       b'GAAGTCGTATCTGTCCGGACGGAAGCAGGAAGCGGGAGCGTAGGGCCACGCCTGCGGCGCTGCTGGTTGAGGCTGTGTGGGTCGGGGACGGGCCGAGGCGATGGCGGAGAAGTTTGACCACCTAGAGGAGCACCTGGAGAAGTTCGTGGAGAACATTCGGCAGCTCGGCATCATCGTCAGTGACTTCCAGCCCAGCAGCCAGG',\n",
       "       b'GTGTCTGAGCGGCACAGACGAGATCTCGATCGAAGGCGAGATGGCGGACGTGCTAGATCTTCACGAGGCTGGGGGCGAAGATTTCGCCATGGATGAGGATGGGGACGAGAGCATTCACAAACTGAAAGAAAAAGCGAAGAAACGGAAGGGTCGCGGCTTTGGCTCCGAAGAGGGGTCCCGAGCGCGGATGCGTGAGGATTATG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCTCTGCGACAGTTTCCCGAGGTACCTAGTGTCTGAGCGGCACAGACGAGATCTCGATCGAAGGCGAGATGGCGGACGTGCTAGATCTTCACGAGGCTGGGGGCGAAGATTTCGCCATGGATGAGGATGGGGACGAGAGCATTCACAAACTGAAAGAAAAAGCGAAGAAAC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$CTCGCCGCCTCCGCCTCGGCGAATAGCAGCGCGCTGCCCGCCCGGATTGGAGCAGCAGCATCACGCTGACCTCTGCCTGGGATGTAAACCGGACCAGCCGCTGCGGGCAAAGGAAGGCTCTTGGCTCCTTCGGGAAACCCAGCCCCGTCACCGGGCTCCGAGCGGCTCGCAGGCGAGCGACAGC',\n",
       "       b'GAATAGCAGCGCGCTGCCCGCCCGGATTGGAGCAGCAGCATCACGCTGACCTCTGCCTGGGATGTAAACCGGACCAGCCGCTGCGGGCAAAGGAAGGCTCTTGGCTCCTTCGGGAAACCCAGCCCCGTCACCGGGCTCCGAGCGGCTCGCAGGCGAGCGACAGCGGCCTCAGCCCCGGCAGCGCCCAGCGGCGGCTGCGGAAA',\n",
       "       b'CCCAGCGGCGGCTGCGGAAAGCGGAGGGAGTCCGACGCGGGCGCGGGCGGGGAGCGTGCGTCCGTTCGCACAGGCAGCGGGAGGAGGGGCGGCGCGAACCATGGCCGGGGACAGCGAGCAGACCCTGCAGAACCACCAGCAGCCCAACGGCGGCGAGCCCTTCCTTATAGGCGTCAGCGGGGGAACAGCTAGCGGCAAGTCTT',\n",
       "       b'TTGAAGGAAGAGTACAAAATTTTCATCTCGCGAGACTTGTGAGCGGCCATCTTGGTCCTGCCCTGACAGATTCTCCTATCGGGGTCACAGGGACGCTAAGATTGCTACCTGGACTTTCGTTGACCATGCTGTCCCGGGTGGTACTTTCCGCCGCCGCCACAGCGGCCCCCTCTCTGAAGAATGCAGCCTTCCTAGGTCCAGGG',\n",
       "       b'TCTCGCGAGACTTGTGAGCGGCCATCTTGGTCCTGCCCTGACAGATTCTCCTATCGGGGTCACAGGGACGCTAAGATTGCTACCTGGACTTTCGTTGACCATGCTGTCCCGGGTGGTACTTTCCGCCGCCGCCACAGCGGCCCCCTCTCTGAAGAATGCAGCCTTCCTAGGTCCAGGGGTATTGCAGGCAACAAGGACCTTTC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGTCAGCGTCGCTGCCGGTCTCCGGCGGAGACGGACTCTGGAGTTTGGGCGGCCCGGGCGGCCACTAGGTACTCTGATATTCCGTACTAAACACGTCTGCAAGTCAAGATGTCGCACCCGTCCCCCCAAGCCA',\n",
       "       b'$$$$$$$$GGTCAGCGTCGCTGCCGGTCTCCGGCGGAGACGGACTCTGGAGTTTGGGCGGCCCGGGCGGCCACTAGGTACTCTGATATTCCGTACTAAACACGTCTGCAAGTCAAGATGTCGCACCCGTCCCCCCAAGCCAAGCCCTCCAACCCCAGTAACCCTCGAGTCTTCTTTGACGTGGACATCGGAGGGGAGCGAGTT',\n",
       "       b'TCGCTGCCGGTCTCCGGCGGAGACGGACTCTGGAGTTTGGGCGGCCCGGGCGGCCACTAGGTACTCTGATATTCCGTACTAAACACGTCTGCAAGTCAAGATGTCGCACCCGTCCCCCCAAGCCAAGCCCTCCAACCCCAGTAACCCTCGAGTCTTCTTTGACGTGGACATCGGAGGGGAGCGAGTTGGTCGAATTGTCTTAG',\n",
       "       b'TGCATCAGCTGGTCCAGCCGAGGCCAAGTCCCGGGCGCTAGCCCACCTCCCACCCGCCTCTTGGCTCCTCTCCTCTAGGCCGTCGCTTTCGGGTTCTCTCATCGCTTCGTCGTTCGCCAATGTTTGAGGAGAAGGCCAGCAGTCCTTCAGGGAAGATGGGAGGCGAGGAGAAGCCGATTGGTGCTGGTGAAGAGAAGCAAAAG',\n",
       "       b'GAGGCCAAGTCCCGGGCGCTAGCCCACCTCCCACCCGCCTCTTGGCTCCTCTCCTCTAGGCCGTCGCTTTCGGGTTCTCTCATCGCTTCGTCGTTCGCCAATGTTTGAGGAGAAGGCCAGCAGTCCTTCAGGGAAGATGGGAGGCGAGGAGAAGCCGATTGGTGCTGGTGAAGAGAAGCAAAAGGAAGGAGGCAAAAAGAAGA',\n",
       "       b'ACACGGCCTTCGGCACTGTAGCTTTGGGTGGTGGGCTGCAGATTAATTTTGTAACCACCTTAAGAAAAATACGGAACTCTAACTCCTTGCCACTCAAGAAATGTCCTCCCTTTCAGAATATGCCTTCCGCATGTCTCGTCTCAGTGCCCGGCTATTTGGTGAAGTCACCAGGCCTACTAATTCCAAGTCTATGAAAGTGGTGA',\n",
       "       b'AGCTTTGGGTGGTGGGCTGCAGATTAATTTTGTAACCACCTTAAGAAAAATACGGAACTCTAACTCCTTGCCACTCAAGAAATGTCCTCCCTTTCAGAATATGCCTTCCGCATGTCTCGTCTCAGTGCCCGGCTATTTGGTGAAGTCACCAGGCCTACTAATTCCAAGTCTATGAAAGTGGTGAAACTGTTTAGTGAACTGCC',\n",
       "       b'TAGCAGAGAAGACAAGTGGCTGCTACCTTCTGTTATCGTGGGTGGCAGTGACTAGTTTTTCTAGATCTTGACTCCCTGCCGTAACTAAAGATGGAGTACACTGATGCTGAAGTACTATGAGCCTTCGGAACTTGTGGAGAGACTACAAAGTTTTGGTTGTTATGGTCCCTTTAGTTGGGCTCATACATTTGGGGTGGTACAGA',\n",
       "       b'TAAAGAATAATTTTTAATGTTAAAACGTGATAATGCAATAAATAGAAAAATGTGGTTTACAAAATAAAAACGGTCTTCACTAGTTACCACCTGAAGTAAGATGTCTCGTTTGGAAGCTAAGAAGCCATCATTGTGTAAGAGTGAACCACTGACAACTGAGAGAGTCAGGACCACACTTTCTGTCTTGAAAAGAATTGTAACAT',\n",
       "       b'GCGCGGACCGCGCACAGGCGGCGGAGCCGGTATGGGCCCGCCTGACCCTGGGCGCCGCGCCGCACGAGCACCAGCCTAGAGCCAGGACTGAAGCTTCAAGATGGCTGACCAGGACCCTGCGGGCATCAGCCCCCTCCAGCAAATGGTGGCCTCAGGCACCGGGGCTGTGGTTACCTCTCTCTTCATGACACCCCTGGACGTGG',\n",
       "       b'TACGGATTCAGTTCCAGTTTAATGATGTGGCCCTCTAAGGAGATAATTTTGCCTTAAACAGAAAGACTTGACCCTCTTAGGTGTCATACCTAAGATCAGTGTGTTTTTTGTGTCCAATTCTTTTATCACCAAAAAAGAGAAGAAATATTGCAGTGAATGAAGATTCCTCTGCATTTTAGCACTGCTTTTTCAACTGTAGTTGG',\n",
       "       b'TGTCCAATTCTTTTATCACCAAAAAAGAGAAGAAATATTGCAGTGAATGAAGATTCCTCTGCATTTTAGCACTGCTTTTTCAACTGTAGTTGGCTTTTGAATGAGGATGACAATGGAAGAGATGAAGAATGAAGCTGAGACCACATCCATGGTTTCTATGCCCCTCTATGCAGTCATGTATCCTGTGTTTAATGAGCTAGAAC',\n",
       "       b'GCGGCAGCGTGACGCCCTCAAGTTTTGGCGGGAAAAGCGCTGCATTTGGATTCCTGCAGTGGTGGGCAAAGGACAGTCCGCCGAGGTGCTCGGTGGAGTCATGGCAGTGCCCTTTGTGGAAGACTGGGACTTGGTGCAAACCCTGGGAGAAGGTGCCTATGGAGAAGTTCAACTTGCTGTGAATAGAGTAACTGAAGAAGCAG',\n",
       "       b'TGTAGTAAAATTCTATGGTCACAGGAGAGAAGGCAATATCCAATATTTATTTCTGGAGTACTGTAGTGGAGGAGAGCTTTTTGACAGAATAGAGCCAGACATAGGCATGCCTGAACCAGATGCTCAGAGATTCTTCCATCAACTCATGGCAGGGGTGGTTTATCTGCATGGTATTGGAATAACTCACAGGGATATTAAACCAG',\n",
       "       b'$$$$$$$$$$$$$$$$$GTCACTTCCTCTCCAGCCCCTGCGTAATCGATAAGGAAACCCGGACGCTGCTGCCCCTTTCTTTTTTTCAGGCGGCCGGGAAGATGGCGGACATTCAGACTGAGCGTGCCTACCAAAAGCAGCCGACCATCTTTCAAAACAAGAAGAGGGTCCTGCTGGGAGAAACTGGCAAGGAGAAGCTCCCGC',\n",
       "       b'TTCCTCTCCAGCCCCTGCGTAATCGATAAGGAAACCCGGACGCTGCTGCCCCTTTCTTTTTTTCAGGCGGCCGGGAAGATGGCGGACATTCAGACTGAGCGTGCCTACCAAAAGCAGCCGACCATCTTTCAAAACAAGAAGAGGGTCCTGCTGGGAGAAACTGGCAAGGAGAAGCTCCCGCGGTACTACAAGAACATCGGTCT',\n",
       "       b'CTGCTTCGGCGGCAACATCGAGCTCTTCGTCTTCTTCAACGGCGCGCTCGAGAAGGCCCGGCTGCACGAGTGGGTCAAGCGGCAGGGCAACGAGCGCCAGACGGCACAGCAGATCGTCAGCCATGTCCAGAACAAGGGCACCCCGCCGCCAAAGGTCTGGTTCCTGCCGCCCGTCTGCATGGCCCACTGCATCCGCCTGGCGC',\n",
       "       b'GAGCATTGAGGATCACCATCAGGAAGTGATTGGTTTCTGCAGAGAGAATGGTTTCCATGGCTTGGTTGCGTATGACTCTGATTATGCACTGTGCAACATCCCCTACTATTTCAGTGCCCATGCCCTAAAACTGAGCCGGAACGGGAAAAGTCTCACCACAAGCCAATATCTGATGCATGAAGTTGCCAAGCAACTGGACCTGA',\n",
       "       b'CCGCCGCCCCCGCCCGCCAGCCCGCCCGCGCGCCACGGCCCCACCACCCCCGGCCCCGCCGCCCCCCGCCCGCACCCGCGCCCGCGCCCCCGCCGCCGCCATGGGCGTGCAGGGCTTCCAGGACTACATCGAGAAGCACTGCCCGAGCGCCGTGGTGCCGGTGGAGCTGCAGAAGCTGGCCCGGGGCAGCCTGGTGGGCGGCG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ACTCTCGCGAGATCCCTACTGGCTATAAAGGCAGCGCCCCGGAGAGCTCTTGCGCGTCTTGTTCTTGCCTGGTGTCGGTGGTTAGTTTCTGCGACTTGTGTTGGGACTGGTGAGTGTGGGCAGTGCGGCCCCTGCGGAGTGAGGCGCGGCGCGCCCTTCTTGCCTGTTGCCTCT',\n",
       "       b'ACTCTCGCGAGATCCCTACTGGCTATAAAGGCAGCGCCCCGGAGAGCTCTTGCGCGTCTTGTTCTTGCCTGGTGTCGGTGGTTAGTTTCTGCGACTTGTGTTGGGACTGGTGAGTGTGGGCAGTGCGGCCCCTGCGGAGTGAGGCGCGGCGCGCCCTTCTTGCCTGTTGCCTCTTCCTCCTCCTGTCCGGGGCCCGCCCGCGC',\n",
       "       b'GAGGCCCGGAGTCCGAGACTGCTTGAGCGCTGCGCACACCCCTCTCGTGGGCCCCCCACGTAGGTGCGGGAACCTGGTTGAACCCCAAGCTGATAGGAAGATGTCTTCAGGAAATGCTAAAATTGGGCACCCTGCCCCCAACTTCAAAGCCACAGCTGTTATGCCAGATGGTCAGTTTAAAGATATCAGCCTGTCTGACTACA',\n",
       "       b'TTGAGCGCTGCGCACACCCCTCTCGTGGGCCCCCCACGTAGGTGCGGGAACCTGGTTGAACCCCAAGCTGATAGGAAGATGTCTTCAGGAAATGCTAAAATTGGGCACCCTGCCCCCAACTTCAAAGCCACAGCTGTTATGCCAGATGGTCAGTTTAAAGATATCAGCCTGTCTGACTACAAAGGAAAATATGTTGTGTTCTT',\n",
       "       b'TGGGCACCCTGCCCCCAACTTCAAAGCCACAGCTGTTATGCCAGATGGTCAGTTTAAAGATATCAGCCTGTCTGACTACAAAGGAAAATATGTTGTGTTCTTCTTTTACCCTCTTGACTTCACCTTTGTGTGCCCCACGGAGATCATTGCTTTCAGTGATAGGGCAGAAGAATTTAAGAAACTCAACTGCCAAGTGATTGGTG',\n",
       "       b'CCCTGCCCCCAACTTCAAAGCCACAGCTGTTATGCCAGATGGTCAGTTTAAAGATATCAGCCTGTCTGACTACAAAGGAAAATATGTTGTGTTCTTCTTTTACCCTCTTGACTTCACCTTTGTGTGCCCCACGGAGATCATTGCTTTCAGTGATAGGGCAGAAGAATTTAAGAAACTCAACTGCCAAGTGATTGGTGCTTCTG',\n",
       "       b'GTGACCCTCCCCCAGGAATGTGGTGACGTCATCGGAGGCGTGGTCGTCCCCAAAATTAGGGAGGAAGAGGAAAAAAAAAAGCCAGAAAAAGTTTTCTTTTCTGGAGTCCCAAACGAGGTGCGGGACGGAAGAGGGGGTGAAGGCCAGAGGCTCGGGGCTTCAAGACCGCTGTCTGGAGTCCCCCTTTCCAGGCCATGTCGGGG',\n",
       "       b'TCTTTTCTGGAGTCCCAAACGAGGTGCGGGACGGAAGAGGGGGTGAAGGCCAGAGGCTCGGGGCTTCAAGACCGCTGTCTGGAGTCCCCCTTTCCAGGCCATGTCGGGGCCCACCTGGCTGCCCCCGAAGCAGCCGGAGCCCGCCAGAGCCCCTCAGGGGAGGGCGATCCCCCGCGGCACCCCGGGGCCACCACCGGCCCACG',\n",
       "       b'CCCGGGGCCTCCCACACCAGTGCCTGAGCAGGAATGGGGAGGGGCCATGATTCACAAGGCCCTGGGAGGTCACTTTAAAGAGGGCTGCTCAACTGCAAGGACGCTGTAAGCAGGAAGAGAAGCCACAGCGCTTCAGAAAAGAGTGGGACAGGGACAAGCATATCTAAGAGGCTGAACATGAATCCACAGATCAGAAACCCGAT',\n",
       "       b'GGGGCCTCCCACACCAGTGCCTGAGCAGGAATGGGGAGGGGCCATGATTCACAAGGCCCTGGGAGGTCACTTTAAAGAGGGCTGCTCAACTGCAAGGACGCTGTAAGCAGGAAGAGAAGCCACAGCGCTTCAGAAAAGAGTGGGACAGGGACAAGCATATCTAAGAGGCTGAACATGAATCCACAGATCAGAAACCCGATGAA',\n",
       "       b'AAGAGGGCTGCTCAACTGCAAGGACGCTGTAAGCAGGAAGAGAAGCCACAGCGCTTCAGAAAAGAGTGGGACAGGGACAAGCATATCTAAGAGGCTGAACATGAATCCACAGATCAGAAACCCGATGAAGGCAATGTATCCAGGCACATTCTACTTCCAATTTAAAAACCTATGGGAAGCCAACGATCGGAACGAAACTTGGC',\n",
       "       b'AGCCGGGGACTCTGCGCCTGCGCCCGCCTGGCCGCCGCCCGCTCTCCCGGCGCGGCAGCTGTCTGGGCTGCTGCGCGCCGCCTAGGTGTCTGGGCGATCTATGGGCAAGAGCAAGGGCCACGATGACAGATTACGGCGAGGAGCAGCGCAACGAGCTGGAGGCCCTGGAGTCCATCTACCCTGACTCCTTCACAGTATTATCA',\n",
       "       b'CCGCCCGCTCTCCCGGCGCGGCAGCTGTCTGGGCTGCTGCGCGCCGCCTAGGTGTCTGGGCGATCTATGGGCAAGAGCAAGGGCCACGATGACAGATTACGGCGAGGAGCAGCGCAACGAGCTGGAGGCCCTGGAGTCCATCTACCCTGACTCCTTCACAGTATTATCAGAAAATCCACCCAGCTTCACCATTACTGTGACGT',\n",
       "       b'CCCGCCTGGCCGCCGCCCGCTCTCCCGGCGCGGCAGCTGTCTGGGCTGCTGCGCGCCGCCTAGGTGTCTGGGCGATCTATGGGCAAGAGCAAGGGCCACGATGACAGATTACGGCGAGGAGCAGCGCAACGAGCTGGAGGCCCTGGAGTCCATCTACCCTGACTCCTTCACAGTATTATCAGAAAATCCACCCAGCTTCACCA',\n",
       "       b'CGGGGGCCGGGCTCGCGGAGGCCCGTCGGTTCGGTCCGCTCTGGGCGTTAGCAAGTGATCTCCAGCCAAGGCGGCCGCCACCCCTTGCACACAGCAGAAAATGCAAAATGACCCTCTGGGGCAGTGAGGGGCTGTGGCCCTCGGCCCCGGCCTGCCGCACCCCCTTCCCGCAGCTGGCGGCCGGCAGCGCCGAACAGGGTCCG',\n",
       "       b'TCCGCTGAGGCGCCGGCCTGAACTGGGCGCGGGAACCAGGCCGCCCTCGGCGCCCAGCCTGCCCTAGTCCCGCGCGCCGCCCCCGCTGTGCCGCGCCCACATGGGTCTGTGCTACAGTCTGCGGCCGCTGCTTTTCGGGGGCCCAGGGGACGACCCCTGCGCGGCCTCGGAGCCGCCGGTGGAGGACGCGCAGCCCGCCCCGG',\n",
       "       b'TGTGCGGTTGGCTGGAGCCAGACCCCACCCCGGCCTCGGCCCATGCTCTAGAGGGGACGTTGCCCCAATCCTGAAGGACTTCGGCACTCGAGACCTGTGGATGCCGCGTTGCTGTGGCCTGCGGGGGTGATCATGAAGCCAGGTGCTACTGGCGAGTCCGATTTGGCCGAAGTGCTGCCCCAGCACAAGTTCGACAGCAAGTC',\n",
       "       b'GCCTCGGCCCATGCTCTAGAGGGGACGTTGCCCCAATCCTGAAGGACTTCGGCACTCGAGACCTGTGGATGCCGCGTTGCTGTGGCCTGCGGGGGTGATCATGAAGCCAGGTGCTACTGGCGAGTCCGATTTGGCCGAAGTGCTGCCCCAGCACAAGTTCGACAGCAAGTCCCTGGAGGCCTACCTAAACCAGCACTTGTCTG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CACGCGGGGCCCAGCTGGACTGCCGCGGGGGATTCTGGGCCAAGATGGCAGCAATGAGGAAGGCGCTTCCGCGGCGACTGGTGGGCTTGGCGTCCCTCCGGGCTGTCAGCACCTCATCTATGGGCACTTTACCAAAGCGGGTGAAAA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGAACAAGCGTCGCGTTTCTGAGGAGAAACTCTTGGTGAGAATTCCCAGAGTGATAATGGCTACCTACAGCCTGGCGAACGAGAGACTACGCGCTCTGGAAGACATTGAACGGGAAATCGGCGCCATCCTTCAGAATGCAGGTACTGTGATCCTAGAAT',\n",
       "       b'$$$$$$GGCGAGGCGCCTGTTGATTGGCCACTGGGGCCCGGGTTCCTCCGGCGGAGCGCGCCTCCCCCCAGATTTCCCGCCAGCAGGAGCCGCGCGGTAGATGCGGTGCTTTTAGGAGCTCCGTCCGACAGAACGGTTGGGCCTTGCCGGCTGTCGGTATGTCGCGACAGAGCACCCTGTACAGCTTCTTCCCCAAGTCTCCG',\n",
       "       b'CGCCTCCCCCCAGATTTCCCGCCAGCAGGAGCCGCGCGGTAGATGCGGTGCTTTTAGGAGCTCCGTCCGACAGAACGGTTGGGCCTTGCCGGCTGTCGGTATGTCGCGACAGAGCACCCTGTACAGCTTCTTCCCCAAGTCTCCGGCGCTGAGTGATGCCAACAAGGCCTCGGCCAGGGCCTCACGCGAAGGCGGCCGTGCCG',\n",
       "       b'CCTTGGCGCGCTCCGCGTCACCGCCCAAGGCGAAGAACCTCAACGGAGGGCTGCGGAGATCGGTAGCGCCTGCTGCCCCCACCAGTTGTGACTTCTCACCAGGAGATTTGGTTTGGGCCAAGATGGAGGGTTACCCCTGGTGGCCTTGTCTGGTTTACAACCACCCCTTTGATGGAACATTCATCCGCGAGAAAGGGAAATCA',\n",
       "       b'ATACTGAGAGCAATGCAACGTGCAGATGAAGCCTTAAATAAAGACAAGATTAAGAGGCTTGAATTGGCAGTTTGTGATGAGCCCTCAGAGCCAGAAGAGGAAGAAGAGATGGAGGTAGGCACAACTTACGTAACAGATAAGAGTGAAGAAGATAATGAAATTGAGAGTGAAGAGGAAGTACAGCCTAAGACACAAGGATCTAG',\n",
       "       b'GGTTGCGGGGGCCGCAGAGCCGGACGAAGACGGAGGGCGGAGCCGGCTTCGGGACTGCGGAGACTACACACCGAGCGAGCGCCTGGGCCCGAAGGGAGCGATGCTGTGGTTCCAGGGCGCCATTCCGGCCGCCATCGCGACGGCCAAAAGGAGCGGCGCGGTCTTCGTGGTGTTCGTGGCAGGTGATGATGAACAGTCTACAC',\n",
       "       b'TGAAGGGGAGAGTGAGGTGATGGCTGCGTTTAAGTTGGATTTCCTTCCAGAAATGATGGTGGATCATTGCTCTTTGAATTCCAGTCCCGTCTCAAAGAAAATGAACGGCACCCTGGACCACCCAGACCAACCAGATCTTGATGCTATCAAGATGTTTGTGGGCCAGGTTCCAAGGACCTGGTCTGAAAAGGACTTGCGGGAAC',\n",
       "       b'GTGAAGTGAAATCTTTGAGGAAGCTAAAGCTGTGTGTATTTGTGGATCAGACAAGTGCAGCAAGTTAATATCATTGGCTTCTGAAGGGGAGAGTGAGGTGATGGCTGCGTTTAAGTTGGATTTCCTTCCAGAAATGATGGTGGATCATTGCTCTTTGAATTCCAGTCCCGTCTCAAAGAAAATGAACGGCACCCTGGACCACC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TTAGCCGCGGTGCAGACTGCGGCGGCGGTGGTCTGAGGAAGTTCTATCTTGGCGCTAAAGCGGAGACGCATCCCCCGACCCGAGGCTACGATGAGCACACCGGCCGTGCCCCAGGACCTGCAGCTGCCCCCGAGTCAGAGGGCGCAGTCCG',\n",
       "       b'$$$$$$$$$$TTAGCCGCGGTGCAGACTGCGGCGGCGGTGGTCTGAGGAAGTTCTATCTTGGCGCTAAAGCGGAGACGCATCCCCCGACCCGAGGCTACGATGAGCACACCGGCCGTGCCCCAGGACCTGCAGCTGCCCCCGAGTCAGAGGGCGCAGTCCGCATTCAAAGAGCAAAGAAGACAAAAACTCAAGGAACATCTGT',\n",
       "       b'CCGAGTCAGAGGGCGCAGTCCGCATTCAAAGAGCAAAGAAGACAAAAACTCAAGGAACATCTGTTGAGAAGAAAAACGCTTTTTGCATACAAGCAGGAAAATGAGATGTTATCCAGTAGTAGAGATCAGAGAGTTGTGACATCTGAGGACCAAGTTCAAGAAGGGACTAAAGTGCTGAAACTTAAAACAAAAATGGCTGATAA',\n",
       "       b'ATTTAGAATCCGGAAGGAAAAGGAAATGAAATGTGAAGAAACTCATGCACCAAACTCGAACTGGGTATATGTGATGTTACCTAGTAAGAAGACTGTTAGAATGCCCTCGGTAACACAGAGGCTGAGAGATCCTGACATAAATCCTTGTTTGTCGGAATCTGATGCTTCCACCAGATGTCTGGATGAAAATAACTATGACAGGG',\n",
       "       b'GGAGGCCGGAGTTAATACACGAGGAACTCATGCAAAGGAGGGGACTTTCGGAAATCCAAACTTAGAGTGCCTTGTATTTAGAATCCGGAAGGAAAAGGAAATGAAATGTGAAGAAACTCATGCACCAAACTCGAACTGGGTATATGTGATGTTACCTAGTAAGAAGACTGTTAGAATGCCCTCGGTAACACAGAGGCTGAGAG',\n",
       "       b'AGCCCTGAGCAGCCCCACCGCCGCCGCCGGCCTAGTTACCATCACACCCCGGGAGGAGCCGCAGCTGCCGCAGCCGGCCCCAGTCACCATCACCGCAACCATGAGCAGCGAGGCCGAGACCCAGCAGCCGCCCGCCGCCCCCCCCGCCGCCCCCGCCCTCAGCGCCGCCGACACCAAGCCCGGCACTACGGGCAGCGGCGCAG',\n",
       "       b'TTTGGGAACAGTAAAATGGTTCAATGTAAGGAACGGATATGGTTTCATCAACAGGAATGACACCAAGGAAGATGTATTTGTACACCAGACTGCCATAAAGAAGAATAACCCCAGGAAGTACCTTCGCAGTGTAGGAGATGGAGAGACTGTGGAGTTTGATGTTGTTGAAGGAGAAAAGGGTGCGGAGGCAGCAAATGTTACAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$TGGGAGGGGCGCGCTGGGGAGCTTCGGCGCATGCGCGCTGAGGCCTGCCTGACCGACCTTCAGCAGGGCTGTGGCTACCATGTTCTCTCGCGCGGGTGTCGCTGGGCTGTCGGCCTGGACCTTGCAGCCGCAATGGATTCAAGTTCGAAATATGGCAACTTTGAAAGATAT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$TGGGAGGGGCGCGCTGGGGAGCTTCGGCGCATGCGCGCTGAGGCCTGCCTGACCGACCTTCAGCAGGGCTGTGGCTACCATGTTCTCTCGCGCGGGTGTCGCTGGGCTGTCGGCCTGGACCTTGCAGCCGCAATGGATTCAAGTTCGAAATATGGCAACTTTGAAAGATATCACCAGGAGAC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CATGCTGTTCTGACAGTTTGAGATTACTTATTGTCTTTTCTGGGAAGACAAAAACATGTCGGAGACTGCTCCACTTGCTCCTACCATTCCTGCACCCGCAGAAAAAACACCTGTGAAGAAAAAGGCGAAGAAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CATGCTGTTCTGACAGTTTGAGATTACTTATTGTCTTTTCTGGGAAGACAAAAACATGTCGGAGACTGCTCCACTTGCTCCTACCATTCCTGCACCCGCAGAAAAAACACCTGTGAAGAAAAAGGCGAAGAAGGCAGGCGCAACTGCTGGGAAACGCA',\n",
       "       b'GCCCCGGGAGGGCTGTTCGGGCCAGCGCCCGCCGGCTGCTCCGCGCTGACAGCGCCGGGCTGGGGCGGGGCGGGGGGCTTTGCAGGCCGCCAGTGTCGACATGCTGCTGGAGGAGGTTCGCGCCGGCGACCGGCTGAGTGGGGCGGCGGCCCGGGGCGACGTGCAGGAGGTGCGCCGCCTTCTGCACCGGGAGCTGGTGCATC',\n",
       "       b'GGATGCCCTGGTGAGGATGCGGGATCTTTCTTCCTCAGAGAAGCAGGAGCATGTGAAGCTCCAGAAGCTCATGGAAAAGAAGAACCAAGAGCTGGAAGTTGTGAGGCAACAGCGGGAGCGTCTGCAGGAGGAGCTAAGCCAGGCAGAGAGCACCATTGATGAGCTCAAGGAGCAGGTGGATGCTGCTCTGGGTGCTGAGGAGA',\n",
       "       b'CTCTATGAGGGCCCAGCGCCCTGACCCTCCTGCCTAGGTTTCTACCTTTTCTCTCTGTCTTTGGCCAGCTGGGGGAGGGGGTAGAGGCCGGGTGAGCAACATGGCACAGAGCAAGAGGCACGTGTACAGCCGGACGCCCAGCGGCAGCAGGATGAGTGCGGAGGCAAGCGCCCGGCCTCTGCGGGTGGGCTCCCGTGTAGAGG',\n",
       "       b'TAAGGCCAGAGAGATCTTGGTAGAGGAGAGCAACGTGCAGAGGGTGGACTCGCCAGTCACAGTGTGCGGCGACATCCATGGACAATTCTATGACCTCAAAGAGCTGTTCAGAGTAGGTGGCGACGTCCCTGAGACCAACTACCTCTTCATGGGGGACTTTGTGGACCGTGGCTTCTATAGCGTCGAAACGTTCCTCCTGCTGC',\n",
       "       b'CTCGCCAGTCACAGTGTGCGGCGACATCCATGGACAATTCTATGACCTCAAAGAGCTGTTCAGAGTAGGTGGCGACGTCCCTGAGACCAACTACCTCTTCATGGGGGACTTTGTGGACCGTGGCTTCTATAGCGTCGAAACGTTCCTCCTGCTGCTGGCACTTAAGGTTCGCTATCCTGATCGCATCACACTGATCCGGGGCA',\n",
       "       b'CGACATCCATGGACAATTCTATGACCTCAAAGAGCTGTTCAGAGTAGGTGGCGACGTCCCTGAGACCAACTACCTCTTCATGGGGGACTTTGTGGACCGTGGCTTCTATAGCGTCGAAACGTTCCTCCTGCTGCTGGCACTTAAGGTTCGCTATCCTGATCGCATCACACTGATCCGGGGCAACCATGAGAGTCGCCAGATCA',\n",
       "       b'AGGGAGCCGGAGAGCCGGAACCGGAGTCGCAGCGGCGGAGACCCCTGTGCGGTGCGGAGGGGGCGGCGGCCCCGACTCTGACCCGCGCCGGGGGTGGGCCATGGCGGAGATCAGCGACCTGGACCGGCAGATCGAGCAGCTGCGTCGCTGCGAGCTCATCAAGGAGAGCGAAGTCAAGGCCCTGTGCGCTAAGGCCAGAGAGA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GGCCTCAACATGGCGGTTCCGGCCGGGCAGTGACCAAGGTTTTGCCGTCCGAAGGACTAAGTGGTGACTGTCGGCGTCTCCACCTATCGGGGTGGAATGCGAGCACGCGGGG',\n",
       "       b'TGCGAGCACGCGGGGACGAGCGCTGAGAAGCGGCGGTGACGGGAAGGGGGGGGTCAGTGGATTGTGCCCCAGAAACCGAAGCGGCGGCGTCTGTTCCTTCTTGTTTCTAGGCTCCAGTGCGTTCGGGGCCCCGCCCGGCCGGGCCAGGCCGGCGGGCGGCGGCGGTAGCTGCTGCAGCCGCAGGATAACCTCGCAGGGTGGGC',\n",
       "       b'CGGGCCAGGCCGGCGGGCGGCGGCGGTAGCTGCTGCAGCCGCAGGATAACCTCGCAGGGTGGGCCGGAGGGCGGGCGCCGCCGCTGCCTGTGCTGCGGCGATGGCCCAGTGTGTACAATCAGTGCAGGAGCTAATCCCGGACTCCTTCGTCCCCTGTGTCGCTGCGCTGTGCAGCGACGAAGCCGAGCGGCTCACTCGTCTCA',\n",
       "       b'CCCGTAGGGAGCCGTGGGCGCTCGGTGCCCGGGCCGGGCAGGACAGAATAATAAGCTGAATAGAATCTGACCATTGGCTTTCACCTGGCCAGGACCTTCTATGTAGCTCTCCTTTTGTGGCCCATGTGCTGCATCCTCTGCCCTCAGTGTGCAACTGGCCCCCAACGCAATGTGTGTTTGTCAAACCATGGAAGTGGGGCAGT',\n",
       "       b'ACCATTGGCTTTCACCTGGCCAGGACCTTCTATGTAGCTCTCCTTTTGTGGCCCATGTGCTGCATCCTCTGCCCTCAGTGTGCAACTGGCCCCCAACGCAATGTGTGTTTGTCAAACCATGGAAGTGGGGCAGTATGGCAAGAATGCAAGTCGGGCTGGAGACCGGGGAGTCCTCCTGGAGCCCTTCATCCACCAAGTAGGCG',\n",
       "       b'GGTCTGTGTTTTGGCAGTTGCCGCGACAACAGTCACTTCCGGGAAGGGGCTCTGCGAATCTCCTTCCGTCGGTCCGCTCAGAATCAGCTGTCCTCTCAGACTGTGTGGGTGGTTTCCCCGGCCGCAGCTCCGTACGGGCTTGGATTGCTGGGCCTCGGTGCACCCCAGCCTCCCCCACTCGGGTTCTGAGCTTGAGCTGGCGG',\n",
       "       b'CAGACTGTGTGGGTGGTTTCCCCGGCCGCAGCTCCGTACGGGCTTGGATTGCTGGGCCTCGGTGCACCCCAGCCTCCCCCACTCGGGTTCTGAGCTTGAGCTGGCGGCTCTTTAACTCTGCTTCACTGTTGCTCTTGGCAACATCCACTTCCGGGAGCGAGTGCCGTTTCCCCCGCTCACCGCGGGCTAGGGAGCGTGGGATT',\n",
       "       b'GCGTCGCAGCTGCTGGCGATCCGGCGACCCTCGGCCGGCAGGACCCGCGGGCCACGCAGCCGGGGCCTTCTCAACGCCTCAGTACCTCGGCGGGACCGCCATGGTTCTGCTGCACGTGAAGCGGGGCGACGAGAGCCAGTTCCTGCTGCAGGCGCCTGGGAGTACCGAGCTGGAGGAGCTCACGGTGCAGGTGGCCCGGGTCT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CGGGAAGACTGCATCCGGCTCCAGGAAAAGCGAGTGGGATATCCCAATCTTTGGACTGCATCCTGGTTGCCTCTACTGTGGTCACCTTTGGGAAGAAATGTCTTCTGTAAAAAGAAGTCTGAAGCAAGAAATAGTTACTCAGTTTCACTGTTCAGCTGCTGAAGG',\n",
       "       b'$$$CGGGAAGACTGCATCCGGCTCCAGGAAAAGCGAGTGGGATATCCCAATCTTTGGACTGCATCCTGGTTGCCTCTACTGTGGTCACCTTTGGGAAGAAATGTCTTCTGTAAAAAGAAGTCTGAAGCAAGAAATAGTTACTCAGTTTCACTGTTCAGCTGCTGAAGGAGATATTGCCAAGTTAACAGGAATACTCAGTCATT',\n",
       "       b'ACGGCTCCCGGGCCCGCCCTCCTCTGACCCCTCCCCTCTCTCCGTTTCCCCCTCTCCCCCTCCTCCGCCGACCGAGCAGTGACTTAAGCAACGGAGCGCGGTGAAGCTCATTTTTCTCCTTCCTCGCAGCCGCGCCAGGGAGCTCGCGGCGCGCGGCCCCTGTCCTCCGGCCCGAGATGAATCCTGCGGCAGAAGCCGAGTTC',\n",
       "       b'CAGTGACTTAAGCAACGGAGCGCGGTGAAGCTCATTTTTCTCCTTCCTCGCAGCCGCGCCAGGGAGCTCGCGGCGCGCGGCCCCTGTCCTCCGGCCCGAGATGAATCCTGCGGCAGAAGCCGAGTTCAACATCCTCCTGGCCACCGACTCCTACAAGGTTACTCACTATAAACAATATCCACCCAACACAAGCAAAGTTTATT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GTAAGTAAGCCTGCCAGACACACTGTGACGGCTGCCTGAAGCTAGTGAGTCGCGGCGCCGCGCACTGGTGGTTGGGTCAGTGCCGCGCGCCGATCGGTCGTTACCGCGAGGCGCTGGTGGCCTTC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GTAAGTAAGCCTGCCAGACACACTGTGACGGCTGCCTGAAGCTAGTGAGTCGCGGCGCCGCGCACTGGTGGTTGGGTCAGTGCCGCGCGCCGATCGGTCGTTACCGCGAGGCGCTGGTGGCCTTCAG',\n",
       "       b'GCGCGCCGATCGGTCGTTACCGCGAGGCGCTGGTGGCCTTCAGGCTGGACGGCGCGGGTCAGCCCTGGTTCGCCGGCTTCTGGGTCTTTGAACAGCCGCGATGTCGATCTTCACCCCCACCAACCAGATCCGCCTAACCAATGTGGCCGTGGTACGGATGAAGCGTGCCGGGAAGCGCTTCGAAATCGCCTGCTACAAAAACA',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CTTCAGCCGCTTCCCTCGAGCCTGCAGTGCGCAAGCGCGGGACATCTCCGTTTCCCTCCCTCAGCCCCTTCCCCCCCTACCCCCCCGCCCCGGCCTCCTTTCCCCTTCACGAAGCCGGCTCTGG',\n",
       "       b'CCTCCTTTCCCCTTCACGAAGCCGGCTCTGGGGCGCGCTCACCCCTGTGAGGAGGCCGGAGGTCGGACTCAGGAGGCTCCTTCTCCACTCCCGGAAGATCATGTACCAGCCCAGCCGGGGTGCGGCCCGGCGTCTCGGCCCTTGCCTGCGCGCCTACCAGGCTCGACCCCAGGTGAGCGGAGGAGAAGAGGGAGGGAGGAGAG',\n",
       "       b'CTCACTCACAGCCTCCCTTCCTTCTTTCTCCCTCCGCCTCCCGAGCACCAGCGCGCTCTGAGCTGCCCCCAGGGTCCCTCCCCCGCCGCCAGCAGCCCATTTGGAGGGAGGAAGTAAGGGAAGAGGAGAGGAAGGGGAGCCGGACCGACTACCCAGACAGAGCCGGTGAATGGGTTTGTGGTGACCCCCGCCCCCCACCCCAC',\n",
       "       b'CAGGGTCCCTCCCCCGCCGCCAGCAGCCCATTTGGAGGGAGGAAGTAAGGGAAGAGGAGAGGAAGGGGAGCCGGACCGACTACCCAGACAGAGCCGGTGAATGGGTTTGTGGTGACCCCCGCCCCCCACCCCACCCTCCCTTCCCACCCGACCCCCAACCCCCATCCCCAGTTCGAGCCGCCGCCCGAAAGGCCGGGCCGTCG',\n",
       "       b'CCTTCCCACCCGACCCCCAACCCCCATCCCCAGTTCGAGCCGCCGCCCGAAAGGCCGGGCCGTCGTCTTAGGAGGAGTCGCCGCCGCCGCCACCTCCGCCATGGAGCTGATCACCATTCTCGAGAAGACCGTGTCTCCCGATCGGCTGGAGCTGGAAGCGGCGCAGAAGTTCCTGGAGCGTGCGGCCGTGGAGAACCTGCCCA',\n",
       "       b'TCCCACCCGACCCCCAACCCCCATCCCCAGTTCGAGCCGCCGCCCGAAAGGCCGGGCCGTCGTCTTAGGAGGAGTCGCCGCCGCCGCCACCTCCGCCATGGAGCTGATCACCATTCTCGAGAAGACCGTGTCTCCCGATCGGCTGGAGCTGGAAGCGGCGCAGAAGTTCCTGGAGCGTGCGGCCGTGGAGAACCTGCCCACTT',\n",
       "       b'CATCCCCAGTTCGAGCCGCCGCCCGAAAGGCCGGGCCGTCGTCTTAGGAGGAGTCGCCGCCGCCGCCACCTCCGCCATGGAGCTGATCACCATTCTCGAGAAGACCGTGTCTCCCGATCGGCTGGAGCTGGAAGCGGCGCAGAAGTTCCTGGAGCGTGCGGCCGTGGAGAACCTGCCCACTTTCCTTGTGGAACTGTCCAGAG',\n",
       "       b'TCTCGAGAAGACCGTGTCTCCCGATCGGCTGGAGCTGGAAGCGGCGCAGAAGTTCCTGGAGCGTGCGGCCGTGGAGAACCTGCCCACTTTCCTTGTGGAACTGTCCAGAGTGCTGGCAAATCCAGGAAACAGTCAGGTTGCCAGAGTTGCAGCTGGTCTACAAATCAAGAACTCTTTGACATCTAAAGATCCAGATATCAAGG',\n",
       "       b'ATCCAGGAAACAGTCAGGTTGCCAGAGTTGCAGCTGGTCTACAAATCAAGAACTCTTTGACATCTAAAGATCCAGATATCAAGGCACAATATCAGCAGAGGTGGCTTGCTATTGATGCTAATGCTCGACGAGAAGTCAAGAACTATGTTTTGCAGACATTGGGTACAGAAACTTACCGGCCTAGTTCTGCCTCACAGTGTGTG',\n",
       "       b'$$$$$$$$$$$$$GAGAAACGCGTCCTGAGAAAAAAGGGGAGGGGCGAGGGAGAGGATTTGCGCGTGCGCAAAAGTAGTTGATGGAAATCGGCCGTTGGGATGCTGTCTAAGCTTGGATACCTGAGTAATAACGGACAACAGATAAAGCTCCGCATCCTTGCGCCACGTGCTTCGGTCCGTGGTTTGCGTGCAGACGTTTGAC',\n",
       "       b'CGGCGGATCAGCTGGATACTCTTGTTACCAGAATTCCAAAGGTTCTGATAGAATCAAAGATGGATACAAAGTGAACTCACACATAGCTAAGCTGCAAGAGTTATGGAAAACTCCCCAAAATCAAACAATCCACCTCTCTAAATCAATGATGGAGGCGTCCTTTTTCAAGCATCCAGACCTCACCACAGGCCAGAAGCGTTACC',\n",
       "       b'CGGGCAGTGTCCGAACGGCTTCGGAGGGGCGAGAAGCCAGCATCCGAGCCGCCTCTCCGGAATACCAGCAGCCTGACGCACGCGTGCTGTCGGGGGAGGGATGCTGGGACAGCTGCTCCCGCACACGGCTCGCGGTCTCGGCGCCGCGGAGATGCCCGGCCAGGGTCCGGGGTCCGACTGGACGGAGCGTAGCTCTTCTGCAG',\n",
       "       b'GTCCTGGGCCCCAGGCTCCCGGAAGTGCTGCCCGGCGCTCCGGAAGCGATTCATCGGGCCGCGAGCGCCCTCCCCGTCGTTTTCCGTGAGAGACGTAGAGCTGAGCGACCCAGCCCGCGAGCGAGATGCCGGTGGCCGTGGGTCCCTACGGACAGTCCCAGCCAAGCTGCTTCGACCGTGTCAAAATGGGCTTCGTGATGGGT',\n",
       "       b'AAGCGATTCATCGGGCCGCGAGCGCCCTCCCCGTCGTTTTCCGTGAGAGACGTAGAGCTGAGCGACCCAGCCCGCGAGCGAGATGCCGGTGGCCGTGGGTCCCTACGGACAGTCCCAGCCAAGCTGCTTCGACCGTGTCAAAATGGGCTTCGTGATGGGTTGCGCCGTGGGCATGGCGGCCGGGGCGCTCTTCGGCACCTTTT',\n",
       "       b'CCGCGAGCGCCCTCCCCGTCGTTTTCCGTGAGAGACGTAGAGCTGAGCGACCCAGCCCGCGAGCGAGATGCCGGTGGCCGTGGGTCCCTACGGACAGTCCCAGCCAAGCTGCTTCGACCGTGTCAAAATGGGCTTCGTGATGGGTTGCGCCGTGGGCATGGCGGCCGGGGCGCTCTTCGGCACCTTTTCCTGTCTCAGGATCG',\n",
       "       b'TGCTGCCCGGCGCTCCGGAAGCGATTCATCGGGCCGCGAGCGCCCTCCCCGTCGTTTTCCGTGAGAGACGTAGAGCTGAGCGACCCAGCCCGCGAGCGAGATGCCGGTGGCCGTGGGTCCCTACGGACAGTCCCAGCCAAGCTGCTTCGACCGTGTCAAAATGGGCTTCGTGATGGGTTGCGCCGTGGGCATGGCGGCCGGGG',\n",
       "       b'GCCTCAGTTTGGAGGTCGCGCTCACTGCGACGGCAGGCTTTGAGTGTAGCACTTGGTAGTTCTTCCTCTGCTCTGCTTCCCTTCGGAGGAAAATTTCAGGCTGAAGGTTTAGCGGGTGCCGCCTCTAAAGAGAGCAATCACTACACTTATGGCTGGGATTTTGCGCTTAGTAGTTCAATGGCCCCCAGGCAGACTACAGACTG',\n",
       "       b'GCACTTGGTAGTTCTTCCTCTGCTCTGCTTCCCTTCGGAGGAAAATTTCAGGCTGAAGGTTTAGCGGGTGCCGCCTCTAAAGAGAGCAATCACTACACTTATGGCTGGGATTTTGCGCTTAGTAGTTCAATGGCCCCCAGGCAGACTACAGACTGTGACAAAAGGTGTGGAGTCTCTTATTTGTACAGATTGGATTCGTCACA',\n",
       "       b'AGGCTCTGCAATGGCGAATTCTGAGAGCAAAACTGCCAATAAACGATCTGCATCTACTGAAAAACTTGAACAGGGTACTTCTGCTTTAATCAGACAAATGCCTTTGTCATCTGCAGGCCTTCAAAATTCCGTTGCCAAAAGGAAAACAGACAAGGAGAGAAGCTCATCTTTAAATAGAAGAGATAGTAACCTACATTCGTCTA',\n",
       "       b'GCCCCGCCCACCGGCAGCCCGGCCACGACCCAAGCGGAGGCCGCGCCGACGCCTGCGCAATGTATGCGGAGAGCCACCACCGCCTCCGGTCCCGACTCCGATGATGGCGGACGGCGCCGCAGCTGGCGCTGGCGGCAGCCCATCCTTGAGAGAGCTGCGGGCACGGATGGTTGCTGCAGCAAACGAGATTGCTAAGGAAAGGA',\n",
       "       b'TGCGTCCCGGCGCTCGGCTTTCCCTCCGCCGGTCCCGCCCTCCGTCGCGGCGGCGCGGTGTACCCTGGGATAGGGAGCGATCTCCGAGCGAGGCGGCAAGATGGACGCGGGATTTTTCCGCGGAACAAGTGCAGAACAGGATAATCGGTTCAGCAACAAACAGAAGAAACTACTGAAGCAGCTGAAATTTGCAGAATGCCTAG',\n",
       "       b'CGCCGGTCCCGCCCTCCGTCGCGGCGGCGCGGTGTACCCTGGGATAGGGAGCGATCTCCGAGCGAGGCGGCAAGATGGACGCGGGATTTTTCCGCGGAACAAGTGCAGAACAGGATAATCGGTTCAGCAACAAACAGAAGAAACTACTGAAGCAGCTGAAATTTGCAGAATGCCTAGAAAAAAAGGTGGACATGAGCAAAGTA',\n",
       "       b'GCGAGACCCCGCCCCATCCCCGACTGCCTGAACCGCGCCAGGAGACGGACCGCAAGTCCAGCGTACCCACAGACGACTCAGGCGGGAGACGAGCGGTGTCATGGCCGCCGACAGTGACGATGGCGCAGTTTCAGCTCCCGCAGCTTCCGACGGTGGTGTCAGCAAAAGCACAACATCTGGGGAGGAGCTAGTAGTCCAGGTTC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GTGTAACCAGCTGGGAGCCAGCCGGCAGGACGCTGTGAGTTGGCGTGCTAGTGGGATGGCAGATGAGGAAGAAGACCCCACGTTTGAGGAAGAAAATGAAGAAATTGGAGGAGGTGCAGAAGGTGGACAGGGTAAAAGAAAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$GTGTAACCAGCTGGGAGCCAGCCGGCAGGACGCTGTGAGTTGGCGTGCTAGTGGGATGGCAGATGAGGAAGAAGACCCCACGTTTGAGGAAGAAAATGAAGAAATTGGAGGAGGTGCAGAAGGTGGACAGGGTAAAAGAAAGAGACTTTTTTCTAAAG',\n",
       "       b'$$$$$$$$$GTGTAACCAGCTGGGAGCCAGCCGGCAGGACGCTGTGAGTTGGCGTGCTAGTGGGATGGCAGATGAGGAAGAAGACCCCACGTTTGAGGAAGAAAATGAAGAAATTGGAGGAGGTGCAGAAGGTGGACAGGGTAAAAGAAAGAGACTTTTTTCTAAAGAATTGCGATGTATGATGTATGGCTTTGGGGATGACC',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CGTTTATGGCCGCGTTAAGTCTGAGTGCCGCTTTGAGTTGTTGAATGAAGTGAACTTCATTTGTCAGCGTTCGGTTCATGAACTGGAATGTAAGAGGCACCAGAGGAT',\n",
       "       b'TGCCAAGGCCAGATATCTCAGGAAAGATGAGGGCAGTAATAAGCAAGTTTATTCTGTTCCTCATTTTTTTTTAGCTGGAGCAGCTAAGGAGAGATCACAGATGAATTCTCAAACTGAAGATCATGCCTTGGCACCTGTGAGGAACACTATTCAACTCCCAACACAACCTTTGAATTCAGAGGAGTGGGATAAACTTAAGGAAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CGAGGCCACCAGGGTGACTGCGGGATTCCGATCTGCGCCGGAGCTGCGATGCTAGAGCACTCTTGCCACCCCCACCCCACGGACGTGTTGCAGTGATATCAGAATTTTGCGTGCGGTTTACCCGTGTTTAACCTCTTTGCGTCTCGCTTCT',\n",
       "       b'GAGACCCCTTGGACAAACAGATTTTTGCACTGGGGATAGAACTTGAGCAATTTCTGTCTTGGCCTCGCCACTGACGTCCCTTCTTTCCTGTGGGGACAGGATGGACAGATTCCTGGTGAAAGGGGCTCAAGGGGGCCTTTTGAGGAAGCAGGAGGAGCAAGAGCCAACTGGAGAAGAGCCAGCTGTGTTGGGAGGAGACAAAG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCTGCGTCTCTGCCCGCCCCGTGGCGCCCGAGTGCACTGAAGATGGCGGCTGCTGTAGGACGGTTGCTCCGAGCGTCGGTTGCCCGACATGTGAGTGCCATTCCTTGGGGCATTTCTGCCACTGCAGCCCTCAGGCCTGCTGCAT',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCTGCGTCTCTGCCCGCCCCGTGGCGCCCGAGTGCACTGAAGATGGCGGCTGCTGTAGGACGGTTGCTCCGAGCGTCGGTTGCCCGACATGTGAGTGCCATTCCTTGGGGCATTTCTGCCACTGCAGCCCTCAGGCCTGCTGCATGTGGAAGAACGAGCTTG',\n",
       "       b'$$$$$$$$$$$$$$$$$$$$$$$CCCTGCGTCTCTGCCCGCCCCGTGGCGCCCGAGTGCACTGAAGATGGCGGCTGCTGTAGGACGGTTGCTCCGAGCGTCGGTTGCCCGACATGTGAGTGCCATTCCTTGGGGCATTTCTGCCACTGCAGCCCTCAGGCCTGCTGCATGTGGAAGAACGAGCTTGACAAATTTATTGTGTTC',\n",
       "       b'TGCCCGACATGTGAGTGCCATTCCTTGGGGCATTTCTGCCACTGCAGCCCTCAGGCCTGCTGCATGTGGAAGAACGAGCTTGACAAATTTATTGTGTTCTGGTTCCAGTCAAGCAAAATTATTCAGCACCAGTTCCTCATGCCATGCACCTGCTGTCACCCAGCATGCACCCTATTTTAAGGGTACAGCCGTTGTCAATGGAG',\n",
       "       b'CGGAGCCCTGCCTGTTCCCTGTCCATCCAGGCCAGCAGCTGAAGGAGCCTCACCTGCCTCCCTTCTCTGAGTAGCACGGATTTGAGGAGAAGCAGCGAAGATGTCCAGCGAGCCTCCCCCTCCTTATCCTGGGGGCCCCACAGCCCCACTTCTGGAAGAGAAAAGTGGAGCCCCGCCCACCCCAGGCCGTTCCTCCCCAGCTG'],\n",
       "      dtype='|S203')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25baebcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F12_allele_C</td>\n",
       "      <td>56</td>\n",
       "      <td>GCTAGCCTATTGATCTGGACTCCTGGATAGGCAGCTGGACCAACGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F12_allele_T</td>\n",
       "      <td>56</td>\n",
       "      <td>GCTAGCCTATTGATCTGGACTCCTGGATAGGCAGCTGGACCAACGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F12_mut1</td>\n",
       "      <td>56</td>\n",
       "      <td>GCTAGCCTATTGATCTGGACTCCTGGATAGGCAGCTGGACCAACGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F12_mut2</td>\n",
       "      <td>56</td>\n",
       "      <td>GCTAGCCTATTGATCTGGACTCCTGGATAGGCAGCTGGACCAACGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F12_mut3</td>\n",
       "      <td>56</td>\n",
       "      <td>GCTAGCCTATTGATCTGGACTCCTGGATAGGCAGCTGGACCAACGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F12_uORF1</td>\n",
       "      <td>56</td>\n",
       "      <td>GCTAGCCTATTGATGTGGACTCCTGGATAGGCAGCTGGACCAACGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F12_uORF2</td>\n",
       "      <td>56</td>\n",
       "      <td>GCTAGCCTATTGATCTGGACTCCTGGATGGGCAGCTGGACCAACGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F12_uORF3</td>\n",
       "      <td>56</td>\n",
       "      <td>GCTAGCCTATTGATATGGACTCCTGGATAGGCAGCTGGACCAACGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hsdl2_n</td>\n",
       "      <td>175</td>\n",
       "      <td>GCTAGCTCTTGTAAGCTCTCGGTCTTGTAGGATCTCGGTCTTGTAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hsdl2_u</td>\n",
       "      <td>175</td>\n",
       "      <td>GCTAGCTCTTGTAAGCTCTCGGTCTTGTAGGATCTCGGTCTTGTAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pir_n</td>\n",
       "      <td>281</td>\n",
       "      <td>GCTAGCAGAGAGCCTTGGGGCGGAGTCAGAGAATCCAAACCCAGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pir_u</td>\n",
       "      <td>281</td>\n",
       "      <td>GCTAGCAGAGAGCCATGGGGCGGAGTCAGAGAATCCAAACCCAGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lycat_n</td>\n",
       "      <td>195</td>\n",
       "      <td>GCTAGCGGTGGAGCCCGGAGGGACGCATTACTAAGGCGACGGGGCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lycat_u</td>\n",
       "      <td>195</td>\n",
       "      <td>GCTAGCGGTGGAGCCCGGAGGGACGCATTACTAAGGCGACGGGGCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ccdc13_n</td>\n",
       "      <td>221</td>\n",
       "      <td>GCTAGCGAGGCCTGGGCACTGTTGCCTGTGAGGAGCAGTCGGTCCA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ccdc13_u</td>\n",
       "      <td>221</td>\n",
       "      <td>GCTAGCGAGGCCTGGGCACTGTTGCCTGTGAGGAGCAGTCGGTCCA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A630047E20Rik_n</td>\n",
       "      <td>242</td>\n",
       "      <td>GCTAGCGGAGCGAGGTGCGCGCTCACCCTCGGGTTCTGAGCCGGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A630047E20Rik_u</td>\n",
       "      <td>242</td>\n",
       "      <td>GCTAGCGGAGCGAGGTGCGCGCTCACCCTCGGGTTCTGAGCCGGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Acsm2_n</td>\n",
       "      <td>118</td>\n",
       "      <td>GCTAGCAGTGCTCTTCTCTCCACTGTTGCTGCAGGAATTCTCAAAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Acsm2_u</td>\n",
       "      <td>118</td>\n",
       "      <td>GCTAGCAGTGCTCTTCTCTCCACTGATGCTGCAGGAATTCTCAAAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Slc25a15_n</td>\n",
       "      <td>181</td>\n",
       "      <td>GCTAGCGGAGGGCCCGAGGGCCGGACCCACAGGGCGACCTTAAAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Slc25a15_u</td>\n",
       "      <td>181</td>\n",
       "      <td>GCTAGCGGAGGGCCCGAGGGCCGGACCCACAGGGCGACCTTAAAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Phb_n</td>\n",
       "      <td>87</td>\n",
       "      <td>GCTAGCCACGCGCAGTATCCGGAGCTGGGGAATTCTTGTGGAGGTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Phb_u</td>\n",
       "      <td>87</td>\n",
       "      <td>GCTAGCCACGCGCAGTATCCGGAGCTGGGGAATTCATGTGGAGGTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mut_n</td>\n",
       "      <td>102</td>\n",
       "      <td>GCTAGCGGCGTCTGGGTTCGGTTCTGAAGTCCGGGCTTGGTCCGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Mut_u</td>\n",
       "      <td>102</td>\n",
       "      <td>GCTAGCGGCGTCTGGGTTCGGTTCTGAAGTCCGGGCTTGGTCCGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mrpl11_n</td>\n",
       "      <td>85</td>\n",
       "      <td>GCTAGCACCTCTGACCCAAATTGGCCGCGCCCAGAGCGTAGTTCTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Mrpl11_u</td>\n",
       "      <td>85</td>\n",
       "      <td>GCTAGCACCTCTGACCCAAAATGGCCGCGCCCAGAGCGTAGTTCTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Lrpprc_n</td>\n",
       "      <td>280</td>\n",
       "      <td>GCTAGCGCCAGGCTCGCTGAGAGCCGGGGCGCTGGACAAGGGAACA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Lrpprc_u</td>\n",
       "      <td>280</td>\n",
       "      <td>GCTAGCGCCAGGCTCGCTGAGAGCCGGGGCGCTGGACAAGGGAACA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Glyctk_n</td>\n",
       "      <td>144</td>\n",
       "      <td>GCTAGCGGACTTGGAGCAGAGTGTCCAGAAGACTGGTGTGTGGTCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Glyctk_u</td>\n",
       "      <td>144</td>\n",
       "      <td>GCTAGCGGACTTGGAGCAGAGTGTCCAGAAGACTGGTGTGTGGTCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Uqcc_n</td>\n",
       "      <td>312</td>\n",
       "      <td>GCTAGCTTGTGGAGGAACATGGCGGCACGAGGTTGCTGGTGCGAGT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Uqcc_u</td>\n",
       "      <td>312</td>\n",
       "      <td>GCTAGCTTGTGGAGGAACATGGCGGCACGAGGTTGCTGGTGCGAGT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1200015F23Rik_n</td>\n",
       "      <td>63</td>\n",
       "      <td>GCTAGCACAGAGTGAAAGCGCGGTGCCTGCTGCTGCCTTGGTGGCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1200015F23Rik_u</td>\n",
       "      <td>63</td>\n",
       "      <td>GCTAGCACAGAGTGAAAGCGCGGTGCCTGCTGCTGCCATGGTGGCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sfxn3_n</td>\n",
       "      <td>227</td>\n",
       "      <td>GCTAGCGTCTCAACGGCCTGGTCTGGGAGAATCACTCTGGACATCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Sfxn3_u</td>\n",
       "      <td>227</td>\n",
       "      <td>GCTAGCGTCTCAACGGCCTGGTCTGGGAGAATCACTCTGGACATCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>CASP8_n</td>\n",
       "      <td>308</td>\n",
       "      <td>GCTAGCGCTCTGAGTTTTTGGTTTCTGTTTCACCTTGTGTCTGAGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>CASP8_u</td>\n",
       "      <td>308</td>\n",
       "      <td>GCTAGCGCTCTGAGTTTTTGGTTTCTGTTTCACCTTGTGTCTGAGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MC2R_n</td>\n",
       "      <td>184</td>\n",
       "      <td>GCTAGCATTCCTTCTCATTCATTTTGCCCAGAAAGTTCCTGCTTCA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>MC2R_u</td>\n",
       "      <td>184</td>\n",
       "      <td>GCTAGCATTCCTTCTCATTCATTTTGCCCAGAAAGTTCCTGCTTCA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>KDR_n</td>\n",
       "      <td>308</td>\n",
       "      <td>GCTAGCCTGAGTCCCGGGACCCCGGGAGAGCGGTCAGTGTGTGGTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>KDR_u</td>\n",
       "      <td>308</td>\n",
       "      <td>GCTAGCCTGAGTCCCGGGACCCCGGGAGAGCGGTCAATGTGTGGTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>TAS2R3_n</td>\n",
       "      <td>68</td>\n",
       "      <td>GCTAGCCAGTGAGGAGATTCTACGTATCAACAGAAAGAACAAAGAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>TAS2R3_u</td>\n",
       "      <td>68</td>\n",
       "      <td>GCTAGCCAGTGAGGAGATTCTATGTATCAACAGAAAGAACAAAGAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>HBB_n</td>\n",
       "      <td>57</td>\n",
       "      <td>GCTAGCACATTTGCTTCTGACACAACTGTGTTCACTAGCAACCTCA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>HBB_u</td>\n",
       "      <td>57</td>\n",
       "      <td>GCTAGCACATTTGCTTCTGACACAACTATGTTCACTAGCAACCTCA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>PRKAR1A_n</td>\n",
       "      <td>160</td>\n",
       "      <td>GCTAGCGATTGGCTGCGGCCAGGCCGTTTCCGGTGGAGCTGTCGCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>PRKAR1A_u</td>\n",
       "      <td>160</td>\n",
       "      <td>GCTAGCGATTGGCTGCGGCCAGGCCGTTTCCGGTGGAGCTGTCGCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>IRF6_n</td>\n",
       "      <td>270</td>\n",
       "      <td>GCTAGCGAGCTCGGCGCACCTGGGCTGGGCAGGTAAGGGCTGGTGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>IRF6_u</td>\n",
       "      <td>270</td>\n",
       "      <td>GCTAGCGAGCTCGGCGCACCTGGGCTGGGCAGGTAAGGGCTGGTGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SRY_n</td>\n",
       "      <td>155</td>\n",
       "      <td>GCTAGCGTTGAGGGGGTGTTGAGGGCGGAGAAATGCAAGTTTCATT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SRY_u</td>\n",
       "      <td>155</td>\n",
       "      <td>GCTAGCGTTGAGGGGGTGTTGAGGGCGGAGAAATGCAAGTTTCATT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SPINK1_n</td>\n",
       "      <td>127</td>\n",
       "      <td>GCTAGCAGCCCAGTAGGTGGGGCCTTGCTGCCATCTGCCATATGAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>SPINK1_u</td>\n",
       "      <td>127</td>\n",
       "      <td>GCTAGCAGCCCAGTAGGTGGGGCCTTGCTGCCATCTGCCATATGAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0    1                                                  2\n",
       "0      F12_allele_C   56  GCTAGCCTATTGATCTGGACTCCTGGATAGGCAGCTGGACCAACGG...\n",
       "1      F12_allele_T   56  GCTAGCCTATTGATCTGGACTCCTGGATAGGCAGCTGGACCAACGG...\n",
       "2          F12_mut1   56  GCTAGCCTATTGATCTGGACTCCTGGATAGGCAGCTGGACCAACGG...\n",
       "3          F12_mut2   56  GCTAGCCTATTGATCTGGACTCCTGGATAGGCAGCTGGACCAACGG...\n",
       "4          F12_mut3   56  GCTAGCCTATTGATCTGGACTCCTGGATAGGCAGCTGGACCAACGG...\n",
       "5         F12_uORF1   56  GCTAGCCTATTGATGTGGACTCCTGGATAGGCAGCTGGACCAACGG...\n",
       "6         F12_uORF2   56  GCTAGCCTATTGATCTGGACTCCTGGATGGGCAGCTGGACCAACGG...\n",
       "7         F12_uORF3   56  GCTAGCCTATTGATATGGACTCCTGGATAGGCAGCTGGACCAACGG...\n",
       "8           Hsdl2_n  175  GCTAGCTCTTGTAAGCTCTCGGTCTTGTAGGATCTCGGTCTTGTAG...\n",
       "9           Hsdl2_u  175  GCTAGCTCTTGTAAGCTCTCGGTCTTGTAGGATCTCGGTCTTGTAG...\n",
       "10            Pir_n  281  GCTAGCAGAGAGCCTTGGGGCGGAGTCAGAGAATCCAAACCCAGGG...\n",
       "11            Pir_u  281  GCTAGCAGAGAGCCATGGGGCGGAGTCAGAGAATCCAAACCCAGGG...\n",
       "12          Lycat_n  195  GCTAGCGGTGGAGCCCGGAGGGACGCATTACTAAGGCGACGGGGCT...\n",
       "13          Lycat_u  195  GCTAGCGGTGGAGCCCGGAGGGACGCATTACTAAGGCGACGGGGCT...\n",
       "14         Ccdc13_n  221  GCTAGCGAGGCCTGGGCACTGTTGCCTGTGAGGAGCAGTCGGTCCA...\n",
       "15         Ccdc13_u  221  GCTAGCGAGGCCTGGGCACTGTTGCCTGTGAGGAGCAGTCGGTCCA...\n",
       "16  A630047E20Rik_n  242  GCTAGCGGAGCGAGGTGCGCGCTCACCCTCGGGTTCTGAGCCGGGG...\n",
       "17  A630047E20Rik_u  242  GCTAGCGGAGCGAGGTGCGCGCTCACCCTCGGGTTCTGAGCCGGGG...\n",
       "18          Acsm2_n  118  GCTAGCAGTGCTCTTCTCTCCACTGTTGCTGCAGGAATTCTCAAAC...\n",
       "19          Acsm2_u  118  GCTAGCAGTGCTCTTCTCTCCACTGATGCTGCAGGAATTCTCAAAC...\n",
       "20       Slc25a15_n  181  GCTAGCGGAGGGCCCGAGGGCCGGACCCACAGGGCGACCTTAAAAA...\n",
       "21       Slc25a15_u  181  GCTAGCGGAGGGCCCGAGGGCCGGACCCACAGGGCGACCTTAAAAA...\n",
       "22            Phb_n   87  GCTAGCCACGCGCAGTATCCGGAGCTGGGGAATTCTTGTGGAGGTC...\n",
       "23            Phb_u   87  GCTAGCCACGCGCAGTATCCGGAGCTGGGGAATTCATGTGGAGGTC...\n",
       "24            Mut_n  102  GCTAGCGGCGTCTGGGTTCGGTTCTGAAGTCCGGGCTTGGTCCGGG...\n",
       "25            Mut_u  102  GCTAGCGGCGTCTGGGTTCGGTTCTGAAGTCCGGGCTTGGTCCGGG...\n",
       "26         Mrpl11_n   85  GCTAGCACCTCTGACCCAAATTGGCCGCGCCCAGAGCGTAGTTCTT...\n",
       "27         Mrpl11_u   85  GCTAGCACCTCTGACCCAAAATGGCCGCGCCCAGAGCGTAGTTCTT...\n",
       "28         Lrpprc_n  280  GCTAGCGCCAGGCTCGCTGAGAGCCGGGGCGCTGGACAAGGGAACA...\n",
       "29         Lrpprc_u  280  GCTAGCGCCAGGCTCGCTGAGAGCCGGGGCGCTGGACAAGGGAACA...\n",
       "30         Glyctk_n  144  GCTAGCGGACTTGGAGCAGAGTGTCCAGAAGACTGGTGTGTGGTCT...\n",
       "31         Glyctk_u  144  GCTAGCGGACTTGGAGCAGAGTGTCCAGAAGACTGGTGTGTGGTCT...\n",
       "32           Uqcc_n  312  GCTAGCTTGTGGAGGAACATGGCGGCACGAGGTTGCTGGTGCGAGT...\n",
       "33           Uqcc_u  312  GCTAGCTTGTGGAGGAACATGGCGGCACGAGGTTGCTGGTGCGAGT...\n",
       "34  1200015F23Rik_n   63  GCTAGCACAGAGTGAAAGCGCGGTGCCTGCTGCTGCCTTGGTGGCT...\n",
       "35  1200015F23Rik_u   63  GCTAGCACAGAGTGAAAGCGCGGTGCCTGCTGCTGCCATGGTGGCT...\n",
       "36          Sfxn3_n  227  GCTAGCGTCTCAACGGCCTGGTCTGGGAGAATCACTCTGGACATCC...\n",
       "37          Sfxn3_u  227  GCTAGCGTCTCAACGGCCTGGTCTGGGAGAATCACTCTGGACATCC...\n",
       "38          CASP8_n  308  GCTAGCGCTCTGAGTTTTTGGTTTCTGTTTCACCTTGTGTCTGAGC...\n",
       "39          CASP8_u  308  GCTAGCGCTCTGAGTTTTTGGTTTCTGTTTCACCTTGTGTCTGAGC...\n",
       "40           MC2R_n  184  GCTAGCATTCCTTCTCATTCATTTTGCCCAGAAAGTTCCTGCTTCA...\n",
       "41           MC2R_u  184  GCTAGCATTCCTTCTCATTCATTTTGCCCAGAAAGTTCCTGCTTCA...\n",
       "42            KDR_n  308  GCTAGCCTGAGTCCCGGGACCCCGGGAGAGCGGTCAGTGTGTGGTC...\n",
       "43            KDR_u  308  GCTAGCCTGAGTCCCGGGACCCCGGGAGAGCGGTCAATGTGTGGTC...\n",
       "44         TAS2R3_n   68  GCTAGCCAGTGAGGAGATTCTACGTATCAACAGAAAGAACAAAGAT...\n",
       "45         TAS2R3_u   68  GCTAGCCAGTGAGGAGATTCTATGTATCAACAGAAAGAACAAAGAT...\n",
       "46            HBB_n   57  GCTAGCACATTTGCTTCTGACACAACTGTGTTCACTAGCAACCTCA...\n",
       "47            HBB_u   57  GCTAGCACATTTGCTTCTGACACAACTATGTTCACTAGCAACCTCA...\n",
       "48        PRKAR1A_n  160  GCTAGCGATTGGCTGCGGCCAGGCCGTTTCCGGTGGAGCTGTCGCC...\n",
       "49        PRKAR1A_u  160  GCTAGCGATTGGCTGCGGCCAGGCCGTTTCCGGTGGAGCTGTCGCC...\n",
       "50           IRF6_n  270  GCTAGCGAGCTCGGCGCACCTGGGCTGGGCAGGTAAGGGCTGGTGC...\n",
       "51           IRF6_u  270  GCTAGCGAGCTCGGCGCACCTGGGCTGGGCAGGTAAGGGCTGGTGC...\n",
       "52            SRY_n  155  GCTAGCGTTGAGGGGGTGTTGAGGGCGGAGAAATGCAAGTTTCATT...\n",
       "53            SRY_u  155  GCTAGCGTTGAGGGGGTGTTGAGGGCGGAGAAATGCAAGTTTCATT...\n",
       "54         SPINK1_n  127  GCTAGCAGCCCAGTAGGTGGGGCCTTGCTGCCATCTGCCATATGAC...\n",
       "55         SPINK1_u  127  GCTAGCAGCCCAGTAGGTGGGGCCTTGCTGCCATCTGCCATATGAC..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sseqs=pd.read_csv('final_true_vs_predicts/FXII_seq.txt',sep='\\t',header=None)\n",
    "sseqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91faa43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "101d8520",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENST00000343053.6\n",
      "D:\\sorf_models\\model\\tests\\model_saves\\train_2_15\\run_all_1.pkl loaded.\n",
      "D:\\sorf_models\\model\\tests\\model_saves\\train_2_15\\run_all_2.pkl loaded.\n",
      "D:\\sorf_models\\model\\tests\\model_saves\\train_2_15\\run_all_3.pkl loaded.\n",
      "D:\\sorf_models\\model\\tests\\model_saves\\train_2_15\\run_all_4.pkl loaded.\n",
      "D:\\sorf_models\\model\\tests\\model_saves\\train_2_15\\run_all_5.pkl loaded.\n",
      "D:\\sorf_models\\model\\tests\\model_saves\\train_2_15\\run_all_6.pkl loaded.\n",
      "D:\\sorf_models\\model\\tests\\model_saves\\train_2_15\\run_all_7.pkl loaded.\n",
      "D:\\sorf_models\\model\\tests\\model_saves\\train_2_15\\run_all_8.pkl loaded.\n",
      "D:\\sorf_models\\model\\tests\\model_saves\\train_2_15\\run_all_9.pkl loaded.\n",
      "D:\\sorf_models\\model\\tests\\model_saves\\train_2_15\\run_all_10.pkl loaded.\n"
     ]
    }
   ],
   "source": [
    "use_own=False\n",
    "sseq=sseqs[2].values[ss]\n",
    "test_o=sseqs[0].values[ss]\n",
    "test_o=\"ENST00000343053.6\"\n",
    "sseq=\"ATTAGAGTCTGTGCTTCACTTCCGTTCCAGCCTCAGCGGCAGCTGGATCGCTCGACGGAGTGCCTCTGGTAGTTGGCCAAGACGCCGAATATCAAAATCTTCAGCGGCAGCTCCCACCAGGACTTATCCCAGAAAATTGCTGACCGCCTGGGCCTGGAGCTAGGCAAGGTGGTGACTAAGAAATTCAGCAACCAGGAGACCTGCGTGGAAATTGATGAGAGTGTGCGTGGAGAGGATGTCTACATCGTTCAGAGTGGTTGTGGCGAAATCAACGACAGTCTAATGGAGCTTTTGATCATGATTAATGCCTGCAAGATTGCTTCAGCTAGCCGAGTTACTGCAGTCATCCCATGCTTCCCTTATGCCCGACAGGATAAGAAGGATAAGAGCCGGTCCCCAATCTCTGCCAAGCTTGTTGCAAATATG\"\n",
    "if use_own==False:\n",
    "    sseq=fa[test_o]\n",
    "my_padded_seq=\"P\"*padding_size+sseq+\"P\"*padding_size\n",
    "\n",
    "pattern=re.compile(r'(?=(ATG|TTG|CTG|GTG|AAG|ACG|AGG|ATA|ATT|ATC))')\n",
    "it=re.finditer(pattern,my_padded_seq)\n",
    "pos3=[i.span()[0] for i in it][0:(TIS_max_num+3)]\n",
    "pos2=pos3[0:(TIS_max_num+1)]\n",
    "pos=pos2[0:TIS_max_num]\n",
    "if len(pos2)==len(pos):\n",
    "    pos2=pos2+[pos2[len(pos2)-1]+20]\n",
    "my_seq=torch.stack([torch.tensor([dict[j] for j in list(my_padded_seq[(p-padding_size):(p+padding_size+1)])], dtype=torch.long) for p in pos])\n",
    "my_target=torch.tensor([1 for j in range(len(pos))])\n",
    "my_weight=torch.tensor([1]*len(pos))\n",
    "pos1=[padding_size]+pos\n",
    "my_dis=torch.stack([torch.tensor([pos1[i+1]-pos1[i] for i in range(len(pos1)-1)]),torch.tensor([pos2[i+1]-pos2[i] for i in range(len(pos2)-1)])],1)\n",
    "my_dis=my_dis/sqrt_scale\n",
    "\n",
    "print(test_o)\n",
    "MyvalData = testoneMyDataset(inputset=[my_seq], targetset=[my_target], weightset=[my_weight], disset=[my_dis], transcriptset=[test_o])\n",
    "Myvalloader = torch.utils.data.DataLoader(MyvalData, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn_padd, drop_last=True)\n",
    "outputss=pd.DataFrame()\n",
    "for t_run in range(1,11):\n",
    "    writer_title='run_all_'+str(t_run)\n",
    "    state = torch.load(save_path + \"\\\\\"+run_header+\"\\\\\"+writer_title+\".pkl\")\n",
    "    Mymodel = MyLSTM(dropout=dropout, hidden_dim=hidden_dim, num_layers=num_layers, proj_size=proj_size)\n",
    "    Mymodel.to(device)\n",
    "    optimizer = optim.SGD(Mymodel.parameters(), lr=lr, momentum=momentum)\n",
    "    Mymodel.load_state_dict(state['state_dict'])\n",
    "    optimizer.load_state_dict(state['optimizer'])\n",
    "    epoch = state['epoch']\n",
    "    jj = state['jj']\n",
    "    converge_level = state['converge_level']\n",
    "    running_loss = state['running_loss']\n",
    "    inspect_loss = state['inspect_loss']\n",
    "    loss_ratio = state['loss_ratio']\n",
    "    sigma_index = state['sigma_index']\n",
    "    print(save_path + \"\\\\\"+run_header+\"\\\\\"+writer_title+\".pkl loaded.\")\n",
    "    with torch.no_grad():\n",
    "        iter0=iter(enumerate(Myvalloader, 0))\n",
    "        iii, batch=next(iter0)\n",
    "        inputs, sizes, labels, weights, diss, transcriptt = batch\n",
    "        outputs = Mymodel(x=inputs, sizes=sizes, diss=diss)\n",
    "        loss = criterion(outputs, labels, weights, torch.sum(sizes), loss_ratio)\n",
    "        outputss['run_'+str(t_run)]=np.array(outputs.cpu().flatten(0))\n",
    "\n",
    "outputss.to_csv('final_true_vs_predicts\\\\inspect_output.txt',sep='\\t',index=False)\n",
    "np.savetxt('final_true_vs_predicts\\\\inspect.txt',np.array([1]*len(sseq)),header=test_o)\n",
    "#pos=[i[1] for i in find_TIS(test_o)]\n",
    "\n",
    "pattern=re.compile(r'(?=(ATG|TTG|CTG|GTG|AAG|ACG|AGG|ATA|ATT|ATC))')\n",
    "it=re.finditer(pattern,sseq)\n",
    "TIS=[(i.group(1),i.span()[0]) for i in it]\n",
    "pos=[i[1] for i in TIS[0:TIS_max_num]]\n",
    "\n",
    "np.savetxt('final_true_vs_predicts\\\\inspect_pos.txt',np.array(pos),header=test_o)\n",
    "ss+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b40e7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323982\n"
     ]
    }
   ],
   "source": [
    "##突变模拟\n",
    "lnc_fa=read_fasta('all_lnc_new_plane.fa')\n",
    "print(len(lnc_fa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2c22a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "fe68f43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3,  0],\n",
      "         [ 4,  5,  6,  0],\n",
      "         [-1,  0,  1,  0]],\n",
      "\n",
      "        [[ 1, -1,  1,  0],\n",
      "         [ 4,  4,  4,  0],\n",
      "         [ 3, -3,  3,  0]]])\n",
      "torch.Size([2, 3, 4])\n",
      "tensor([1, 2, 3, 0])\n",
      "tensor([[[ 6],\n",
      "         [15],\n",
      "         [ 2]],\n",
      "\n",
      "        [[ 3],\n",
      "         [12],\n",
      "         [ 9]]])\n",
      "tensor([[[ 0.1667,  0.3333,  0.5000,  0.0000],\n",
      "         [ 0.2667,  0.3333,  0.4000,  0.0000],\n",
      "         [-0.5000,  0.0000,  0.5000,  0.0000]],\n",
      "\n",
      "        [[ 0.3333, -0.3333,  0.3333,  0.0000],\n",
      "         [ 0.3333,  0.3333,  0.3333,  0.0000],\n",
      "         [ 0.3333, -0.3333,  0.3333,  0.0000]]])\n",
      "tensor([[ 0.2500,  0.0000,  0.4167,  0.0000],\n",
      "        [ 0.3000,  0.3333,  0.3667,  0.0000],\n",
      "        [-0.0833, -0.1667,  0.4167,  0.0000]])\n",
      "tensor([0.4167, 0.3667, 0.4167])\n",
      "tensor([1.0000, 0.8800, 1.0000])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "test1=torch.tensor([[1,2,3,0],[4,5,6,0],[-1,0,1,0]])\n",
    "test2=torch.tensor([[1,-1,1,0],[4,4,4,0],[3,-3,3,0]])\n",
    "test=torch.stack((test1,test2))\n",
    "print(test)\n",
    "print(test.size())\n",
    "print(test[0,0])\n",
    "print(torch.sum(torch.abs(test),2,keepdim=True))\n",
    "print(test/torch.sum(torch.abs(test),2,keepdim=True))\n",
    "test3=torch.mean(test/torch.sum(torch.abs(test),2,keepdim=True),0,keepdim=False)\n",
    "print(test3)\n",
    "test4,test5=torch.max(test3,1)\n",
    "print(test4)\n",
    "test3=test4/test3[0][test5]\n",
    "print(test3)\n",
    "print(len(test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "adb775c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyLSTM(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(5, 3), stride=(1, 1), padding=(2, 1))\n",
       "  (conv2): Conv2d(16, 16, kernel_size=(5, 3), stride=(1, 1), padding=(2, 1))\n",
       "  (fc0): Linear(in_features=4080, out_features=62, bias=True)\n",
       "  (rnn): LSTM(64, 128, num_layers=2, batch_first=True)\n",
       "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (lrelu1): LeakyReLU(negative_slope=0.05)\n",
       "  (lrelu2): LeakyReLU(negative_slope=0.05)\n",
       ")"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_run=1\n",
    "writer_title='run_all_'+str(t_run)\n",
    "state = torch.load(save_path + \"\\\\\"+run_header+\"\\\\\"+writer_title+\".pkl\")\n",
    "Mymodel1 = MyLSTM(dropout=dropout, hidden_dim=hidden_dim, num_layers=num_layers, proj_size=proj_size)\n",
    "Mymodel1.to(device)\n",
    "Mymodel1.load_state_dict(state['state_dict'])\n",
    "Mymodel1.eval()\n",
    "\n",
    "t_run=2\n",
    "writer_title='run_all_'+str(t_run)\n",
    "state = torch.load(save_path + \"\\\\\"+run_header+\"\\\\\"+writer_title+\".pkl\")\n",
    "Mymodel2 = MyLSTM(dropout=dropout, hidden_dim=hidden_dim, num_layers=num_layers, proj_size=proj_size)\n",
    "Mymodel2.to(device)\n",
    "Mymodel2.load_state_dict(state['state_dict'])\n",
    "Mymodel2.eval()\n",
    "\n",
    "t_run=3\n",
    "writer_title='run_all_'+str(t_run)\n",
    "state = torch.load(save_path + \"\\\\\"+run_header+\"\\\\\"+writer_title+\".pkl\")\n",
    "Mymodel3 = MyLSTM(dropout=dropout, hidden_dim=hidden_dim, num_layers=num_layers, proj_size=proj_size)\n",
    "Mymodel3.to(device)\n",
    "Mymodel3.load_state_dict(state['state_dict'])\n",
    "Mymodel3.eval()\n",
    "\n",
    "t_run=4\n",
    "writer_title='run_all_'+str(t_run)\n",
    "state = torch.load(save_path + \"\\\\\"+run_header+\"\\\\\"+writer_title+\".pkl\")\n",
    "Mymodel4 = MyLSTM(dropout=dropout, hidden_dim=hidden_dim, num_layers=num_layers, proj_size=proj_size)\n",
    "Mymodel4.to(device)\n",
    "Mymodel4.load_state_dict(state['state_dict'])\n",
    "Mymodel4.eval()\n",
    "\n",
    "t_run=5\n",
    "writer_title='run_all_'+str(t_run)\n",
    "state = torch.load(save_path + \"\\\\\"+run_header+\"\\\\\"+writer_title+\".pkl\")\n",
    "Mymodel5 = MyLSTM(dropout=dropout, hidden_dim=hidden_dim, num_layers=num_layers, proj_size=proj_size)\n",
    "Mymodel5.to(device)\n",
    "Mymodel5.load_state_dict(state['state_dict'])\n",
    "Mymodel5.eval()\n",
    "\n",
    "t_run=6\n",
    "writer_title='run_all_'+str(t_run)\n",
    "state = torch.load(save_path + \"\\\\\"+run_header+\"\\\\\"+writer_title+\".pkl\")\n",
    "Mymodel6 = MyLSTM(dropout=dropout, hidden_dim=hidden_dim, num_layers=num_layers, proj_size=proj_size)\n",
    "Mymodel6.to(device)\n",
    "Mymodel6.load_state_dict(state['state_dict'])\n",
    "Mymodel6.eval()\n",
    "\n",
    "t_run=7\n",
    "writer_title='run_all_'+str(t_run)\n",
    "state = torch.load(save_path + \"\\\\\"+run_header+\"\\\\\"+writer_title+\".pkl\")\n",
    "Mymodel7 = MyLSTM(dropout=dropout, hidden_dim=hidden_dim, num_layers=num_layers, proj_size=proj_size)\n",
    "Mymodel7.to(device)\n",
    "Mymodel7.load_state_dict(state['state_dict'])\n",
    "Mymodel7.eval()\n",
    "\n",
    "t_run=8\n",
    "writer_title='run_all_'+str(t_run)\n",
    "state = torch.load(save_path + \"\\\\\"+run_header+\"\\\\\"+writer_title+\".pkl\")\n",
    "Mymodel8 = MyLSTM(dropout=dropout, hidden_dim=hidden_dim, num_layers=num_layers, proj_size=proj_size)\n",
    "Mymodel8.to(device)\n",
    "Mymodel8.load_state_dict(state['state_dict'])\n",
    "Mymodel8.eval()\n",
    "\n",
    "t_run=9\n",
    "writer_title='run_all_'+str(t_run)\n",
    "state = torch.load(save_path + \"\\\\\"+run_header+\"\\\\\"+writer_title+\".pkl\")\n",
    "Mymodel9 = MyLSTM(dropout=dropout, hidden_dim=hidden_dim, num_layers=num_layers, proj_size=proj_size)\n",
    "Mymodel9.to(device)\n",
    "Mymodel9.load_state_dict(state['state_dict'])\n",
    "Mymodel9.eval()\n",
    "\n",
    "t_run=10\n",
    "writer_title='run_all_'+str(t_run)\n",
    "state = torch.load(save_path + \"\\\\\"+run_header+\"\\\\\"+writer_title+\".pkl\")\n",
    "Mymodel10 = MyLSTM(dropout=dropout, hidden_dim=hidden_dim, num_layers=num_layers, proj_size=proj_size)\n",
    "Mymodel10.to(device)\n",
    "Mymodel10.load_state_dict(state['state_dict'])\n",
    "Mymodel10.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bc77f29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 1, 1, 1, 4, 6])\n",
      "tensor([2, 5, 8])\n",
      "{0, 1, 4, 7}\n",
      "[2, 3, 5, 6, 8, 9]\n",
      "tensor([ 3,  4,  6,  7,  9, 10])\n"
     ]
    }
   ],
   "source": [
    "test=torch.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "print(test[[0,1,0,0,0,3,5]])\n",
    "test1=list(range(1,test.size()[0],3))\n",
    "print(test[test1])\n",
    "print(set([0]+list(range(1,test.size()[0],3))))\n",
    "print(list(set(range(test.size()[0]))-set([0]+list(range(1,test.size()[0],3)))))\n",
    "print(test[list(set(range(test.size()[0]))-set([0]+list(range(1,test.size()[0],3))))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "52933ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test1</th>\n",
       "      <th>test2</th>\n",
       "      <th>test3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test1  test2  test3\n",
       "0     a      1      3\n",
       "1     b      2      3\n",
       "2     c      3      3"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1=[\"a\",\"b\",\"c\"]\n",
    "print(test1[0:2])\n",
    "test2=np.array([1,2,3])\n",
    "test3=np.array([3,3,3])\n",
    "pd.DataFrame({\"test1\":test1,\"test2\":test2,\"test3\":test3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3696fdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HSALNT0000002', 'HSALNT0000003', 'HSALNT0000004']\n"
     ]
    }
   ],
   "source": [
    "print(list(lnc_fa.keys())[0:3])\n",
    "random.seed(121)\n",
    "dic1={\"A\": 0,\"T\": 1,\"G\": 2,\"C\": 3}\n",
    "ATGC=list('ATGC')\n",
    "HIS={}\n",
    "LNC=[]\n",
    "smut=[]\n",
    "dmut=[]\n",
    "def mutate(x,a,b):\n",
    "    return x[:a]+ATGC[(dic1[x[a]]+b+1) % 4]+x[(a+1):]\n",
    "\n",
    "for lnc in list(lnc_fa.keys())[0:3]:\n",
    "    lnc_len=len(lnc_fa[lnc])\n",
    "    mut1_num=min(250,lnc_len)\n",
    "    his=[set([(-1,-1),(-1,-1)])]\n",
    "    padded_lnc_list=[\"P\"*padding_size+lnc_fa[lnc]+\"P\"*padding_size]\n",
    "    \n",
    "    for i in range(mut1_num):\n",
    "        for j in range(3):\n",
    "            his.append(set([(i,j),(-1,-1)]))\n",
    "            padded_lnc_list.append(\"P\"*padding_size+mutate(lnc_fa[lnc],i,j)+\"P\"*padding_size)\n",
    "            for k in range(50):\n",
    "                m=list(set(list(range(mut1_num)))-set([i]))[random.randint(0,mut1_num-2)]\n",
    "                n=random.randint(0,2)\n",
    "                while set([(i,j),(m,n)]) in his:\n",
    "                    m=list(set(list(range(mut1_num)))-set([i]))[random.randint(0,mut1_num-2)]\n",
    "                    n=random.randint(0,2)\n",
    "                his.append(set([(i,j),(m,n)]))\n",
    "                padded_lnc_list.append(\"P\"*padding_size+mutate(mutate(lnc_fa[lnc],i,j),m,n)+\"P\"*padding_size)\n",
    "    my_seq = []\n",
    "    my_target=[]\n",
    "    my_weight=[]\n",
    "    my_dis=[]\n",
    "    for iii in range(len(padded_seq_list)):\n",
    "        ii=padded_seq_list[iii]\n",
    "        pattern=re.compile(r'(?=(ATG|TTG|CTG|GTG|AAG|ACG|AGG|ATA|ATT|ATC))')\n",
    "        it=re.finditer(pattern,ii)\n",
    "        pos3=[i.span()[0] for i in it][0:(TIS_max_num+3)]\n",
    "        pos2=pos3[0:(TIS_max_num+1)]\n",
    "        pos=pos2[0:TIS_max_num]\n",
    "        if len(pos2)==len(pos):\n",
    "            pos2=pos2+[pos2[len(pos2)-1]+20]\n",
    "        my_seq.append(torch.stack([torch.tensor([dict[j] for j in list(ii[(p-padding_size):(p+padding_size+1)])], dtype=torch.long) for p in pos]))\n",
    "        my_target.append(torch.tensor([1 for j in range(len(pos))]))\n",
    "        my_weight.append(torch.tensor([1]*len(pos)))\n",
    "        pos1=[padding_size]+pos\n",
    "        my_dis.append(torch.stack([torch.tensor([pos1[i+1]-pos1[i] for i in range(len(pos1)-1)]),torch.tensor([pos2[i+1]-pos2[i] for i in range(len(pos2)-1)])],1))\n",
    "    my_dis=[i/sqrt_scale for i in my_dis]\n",
    "    MyvalData = testoneMyDataset(inputset=my_seq, targetset=my_target, weightset=my_weight, disset=my_dis, transcriptset=his)\n",
    "    Myvalloader = torch.utils.data.DataLoader(MyvalData, batch_size=len(MyvalData), shuffle=False, num_workers=0, collate_fn=collate_fn_padd, drop_last=True)\n",
    "    iter0=iter(enumerate(Myvalloader, 0))\n",
    "    iii, batch=next(iter0)\n",
    "    inputs, sizes, labels, weights, diss, transcriptt = batch\n",
    "    o1=Mymodel1(x=inputs, sizes=sizes, diss=diss)\n",
    "    o2=Mymodel2(x=inputs, sizes=sizes, diss=diss)\n",
    "    o3=Mymodel3(x=inputs, sizes=sizes, diss=diss)\n",
    "    o4=Mymodel4(x=inputs, sizes=sizes, diss=diss)\n",
    "    o5=Mymodel5(x=inputs, sizes=sizes, diss=diss)\n",
    "    o6=Mymodel6(x=inputs, sizes=sizes, diss=diss)\n",
    "    o7=Mymodel7(x=inputs, sizes=sizes, diss=diss)\n",
    "    o8=Mymodel8(x=inputs, sizes=sizes, diss=diss)\n",
    "    o9=Mymodel9(x=inputs, sizes=sizes, diss=diss)\n",
    "    o10=Mymodel10(x=inputs, sizes=sizes, diss=diss)\n",
    "    outputs=torch.stack((o1,o2,o3,o4,o5,o6,o7,o8,o9,o10))\n",
    "    del o1,o2,o3,o4,o5,o6,o7,o8,o9,o10\n",
    "    \n",
    "    outputs=torch.mean(outputs/torch.sum(torch.abs(outputs),2,keepdim=True),0,keepdim=False)\n",
    "    max_peak,indices = torch.max(outputs,1,keepdim=False)\n",
    "    outputs=max_peak/outputs[0][indices]\n",
    "    \n",
    "    LNC.append(lnc)\n",
    "    smut.append(np.array(torch.mean(outputs[list(range(1,len(outputs),51))]).cpu()))\n",
    "    dmut.append(np.array(torch.mean(outputs[list(set(range(len(outputs)))-set([0]+list(range(1,len(outputs),51))))]).cpu()))\n",
    "    \n",
    "    max_peak=np.array(max_peak.cpu())\n",
    "    outputs=np.array(outputs.cpu())\n",
    "    HIS[lnc]=[(list(i)[0][0],list(i)[0][1],list(i)[1][0],list(i)[1][1],outputs[i],max_peak[i]) for i in range(len(his))]\n",
    "    #pd.DataFrame([[list(i)[0][0],list(i)[0][1],list(i)[1][0],list(i)[1][1]] for i in his]).to_csv(\"test.txt\",sep=\"\\t\")\n",
    "pd.DataFrame({\"lncRNA\": LNC,\"smut\": smut,\"dmut\": dmut}).to_csv(\"test.txt\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8576ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t='ENST00000354336.8'\n",
    "t_index=[i for i in range(len(transcript_all)) if transcript_all[i]==test_t][0]\n",
    "t_run=int(t_index/(overall_size/10))\n",
    "\n",
    "writer_title='run_'+str(t_run)\n",
    "state = torch.load(save_path + \"\\\\\"+run_header+\"\\\\\"+writer_title+\".pkl\")\n",
    "Mymodel = MyLSTM(dropout=dropout, hidden_dim=hidden_dim, num_layers=num_layers, proj_size=proj_size)\n",
    "Mymodel.to(device)\n",
    "optimizer = optim.SGD(Mymodel.parameters(), lr=lr, momentum=momentum)\n",
    "Mymodel.load_state_dict(state['state_dict'])\n",
    "optimizer.load_state_dict(state['optimizer'])\n",
    "epoch = state['epoch']\n",
    "jj = state['jj']\n",
    "converge_level = state['converge_level']\n",
    "running_loss = state['running_loss']\n",
    "inspect_loss = state['inspect_loss']\n",
    "loss_ratio = state['loss_ratio']\n",
    "sigma_index = state['sigma_index']\n",
    "val_min_loss = state['val_min_loss']\n",
    "print(save_path + \"\\\\\"+run_header+\"\\\\\"+writer_title+\".pkl loaded.\")\n",
    "\n",
    "print(t_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shit=mindex[0]\n",
    "pred_index=[i for i in range(len(transcript_all)) if transcript_all[i]==test_t][0]\n",
    "valseq=seq_all[pred_index]\n",
    "valtranscript=transcript_all[pred_index]\n",
    "print(valtranscript)\n",
    "print(valseq.shape)\n",
    "MyvalData = testoneMyDataset(inputset=[seq_all[pred_index]], targetset=[target_all[pred_index]], weightset=[weight_all[pred_index]], disset=[dis_all[pred_index]], transcriptset=[transcript_all[pred_index]])\n",
    "Myvalloader = torch.utils.data.DataLoader(MyvalData, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn_padd, drop_last=True)\n",
    "print(len(MyvalData))\n",
    "with torch.no_grad():\n",
    "    iter0=iter(enumerate(Myvalloader, 0))\n",
    "    iii, batch=next(iter0)\n",
    "    inputs, sizes, labels, weights, diss, transcriptt = batch\n",
    "    outputs = Mymodel(x=inputs, sizes=sizes, diss=diss)\n",
    "    loss = criterion(outputs, labels, weights, torch.sum(sizes), loss_ratio)\n",
    "    print(transcriptt)\n",
    "    print(loss)\n",
    "    print(labels)\n",
    "    print(outputs)\n",
    "    print(weights[0])\n",
    "    print(diss)\n",
    "\n",
    "inspect_index([i for i in range(len(transcripts)) if transcripts[i]==valtranscript][0])\n",
    "np.savetxt('final_true_vs_predicts\\\\inspect_output.txt',np.array(outputs.cpu().flatten(0)),header=valtranscript)\n",
    "pos=[i[1] for i in find_TIS(valtranscript)]\n",
    "np.savetxt('final_true_vs_predicts\\\\inspect_pos.txt',np.array(pos),header=valtranscript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ea7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存状态\n",
    "state = {\n",
    "    'epoch': epoch,\n",
    "    'jj': jj,\n",
    "    'converge_level': converge_level,\n",
    "    'running_loss': running_loss,\n",
    "    'inspect_loss': inspect_loss,\n",
    "    'state_dict': Mymodel.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'j': j,\n",
    "    'loss_ratio': loss_ratio,\n",
    "    'sigma_index': sigma_index,\n",
    "    'val_min_loss': val_min_loss\n",
    "}\n",
    "os.makedirs(save_path + \"\\\\\"+run_header, exist_ok=True)\n",
    "torch.save(state, save_path + \"\\\\\"+run_header+\"\\\\\"+writer_title+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26438cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c500a91c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
